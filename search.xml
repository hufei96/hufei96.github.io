<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"/>
      <url>/2023/01/22/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h1><p>方案均以粗糙的 Python 玩具代码为例</p><h2 id="方案-1（Accept-Read-x2F-Write）"><a href="#方案-1（Accept-Read-x2F-Write）" class="headerlink" title="方案 1（Accept + Read&#x2F;Write）"></a>方案 1（Accept + Read&#x2F;Write）</h2><pre><code class="python">import socketdef handle(client_socket, client_address):    // L6    while True:        data = client_socket.recv(4096)        if data:            sent = client_socket.send(data)    # sendall?        else:            print &quot;disconnect&quot;, client_address            client_socket.close()            // L13            breakif __name__ == &quot;__main__&quot;:    listen_address = (&quot;0.0.0.0&quot;, 2007)    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)    server_socket.bind(listen_address)    server_socket.listen(5)    // L21    while True:        (client_socket, client_address) = server_socket.accept()        print &quot;got connection from&quot;, client_address        // L24        handle(client_socket, client_address)</code></pre><p>这个方案实际上不是一个并发服务器，它是迭代的。</p><p><code>L6 ~ L13</code> 是这个服务的业务逻辑循环，<code>L21 ~ L24</code> 决定了它每次只能处理一个请求，当前请求未处理完前，无法接受下一个请求。</p><p><strong>缺点</strong>：每次只能处理一个请求，当前请求未处理完前，无法接受下一个请求。</p><h2 id="方案-2（Accept-Fork）"><a href="#方案-2（Accept-Fork）" class="headerlink" title="方案 2（Accept + Fork）"></a>方案 2（Accept + Fork）</h2><pre><code class="python">from SocketServer import BaseRequestHandler, TCPServerfrom SocketServer import ForkingTCPServer, ThreadingTCPServerclass EchoHandler(BaseRequestHandler):    def handle(self):        print &quot;got connection from&quot;, self.client_address        // L9        while True:            data = self.request.recv(4096)            if data:                sent = self.request.send(data)    # sendall?            else:                print &quot;disconnect&quot;, self.client_address                self.request.close()                // L16                breakif __name__ == &quot;__main__&quot;:    listen_address = (&quot;0.0.0.0&quot;, 2007)    server = ForkingTCPServer(listen_address, EchoHandler)    server.serve_forever()</code></pre><p><code>L9 ~ L16</code> 依旧是业务逻辑代码，但是此时每个客户连接，都会 <code>fork</code> 一个子进程去处理。</p><p>在这个方案中，业务逻辑已经初步从网络框架中分离出来，但是仍然和 IO 紧密结合。</p><p><strong>缺点</strong>：每个connect都需要fork一个子进程处理，性能差，无法处理过多的并发连接。</p><p>这种方案适合“计算响应的工作量远大于fork()的开销”这种情况， 比如数据库服务器。 这种方案适合长连接， 但不太适合短连接  </p><h2 id="方案-3（Accept-Thread）"><a href="#方案-3（Accept-Thread）" class="headerlink" title="方案 3（Accept + Thread）"></a>方案 3（Accept + Thread）</h2><pre><code class="python">// diff echo-fork.py echo-thread.pyif __name__ == &quot;__main__&quot;:    listen_address = (&quot;0.0.0.0&quot;, 2007)    - server = ForkingTCPServer(listen_address, EchoHandler)    + server = ThreadingTCPServer(listen_address, EchoHandler)    server.serve_forever()</code></pre><p>相比于方案 2，就是把进程改为了线程。进程和线程有什么区别呢？对于 Linux Kernel 而言，没有区别，所以 Too Many Process 和 Too Many Thread 是一样的，线程创建、销毁和调度带来的代价。除此之外，线程之间共享数据，额外产生的 cache locality 的问题。</p><p>所以这个方案跟方案2优缺点一样，仍然不适合短连接。</p><h2 id="方案-4-x2F-5（Process-x2F-Thread-Pool）"><a href="#方案-4-x2F-5（Process-x2F-Thread-Pool）" class="headerlink" title="方案 4&#x2F;5（Process&#x2F;Thread Pool）"></a>方案 4&#x2F;5（Process&#x2F;Thread Pool）</h2><p>这是对方案2和3的优化，为了避免过多进程&#x2F;线程带来的负担，提前创建好进程&#x2F;线程池。详细分析描述见 UNP，再次不过多赘述。方<br>案4和方案5这两个方案都是Apache httpd长期使用的方案  </p><p>额外说下<code>惊群问题</code>：传统意义上的惊群问题是指多进程&#x2F;线程同时阻塞在 Accept 上，这时一个连接到来，内核将所有阻塞在 Accept 上的进程&#x2F;线程全部唤醒，但是只有一个进程&#x2F;线程可以拿到新连接，其他的进程&#x2F;线程等于是白唤醒了，白产生了线程切换调度的代价。</p><ul><li>现在的 Linux 内核，已经不会发生传统的 Accept 惊群。内核只会唤醒一个阻塞住的进程&#x2F;线程。</li><li>但是使用 Epoll 处理非阻塞 Accept，依旧有可能发生惊群。原因是 Epoll 通知某个进程&#x2F;线程处理 Accept 事件后，会继续通知其他进程&#x2F;线程，直到全部唤醒或某个进程已将该事件处理完毕。</li><li>Nginx 如何处理惊群：<code>accept_mutex</code>，抢到锁的进程才会把 Accept 事件添加到监听事件中，同时加入其他算法减少同时竞争锁的情况。</li></ul><h2 id="中场总结"><a href="#中场总结" class="headerlink" title="中场总结"></a>中场总结</h2><p>以上几种方案都是阻塞式网络编程， 程序流程（thread of control）通常阻塞在read()上， 等待数据到达。 但是TCP是个全双工协议， 同时支持read()和write()操作， 当一个线程／ 进程阻塞在read()上， 但程序又想给这个TCP连接发数据， 那该怎么办？ 比如说echo client， 既要从stdin读， 又要从网络读， 当程序正在阻塞地读网络的时候， 如何处理键盘输入？</p><p>又比如proxy， 既要把连接a收到的数据发给连接b， 又要把从b收到的数据发给a， 那么到底读哪个？一种方法是用两个线程／ 进程， 一个负责读， 一个负责写。 [UNP]也在实现echo client时介绍了这种方案。 </p><p>另一种方法是使用IO multiplexing， 也就是select&#x2F;poll&#x2F;epoll&#x2F;kqueue这一系列的“多路选择器”， 让一个thread of control能处理多个连接。 “IO复用”其实复用的不是IO连接， 而是复用线程。 使用select&#x2F;poll几乎肯定要配合non-blocking IO， 而使用non-blocking IO肯定要使用应用层buffer。</p><p>网络编程需要解决每个socket什么时候可读，可以读多少的问题。当socket不可读时去读就会被阻塞，可读但读少了会导致接收信息不完全。</p><p>方案1没有解决这两个问题，它同一时间只能处理一个连接，没数据可读时会被阻塞住，直到客户端断开连接read返回0之后才能去处理下一个连接。</p><p>方案2和3通过给每一个连接分配一个线程&#x2F;进程解决了这两个问题，不知道socket什么时候可读没关系，我给你每个socket都分配一个线程&#x2F;进程，不处理完不返回，这样每个连接都能同时得到处理了。但这又出现了新的问题：内核管理线程&#x2F;进程是需要资源的，一般保持在几十个线程&#x2F;进程，而并发连接数则可能过万，系统无法支持这么大的资源消耗。</p><p>方案4和5通过建立线程&#x2F;进程池的方式解决了方案2和3中新出的问题，但每个socket什么时候可读，可以读多少的问题又出现了。本质上方案4&#x2F;5和方案1没有差别，只是可以同时处理的连接从一个扩大到了几十个，当线程池中的线程全部被阻塞住了之后就会跟方案1一样，无法处理其他的连接，直到某个连接断开线程返回。</p><p><strong>根本解决方法：</strong>IO多路复用和非阻塞IO</p><p>所谓的 IO 多路复用，复用的是什么呢？复用的线程。通过诸如 <code>select</code>、<code>poll</code>、<code>epoll</code> 这种技术使得一个线程可以监听多个连接上的读、写事件。非阻塞IO则是指read&#x2F;write时不会因为不可读&#x2F;不可写就被阻塞住，不管什么情况都会立刻返回。</p><p>IO多路复用解决了每个socket什么时候可读的问题，用select&#x2F;epoll同时管理多个socket，可读时触发中断(内核负责)，只返回可读&#x2F;可写的socket。</p><p>非阻塞IO解决了每个socket可以读多少的问题，当socket不可读时read并不会被阻塞，这样我们可以一直循环读直到读空缓冲区。</p><p>如果只有非阻塞IO没有IO多路复用的话，我们没有很好的探查每个socket是否可读的手段，必须对每个socket调用非阻塞read进行轮询，效率十分低下。</p><p>只有IO多路复用而没有非阻塞IO为什么也不行呢，返回可读的时候直接读就行，不需要考虑是否会阻塞。这个原因之后会说。</p><p><strong>为什么不聊异步 IO？</strong></p><ul><li>Linux 异步 IO 并不完善。POSIX AIO 是使用线程池调用阻塞 IO 模拟的；Kernel AIO 并不是为 socket 设计的。</li><li>异步 IO 不见得性能要好（总归要做这些工作，将这些事分配给其他线程或者内核去做并没有影响工作的总量）。</li></ul><h3 id="Epoll"><a href="#Epoll" class="headerlink" title="Epoll"></a>Epoll</h3><h4 id="Epoll实现"><a href="#Epoll实现" class="headerlink" title="Epoll实现"></a>Epoll实现</h4><p>Epoll 的实现原理非常简洁：</p><ul><li><code>epoll_create</code> 会在内核空间初始化一个红黑树和一个链表；</li><li><code>epoll_ctl</code> 会将对应的 <code>socket</code> 插入到红黑树中，同时设置目标文件的事件回调函数；</li><li><code>epoll_wait</code> 会观察链表是否非空，如果非空则返回给用户；如果空，则阻塞等待，当某个 <code>fd</code> 上的事件来了，会调用事件回调函数，将对应的 <code>fd</code> 结构加到链表中，并唤醒等待在 <code>epoll_wait</code> 的线程。</li></ul><p>额外的一些知识：</p><ul><li><code>epoll</code> 的 <code>LT</code> 和 <code>ET</code> 的实现非常清晰，每当 <code>epoll_wait</code> 将链表中的 <code>fdlist</code> 返回给用户态后，将会清空这个链表，不过对于设置为 <code>LT</code> 的 <code>fd</code>，将会重新加到这个链表中。</li><li><code>epoll_wait</code> 返回链表上的 <code>fd</code> 时，会再次判断该 <code>fd</code> 的事件状态，如果无效，则不会返回，也不会再次加入到链表中。</li></ul><p>由此，最后一个核心问题：<code>epoll_wait</code> 会陷入睡眠，等待唤醒，毫无疑问这个操作是事件回调函数来做的，那么，回调函数又是什么机制呢？</p><p>这就是协议栈和硬件协助完成的：</p><ol><li>当网卡数据到来后，会通过总线向CPU发送硬件中断。</li><li>内核获取操作权，执行中断处理逻辑。</li><li>中断处理逻辑会确定 <code>socket</code> 的相关信息，并调用 <code>epoll</code> 注册的回调函数。</li></ol><h4 id="ET-x2F-LT"><a href="#ET-x2F-LT" class="headerlink" title="ET&#x2F;LT"></a>ET&#x2F;LT</h4><p>epoll 支持两种事件触发模式，分别是<strong>边缘触发（edge-triggered，ET和水平触发（level-triggered，LT）</strong>。</p><p>这两个术语还挺抽象的，其实它们的区别还是很好理解的。</p><ul><li>使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，<strong>服务器端只会从 epoll_wait 中苏醒一次</strong>，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；</li><li>使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，<strong>服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束</strong>，目的是告诉我们有数据需要读取；</li></ul><p>举个例子，你的快递被放到了一个快递箱里，如果快递箱只会通过短信通知你一次，即使你一直没有去取，它也不会再发送第二条短信提醒你，这个方式就是边缘触发；如果快递箱发现你的快递没有被取出，它就会不停地发短信通知你，直到你取出了快递，它才消停，这个就是水平触发的方式。</p><p>一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。</p><p>select&#x2F;poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。</p><p><strong>Epoll必须使用非阻塞IO的原因</strong></p><p><strong>ET</strong></p><p>如果使用边缘触发模式，I&#x2F;O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会<strong>循环</strong>从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，<strong>边缘触发模式一般和非阻塞 I&#x2F;O 搭配使用</strong>，程序会一直执行 I&#x2F;O 操作，直到系统调用（如 <code>read</code> 和 <code>write</code>）返回错误，错误类型为 <code>EAGAIN</code> 或 <code>EWOULDBLOCK</code>。</p><p><strong>LT</strong></p><p>LT 模式看起来没这个问题，反正没读完会一直提示，看起来使用阻塞IO也没有问题。但是因为某些原因，LT 研究需要使用 <code>Non-Blocking IO</code>。</p><p>关于原因，网上很多人举例子会说：假设 socket 缓冲区只有 100 byte，但是 read 试图读 200 byte，这时会阻塞，其实这时错误的。</p><p>经过实际实验，阻塞 <code>read</code> 和 <code>write</code> 的语义如下：</p><p><strong>read</strong> :</p><ul><li>如果缓冲区有数据，read 将会将缓冲区中的所有数据（或者等于指定读的数目）返回，返回值可以小于 read 中的大小参数。</li><li>如果缓冲区没有数据，read 将会阻塞，直到缓冲区来了数据，此时全部读出，立即返回。</li></ul><p><strong>write</strong> :</p><ul><li><strong>write 会一直阻塞到指定大小的数据全部写入缓冲区为止</strong>。也就是说，如果缓冲区可写 100 byte，试图 write 200byte，则 write 调用会阻塞到 200 byte 全部写入缓冲区为止。</li></ul><p>所以，LT 模式依旧要用 <code>Non-Blocking IO</code> 的原因为：</p><ol><li>对于 <code>write</code> 而言，如果指定 <code>write</code> 的数据大小大于写缓冲区的大小，将阻塞至写完为止。</li><li>对于 <code>read</code> 而言，<code>epoll</code> 返回 <code>EPOLLIN</code>，不代表一定可写，见 man select。</li></ol><h3 id="为什么non-blocking网络编程中应用层buffer是必需的"><a href="#为什么non-blocking网络编程中应用层buffer是必需的" class="headerlink" title="为什么non-blocking网络编程中应用层buffer是必需的"></a>为什么non-blocking网络编程中应用层buffer是必需的</h3><p>non-blocking IO的核心思想是避免阻塞在read()或write()或其他IO系统调用上， 这样可以最大限度地复用thread-of-control， 让一个线程能服务于多个socket连接。 IO线程只能阻塞在IO multiplexing函数上， 如select&#x2F;poll&#x2F;epoll_wait。 这样一来， 应用层的缓冲是必需的， 每个TCPsocket都要有stateful的input buffer和output buffer。</p><p><strong>TcpConnection必须要有output buffer</strong></p><p>考虑一个常见场景： 程序想通过TCP连接发送100kB的数据， 但是在write()调用中， 操作系统只接受了80kB（受TCP advertised window的控制）， 你肯定不想在原地等待， 因为不知道会等多久（取决于对方什么时候接收数据， 然后滑动TCP窗口） 。 程序应该尽快交出控制权， 返回event loop。 在这种情况下， 剩余的20kB数据怎么办？</p><p>对于应用程序而言， 它只管生成数据， 它不应该关心到底数据是一次性发送还是分成几次发送， 这些应该由网络库来操心， 程序只要调用TcpConnection::send()就行了， 网络库会负责到底。 网络库应该接管这剩余的20kB数据， 把它保存在该TCP connection的output buffer里， 然后注册POLLOUT事件， 一旦socket变得可写就立刻发送数据。 当然， 这第二次write()也不一定能完全写入20kB， 如果还有剩余， 网络库应该继续关注POLLOUT事件； 如果写完了20kB， 网络库应该停止关注POLLOUT， 以免造成busy loop。 （muduo EventLoop采用的是epoll leveltrigger， 原因见下方。 ）</p><p>如果程序又写入了50kB， 而这时候output buffer里还有待发送的20kB数据， 那么网络库不应该直接调用write()， 而应该把这50kB数据<br>append在那20kB数据之后， 等socket变得可写的时候再一并写入。如果output buffer里还有待发送的数据， 而程序又想关闭连接（对<br>程序而言， 调用TcpConnection::send()之后他就认为数据迟早会发出去） ， 那么这时候网络库不能立刻关闭连接， 而要等数据发送完毕， 见此处“为什么TcpConnection:: shutdown()没有直接关闭TCP连接”中的讲解。</p><p>综上， 要让程序在write操作上不阻塞， 网络库必须要给每个TCPconnection配置output buffer。</p><p><strong>TcpConnection必须要有input buffer</strong></p><p>TCP是一个无边界的字节流协议， 接收方必须要处理“收到的数据尚不构成一条完整的消息”和“一次收到两条消息的数据”等情况。 一个常见的场景是， 发送方send()了两条1kB的消息（共2kB） ， 接收方收到数据的情况可能是：</p><ul><li>一次性收到2kB数据；</li><li>分两次收到， 第一次600B， 第二次1400B；</li><li>分两次收到， 第一次1400B， 第二次600B；</li><li>分两次收到， 第一次1kB， 第二次1kB；</li><li>分三次收到， 第一次600B， 第二次800B， 第三次600B；</li><li>其他任何可能。 一般而言， 长度为n字节的消息分块到达的可能性有2n-1种。</li></ul><p>网络库在处理“socket可读”事件的时候， 必须一次性把socket里的数据读完（从操作系统buffer搬到应用层buffer） ， 否则会反复触发<br>POLLIN事件， 造成busy-loop。 那么网络库必然要应对“数据不完整”的情况， 收到的数据先放到input buffer里， 等构成一条完整的消息再通知程序的业务逻辑。 这通常是codec的职责， 见§7.3“Boost.Asio的聊天服务器”中的“TCP分包”的论述与代码。 所以， 在TCP网络编程中， 网络库必须要给每个TCP connection配置input buffer。</p><p><strong>muduo EventLoop采用的是epoll(4) level trigger</strong>， 而不是edge trigger。 </p><ul><li>一是为了与传统的poll(2)兼容， 因为在文件描述符数目较少，活动文件描述符比例较高时， epoll(4)不见得比poll(2)更高效， 必要时可以在进程启动时切换Poller。 </li><li>二是level trigger编程更容易， 以往select(2)&#x2F;poll(2)的经验都可以继续用， 不可能发生漏掉事件的bug。</li><li>三是读写的时候不必等候出现EAGAIN， 可以节省系统调用次数， 降低延迟。</li></ul><p>所有muduo中的IO都是带缓冲的IO（buffered IO） ， 你不会自己去read()或write()某个socket， 只会操作TcpConnection的input buffer和output buffer。 更确切地说， 是在onMessage()回调里读取input buffer； 调用TcpConnection::send()来间接操作output buffer， 一般不会直接操作outputbuffer。</p><p>对于网络程序来说， 一个简单的验收测试是： 输入数据每次收到一个字节（200字节的输入数据会分200次收到， 每次间隔10ms） ， 程序的功能不受影响。 对于muduo程序， 通常可以用codec来分离“消息接收”与“消息处理”， 见§7.6“在muduo中实现Protobuf编解码器与消息分发器”对“编解码器codec”的介绍。</p><p>如果某个网络库只提供相当于char buf[8192]的缓冲， 或者根本不提供缓冲区， 而仅仅通知程序“某socket可读／ 某socket可写”， 要程序自己操心IO buffering， 这样的网络库用起来就很不方便了。  </p><h2 id="方案-6（Reactor）"><a href="#方案-6（Reactor）" class="headerlink" title="方案 6（Reactor）"></a>方案 6（Reactor）</h2><pre><code class="python">import socketimport selectserver_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)server_socket.bind((&#39;&#39;, 2007))server_socket.listen(5)# serversocket.setblocking(0)poll = select.poll() # epoll() should work the sameconnections = &#123;&#125;handlers = &#123;&#125;def handle_input(socket, data):    socket.send(data) # sendall() partial?def handle_request(fileno, event):    if event &amp; select.POLLIN:        client_socket = connections[fileno]        data = client_socket.recv(4096)        if data:            handle_input(client_socket, data)        else:            poll.unregister(fileno)            client_socket.close()            del connections[fileno]            del handlers[fileno]def handle_accept(fileno, event):    (client_socket, client_address) = server_socket.accept()    print &quot;got connection from&quot;, client_address    # client_socket.setblocking(0)    poll.register(client_socket.fileno(), select.POLLIN)    connections[client_socket.fileno()] = client_socket    handlers[client_socket.fileno()] = handle_requestpoll.register(server_socket.fileno(), select.POLLIN)handlers[server_socket.fileno()] = handle_accept// L42while True:    events = poll.poll(10000)  # 10 seconds    for fileno, event in events:        handler = handlers[fileno]        // L46        handler(fileno, event)</code></pre><p>注意以上代码不是功能完善的IO multiplexing范本， 它没有考虑错误处理， 也没有实现定时功能， 而且只适合侦听（listen） 一个端口的网络服务程序。 如果需要侦听多个端口， 或者要同时扮演客户端， 那么代码的结构需要推倒重来。这个代码骨架可用于实现多种TCP服务器。  </p><p>传统网络编程把业务逻辑隐藏在一个大循环中的做法其实不利于将来功能的扩展， 我们能不能设法把业务逻辑抽取出来， 与网络基础代码分离呢 。</p><p>这是最基本的单线程 Reactor 方案，所谓 Reactor，是 Douglas C. Schmidt （ACE作者）提出的概念。Doug Schmidt指出， 其实网络编程中有很多是事务性（routine） 的工作， 可以提取为公用的框架或库， 而用户只需要填上关键的业务逻辑代码， 并将回调注册到框架中， 就可以实现完整的网络服务， 这正是Reactor模式的主要思想。 <strong>Reactor的意义在于将消息（IO事件） 分发到用户提供的处理函数， 并保持网络部分的通用代码不变， 独立于用户的业务逻辑。</strong>  </p><p>Reactor 模式就是事件驱动模型。一般由一个 <code>event dispatcher</code>（上文提到的 IO Multiplexing）等待各类事件(等待socket可读可写)，事件发生后原地调用对应的 <code>event handler</code>(读写socket)，handler处理完成返回后继续循环等待事件，这个循环过程也称为 <code>event loop</code>。Reactor事件循环所在的线程通常叫IO线程。 通常由网络库负责读写socket， 用户代码负载解码、 计算、 编码。  </p><p>上面例子中的 <code>L42 ~ L46</code> 就是 <code>event loop</code>，事件发生后，交由 <code>handle_xxx</code> 处理，这样子，网络框架就实现了业务逻辑和事件的分离。对于单线程 Reactor，戈君评价如下：</p><p><img src="https://sleepy-1256633542.cos.ap-beijing.myqcloud.com/20181222103157.png" alt="img"></p><p>图中指出，一个 event loop 对应于一个线程，但是 handle callback 往往是交由业务实现，如果业务回调运行时间很长，则性能非常不可控，因为阻塞在运行 callback 时会导致其他就绪事件无法分发。适合IO密集的应用， 不太适合CPU密集的应用， 因为较难发挥多核的威力。   </p><p>Redis 就是这种模型。标准的 IO-Bound 服务，瓶颈几乎一定在网络 IO 上，单线程的 Reactor 就会有很好的性能。</p><h2 id="方案-7-x2F-8（Reactor-thread-per-task-x2F-work-thread"><a href="#方案-7-x2F-8（Reactor-thread-per-task-x2F-work-thread" class="headerlink" title="方案 7&#x2F;8（Reactor + thread per task&#x2F; work thread)"></a>方案 7&#x2F;8（Reactor + thread per task&#x2F; work thread)</h2><p>方案 7、8都是试图解决单线程 Reactor 问题的过渡方案。</p><p>方案 7 是指不在 Reactor 线程中进行计算任务，而是每个请求到来，创建一个新的线程去计算， 以充分利用多核CPU。 这是非常<br>初级的多线程应用， 因为它为每个请求（而不是每个连接） 创建了一个新线程。 这个开销可以用线程池来避免， 即方案9。   </p><p>方案 8 是指每个连接到来创建一个计算线程，该连接上的所有请求都由这个线程计算。</p><p>方案 7 除性能问题外，额外问题是 out-of-order，即同时创建多个线程去计算同一个连接上收到的多个请求，那么算出结果的次序是不确定的，即同一个连接上结果出现的顺序是不确定的，不能保证先到达的请求先返回。所以要使用id， 以便客户端区分response对应的是哪个request。  </p><p>为了让返回结果顺序确定，方案8为每个连接创建一个计算线程，每个连接上的请求发给同一个计算线程去算。但是并发连接数受限于线程数目。</p><p>方案8与方案7的另外一个区别是单个client的最大CPU占用率。 在方案7中， 一个TCP连接上发来的一长串突发请求（burst requests） 可以占满全部8个core； 而在方案8中， 由于每个连接上的请求固定由同一个线程处理， 那么它最多占用12.5％的CPU资源。 <strong>这两种方案各有优劣， 取决于应用场景的需要（到底是公平性重要还是突发性能重要）</strong>。 这个区别在方案9和方案10中同样存在， 需要根据应用来取舍。  </p><p>想都不用想，这两种方案又回到了一个连接一个线程，性能还不如方案 3。</p><h2 id="方案-9（Reactor-thread-pool）"><a href="#方案-9（Reactor-thread-pool）" class="headerlink" title="方案 9（Reactor + thread pool）"></a>方案 9（Reactor + thread pool）</h2><p>方案 9 是解决方案 7、8 为每个请求&#x2F;连接创建线程的缺陷，可以使用固定大小的线程池。网络 IO 交由 Reactor 线程处理，计算任务则交给 thread pool 处理。线程池的另一个作用是执行阻塞操作，如数据库查询操作。如果计算任务彼此独立， 而且IO的压力不大， 那么这种方案是非常适用的。   </p><p><img src="https://sleepy-1256633542.cos.ap-beijing.myqcloud.com/20181222102937.png" alt="img"></p><p>看上去挺美好，实际上也确实不错，在 IO 压力不大，计算任务存在阻塞（数据库请求、写文件等）非常适合这种方案。</p><p>不过来看下戈君的评价：</p><p><img src="https://sleepy-1256633542.cos.ap-beijing.myqcloud.com/20181222102957.png" alt="img"></p><p>嗯。。。一针见血：</p><ul><li>分发请求给线程池的过程是 <code>Highly contended</code>，高并发的场景下，会严重影响性能。</li><li>IO 由 Reactor 线程管理，计算却交由其他线程，导致读写数据和处理数据不在同一个线程内，这种多线程情况下产生的 <code>cache bouncing</code> 代价不可忽视。</li><li>所有的 <code>epoll_ctl</code> 操作都作用在同一个红黑树上，对于短连接而言，会带来大量的 O(logn) 的添加、删除操作，并不是那么的快。</li></ul><p>如果 IO 压力较大，一个 Reactor 处理不过来，就引入了方案 10和11.</p><h2 id="方案-10-x2F-11（Reactors-in-threads-x2F-processes）"><a href="#方案-10-x2F-11（Reactors-in-threads-x2F-processes）" class="headerlink" title="方案 10&#x2F;11（Reactors in threads&#x2F;processes）"></a>方案 10&#x2F;11（Reactors in threads&#x2F;processes）</h2><p><img src="https://sleepy-1256633542.cos.ap-beijing.myqcloud.com/20181222103019.png" alt="img"></p><p>方案 10 是 muduo 内置的多线程方案。方案特点是 one loop per thread，由一个 main Reactor 来负责 accept 事件，然后把连接转交给某个 sub Reactor 中，这样该连接的所有操作都在 sub Reactor 中处理。</p><p>非常不错的多线程&#x2F;进程方案。 one loop per thread + 等同于 CPU 核数的 IO Thread。</p><p>其中，一个 Main Thread 负责 Accept，剩下的 event loop 负责接收 Accept 到的连接，且原地处理接下来的 IO 及计算任务。与方案9的线程池相比， 方案10减少了进出thread pool的两次上下文切换， 在把多个连接分散到多个Reactor线程之后， 小规模计算可以在当<br>前IO线程完成并发回结果， 从而降低响应的延迟。 </p><p>方案 11（多进程 + 每个进程一个 Reactor）是 Nginx 的内置方案。连接之间无交互，工作进程之间相互独立。如果连接之间无交互，这是非常好的选择。可以热升级。</p><h2 id="方案-12-Reactors-thread-pool）"><a href="#方案-12-Reactors-thread-pool）" class="headerlink" title="方案 12 (Reactors + thread pool）"></a>方案 12 (Reactors + thread pool）</h2><p>方案 12 是方案 9 和 方案 10 的混合，使用多个 Reactor 来处理 IO 的同时，可以使用线程池来处理计算，能够适用于大部分的场景，因为 thread pool 的数目应当是可调控的，当设为 0 时，就退化为方案 10.</p><p><img src="https://sleepy-1256633542.cos.ap-beijing.myqcloud.com/20181222103040.png" alt="img"></p><h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><h3 id="Muduo"><a href="#Muduo" class="headerlink" title="Muduo"></a>Muduo</h3><p>上面的方案就是从中总结的，Muduo 实现了方案 10 和方案 12.</p><h3 id="Netty"><a href="#Netty" class="headerlink" title="Netty"></a>Netty</h3><p>方案10</p><h3 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h3><p>方案11</p><h3 id="UB-XPOOL"><a href="#UB-XPOOL" class="headerlink" title="UB - XPOOL"></a>UB - XPOOL</h3><p>以线程代替进程的方案 11</p><h3 id="UB-EPPOOL"><a href="#UB-EPPOOL" class="headerlink" title="UB - EPPOOL"></a>UB - EPPOOL</h3><p>方案 9</p><h3 id="UB-SXPOOL"><a href="#UB-SXPOOL" class="headerlink" title="UB - SXPOOL"></a>UB - SXPOOL</h3><p>方案 12</p><h3 id="Golang-amp-amp-brpc"><a href="#Golang-amp-amp-brpc" class="headerlink" title="Golang &amp;&amp; brpc"></a>Golang &amp;&amp; brpc</h3><p>golang 的 <code>goroutine</code> 和 brpc 的 <code>bthread</code> 都是 M:N 的用户态线程库。brpc 暂且不提（只看了 bthread 的部分，还没看网络框架的部分），golang 是将 <code>read</code> 和 <code>write</code> 进行了 hook，给应用层以同步阻塞调用的假象。实际上底层依旧是由 <code>epoll</code> 来完成 <code>IO Multiplexing</code> 的工作。</p><p><img src="https://sleepy-1256633542.cos.ap-beijing.myqcloud.com/20181222103102.png" alt="img"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>一个程序到底是使用一个event loop还是使用多个event loops呢？ZeroMQ的手册给出的建议是， <strong>按照每千兆比特每秒的吞吐量配一个</strong><br><strong>event loop的比例来设置event loop的数目</strong>， 即muduo::TcpServer::setThreadNum()的参数。</p><p>依据这条经验规则， 在编写运行于千兆以太网上的网络程序时， 用一个event loop就足以应付网络IO。<strong>如果程序本身没有多少计算量， 而主要瓶颈在网络带宽， 那么可以按这条规则来办， 只用一个event loop。 另一方面， 如果程序的IO带宽较小， 计算量较大， 而且对延迟不敏感， 那么可以把计算放到threadpool中， 也可以只用一个event loop。</strong></p><p>值得指出的是， 以上假定了TCP连接是同质的， 没有优先级之分，我们看重的是服务程序的总吞吐量。 但是如果TCP连接有优先级之分，那么单个event loop可能不适合， 正确的做法是把高优先级的连接用单独的event loop来处理。</p><p>在muduo中， 属于同一个event loop的连接之间没有事件优先级的差别。 我这么设计的原因是为了防止优先级反转。 比方说一个服务程序有10个心跳连接， 有10个数据请求连接， 都归属同一个event loop， 我们认为心跳连接有较高的优先级， 心跳连接上的事件应该优先处理。 但是由于事件循环的特性， 如果数据请求连接上的数据先于心跳连接到达（早到1ms） ， 那么这个event loop就会调用相应的event handler去处理数据请求， 而在下一次epoll_wait()的时候再来处理心跳事件。 <strong>因此在同一个event loop中区分连接的优先级并不能达到预想的效果。 我们应该用单独的event loop来管理心跳连接</strong>， 这样就能避免数据连接上的事件阻塞了心跳事件， 因为它们分属不同的线程。  </p><p>我再用银行柜台办理业务为比喻， 简述各种模型的特点。 银行有旋转门， 办理业务的客户人员从旋转门进出（IO） ； 银行也有柜台， 客户在柜台办理业务（计算） 。 要想办理业务， 客户要先通过旋转门进入银行； 办理完之后， 客户要再次通过旋转门离开银行。 一个客户可以办理多次业务， 每次都必须从旋转门进出（TCP长连接） 。 另外， 旋转门一次只允许一个客户通过（无论进出） ， 因为read()&#x2F;write()只能同时调用其中一个。</p><p>方案6： 这间小银行有一个旋转门、 一个柜台， 每次只允许一名客户办理业务。 而且当有人在办理业务时， 旋转门是锁住的（计算和IO在同一线程） 。 为了维持工作效率， 银行要求客户应该尽快办理业务， 最好不要在取款的时候打电话去问家里人密码， 也不要在通过旋转门的时候停下来系鞋带， 这都会阻塞其他堵在门外的客户。 如果客户很少， 这是很经济且高效的方案； 但是如果场地较大（多核） ， 则这种布局就浪费了不少资源， 只能并发（concurrent） 不能并行（parallel） 。 如果确实一次办不完， 应该离开柜台， 到门外等着， 等银行通知再来继续办理（分阶段回调）。</p><p>方案9： 这间银行有一个旋转门， 一个或多个柜台。 银行进门之后有一个队列， 客户在这里排队到柜台（线程池） 办理业务。 即在单线程Reactor后面接了一个线程池用于计算， 可以利用多核。 旋转门基本是不锁的， 随时都可以进出。 但是排队会消耗一点时间， 相比之下， 方案6中客户一进门就能立刻办理业务。 另外一种做法是线程池里的每个线程有自己的任务队列， 而不是整个线程池共用一个任务队列。 这样的好处是避免全局队列的锁争用， 坏处是计算资源有可能分配不平均， 降低并行度。</p><p>方案10： 这间大银行相当于包含方案6中的多家小银行， 每个客户进大门的时候就被固定分配到某一间小银行中， 他的业务只能由这间小银行办理， 他每次都要进出小银行的旋转门。 但总体来看， 大银行可以同时服务多个客户。 这时同样要求办理业务时不能空等（阻塞） ， 否则会影响分到同一间小银行的其他客户。 而且必要的时候可以为VIP客户单独开一间或几间小银行， 优先办理VIP业务。 这跟方案6不同， 当普通客户在办理业务的时候， VIP客户也只能在门外等着（见图6-11的右图） 。 这是一种适应性很强的方案， 也是muduo原生的多线程IO模型。</p><p>方案12： 这间大银行有多个旋转门， 多个柜台。 旋转门和柜台之间没有一一对应关系， 客户进大门的时候就被固定分配到某一旋转门中<br>（奇怪的安排， 易于实现线程安全的IO， 见§4.6） ， 进入旋转门之后，有一个队列， 客户在此排队到柜台办理业务。 这种方案的资源利用率可能比方案10更高， 一个客户不会被同一小银行的其他客户阻塞， 但延迟也比方案10略大。  </p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E7%BD%91%E7%BB%9Cio%E6%A8%A1%E5%9E%8B/"/>
      <url>/2023/01/22/%E7%BD%91%E7%BB%9Cio%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="网络io模型"><a href="#网络io模型" class="headerlink" title="网络io模型"></a>网络io模型</h2><h1 id="网络-IO-概念准备"><a href="#网络-IO-概念准备" class="headerlink" title="网络 IO 概念准备"></a>网络 IO 概念准备</h1><p>在讨论网络 IO 之前，一定要有一个概念上的准备前提: <strong>不要用操作磁盘文件的经验去看待网络 IO。</strong> 具体的原因我们在下文中会介绍到。</p><p>相比于传统的网络 IO 来说，一个普通的文件描述符的操作可以分为两部分。以 <code>read</code> 为例，我们利用 read 函数从 socket 中同步阻塞的读取数据，整个流程如下所示：</p><p><img src="https://www.cyhone.com/img/noblocking-io/block-read.png" alt="read 示意图"></p><ol><li>调用 read 后，该调用会转入内核调用</li><li>内核会等待该 socket 的可读事件，直到远程向 socket 发送了数据。可读事件成立 (这里还需要满足 TCP 的低水位条件，但是不做太详细的讨论)</li><li>数据包到达内核，接着内核将数据拷贝到用户进程中，也就是 read 函数指定的 buffer 参数中。至此，read 调用结束。</li></ol><p>可以看到除了转入内核调用，与传统的磁盘 IO 不同的是，网络 IO 的读写大致可以分为两个阶段：</p><ol><li>等待阶段：等待 socket 的可读或者可写事件成立</li><li>拷贝数据阶段：将数据从内核拷贝到用户进程，或者从用户进程拷贝到内核中，</li></ol><h1 id="三种-IO-模型的区别"><a href="#三种-IO-模型的区别" class="headerlink" title="三种 IO 模型的区别"></a>三种 IO 模型的区别</h1><p>我们日常开发遇到最多的三种 IO 模型分别是：同步阻塞 IO、同步非阻塞 IO、异步 IO。</p><p>这些名词非常容易混淆，为什么一个 IO 会有两个限定词：同步和阻塞？同步和阻塞分别代表什么意思？<br>简单来说：</p><ol><li>等待 <strong>阻塞</strong>: 在 socket 操作的第一个阶段，也就是用户等待 socket 可读可写事件成立的这个阶段。如果一直等待下去，直到成立后，才进行下个阶段，则称为阻塞式 IO；如果发现 socket 非可读可写状态，则直接返回，不等待，也不进行下个阶段，则称为非阻塞式 IO。</li><li>拷贝 <strong>同步</strong>: 从内核拷贝到用户空间的这个阶段，如果直到从开始拷贝直到拷贝结束，read 函数才返回，则称为同步 IO。如果在调用 read 的时候就直接返回了，等到数据拷贝结束，才通过某种方式 (例如回调) 通知到用户，这种被称为异步 IO。</li></ol><p>所谓异步，实际上就是非同步非阻塞。</p><h2 id="同步阻塞-IO"><a href="#同步阻塞-IO" class="headerlink" title="同步阻塞 IO"></a>同步阻塞 IO</h2><pre><code class="c">read(fd, buffer, count)</code></pre><p>Linux 下面如果直接不对 fd 进行特殊处理，直接调用 read，就是同步阻塞 IO。同步阻塞 IO 的两个阶段都需要等待完成后，read 才会返回。</p><p><strong>也就是说，如果远程一直没有发送数据，则 read 一直就不会返回，整个线程就会阻塞到这里了。</strong></p><h2 id="同步非阻塞-IO"><a href="#同步非阻塞-IO" class="headerlink" title="同步非阻塞 IO"></a>同步非阻塞 IO</h2><p>对于同步非阻塞 IO 来说，如果没有可读可写事件，则直接返回；如果有，则进行第二个阶段，复制数据。<br>在 linux 下面，需要使用 fcntl 将 fd 变为非阻塞的。</p><pre><code class="c">int flags = fcntl(socket, F_GETFL, 0);fcntl(socket, F_SETFL, flags | O_NONBLOCK);</code></pre><p>同时，如果 read 的时候，fd 不可读，则 read 调用会触发一个 EWOULDBLOCK 错误 (或者 EAGAIN，EWOULDBLOCK 和 EAGAIN 是一样的)。用户只要检查下 <code>errno == EWOULDBLOCK</code>, 即可判断 read 是否返回正常。</p><p>基本在 Linux 下进行网络编程，非阻塞 IO 都是不二之选。</p><h2 id="异步-IO"><a href="#异步-IO" class="headerlink" title="异步 IO"></a>异步 IO</h2><p>Linux 开发者应该很少使用纯粹的异步 IO。因为目前来说，Linux 并没有一个完美的异步 IO 的解决方案。pthread 虽然提供了 aio 的接口，但是这里不做太具体的讨论了。</p><p>我们平常接触到的异步 IO 库或者框架都是在代码层面把操作封装成了异步。但是在具体调用 read 或者 write 的时候，一般还是用的非阻塞式 IO。</p><h1 id="不能用操作磁盘-IO-的经验看待网络-IO"><a href="#不能用操作磁盘-IO-的经验看待网络-IO" class="headerlink" title="不能用操作磁盘 IO 的经验看待网络 IO"></a>不能用操作磁盘 IO 的经验看待网络 IO</h1><p>为什么不能用操作磁盘 IO 的经验看待网络 IO。实际上在磁盘 IO 中，等待阶段是不存在的，因为磁盘文件并不像网络 IO 那样，需要等待远程传输数据。</p><p>所以有的时候，习惯了操作磁盘 IO 的开发者会无法理解同步阻塞 IO 的工作过程，无法理解为什么 read 函数不会返回。</p><p>关于磁盘 IO 与同步非阻塞的讨论，在知乎上有一篇帖子 <a href="https://www.zhihu.com/question/52989189">为什么书上说同步非阻塞 io 在对磁盘 io 上不起作用?</a> 讨论了这个问题。</p><h1 id="为什么在-Linux-网络编程中最好要用非阻塞式-IO？"><a href="#为什么在-Linux-网络编程中最好要用非阻塞式-IO？" class="headerlink" title="为什么在 Linux 网络编程中最好要用非阻塞式 IO？"></a>为什么在 Linux 网络编程中最好要用非阻塞式 IO？</h1><p>上文说到，在 linux 网络编程中，如果使用阻塞式的 IO，假如某个 fd 长期不可读，那么一个线程相应将会被长期阻塞，那么线程资源就会被白白浪费。</p><p>那么，如果我们用了 epoll，还必须要使用非阻塞 IO 吗？ 因为如果使用 epoll 监听了 fd 的可读事件，在 epoll_wait 之后调用 read，此时 fd 一定是可读的， 那么此时非阻塞 IO 相比于阻塞 IO 的优势不就没了吗？</p><p>实际上，并不是这样的。<strong>epoll 也必须要搭配非阻塞 IO 使用。</strong></p><p>总结来说，原因有二：</p><ol><li>fd 在 read 之前有可能会重新进入不可读的状态。要么被其他方式读走了 (参考惊群问题), 还有可能被内核抛弃了，总的来说，fd 因为在 read 之前，数据被其他方式读走，fd 重新变为不可读。此时，用阻塞式 IO 的 read 函数就会阻塞整个线程。</li><li>epoll 只是返回了可读事件，但是并没有返回可以读多少数据量。因此，非阻塞 IO 的做法是读多次，直到不能读。而阻塞 io 却只能读一次，因为万一一次就读完了缓冲区所有数据，第二次读的时候，read 就会又阻塞了。但是对于 epoll 的 ET 模式来说，缓冲区的数据只会在改变的通知一次，如果此次没有消费完，在下次数据到来之前，可读事件再也不会通知了。那么对于只能调用一次 read 的阻塞式 IO 来说，未读完的数据就有可能永远读不到了。</li></ol><p>因此，在 Linux 网络编程中最好使用非阻塞式 IO。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
      <url>/2023/01/22/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="数据结构和算法"><a href="#数据结构和算法" class="headerlink" title="数据结构和算法"></a>数据结构和算法</h1><h2 id="线性表"><a href="#线性表" class="headerlink" title="线性表"></a>线性表</h2><h3 id="顺序表"><a href="#顺序表" class="headerlink" title="顺序表"></a>顺序表</h3><p>性能：</p><ul><li>增：平均O(n)，最好在末尾插入O(1)</li><li>删：平均O(n)，最好在末尾删除O(1)</li><li>查：有序表可达O(logn)，无序表O(n)</li><li>改：有序表可达O(logn)，无序表O(n)</li></ul><p>优点：随机存取,所有数据在O(1)时间内可以访问</p><p>缺点：</p><ul><li>空间利用率不高(预先按最大空间分配)</li><li>插入删除性能低，需要移动大量元素</li><li>表的容量扩充时，空间再分配和复制需要大量开销</li></ul><p>结论：顺序表适合输入数据一定，无太多动态操作，查找操作居多的应用问题</p><p><strong>刷题技巧</strong></p><p><strong>双指针</strong></p><p>1.快慢指针</p><p>数组问题中比较常见的快慢指针技巧，是让你<strong>原地修改数组</strong>。我们让慢指针 <code>slow</code> 走在后面，快指针 <code>fast</code> 走在前面探路，找到一个不重复的元素就赋值给 <code>slow</code> 并让 <code>slow</code> 前进一步。</p><p>如让你在有序数组&#x2F;链表中去重或对数组中的某些元素进行原地删除。比如力扣第 27 题「 <a href="https://leetcode.cn/problems/remove-element/">移除元素</a>」，力扣第 83 题「 <a href="https://leetcode.cn/problems/remove-duplicates-from-sorted-list/">删除排序链表中的重复元素</a>」，力扣第 26 题「 <a href="https://leetcode.cn/problems/remove-duplicates-from-sorted-array/">删除有序数组中的重复项</a>」</p><p>2.滑动窗口</p><p><code>left</code> 指针在后，<code>right</code> 指针在前，两个指针中间的部分就是「窗口」，算法通过扩大和缩小「窗口」来解决某些问题。</p><p>需要思考以下四个问题</p><ul><li>当移动 <code>right</code> 扩大窗口，即加入字符时，应该更新哪些数据？</li><li>什么条件下，窗口应该暂停扩大，开始移动 <code>left</code> 缩小窗口？</li><li>当移动 <code>left</code> 缩小窗口，即移出字符时，应该更新哪些数据？</li><li>我们要的结果应该在扩大窗口时还是缩小窗口时进行更新？</li></ul><pre><code class="c++">/* 滑动窗口算法框架 */void slidingWindow(string s, string t) &#123;    unordered_map&lt;char, int&gt; need, window; //need 和 window 相当于计数器，分别记录 t 中字符出现次数和「窗口」中的相应字符的出现次数    for (char c : t) need[c]++;        int left = 0, right = 0;    int valid = 0;  //valid 变量表示窗口中满足 need 条件的字符个数    while (right &lt; s.size()) &#123;        // c 是将移入窗口的字符        char c = s[right];        // 增大窗口        right++;        // 进行窗口内数据的一系列更新        ...                // 判断左侧窗口是否要收缩        while (window needs shrink) &#123;            // d 是将移出窗口的字符            char d = s[left];            // 缩小窗口            left++;            // 进行窗口内数据的一系列更新            ...        &#125;    &#125;&#125;</code></pre><p>力扣第 76 题「 <a href="https://leetcode.cn/problems/minimum-window-substring/">最小覆盖子串</a>」,力扣第 438 题「 <a href="https://leetcode.cn/problems/find-all-anagrams-in-a-string/">找到字符串中所有字母异位词</a>」</p><p>3.左右指针</p><p>可解决2sum，二分查找之类的问题</p><p><strong>区域和</strong></p><p>1.前缀数组</p><p>构造前缀和&#x2F;前缀积矩阵解决原始数组不会被修改的情况下，<strong>频繁查询某个区间的累加和&#x2F;积</strong>的情况。</p><p>如力扣第 303 题「 <a href="https://leetcode.cn/problems/range-sum-query-immutable/">区域和检索 - 数组不可变</a>」，力扣第 304 题「 <a href="https://leetcode.cn/problems/range-sum-query-2d-immutable/">二维区域和检索 - 矩阵不可变</a>」，<a href="https://leetcode.cn/problems/subarray-sum-equals-k/?show=1">560. 和为 K 的子数组</a></p><p>2.差分数组</p><p>差分数组的主要适用场景是<strong>频繁对原始数组的某个区间的元素进行增减</strong>。一个 <code>diff</code> 差分数组，<code>diff[i]</code> 就是 <code>nums[i]</code> 和 <code>nums[i-1]</code> 之差。</p><pre><code class="c++">int[] diff = new int[nums.length];// 构造差分数组diff[0] = nums[0];for (int i = 1; i &lt; nums.length; i++) &#123;    diff[i] = nums[i] - nums[i - 1];&#125;</code></pre><p>通过这个 <code>diff</code> 差分数组是可以反推出原始数组 <code>nums</code> 的，代码逻辑如下：</p><pre><code class="c++">int[] res = new int[diff.length];// 根据差分数组构造结果数组res[0] = diff[0];for (int i = 1; i &lt; diff.length; i++) &#123;    res[i] = res[i - 1] + diff[i];&#125;</code></pre><p><strong>这样构造差分数组 <code>diff</code>，就可以快速进行区间增减的操作</strong>，如果你想对区间 <code>nums[i..j]</code> 的元素全部加 3，那么只需要让 <code>diff[i] += 3</code>，然后再让 <code>diff[j+1] -= 3</code> 即可</p><p>如力扣第 1109 题「 <a href="https://leetcode.cn/problems/corporate-flight-bookings/">航班预订统计</a>」</p><p><strong>遍历矩阵</strong></p><p>1.顺逆时针旋转矩阵</p><p>顺时针90度旋转矩阵，相当于先按照左上到右下的对角线进行镜像对称，再对矩阵每一行反转</p><p>逆时针90度旋转矩阵，相当于先按照右上到左下的对角线进行镜像对称，再对矩阵每一行反转</p><p>力扣第 48 题「 <a href="https://leetcode.cn/problems/rotate-image/">旋转图像</a>」</p><p>2.螺旋遍历矩阵</p><p>按照右、下、左、上的顺序遍历数组，并使用四个变量upper_bound, lower_bound，left_bound, right_bound圈定未遍历元素的边界，</p><p>随着螺旋遍历，相应的边界会收缩，直到螺旋遍历完整个数组。</p><p>力扣第 54 题「 <a href="https://leetcode.cn/problems/spiral-matrix/">螺旋矩阵</a>」，力扣第 59 题「 <a href="https://leetcode.cn/problems/spiral-matrix-ii/">螺旋矩阵 II</a>」</p><h3 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h3><p>性能：</p><ul><li>增：O(n)，最好已知前驱结点O(1)</li><li>删：O(n)，最好已知前驱结点O(1)</li><li>查：O(n)</li><li>改：O(n)</li></ul><p>优点：插入删除无需移动其他元素，相比顺序表效率更高</p><p>缺点：</p><ul><li>相比顺序表查询效率低下</li></ul><p>结论：链表适合动态操作居多的应用</p><p><strong>双向链表</strong></p><p>解决了找前驱结点的问题，插入删除效率更高</p><p><strong>循环链表</strong></p><p>可以从链表的任意一个结点出发遍历整个链表</p><p><strong>刷题技巧</strong></p><p><strong>虚拟头结点</strong></p><p>构造 <code>dummy</code> 结点，可以避免处理空指针的情况，同时在首部进行插入和删除也会更加简单，降低代码的复杂性。</p><p><strong>双指针</strong></p><p>通过双指针找链表的倒数第n个结点，找链表的中点，找环，找两条链表的交点等</p><p>力扣第 160 题「 <a href="https://leetcode.cn/problems/intersection-of-two-linked-lists/">相交链表</a>」，力扣第 876 题「 <a href="https://leetcode.cn/problems/middle-of-the-linked-list/">链表的中间结点</a>」，力扣第 19 题「 <a href="https://leetcode.cn/problems/remove-nth-node-from-end-of-list/">删除链表的倒数第 N 个结点</a>」，<a href="https://leetcode.cn/problems/palindrome-linked-list/">234. 回文链表</a></p><p><strong>链表排序</strong></p><p>1.归并排序</p><p>通过快慢指针找到链表中点，两边分别排序再merge</p><pre><code class="c++">class Solution &#123;public:    ListNode* sortList(ListNode* head) &#123;        if(!head || head-&gt;next == nullptr) return head;        ListNode* slow = head;        ListNode* fast = head-&gt;next;        while(fast != nullptr &amp;&amp; fast-&gt;next != nullptr) &#123;            slow = slow-&gt;next;            fast = fast-&gt;next-&gt;next;        &#125;        ListNode* right = slow-&gt;next;        slow-&gt;next = nullptr;        auto left_head = sortList(head);        auto right_head = sortList(right);        auto res = merge(left_head, right_head);        return res;    &#125;private:    ListNode* merge(ListNode* left, ListNode* right) &#123;        ListNode dummy;        ListNode* head = &amp;dummy;        while(left != nullptr &amp;&amp; right != nullptr) &#123;            if(left-&gt;val &lt; right-&gt;val) &#123;                head-&gt;next = left;                left = left-&gt;next;            &#125; else &#123;                head-&gt;next = right;                right = right-&gt;next;            &#125;            head = head-&gt;next;        &#125;        if(left) &#123;            head-&gt;next = left;        &#125; else &#123;            head-&gt;next = right;        &#125;        return dummy.next;    &#125;&#125;;</code></pre><p>2.快速排序</p><p>通过交换结点的值来进行快速排序，但会变更原来的结点</p><pre><code class="c++">class Solution &#123;public:    ListNode* sortList(ListNode* head) &#123;      if(head == nullptr || head-&gt;next == nullptr) return head;      quickSort(head, nullptr);      return head;    &#125;private:    void quickSort(ListNode* head, ListNode* tail) &#123;        if(head == tail || head-&gt;next == tail) return;        auto pivot = head-&gt;val;        ListNode * left = head;        for(auto cur = head-&gt;next; cur != tail; cur = cur-&gt;next) &#123;            if(cur-&gt;val &lt; pivot) &#123;                left = left-&gt;next;                swap(left-&gt;val, cur-&gt;val);            &#125;        &#125;        swap(head-&gt;val, left-&gt;val);        quickSort(head, left);        quickSort(left-&gt;next, tail);    &#125;&#125;;</code></pre><p>通过构造两条链表分别存放大于和小于pivot的结点，两条链条分别排序再合并</p><pre><code class="c++">class Solution &#123;public:    ListNode* sortList(ListNode* head) &#123;        if(head == nullptr || head-&gt;next == nullptr) return head;         return quickSort(head);    &#125;private:    ListNode* quickSort(ListNode* head) &#123;        if(head == nullptr || head-&gt;next == nullptr) return head;        auto pivot = head-&gt;val;        ListNode left,right;        ListNode* l = &amp;left;        ListNode* r = &amp;right;        for(auto cur = head-&gt;next; cur != nullptr; cur = cur-&gt;next) &#123;            if(cur-&gt;val &lt; pivot) &#123;                l-&gt;next = cur;                l = l-&gt;next;            &#125; else &#123;                r-&gt;next = cur;                r = r-&gt;next;            &#125;        &#125;        l-&gt;next = nullptr;        r-&gt;next = nullptr;        auto left_head = quickSort(left.next);        auto right_head = quickSort(right.next);        if(left_head == nullptr) &#123;            head-&gt;next = right_head;            left_head = head;        &#125; else &#123;            auto tmp = left_head;            while(tmp-&gt;next != nullptr) &#123;                tmp = tmp-&gt;next;            &#125;            tmp-&gt;next = head;            head-&gt;next = right_head;        &#125;        return left_head;    &#125;&#125;;</code></pre><h2 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E5%AE%9A%E6%97%B6%E5%99%A8/"/>
      <url>/2023/01/22/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E5%AE%9A%E6%97%B6%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="如何实现一个定时器"><a href="#如何实现一个定时器" class="headerlink" title="如何实现一个定时器"></a>如何实现一个定时器</h1><h2 id="使用linux信号触发定时任务"><a href="#使用linux信号触发定时任务" class="headerlink" title="使用linux信号触发定时任务"></a>使用linux信号触发定时任务</h2><p>可以使用操作系统API预订一个 <code>SIGALRM</code> 信号，在指定的时间后程序就能收到信号，在信号的处理函数中就能实现定时任务。具体的系统API如下：</p><pre><code class="c++">#include &lt;unistd.h&gt;unsigned int alarm(unsigned int seconds);</code></pre><p>这里值得一提的是另一个信号 <code>SIGVTALRM</code> ，可以使用 <code>setitimer</code> 系统接口进行设置。这个定时器计算的是程序在用户模式（user mode）消耗的时间。另外，这个定时器还可以通过传入的 <code>struct itimerval</code> 设置为循环触发。</p><pre><code class="c++">#include &lt;sys/time.h&gt;int setitimer(int which, const struct itimerval *new_value,          struct itimerval *old_value);</code></pre><p>需要 <strong>注意</strong> 的是这两个API在同时使用时可能会相互干扰，它们可能会共用同一个定时器。</p><h2 id="通过timerfd实现定时任务"><a href="#通过timerfd实现定时任务" class="headerlink" title="通过timerfd实现定时任务"></a>通过timerfd实现定时任务</h2><p>timerfd是linux独有的接口，可以在定时器超时后通过一个文件描述符通知程序。</p><pre><code class="c++">#include &lt;sys/timerfd.h&gt;int timerfd_create(int clockid, int flags);int timerfd_settime(int fd, int flags,            const struct itimerspec *new_value,            struct itimerspec *old_value);int timerfd_gettime(int fd, struct itimerspec *curr_value);</code></pre><p>当这个文件描述符变为可读（readable）时，说明定时器超时了。最方便的是，这个文件描述符可以通过类似select的多路复用接口管理，这样我们就能同时设置并等待多个定时器了。</p><h2 id="在网络编程中借助epoll的等待间隔执行定时任务"><a href="#在网络编程中借助epoll的等待间隔执行定时任务" class="headerlink" title="在网络编程中借助epoll的等待间隔执行定时任务"></a>在网络编程中借助epoll的等待间隔执行定时任务</h2><p>在网络编程中，通常都会用到IO复用，如select&#x2F;poll&#x2F;epoll等，它们会帮你同时检查多个socket上是否有读写操作。这些接口都有一个等待时间，在这个指定时间是最大等待时间，即使在没有需要处理的IO操作时也会返回。这个时间是一般是个固定值，如10ms&#x2F;20ms&#x2F;50ms，它被称作网络库的基准频率。在这段空余时间中可以检查定时器是否超时，并执行超时定时器的回调函数。</p><p>伪代码示例如下：</p><pre><code class="c++">def update_events(milisec = 10):    result = selector.select(milisec)    for fd, event in result:    do something with socket event    current = time.time()    update_timer(current)while 1:    WAIT_MILLISEC = 10    update_events(WAIT_MILLISEC)</code></pre><p>在两次select的间隔中可以进行一些定时操作，关键就在 <code>update_timer</code> 中的实现：</p><pre><code class="c++">def update_timer (current):    for timer in available_timers:     while current &gt;= timer.expires:         timer.callback(current)         timer.expires += timer.period</code></pre><p><code>available_timers</code> 记录着当前所有的定时器， <code>timer.expires</code> 是他们需要被触发的时间，如果当前时间大于等于这个 <code>timer.expires</code> ，认为该定时器触发了。 <strong>注意</strong> <code>timer.expires</code> 更新的时候是 <code>+= period</code> ，而不是 <code>= current + period</code> ，后者会导致误差积累，长时间运行后偏差会越来越大。同时这里需要 <code>while</code> ，因为定时器的回调函数在执行时可能跨越两个以上周期，当然只触发一次的就不需要了。</p><p>可以将定时器存在一个优先队列中，每次从队列的前面取出定时器进行超时判断，直到出现了一个没超时的就终止判断，这样可以避免每次都扫描全部定时器。</p><p>在所有定时器的超时时间都相同时，可以将它们存放在一个单向队列中，每次增加时都放在最后，并从前面开始检查超时，这样只需要检查队列头部的那部分定时器了。</p><p>另一种思路是动态调整等待的间隔，每次选出最先需要超时的定时器，计算它的超时时间，将这个时间作为select的等待时间。这样每次时间都不一样，每次都基本准确，同时不会占用多余的CPU，这种模式叫做 <code>TICKLESS</code> 。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E9%9D%9E%E6%B3%95%E8%BE%93%E5%85%A5%E4%BB%A5%E5%8F%8A%E6%9E%84%E9%80%A0%E5%BC%82%E5%B8%B8%E6%83%85%E5%86%B5/"/>
      <url>/2023/01/22/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E9%9D%9E%E6%B3%95%E8%BE%93%E5%85%A5%E4%BB%A5%E5%8F%8A%E6%9E%84%E9%80%A0%E5%BC%82%E5%B8%B8%E6%83%85%E5%86%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="如何处理非法输入以及构造异常情况"><a href="#如何处理非法输入以及构造异常情况" class="headerlink" title="如何处理非法输入以及构造异常情况"></a>如何处理非法输入以及构造异常情况</h1><h2 id="非法输入"><a href="#非法输入" class="headerlink" title="非法输入"></a>非法输入</h2><p>假设我们要设计一个关于people的class，并进行如下约定:</p><ol><li>age 小于 0 的baby不在我们的考虑范围之内.</li><li>age 大于 200 的people我们认为是不存在的.</li></ol><p>如果我们以非法的参数构造People并进行相关的函数调用，如下:</p><pre><code class="c++">People p(-1);p.Sing();</code></pre><p>那么这样实在是太糟糕了，因为在调用Sing()时我们甚至不知道调用的对象的内部状态是非法的，这也就成为bug的一个源泉.</p><p>总结一下上面的例子中遇到的问题:<strong>在以特定的参数构造一个对象时，如果参数非法或构造失败，我们应当向调用者反馈这一信息</strong>.</p><p>对于一般的成员函数，如果能够有返回值，那么我们可以通过返回值来标识传递给函数的参数非法或内部运行失败这种情况.<br>但是对于构造函数，因为它不能有返回值，所以，我们必须使用其它的方法来向调用者反馈”传递给构造函数的参数非法或构造失败”.</p><p>针对于这一问题有三种解决方案:</p><p><strong>第一种方案:在构造函数的参数中传递一个额外的参数用于标识构造是否成功.</strong><br>在这种方案的指导下，代码如下:</p><pre><code class="c++">class People&#123;    public:        People( int iAge , bool &amp;bInitStatus )        : m_iAge( iAge )        &#123;            if( ( iAge &lt; 0 ) || ( iAge &gt; 200 ) )            &#123;                bInitStatus = false;            &#125;            else            &#123;                bInitStatus = true;            &#125;        &#125;&#125;;bool bInitStatus = false;People p( -1 , bInitStatus );if( false == bInitStatus )&#123;    // handle error&#125;else&#123;    p.Sing();&#125;</code></pre><p>这种方法是可行的，但是代码看起来过于丑陋且不够直观</p><p><strong>第二种方案:使用两段构造的形式.</strong><br>所谓的两段构造是指一个对象的内部状态的初始化分两步完成，将构造函数中的部分初始化操作转移到一个辅助初始化的成员函数中:<br>第一步是通过构造函数来完成部分内部状态的初始化.<br>第二步是通过类似于 Initialize 之类的成员函数来完成对象内部状态的最终初始化.</p><p>两段构造的形式在 MFC 中广泛使用.在MFC中我们经常看到类似于 Initialize , Create 之类的函数.<br>基于两段构造的形式，代码如下:</p><pre><code class="c++">class People&#123;    public:        People( void )        : m_iAge( INVALID_AGE )        &#123;        &#125;                bool Initialize( int iAge )        &#123;            if( ( iAge &lt; 0 ) || ( iAge &gt; 200 ) )            &#123;                return false;            &#125;            else            &#123;                m_iAge = iAge;                return true;            &#125;                    &#125;&#125;;People hebe;const bool bStatus = hebe.Initialize( 20 );if( false == bInitStatus )&#123;    // handle error&#125;else&#123;    hebe.Sing();&#125;</code></pre><p>这种方案似乎比第一种方案更优，但是仍有一个潜在的问题:对象是以两步构造完成的。第一步构造是由构造函数来完的，OK，这一点我们不用担心，编译器帮我们保证。但是第二步是由类似于 Initialize 之类的成员函数来完成的，如果我们在构造一个People对象之后忘记了调用 Initialize ，那么这个对象的内部状态仍然是非法的，后续的操作也将由此引发bug.这也是”两段构造”这种形式受到诟病的原因之一。<br>另一方面，”两段构造”的形式与C++的”RAII”，Resource Acquisition Is Initialization(资源获取即初始化)，这一原则相违背.</p><p><strong>第三种方案:使用异常</strong></p><p>即是当用于构造 People 对象的参数非法时，我们选择在构造函数中抛出一个异常来反馈给调用者”参数非法,构造失败”的相关信息.</p><pre><code class="c++">class People&#123;    public:        explicit People( int iAge ) throw( std::invalid_arguement )        : m_iAge( iAge )        &#123;            if( ( iAge &lt; 0 ) || ( iAge &gt; 200 ) )            &#123;                throw std::invalid_arguement( &quot;invalid argument&quot; );            &#125;        &#125;&#125;;try&#123;    People hebe( 20 );    hebe.Sing();&#125;catch( const std::invalid_arguement &amp;refExcept )&#123;    // handle exception here.&#125;</code></pre><h2 id="构造异常"><a href="#构造异常" class="headerlink" title="构造异常"></a>构造异常</h2><p><strong>C++规定:如果执行构造函数的过程中产生异常，那么这个未被成功构造的对象的析构函数将不会被调用.</strong></p><p><strong>第一种方案：二段式构造</strong></p><p>将对象的构造过程，分为两类。</p><ul><li>资源无关的初始化，比如赋值</li><li>调用系统资源的操作，比如内存申请，访问文件</li></ul><p>对于第一类，可以认为是安全的，放在第一阶段构造，但是第二类是有可能会出异常的，放在第二阶段构造。</p><pre><code class="c++">#include &lt;iostream&gt;class Test&#123;private:    int mi;    int* array;    Test(int i)  //第一阶段构造，完成基本的赋值操作    &#123;        mi = i;        array = NULL;    &#125;    bool construct() //第二阶段构造，申请内存    &#123;        bool ret = true;        array = new int[5];        if(array)        &#123;            for(int i = 0; i &lt; 5; ++ i)            &#123;                array[i] = i;            &#125;        &#125;        else        &#123;            ret = false;        &#125;        return ret;    &#125;public:        static Test* NewInstance(int i)//对象创建函数    &#123;        Test* ret = new Test(i); //调用第一阶构造        if(!(ret &amp;&amp; ret-&gt;construct()))        &#123;            delete ret;            ret = NULL;        &#125;        return ret;    &#125;    ~Test()    &#123;        if(array)        &#123;            delete[] array;        std::cout &lt;&lt; &quot;destroy&quot; &lt;&lt; std::endl;        &#125;    &#125;&#125;;int main(void)&#123;    Test* t = Test::NewInstance(1);    return 0;&#125;</code></pre><p>如上若二阶段构造失败的处理方式和正常析构不同。</p><p><strong>第二种方案：在构造函数内catch异常或者使用智能指针管理资源</strong></p><pre><code class="cpp">person::person(const string&amp; name):    a(NULL),   // 初始化为空指针是必须的    b(NULL)&#123;    try     &#123;        a = new A();        b = new B();      &#125;     catch(...)   // 捕获所有异常    &#123;        delete a;        delete b;        throw;   // 继续传递异常    &#125;&#125;</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E5%86%85%E7%BD%AE%E7%B1%BB%E5%9E%8B%E5%92%8CPOD%E7%B1%BB%E5%9E%8B/"/>
      <url>/2023/01/22/%E5%86%85%E7%BD%AE%E7%B1%BB%E5%9E%8B%E5%92%8CPOD%E7%B1%BB%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="内置类型和POD类型"><a href="#内置类型和POD类型" class="headerlink" title="内置类型和POD类型"></a>内置类型和POD类型</h1><h2 id="内置类型"><a href="#内置类型" class="headerlink" title="内置类型"></a>内置类型</h2><p>内置类型（也称基本类型）由 C++ 语言标准指定，内置于编译器中。 内置类型未在任何头文件中定义。 内置类型分为以下几个类别：</p><table><thead><tr><th>类型</th><th>关键字</th></tr></thead><tbody><tr><td>布尔类型</td><td>bool</td></tr><tr><td>字符型</td><td>char，wchar_t，char8_t(c++20)，char16_t(c++11)，char32_t(c++11)</td></tr><tr><td>整型</td><td>int</td></tr><tr><td>浮点型</td><td>float，double，long double</td></tr><tr><td>无类型</td><td>void，nullptr(c++11)</td></tr></tbody></table><h3 id="C-类型修饰符"><a href="#C-类型修饰符" class="headerlink" title="C ++类型修饰符"></a>C ++类型修饰符</h3><p>我们可以使用类型修饰符来进一步修改一些基本数据类型。C ++中有5种类型修饰符。他们是：</p><ul><li>signed</li><li>unsigned</li><li>short</li><li>long</li><li>long long(c++11)</li></ul><p><strong>所以long和short不是类型，而是修饰符</strong></p><p>其中char只能用signed和unsigned修饰，int可以用所有修饰符修饰。</p><h3 id="字符型详解"><a href="#字符型详解" class="headerlink" title="字符型详解"></a>字符型详解</h3><p>类型 <strong><code>char</code><strong>、</strong><code>wchar_t</code><strong>、</strong><code>char8_t</code><strong>、</strong><code>char16_t</code></strong> 和 <strong><code>char32_t</code></strong> 是内置类型，可表示字母数字字符，非字母数字字形和非打印字符。</p><p><strong><code>char</code></strong> 类型是 C 和 C++ 中的原始字符类型。 <strong><code>char</code></strong> 类型可用于存储 ASCII 字符集或任何 ISO-8859 字符集中的字符，以及多字节字符的单个字节，例如 Shift-JIS 或 Unicode 字符集的 UTF-8 编码。 在 Microsoft 编译器中，**<code>char</code>** 是 8 位类型。 它是与 <strong><code>signed char</code></strong> 和 <strong><code>unsigned char</code></strong> 都不同的类型。 默认情况下，**<code>char</code>** 类型的变量将提升到 **<code>int</code>**，就像是从 <strong><code>signed char</code></strong> 类型一样，除非使用 <a href="https://learn.microsoft.com/zh-cn/cpp/build/reference/j-default-char-type-is-unsigned?view=msvc-170"><code>/J</code></a> 编译器选项。 在 <strong><code>/J</code></strong> 的情况下，它们被视为 <strong><code>unsigned char</code></strong> 类型并提升为 <strong><code>int</code></strong> （没有符号扩展）。</p><p>类型 <strong><code>unsigned char</code></strong> 通常用于表示 byte，它不是 C++ 中的内置类型。</p><p><strong><code>wchar_t</code></strong> 类型是实现定义的宽字符类型。 在 Microsoft 编译器中，它表示一个 16 位宽字符，用于存储编码为 UTF-16LE 的 Unicode（Windows 操作系统上的本机字符类型）。通用 C 运行时 (UCRT) 库函数的宽字符版本使用 <strong><code>wchar_t</code></strong> 及其指针和数组类型作为参数和返回值，本机 Windows API 的宽字符版本也是如此。</p><p><strong><code>char8_t</code><strong>、</strong><code>char16_t</code></strong> 和 <strong><code>char32_t</code></strong> 类型分别表示 8 位、16 位和 32 位宽字符。 （**<code>char8_t</code>** 是 C++20 中的新增功能，需要 <code>/std:c++20</code>或 <strong><code>/std:c++latest</code></strong> 编译器选项。）编码为 UTF-8 的 Unicode 可以存储在 <strong><code>char8_t</code></strong> 类型中。 <strong><code>char8_t</code></strong> 和 <strong><code>char</code></strong> 类型的字符串称为“窄”字符串，即使用于编码 Unicode 或多字节字符。 编码为 UTF-16 的 Unicode 可以存储在 <strong><code>char16_t</code></strong> 类型中，而编码为 UTF-32 的 Unicode 可以存储在 <strong><code>char32_t</code></strong> 类型中。 这些类型和 <strong><code>wchar_t</code></strong> 类型的字符串都称为“宽”字符串，但该术语通常特指 <strong><code>wchar_t</code></strong> 类型的字符串。</p><p>在 C++ 标准库中，<code>basic_string</code> 类型专用于窄字符串和宽字符串。 字符的类型为 <strong><code>char</code></strong> 时，使用 <code>std::string</code>；字符的类型为 <strong><code>char8_t</code></strong> 时，使用 <code>std::u8string</code>；字符的类型为 <strong><code>char16_t</code></strong> 时，使用 <code>std::u16string</code>；字符的类型为 <strong><code>char32_t</code></strong> 时，使用 <code>std::u32string</code>；而字符的类型为 <strong><code>wchar_t</code></strong> 时，使用 <code>std::wstring</code>。 其他表示文本的类型（包括 <code>std::stringstream</code> 和 <code>std::cout</code>）均可专用于窄字符串和宽字符串。</p><h3 id="数据类型大小"><a href="#数据类型大小" class="headerlink" title="数据类型大小"></a>数据类型大小</h3><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/typechart.png" alt="image-20221104034339597"></p><p>在这张表中，LP64，ILP64，LLP64是64位平台上的字长模型，ILP32和LP32是32位平台上的字长模型。</p><p>LP64意思是long和pointer是64位，</p><p>ILP64指int，long，pointer是64位，</p><p>LLP64指long long和pointer是64-bit的。</p><p>ILP32指int，long和pointer是32位的，</p><p>LP32指long和pointer是32位的。</p><p><strong>现今所有64位的类Unix平台均使用LP64数据模型，而64位Windows使用LLP64数据模型，除了指针是64位，其他基本类型都没有变</strong></p><h2 id="POD类型"><a href="#POD类型" class="headerlink" title="POD类型"></a>POD类型</h2><p>POD（Plain Old Data）是C++中非常重要的一个概念，用来描述一个类型的属性其中Plain表示这个类型是个平凡的类型，Old表示其与C的兼容性。C++11中将POD划分为两个基本概念：平凡的（trival）和标准布局（standardlayout）。</p><p>粗略地说，POD 类型是一种与 C 兼容的类型，也许同样重要的是与某些 ABI（Application Binary Interface） 优化兼容。为了与 C 兼容，我们需要满足两个约束：</p><ul><li>布局必须与对应的 C 类型相同。</li><li>类型必须以与相应的 C 类型相同的方式传递给函数和从函数返回。</li></ul><p>虚函数要求编译器插入一个或多个指向虚函数表的指针，这在 C 中是不存在的。</p><p>用户定义的拷贝构造函数、移动构造函数、复制赋值和析构函数对参数传递和返回有影响。 许多 C ABI 在寄存器中传递和返回小参数，但传递给用户定义的构造函数&#x2F;赋值&#x2F;析构函数的引用只能使用内存位置。</p><h3 id="平凡性（trivial）"><a href="#平凡性（trivial）" class="headerlink" title="平凡性（trivial）"></a>平凡性（trivial）</h3><p>什么是平凡性呢？通常一个平凡的类或者结构体具有以下特征：</p><ul><li>没有自定义构造函数和析构函数。</li><li>没有自定义拷贝构造函数和移动构造函数。即拥有编译器自动生成的拷贝、移动构造函数。</li><li>没有自定义拷贝赋值运算符和移动赋值运算符。</li><li>不能包含虚函数和虚基类。</li></ul><p>C++11提供了一个类模板来帮我们识别一个类是否是平凡的：template <typename T>struct std::is_trival</p><pre><code class="c++">#include &lt;iostream&gt;using namespace std;class Base&#123;public:   int a;   int b;&#125;; int main()&#123;   cout&lt;&lt;is_trivial&lt;Base&gt;::value&lt;&lt;endl ;   return 0;&#125;</code></pre><h3 id="标准布局"><a href="#标准布局" class="headerlink" title="标准布局"></a>标准布局</h3><p>满足以下条件的类或结构体是标准布局的</p><ul><li><p>所有非静态成员有相同的访问权限，比如都是private的，或者都是public，或者都是protected</p></li><li><p>在类或结构体的继承时，满足以下两种情况之一：</p><ol><li>派生类中有非静态成员，且只有仅包含静态成员的基类。。</li><li>基类有非静态成员，而派生类没有非静态成员。</li><li>这两条综合起来，意即：<strong>继承树中最多只能有一个类有非静态数据成员。</strong></li></ol></li><li><p>类中第一个非静态成员的类型与其基类不同。</p></li><li><p>没有虚函数和虚基类。</p></li><li><p>所有非静态成员都符合标准布局类型，其父类也符合标准布局。</p></li></ul><p>C++11提供了如下模板来判断一个类或结构体对象是否是标准布局</p><p>template <typename T> structstd::is_standard_layout; &#x2F;&#x2F;头文件为<type_traits><br>template <typename T> struct std::is_pod &#x2F;&#x2F;判断一个类型是否是POD，头文件为<type_traits></p><h3 id="POD的好处"><a href="#POD的好处" class="headerlink" title="POD的好处"></a>POD的好处</h3><ul><li>字节赋值，我们可以放心的使用memset和memcpy对POD类型进行初始化和拷贝。</li><li>提供对C内存的兼容。POD类型的数据在C与C++间的操作总是安全的。</li><li>保证了静态初始化的安全有效。POD类型的对象初始化往往更简单</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E7%B1%BB%E5%9E%8B%E5%AE%89%E5%85%A8/"/>
      <url>/2023/01/22/%E7%B1%BB%E5%9E%8B%E5%AE%89%E5%85%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="类型安全"><a href="#类型安全" class="headerlink" title="类型安全"></a>类型安全</h1><p>类型匹配错误，我们把它定义成：</p><blockquote><p>当你试图把一个变量当作类型A来处理时，却意外发现它不是类型A的。它可能是类型B的，也可能什么都不是。</p></blockquote><p>类型安全要杜绝类型匹配错误</p><p>c&#x2F;c++显然不是类型安全的，变量可以进行强制类型转换成与变量名类型不同的类型，编译器不会对此做出检查。c++增加了static_cast，dynamic_cast等类型检查。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E9%9D%99%E6%80%81%E9%93%BE%E6%8E%A5%E5%92%8C%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5/"/>
      <url>/2023/01/22/%E9%9D%99%E6%80%81%E9%93%BE%E6%8E%A5%E5%92%8C%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="静态链接和动态链接"><a href="#静态链接和动态链接" class="headerlink" title="静态链接和动态链接"></a>静态链接和动态链接</h1><h2 id="静态链接"><a href="#静态链接" class="headerlink" title="静态链接"></a><strong>静态链接</strong></h2><p>静态链接是由链接器在链接时将库的内容加入到可执行程序中的做法。</p><p>链接器是一个独立程序，将一个或多个库或目标文件（先前由编译器或汇编器生成）链接到一块生成可执行程序。</p><p>这里的库指的是静态链接库，Windows下以.lib为后缀，Linux下以.a为后缀。</p><h2 id="动态链接"><a href="#动态链接" class="headerlink" title="动态链接"></a><strong>动态链接</strong></h2><p>动态链接（<code>Dynamic Linking</code>），把链接这个过程推迟到了运行时再进行，在可执行文件装载时或运行时，由操作系统的装载程序加载库。</p><p>这里的库指的是动态链接库，Windows下以.dll为后缀，Linux下以.so为后缀。</p><p>值得一提的是，在Windows下的动态链接也可以用到.lib为后缀的文件，但这里的.lib文件叫做导入库，是由.dll文件生成的。</p><h2 id="静态链接与动态链接的优缺点"><a href="#静态链接与动态链接的优缺点" class="headerlink" title="静态链接与动态链接的优缺点"></a><strong>静态链接与动态链接的优缺点</strong></h2><p><strong>（1）静态链接的优缺点：</strong></p><p><strong>优点：</strong></p><ul><li>执行速度略比动态链接库快；</li><li>打包方便，只需保证在开发者的计算机中有正确的.lib文件，在以二进制形式发布程序时不需考虑在用户的计算机上.lib文件是否存在及版本问题。</li><li>在某些情况下相比动态链接可以节省内存，大部分情况下库文件只有有限个函数被使用，静态链接只会加载使用的函数到内存，而动态链接会把库文件所有的函数加载到内存，<strong>如果共享库文件的进程很少，此时静态链接相比动态链接更省内存</strong>。</li></ul><p><strong>缺点：</strong></p><ul><li>使用静态链接多个程序会把相同的库文件打包，并且会把相同的库文件加载到内存，既浪费磁盘空间又浪费内存</li><li>静态链接相比动态链接编译更慢</li><li>静态链接对程序的更新部署和发布很不友好：假如一个模块依赖20个模块，当20个模块其中有一个模块需要更新时，需要将所有的模块都找出来重新编译出一个可执行程序才可以更新成功，每次更新任何一个模块，用户就需要重新获得一个非常大的程序，程序如果使用静态链接，那么通过网络来更新程序也会非常不便，一旦程序任何位置有一个小改动，都会导致整个程序重新下载。</li></ul><p><strong>（2）动态链接的优缺点：</strong></p><p><strong>优点：</strong></p><ul><li>动态链接可以使库文件只在磁盘和内存中仅存在一份，既节省磁盘又节省内存(现在一般会将dll文件一同打包，节省磁盘不存在)</li><li>适用于大规模的软件开发，使开发过程独立、耦合度小，便于不同开发者和开发组织之间进行开发和测试；</li><li>DLL文件与EXE文件独立，只要输出接口不变（即名称、参数、返回值类型和调用约定不变），更换DLL文件不会对EXE文件造成任何影响，因而极大地提高了可维护性和可扩展性；</li></ul><p><strong>缺点：</strong></p><ul><li>使用动态链接库的应用程序不是自完备的，它依赖的DLL模块也要存在，如果使用载入时动态链接，程序启动时发现DLL不存在，系统将终止程序并给出错误信息；</li><li>程序运行速度比静态链接慢；</li><li>dll地狱：程序依赖不同版本同名的dll文件，造成冲突</li></ul><h2 id="dll地狱"><a href="#dll地狱" class="headerlink" title="dll地狱"></a>dll地狱</h2><p>很多Windows的应用程序在发布release版本时会一次性将所有用到的DLL一起打包形成一个大的安装包，用户只需一键安装，无需关注具体的DLL文件的配置问题。但也正是这种黑盒操作导致了可能存在某次安装，将系统中的DLL文件被新DLL文件给覆盖掉，虽然安装的程序可以运行了，但是其他程序可能出现问题了（最为常见的便是Visual studio C++的一些插件库版本覆盖问题）。</p><p>前人总结的经验，DLL HELL发生的三种主要场景：</p><ol><li>使用旧版本的DLL替代了当前系统的新版本DLL，导致了其他程序无法正常运行；</li><li>新版本DLL引入覆盖了旧版本DLL，新版本的DLL没有做到完全的向后兼容；导致旧程序无法运行</li></ol><h3 id="导出类dll兼容问题"><a href="#导出类dll兼容问题" class="headerlink" title="导出类dll兼容问题"></a>导出类dll兼容问题</h3><p>导出类的DLL在维护和修改时有很多地方必需很小心，增加成员变量、修改导出类的基类等操作都可能导致意想不到的后果，也许用户更新了最新版本的DLL库后，应用程序就再也不能工作了。这就是著名的DLLHell（DLL地狱）问题。</p><p>DLL地狱问题是怎么产生的呢？看下面的例子，假设DLL有一个导出类ClassD：</p><pre><code class="cpp">class ClassD&#123;public:    int GetInt()    &#123;        return m_i;    &#125;private:    int m_i;&#125;;</code></pre><p>应用程序使用现在的代码来使用这个类：</p><pre><code class="cpp">ClassD d;printf(“%d”,d.GetInt());</code></pre><p>程序进行正正常，没有什么问题。后来DLL需要升级，对ClassD进行了修改，增加了一个成员变量，如下：</p><pre><code class="cpp">class ClassD&#123;public:    int GetInt()    &#123;        return m_i;    &#125;private:    int m_i2;    int m_i;&#125;;</code></pre><p>把新的DLL编译连接完成后，复制到应用程序目录，这个倒霉的应用程序调用GetInt方法恐怕再也无法得正确的值了。事实上它还算幸运的，如果GetInt的实现改成如下这样，那么它马上就要出错退出了。</p><pre><code class="cpp">intClassD::GetInt() // 修改后&#123;      return m_i++;&#125;</code></pre><p>为什么会出错呢？我们要先从类实例的创建开始，看看使用一个类的工作过程。</p><p>首先，程序语句“ClassD d；”为这个类申请一块内存。这块内存保存该类的所有成员变量，以及虚函数表。内存的大小由类的声明决定，在应用程序编译时就已经确定。</p><p>然后，当调用“d.GetInt()”时，把申请的这一块内存做为this指针传给GetInt函数，GetInt函数从this指向的位置开始，加上m_i应有的偏移量，计算m_i所在的内存位置，并从该位置取数据返回。m_i相对this的偏移量是由m_i在类中定义的位置决定的，定义在前的成员变量在内存中也更靠前。这个偏移量在DLL编译时确定。</p><p>当ClassD的定义改为修改后的状态时，有些东西变了。</p><p>第一个变的是内存的大小。因为修改后的ClassD多了一个成员变量，所以内存也变大了。然而这一点应用程序并不知道。</p><p>第二个变的是m_i的偏移地址。因为在m_i之前定义了一个m_i2，m_i的实现偏移地址实际已经靠后了。所以d.GetInt()访问的将是原来m_i后面的那个位置，而这个位置已经超出原来那块内存的后部范围了。</p><p>很显然，在更换了DLL后，应用程序还按原来的大小申请了一块内存，而它调用的方法却访问了比这块内存更大的区域，出错在所难免。</p><p>同样的情形还会发生在以下这些种情况中：</p><ul><li>应用程序直接访问类的公有变量，而该公有变量在新DLL中定义的位置发生了变化；</li><li>应用程序调用类的一个虚函数，而新的类中，该虚函数的前面又增加了一个虚函数；</li><li>新类的后面增加了成员变量，并且新类的成员函数将访问、修改这些变量；</li><li>修改了新类的基类，基类的大小发生了变化；</li></ul><p>等等，总言而之，一不小心，你的程序就会掉进地狱。通过对这些引起出错的情况进行分析，会发现其实只有三点变化会引起出错，因为这三点是使用这个DLL的应用程序在编译时就需要确定的内容，它们分别是：</p><ul><li>类的大小；</li><li>类成员的偏移地址；</li><li>虚函数的顺序。</li></ul><p>要想做一个可升级的DLL，必需避免以上三个问题。所以以下三点用来使DLL远离地狱。</p><ul><li><strong>不直接生成类的实例</strong>。对于类的大小，当我们定义一个类的实例，或使用new语句生成一个实例时，内存的大小是在编译时决定的。要使应用程序不依赖于类的大小，只有一个办法：应用程序不生成类的实例，使用DLL中的函数来生成。把导出类的构造函数定义为私有的(privated)，在导出类中提供静态(static)成员函数(如NewInstance())用来生成类的实例。因为NewInstance()函数在新的DLL中会被重新编译，所以总能返回大小正确的实例内存。</li><li><strong>不直接访问成员变量</strong>。应用程序直接访问类的成员变量时会用到该变量的偏移地址。所以避免偏移地址依赖的办法就是不要直接访问成员变量。把所有的成员变量的访问控制都定义为保护型(protected)以上的级别，并为需要访问的成员变量定义Get或Set方法。Get或Set方法在编译新DLL时会被重新编译，所以总能访问到正确的变量位置。</li><li><strong>忘了虚函数吧</strong>，就算有也不要让应用程序直接访问它。因为类的构造函数已经是私有(privated)的了，所以应用程序也不会去继承这个类，也不会实现自己的多态。如果导出类的父类中有虚函数，或设计需要（如类工场之类的框架），一定要把这些函数声明为保护的(protected)以上的级别，并为应用程序重新设计调用该虑函数的成员函数。这一点也类似于对成员变量的处理。</li></ul><p>如果导出的类能遵循以上三点，那么以后对DLL的升级将可以认为是安全的。</p><p>如果对一个已经存在的导出类的DLL进行维护，同样也要注意：不要改动所有的成员变量，包括导出类的父类，无论定义的顺序还是数量；不要动所有的虚函数，无论顺序还是数量。</p><p>总结起来，其实是一句话：导出类的DLL不要导出除了函数以外的任何内容。</p><h3 id="解决DLL-Hell的方法"><a href="#解决DLL-Hell的方法" class="headerlink" title="解决DLL Hell的方法"></a><strong>解决DLL Hell的方法</strong></h3><p>预防DLL Hell的方法有以下几种：</p><p><strong>防止DLL覆盖</strong><br>在Windows中，DLL的覆盖问题可以使用Windows文件保护（Windows File Protection WFP)技术来缓解。该技术从Windows2000开始使用。它能阻止未经授权的应用程序覆盖系统的DLL。第三方应用程序不能覆盖操作系统DLL文件，除非它们的安装程序捆绑了Windows更新包，或者在它们的安装程序运行时禁止WFP服务（当然这是一个非常危险的事）；</p><p><strong>避免DLL冲突（conflicting DLLs)</strong><br>解决不同应用程序依赖同名DLL不同版本的问题的一个方案是，让每个应用程序拥有一份自己依赖的DLL，并且把问题DLL的不同版本放到该应用程序的文件夹中，而不是系统DLL目录中，当应用程序需要安装DLL时候，首先从自己的文件夹下寻找所需要的DLL，然后再到系统文件夹中寻找。</p><p>.NET下DLL Hell的解决方案<br>在.NET框架中，一个程序集（Assembly）有两种类型：应用程序程序.exe和库程序.dll。一个程序集包括一个或多个文件，所以需要一个清单文件来描述程序集清单，这个清单文件叫做manifest文件。<br>Manifest文件描述了程序集的名字、版本号、本地文件资源以及程序集依赖的各种资源。Manifest是一个XML描述文件，每个DLL有自己的manifest，每个程序也有自己的manifest。对于应用程序而言，manifest可以和可执行文件在同一个目录下，也可以作为一个资源嵌入到可执行文件的内部(Embed Manifest)。</p><p>在XP之后，操作系统在执行可执行文件时会首先读取程序集的manifest文件，获得该可执行文件所需要的DLL列表，再根据具体的DLL名（包括了版本号等信息）去寻找相应的DLL文件。但是这意味Windows得保存一个DLL共享库的所有版本，已提供给系统精准的匹配。（参见\Winodws\WinSxS目录，该目录下有一系列的同名DLL不同版本的保存）</p><p><strong>对于每个版本DLL，它在WinSxS目录下都有独立的目录，这个目录命令规则要包含机器类型、DLL名字、公钥和版本号，这样多个不同版本的foo.dll就可以存在系统中而不冲突</strong>。但是这种方式过于死板，要求DLL版本等信息必须准确对应，所以这也是为什么Windows下的应用程序发布得自己配备所需的DLL的原因，因为很可能主机上没有你要的那个DLL版本。从这里一对比便可以看到，Linux的共享库版本符号机制便是一个好的设计。</p><h3 id="SO-NAME"><a href="#SO-NAME" class="headerlink" title="SO-NAME"></a><strong>SO-NAME</strong></h3><p>Linux 有了一套规则来命名系统中的每一个共享库，它规定共享库的文件命名规则必须如下：</p><p><strong>libname.so.x.y.z</strong></p><p>最前面使用前缀<strong>lib</strong>，中间为库的名字，后缀为**.so<strong>，后面跟着 <strong>3</strong> 个数字组成的版本号。”x”表示</strong>主版本号，”y”表示次版本号，”z”表示发布版本号。各版本号含义如下：</p><p><strong>主版本号</strong>表示库的重大升级，不同主版本号的库之间是不兼容的；</p><p><strong>次版本号</strong>表示库的增量升级，即增加一些新的接口符号，且保持原有符号不变；</p><p><strong>发布版本号</strong>表示库的一些错误修正、性能的改进等，并不增加任何新的接口，也不对接口进行更改。<strong>相同主、次版本号，不同发布版本号的库之间完全兼容，依赖于某个发布版号的程序可以在任何一个其他发布版本号中正常运行，而无需做任何修改</strong>。</p><p><em>现在的 Linux 中也存在不少不遵守上述规定的”顽固份子”，比如最基本的 C 语言库——Glibc</em>。</p><p><strong>SO-NAME 产生的原因</strong></p><p>严格遵守上述规定，确实能避免动态库因为版本冲突的问题，但是读者可能有疑问：在程序加载或运行的时候，动态链接器是如何知道程序依赖哪些库，如何选择库的不同版本？<br>Solaris和Linux等采用SO-NAME( Shortfor shared object name )的命名机制来记录共享库的依赖关系。每个共享库都有一个对应的“SO-NAME”(共享库文件名去掉次版本号和发布版本号)。比如一个共享库名为libtest.so.3.8.2,那么它的SO-NAME就是libtest.so.3。</p><p>在Linux系统中，系统会为每个共享库所在的目录创建一个跟SO-NAME相同的并且指向它的软连接(Symbol Link)。这个软连接会指向目录中主版本号相同、次版本号和发布版本号最新的共享库。也就是说，比如目录中有两个共享库版本分别为：&#x2F;lib&#x2F;libtest.so.3.8.2和&#x2F;lib&#x2F;libtest.so.3.7.5,么软连接&#x2F;lib&#x2F;libtest.so.3指向&#x2F;lib&#x2F;libtest.so.3.8.2。</p><p>建立以SO-NAME为名字的软连接的目的是，使得所有依赖某个共享库的模块，在编译、链接和运行时，都使用共享库的SO-NAME，而不需要使用详细版本号。在编译生产ELF文件时候，如果文件A依赖于文件B，那么A的链接文件中的”.dynamic”段中会有DT_NEED类型的字段，字段的值就是B的SO-NAME。<strong>这样当动态链接器进行共享库依赖文件查找时，就会依据系统中各种共享库目录中的SO-NAME软连接自动定向到最新兼容版本的共享库。</strong></p><p><strong>建立以 SO-NAME 为名字的软链接使得所有依赖某个共享库的模块，在编译、链接和运行时，都使用共享库的 SO-NAME，而不是使用详细的版本号</strong>。<br>Linux提供了一个工具——ldconfig，当系统中安装或更新一个共享库时，需要运行这个工具，它会遍历默认所有共享库目录，比如&#x2F;lib，&#x2F;usr&#x2F;lib等，然后更新所有的软链接，使她们指向最新共享库。</p><h2 id="显式运行时链接"><a href="#显式运行时链接" class="headerlink" title="显式运行时链接"></a>显式运行时链接</h2><p>支持动态链接的系统往往都支持一种更加灵活的模块加载方式，叫做显式运行时链接（Explicit Run-time Linking），有时候也叫做运行时加载。也就是让程序自己在运行时控制加载指定的模块，并且可以在不需要该模块时将其卸载。</p><p>这种运行时加载使得程序的模块组织变得很灵活，可以用来实现一些诸如插件、驱动等功能。当程序需要用到某个插件或者驱动的时候，才将相应的模块装载进来，而不需要从一开始就将他们全部装载进来，<strong>从而减少了程序启动时间和内存使用</strong>。并且程序可以在运行的时候重新加载某个模块，这样使得程序本身不必重新启动而实现模块的增加、删除、更新等，这对于很多需要长期运行的程序来说是很大的优势。最常见的例子是Web服务器程序，对于Web服务器程序来说，它需要根据配置来选择不同的脚本解释器、数据库连接驱动等，对于不同的脚本解释器分别做成一个独立的模块，当Web服务器需要某种脚本解释器的时候可以将其加载进来；这对于数据库连接的驱动程序也是一样的原理。另外对于一个可靠的Web服务器来说，长期的运行是必要的保证，如果我们需要增加某种脚本解释器，或者某个脚本解释器模块需要升级，则可以通知Web服务器程序重新装载该共享模块以实现相应的目的。</p><p>通过这四个API可以进行显式运行时链接：</p><pre><code class="text">dlopen()：打开动态链接库dlsym()：查找符号dlerror()：错误处理dlclose()：关闭动态链接库</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>为什么要进行动态链接：为了解决静态链接浪费空间和更新困难的缺点。</p><p>动态链接的方式：装载时重定位和地址无关代码技术。</p><p>地址无关代码技术原理：通过GOT段实现间接跳转。</p><p>延迟加载技术原理：对外部函数符号通过PLT段实现延迟绑定及间接跳转。</p><p>如果进行显式运行时链接：通过&lt;dlfcn.h&gt;头文件中的四个函数</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
      <url>/2023/01/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h1><h2 id="网络分层"><a href="#网络分层" class="headerlink" title="网络分层"></a>网络分层</h2><h3 id="为什么要有通用协议和分层"><a href="#为什么要有通用协议和分层" class="headerlink" title="为什么要有通用协议和分层"></a>为什么要有通用协议和分层</h3><p>一开始不同公司都推出属于自身的私有网络协议，相互之间无法兼容。</p><p>于是ISO(国际标准化组织)提出要制定通用的网络协议，这样就可以兼容多种多样的设备。于是ISO制订了一堆协议即OSI协议栈，</p><p>至于为什么要分层，这跟其他复杂系统分层的原因一样，可以将复杂系统简单化。</p><ol><li><strong>各层之间相互独立</strong>：各层之间相互独立，各层之间不需要关心其他层是如何实现的，只需要知道自己如何调用下层提供好的功能就可以了（可以简单理解为接口调用）。<strong>这个和我们对开发时系统进行分层是一个道理</strong>。</li><li><strong>提高了整体灵活性</strong> ：每一层都可以随时替换具体的实现，你只需要保证你提供的功能以及暴露的接口的规则没有改变就行了。<strong>这个和我们平时开发系统的时候要求的高内聚、低耦合的原则也是可以对应上的。</strong></li><li><strong>大问题化小</strong> ：分层可以将复杂的网络间题分解为许多比较小的、界线比较清晰简单的小问题来处理和解决。这样使得复杂的计算机网络系统变得易于设计，实现和标准化。 <strong>这个和我们平时开发的时候，一般会将系统功能分解，然后将复杂的问题分解为容易理解的更小的问题是相对应的，这些较小的问题具有更好的边界（目标和接口）定义。</strong></li></ol><h3 id="OSI七层模型"><a href="#OSI七层模型" class="headerlink" title="OSI七层模型"></a>OSI七层模型</h3><p><strong>应用层</strong>：</p><p>提供为应用软件而设计的接口，软件应用程序（如 Web 浏览器和电子邮件客户端）依靠应用层发起通信。</p><p>基于TCP协议：HTTP，HTTPS，SMTP，POP3，IMAP，NFS（也可以用UDP）</p><p>基于UDP协议：DNS（响应报文过大时会改用TCP，此外主从域名服务器之间通信同步数据时使用TCP），DHCP，RTP</p><p><strong>表示层：</strong> </p><p>把数据转换为能与接收者的系统格式兼容并适合传输的格式，确保数据可供应用程序使用。如加密解密、转换翻译、压缩解压缩。</p><p>两台相互通信的设备可能使用不同的编码方法，因此第 6 层负责将传入数据转换为接收设备应用程序层可以理解的语法。</p><p>如果设备通过加密连接进行通信，则第 6 层负责发送端加密和接收端解密，以便向应用程序层呈现非加密可读数据。</p><p>最后，表示层还负责压缩从应用程序层接收的数据，然后将数据传递到第 5 层。这有助于尽量减少要传输的数据量，从而提高通信速度和效率。</p><p>协议：SSL、TLS</p><p><strong>会话层：</strong></p><p>负责打开和关闭两个设备之间的通信。通信打开与关闭之间的时间称为会话。会话层用于确保会话保持打开的时长足以传输所有交换数据，而后立即关闭会话以避免浪费资源。</p><p>会话层还负责同步数据传输与检查点。例如，如果传输一个 100MB 的文件，会话层可以每 5MB 设置一个检查点。如果在传输了 52MB 后连接断开或崩溃，可以从最后一个检查点恢复会话，也就是只需再传输 50MB 数据。若未设置检查点，则必须从头开始传输整个文件。</p><p>协议：</p><p><strong>传输层：</strong></p><p>第 4 层负责两个设备间的端到端通信(进程到进程)。包括从会话层提取数据，将数据分解为多个数据段（因为网络层有传输容量要求），然后再发送到第 3 层。接收设备传输层负责重组数据段，确保数据可供会话层使用。</p><p>传输层还负责进行流量控制和错误控制。流量控制用于确定最佳传输速度，避免采用快速连接的发送方压垮采用慢速连接的接收方。传输层通过确保接收数据的完整性（如果不完整，则请求重新传输）来对接收端进行错误控制。</p><p>协议：TCP、UDP</p><p><strong>网络层：</strong></p><p>网络层负责促进两个不同网络之间主机到主机之间的数据传输。如果两个通信设备位于同一网络，则不需要使用网络层。如果数据太大而无法在数据链路层上从一个节点传输到另一个节点，则网络层可以将数据段拆分为多个片段（称为数据包），独立发送数据包，并在接收设备上重新组装数据包来实现数据传递。</p><p>网络层还要确定数据到达目的地所需的最佳物理路径，称为路由。</p><p>协议：IP、ICMP</p><p><strong>数据链路层：</strong></p><p>数据链路层与网络层十分相似，但数据链路层用于促进<strong>同一网络</strong>上两个设备之间的数据传输。数据链路层从网络层提取数据包并将数据包分解成更小的部分（称为帧）。它提供错误控制。它定义了在两个物理连接的设备之间建立和终止连接的协议。它还定义了它们之间的流量控制协议。</p><p>协议：MAC，LLC，PPP</p><p><strong>物理层：</strong></p><p>物理层负责在设备（例如网络接口控制器、以太网集线器或网络交换机）与物理传输介质之间传输和接收原始数据(0&#x2F;1)。它将0&#x2F;1转换为电、无线电或光信号。层规范定义了诸如电压电平、电压变化时间、物理数据速率、最大传输距离、调制方案、信道访问方法和物理连接器等特性。物理层规范包含在普遍存在的蓝牙、以太网和 USB 标准的规范中。</p><p>物理层还指定如何在物理信号（例如电压或光脉冲）上进行编码。例如，铜线上的 1 位可能通过从 0 伏到 5 伏信号的转换来表示，而 0 位可能通过从 5 伏信号到 0 伏信号的转换来表示。</p><p>协议：CAN，RS232，RJ45</p><h3 id="TCP-x2F-IP-网络模型"><a href="#TCP-x2F-IP-网络模型" class="headerlink" title="TCP&#x2F;IP 网络模型"></a>TCP&#x2F;IP 网络模型</h3><p>TCP&#x2F;IP 出现时间更早于OSI，但一开始只有协议没有模型，后来OSI出现后与OSI七层模型进行了相对应，划分了四层模型。因为在OSI出现之时已有大量商家支持TCP&#x2F;IP，加上OSI功能太多，太过复杂，TCP&#x2F;IP成了实际使用的网络模型。</p><p><strong>应用层</strong>：</p><p>对应OSI中的应用、表示、会话层</p><p><strong>传输层：</strong></p><p>对应OSI中的传输层</p><p><strong>网络层：</strong></p><p>对应OSI中的网络层</p><p><strong>网络接口层：</strong></p><p>对应OSI中的数据链路层和物理层</p><h2 id="键入网址到网页显示期间发生了什么？"><a href="#键入网址到网页显示期间发生了什么？" class="headerlink" title="键入网址到网页显示期间发生了什么？"></a>键入网址到网页显示期间发生了什么？</h2><p>1.解析 URL</p><p>首先浏览器做的第一步工作就是要对 <code>URL</code> 进行解析，从而生成发送给 <code>Web</code> 服务器的请求信息。</p><p>2.生成http请求</p><p>对 <code>URL</code> 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来就是根据这些信息来生成 HTTP 请求消息了。</p><p>3.DNS查询目的地IP地址</p><p>通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 <code>Web</code> 服务器。</p><p>但在发送之前，还有一项工作需要完成，那就是<strong>查询服务器域名对应的 IP 地址</strong>，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址。</p><p>浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地 DNS 服务器」。</p><p>客户端会发出一个 DNS 请求，问 <a href="http://www.server.com/">www.server.com</a> 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP&#x2F;IP 设置中填写的 DNS 服务器地址）。</p><p>本地域名服务器收到客户端的请求后，如果缓存能找到 <a href="http://www.server.com,则它直接返回/">www.server.com，则它直接返回</a> IP 地址。如果没有，本地 DNS 会去问它的根域名服务器</p><p>根域名服务器收到来自本地 DNS 的请求后，发现后置是 .com，返回.com 顶级域名服务器地址</p><p>本地 DNS 收到顶级域名服务器的地址后，向顶级域名服务器发起请求问<a href="http://www.server.com/">www.server.com</a> 的 IP 地址，依次迭代直到查询到服务器对应的IP地址</p><p>4.将HTTP请求报文传给TCP&#x2F;IP协议栈</p><p>TCP&#x2F;IP协议栈实现了客户端和服务器进程到进程之间的数据传输</p><p>报文依次加上TCP首部、IP首部、MAC首部后从网卡发送出去</p><p>5.网卡将报文转换为电信号从网线发送出去</p><p>网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将<strong>数字信息转换为电信号</strong>，才能在网线上传输，也就是说，这才是真正的数据发送过程。</p><p>负责执行这一操作的是网卡，要控制网卡还需要靠网卡驱动程序。</p><p>网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。</p><p>最后网卡会将包转为电信号，通过网线发送出去。</p><p>6.通过交换机和路由器层层转发将报文传输到服务器</p><p>交换机用于同一网络下设备间的数据传输，基于MAC地址转发。分割了冲突域但没分割广播域，同一网络下的设备之间可以自由通信，交换机无法控制</p><p>而路由器用于不同网络设备间的数据传输，基于IP地址转发。分割了广播域，不同的广播域的通信必须流经路由器，路由器可以控制数据能不能通过；同时路由器的不同端口可以分别连接不同的网络，如一个连以太网，另一个连PPP</p><p>7.服务器的 HTTP 进程把客户端请求资源封装在 HTTP 响应报文里发送给客户端</p><p>8.客户端收到响应报文后，将页面交给浏览器渲染</p><h2 id="LINUX收发数据流程"><a href="#LINUX收发数据流程" class="headerlink" title="LINUX收发数据流程"></a>LINUX收发数据流程</h2><h3 id="Linux-接收网络包的流程"><a href="#Linux-接收网络包的流程" class="headerlink" title="Linux 接收网络包的流程"></a>Linux 接收网络包的流程</h3><p>网卡是计算机里的一个硬件，专门负责接收和发送网络包，当网卡接收到一个网络包后，会通过 DMA 技术，将网络包放入到 Ring Buffer，这个是一个环形缓冲区。</p><p>当有网络包到达时，网卡发起硬件中断，于是会执行网卡硬件中断处理函数，中断处理函数处理完需要<strong>暂时屏蔽中断</strong>，然后唤醒<strong>软中断</strong>来<strong>轮询处理数据</strong>，直到没有新数据时才恢复中断，这样<strong>一次中断处理多个网络包</strong>，于是就可以降低网卡中断带来的性能开销。</p><p>那软中断是怎么处理网络包的呢？它会从 Ring Buffer 中拷贝数据到内核 struct sk_buff 缓冲区中，从而可以作为一个网络包交给网络协议栈进行逐层处理。</p><p>首先，会先进入到网络接口层，在这一层会检查报文的合法性，如果不合法则丢弃，合法则会找出该网络包的上层协议的类型，比如是 IPv4，还是 IPv6，接着再去掉帧头和帧尾，然后交给网络层。</p><p>到了网络层，则取出 IP 包，判断网络包下一步的走向，比如是交给上层处理还是转发出去。当确认这个网络包要发送给本机后，就会从 IP 头里看看上一层协议的类型是 TCP 还是 UDP，接着去掉 IP 头，然后交给传输层。</p><p>传输层取出 TCP 头或 UDP 头，根据四元组「源 IP、源端口、目的 IP、目的端口」 作为标识，找出对应的 Socket，并把数据拷贝到 Socket 的接收缓冲区。</p><p>最后，应用层程序调用 Socket 接口，从内核的 Socket 接收缓冲区读取新到来的数据到应用层。</p><h3 id="Linux-发送网络包的流程"><a href="#Linux-发送网络包的流程" class="headerlink" title="Linux 发送网络包的流程"></a>Linux 发送网络包的流程</h3><p>发送网络包的流程正好和接收流程相反。</p><p>首先，应用程序会调用 Socket 发送数据包的接口，由于这个是系统调用，所以会从用户态陷入到内核态中的 Socket 层，Socket 层会将应用层数据拷贝到 Socket 发送缓冲区中。</p><p>接下来，网络协议栈从 Socket 发送缓冲区中取出数据包，并按照 TCP&#x2F;IP 协议栈从上到下逐层处理。</p><p>如果使用的是 TCP 传输协议发送数据，那么会在传输层增加 TCP 包头，然后交给网络层，网络层会给数据包增加 IP 包，然后通过查询路由表确认下一跳的 IP，并按照 MTU 大小进行分片。</p><p>分片后的网络包，就会被送到网络接口层，在这里会通过 ARP 协议获得下一跳的 MAC 地址，然后增加帧头和帧尾，放到发包队列中。</p><p>这一些准备好后，会触发软中断告诉网卡驱动程序，这里有新的网络包需要发送，最后驱动程序通过 DMA，从发包队列中读取网络包，将其放入到硬件网卡的队列中，随后物理网卡再将它发送出去。</p><p><img src="https://github.com/hufei96/Image/blob/main/linuxnetcommunicate.png?raw=true" alt="linuxnetcommunicate.png"></p><h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><p>HTTP 是超文本传输协议，也就是<strong>H</strong>yperText <strong>T</strong>ransfer <strong>P</strong>rotocol。超文本就是<strong>超越了普通文本的文本</strong>，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。</p><p>HTTP 是一个在计算机世界里专门在<strong>两点</strong>之间传输文字、图片、音频、视频等<strong>超文本</strong>数据的<strong>约定和规范</strong>。</p><p>浏览器（browser），不管是chrome还是IE，它们不仅要能访问自家公司的服务器（server），还需要访问其他公司的网站服务器，因此它们需要有个统一的标准，不然大家没法交流。于是，HTTP就是那个时代用于统一 browser&#x2F;server (b&#x2F;s) 的协议。</p><p>tcp协议只是字节流，接收方收到数据后不一定能理解发送方的意思。http协议相当于定义了说话的规则。HTTP定义了请求对象和响应对象，各种头字段，消息的边界，有了http发送方和接收方才能相互明白。</p><p>Http被设计为客户端发送请求，服务器给出响应的一问一答形式进行通信。<strong>这就意味着如果客户端不主动地向服务器发送消息，服务器就无法主动给客户端推送消息。</strong>这是http的一大缺陷。</p><h3 id="常用状态码"><a href="#常用状态码" class="headerlink" title="常用状态码"></a>常用状态码</h3><p><img src="https://github.com/hufei96/Image/blob/main/HTTPcode.png?raw=true" alt="HTTPcode.png"></p><p><code>1xx</code> 类状态码属于<strong>提示信息</strong>，是协议处理中的一种中间状态，实际用到的比较少。</p><p><code>2xx</code> 类状态码表示服务器<strong>成功</strong>处理了客户端的请求，也是我们最愿意看到的状态。</p><ul><li>「<strong>200 OK</strong>」是最常见的成功状态码，表示一切正常。如果是非 <code>HEAD</code> 请求，服务器返回的响应头都会有 body 数据。</li><li>「<strong>204 No Content</strong>」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。</li><li>「<strong>206 Partial Content</strong>」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。</li></ul><p><code>3xx</code> 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是<strong>重定向</strong>。</p><ul><li>「<strong>301 Moved Permanently</strong>」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。</li><li>「<strong>302 Found</strong>」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。</li></ul><p>301 和 302 都会在响应头里使用字段 <code>Location</code>，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。</p><ul><li>「<strong>304 Not Modified</strong>」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。</li></ul><p><code>4xx</code> 类状态码表示客户端发送的<strong>报文有误</strong>，服务器无法处理，也就是错误码的含义。</p><ul><li>「<strong>400 Bad Request</strong>」表示客户端请求的报文有错误，但只是个笼统的错误。</li><li>「<strong>403 Forbidden</strong>」表示服务器禁止访问资源，并不是客户端的请求出错。</li><li>「<strong>404 Not Found</strong>」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。</li></ul><p><code>5xx</code> 类状态码表示客户端请求报文正确，但是<strong>服务器处理时内部发生了错误</strong>，属于服务器端的错误码。</p><ul><li>「<strong>500 Internal Server Error</strong>」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。</li><li>「<strong>501 Not Implemented</strong>」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。</li><li>「<strong>502 Bad Gateway</strong>」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。</li><li>「<strong>503 Service Unavailable</strong>」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。</li></ul><h3 id="报文常用字段"><a href="#报文常用字段" class="headerlink" title="报文常用字段"></a>报文常用字段</h3><p><em>Host</em> 字段</p><p>客户端发送请求时，用来指定服务器的域名。有了 <code>Host</code> 字段，就可以将请求发往「同一台」服务器上的不同网站。</p><p><em>Content-Length 字段</em></p><p>服务器在返回数据时，会有 <code>Content-Length</code> 字段，表明本次回应的数据长度。</p><p><em>Connection 字段</em></p><p><code>Connection</code> 字段最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。HTTP&#x2F;1.1 版本的默认连接都是持久连接，但为了兼容老版本的 HTTP，需要指定 <code>Connection</code> 首部字段的值为 <code>Keep-Alive</code>。</p><p><em>Content-Type 字段</em></p><p><code>Content-Type</code> 字段用于服务器回应时，告诉客户端，本次数据是什么格式。如Content-Type: text&#x2F;html; charset&#x3D;utf-8。客户端请求的时候，可以使用 <code>Accept</code> 字段声明自己可以接受哪些数据格式。</p><p><em>Content-Encoding 字段</em></p><p><code>Content-Encoding</code> 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式。客户端在请求时，用 <code>Accept-Encoding</code> 字段说明自己可以接受哪些压缩方法。</p><h3 id="GET和POST区别"><a href="#GET和POST区别" class="headerlink" title="GET和POST区别"></a>GET和POST区别</h3><p>根据 RFC 规范，<strong>GET 的语义是从服务器获取指定的资源</strong>，这个资源可以是静态的文本、页面、图片视频等。</p><p>根据 RFC 规范，<strong>POST 的语义是根据请求负荷（报文body）对指定的资源做出处理</strong>，具体的处理方式视资源类型而不同。</p><p><em>区别</em></p><p>1.一般而言，GET 请求的参数位置写在 URL 中，POST 请求携带数据的位置写在报文 body 中。</p><p>URL 规定只能支持 ASCII码，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制(规范无限制)。</p><p> body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。</p><p>2.GET请求会被浏览器主动cache，而POST不会，除非手动设置。</p><p>3.<code>POST </code>比<code> GET</code> 安全，因为数据在地址栏上不可见</p><p>然而，从传输的角度来说，他们都是不安全的，因为<code> HTTP</code> 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文</p><p>只有使用<code>HTTPS</code>才能加密安全、</p><p>4.GET产生一个TCP数据包，而POST产生两个TCP数据包。</p><p>对于<code>GET</code>方式的请求，浏览器会把<code>http header</code>和<code>data</code>一并发送出去，服务器响应200（返回数据）</p><p>对于<code>POST</code>，浏览器先发送<code>header</code>，服务器响应100 <code>continue</code>，浏览器再发送<code>data</code>，服务器响应200 ok</p><p>并不是所有浏览器都会在<code>POST</code>中发送两次包，<code>Firefox</code>就只发送一次</p><p>实际二者区别完全取决于客户端和服务器的协商。开发过程中，开发者不一定会按照 RFC 规范定义的语义来实现 GET 和 POST 方法。可以用 GET 方法实现新增或删除数据的请求，也可以用 POST 方法实现查询数据的请求。同理，GET可以使用body，POST也可以使用URL，一切取决于开发者。</p><h3 id="HTTP有哪几种缓存"><a href="#HTTP有哪几种缓存" class="headerlink" title="HTTP有哪几种缓存"></a>HTTP有哪几种缓存</h3><p>对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都缓存在本地，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了。</p><p>HTTP 缓存有两种实现方式，分别是<strong>强制缓存和协商缓存</strong>。</p><p><em><strong>强制缓存</strong></em></p><p>强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用<strong>缓存的主动性在于浏览器</strong>这边。</p><p>如下，返回的是 200 状态码，但在 size 项中标识的是 from disk cache，就是使用了强制缓存。</p><p><em>Status Code:200(from disk cache)</em></p><p>强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：</p><ul><li><code>Cache-Control</code>， 是一个相对时间；</li><li><code>Expires</code>，是一个绝对时间；</li></ul><p>如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，<strong>Cache-Control的优先级高于 Expires</strong> 。</p><p>Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下：</p><ul><li>当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；</li><li>浏览器再次请求访问服务器中的该资源时，会先<strong>通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期</strong>，如果没有，则使用该缓存，否则重新请求服务器；</li><li>服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。</li></ul><p><em><strong>协商缓存</strong></em></p><p>你可能看到过某些请求的响应码是 <code>304</code>，这个是告诉浏览器可以使用本地缓存的资源。与服务端协商之后，通过协商结果来判断是否使用本地缓存，这种通过<strong>服务端告知客户端是否可以使用缓存</strong>的方式被称为协商缓存。只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。</p><p>协商缓存可以基于两种头部来实现。</p><p>第一种：请求头部中的 <code>If-Modified-Since</code> 字段与响应头部中的 <code>Last-Modified</code> 字段实现，这两个字段的意思是：</p><ul><li>响应头部中的 <code>Last-Modified</code>：标示这个响应资源的最后修改时间；</li><li>请求头部中的 <code>If-Modified-Since</code>：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。</li></ul><p>第二种：请求头部中的 <code>If-None-Match</code> 字段与响应头部中的 <code>ETag</code> 字段，这两个字段的意思是：</p><ul><li>响应头部中 <code>Etag</code>：唯一标识响应资源；</li><li>请求头部中的 <code>If-None-Match</code>：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。</li></ul><p>第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。</p><p>如果 HTTP 响应头部同时有 Etag 和 Last-Modified 字段的时候， Etag 的优先级更高，也就是先会判断 Etag 是否变化了，如果 Etag 没有变化，然后再看 Last-Modified。</p><p>注意，<strong>协商缓存这两个字段都需要配合强制缓存中 Cache-control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求</strong>。</p><p>使用 ETag 字段实现的协商缓存的过程如下；</p><ul><li><p>当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的；</p></li><li><p>当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期，如果没有过期，则直接使用本地缓存；如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识；</p></li><li><p>服务器再次收到请求后，</p><p>会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较：</p><ul><li><strong>如果值相等，则返回 304 Not Modified，不会返回资源</strong>；</li><li>如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识；</li></ul></li><li><p>如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。</p></li></ul><h3 id="HTTP无状态"><a href="#HTTP无状态" class="headerlink" title="HTTP无状态"></a>HTTP无状态</h3><p>HTTP是无状态的协议，因为它的每个请求都是完全独立的，每个请求包含了处理这个请求所需的完整的数据，每一个请求发生时都不需要去回忆过去的请求产生了什么样的记忆，发送请求不涉及到状态变更。即使在HTTP&#x2F;1.1上，同一个连接允许传输多个HTTP请求的情况下，如果第一个请求出错了，后面的请求一般也能够继续处理。这里必须非常明确，无状态的仅仅是 HTTP 这一层，在此之上我们可以搭建有状态的应用层。</p><p>作为对比，SMTP协议，它的第一条消息必须是HELO，用来握手，在HELO发送之前其他任何命令都是不能发送的；接下来一般要进行AUTH阶段，用来验证用户名和密码；接下来可以发送邮件数据；最后，通过QUIT命令退出。可以看到，在整个传输层上，通信的双方是必须要时刻记住当前连接的状态的，因为不同的状态下能接受的命令是不同的；另外，之前的命令传输的某些数据也必须要记住，可能会对后面的命令产生影响。这种就叫做有状态的协议。</p><p><strong>无状态的优点</strong></p><p>1.协议的结构比有状态的协议更简单，一般来说实现起来也更简单，不需要使用状态机，一个循环就行了。</p><p>2.请求相互独立，前面请求出错不会影响后面的请求。</p><p><strong>无状态的缺点</strong></p><p>主要缺点在于，单个请求需要的所有信息都必须要包含在请求中一次发送到服务端，这导致单个消息的结构需要比较复杂，必须能够支持大量元数据，因此HTTP消息的解析要比其他许多协议都要复杂得多。同时，这也导致了相同的数据在多个请求上往往需要反复传输，例如同一个连接上的每个请求都需要传输Host、Authentication、Cookies、Server等往往是完全重复的元数据，一定程度上降低了协议的效率。</p><h3 id="cookie，session和token"><a href="#cookie，session和token" class="headerlink" title="cookie，session和token"></a>cookie，session和token</h3><p><em><strong>session</strong></em></p><p>由于HTTP协议是无状态的协议，所以服务端需要记录用户的状态时，就需要用某种机制来识具体的用户，session就是其中的一种。服务端为每个用户创建了特定的Session用于标识这个用户，Session里面存储着该用户的购物车等详细信息，服务器可以通过这些信息返回该用户的定制化网页，有效解决了追踪用户的问题。</p><p>第一次建立连接时会发一个会话标识给客户(session id)， 说白了就是一个随机的字串，每个人收到的都不一样， 每次客户端向服务器发起HTTP请求的时候，把这个字符串给一并捎过来， 这样服务器就能区分开谁是谁了。</p><p>总结：session 是一个数据结构，由网站的开发者设计，保存在服务器，有一个唯一标识session id，只要客户端传来一个唯一的 session ID，服务器就可以找到对应的 session，认出这个客户。</p><p><em><strong>cookie</strong></em></p><p>Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。</p><p>cookie由服务器生成，发送给浏览器，浏览器把cookie以kv键值对形式保存到某个目录下的文本文件内，下一次请求同一网站时会把该cookie发送给服务器，这样服务器就通过cookie识别了用户的身份。</p><p>可以将session id存在cookie中，将 session ID 通过 cookie 的形式传送给客户端，这样客户端每次发送cookie的同时也发送了session id，所以说cookie可以用来实现session，但这只是session实现方式的一种。若客户端禁用了cookie，还可以通过使用url重写的方式使用session，即每次HTTP交互，URL后面都会被附加上一个诸如 sid&#x3D;xxxxx 这样的参数，服务端据此来识别用户。</p><p><em><strong>token</strong></em></p><p>session存在一定的缺陷：服务器要保存所有人的session id并在客户端请求时进行验证，这对服务器说是一个巨大的开销 ， 严重的限制了服务器扩展能力，比如说我用两个机器组成了一个集群， 小F通过机器A登录了系统， 那session id会保存在机器A上， 假设小F的下一次请求被转发到机器B怎么办？ 机器B没有小F的 session id。那只好做session 的复制了， 把session id 在两个机器复制一份，这样开销很大。</p><p>或者把session id 集中存储到一个地方， 所有的机器都来访问这个地方的数据， 这样一来，就不用复制了， 但是增加了单点失败的可能性， 要是那个负责session 的机器挂了， 所有人都得重新登录一遍。</p><p>于是有人就一直在思考， 让每个客户端去保存session不就可以解决这个问题了吗。</p><p>基于这个思想，token产生了。</p><p>token就是一个令牌，里面是加密的user id和user id的数字签名。客户端在连接时，服务器会生成一份token发给客户端，客户端每次连接时带上token，服务器只需验证token是否合法即可。</p><p>token 和 session 的验证机制最大的区别是用“签名验证机制”代替了“白名单验证机制”。</p><p>session 的问题在于前端传来的 session_id 可以伪造，所以必须在服务器维护一个 session_id 的白名单来验证 session_id 的合法性。token 的改进之处就在这里，token 通过签名机制，只要前端传来的 token 能通过签名认证就是合法的，不需要服务器维护任何东西，所有的需要东西都放在在 token 里面。</p><p><strong>安全问题</strong></p><p>浏览器的跨域+XSRF限制杜绝了钓鱼网站获取token；https杜绝了中间人劫持。</p><h3 id="cookie，localStorage，sessionStorage-的区别"><a href="#cookie，localStorage，sessionStorage-的区别" class="headerlink" title="cookie，localStorage，sessionStorage 的区别"></a>cookie，localStorage，sessionStorage 的区别</h3><p>cookie是在HTML4中使用的给客户端保存数据的，也可以和session配合实现跟踪浏览器用户身份；</p><p>而webstorage（包括：localStorage和sessionStorage）是在HTML5提出来的，纯粹为了保存数据，不会与服务器端通信。</p><p>WebStorage两个主要目标：（1）提供一种在cookie之外存储会话数据的路径。（2）提供一种存储大量可以跨会话存在的数据的机制。</p><p>相同点：</p><p> cookie，localStorage，sessionStorage都是在客户端保存数据的，存储数据的类型：都是字符串。</p><p>不同点：</p><p>1、生命周期：</p><p>localStorage 存储<strong>持久数据</strong>，浏览器关闭后数据<strong>不丢失</strong>除非主动删除数据；</p><p>sessionStorage 数据在当前浏览器窗口关闭后<strong>自动删除</strong>。</p><p>cookie 设置的cookie<strong>过期时间</strong>之前一直有效，即使窗口或浏览器关闭</p><p>2、网络流量：cookie的数据每次都会发给服务器端，而localstorage和sessionStorage不会与服务器端通信，纯粹为了保存数据，所以，webstorage更加节约网络流量。</p><p>3、大小限制：cookie大小限制在4KB，非常小；localstorage和sessionStorage在5M</p><p>4、安全性：WebStorage不会随着HTTP header发送到服务器端，所以安全性相对于cookie来说比较高一些，不会担心截获。</p><p>5、使用方便性上：WebStorage提供了一些方法，数据操作比cookie方便；</p><h3 id="HTTP-x2F-1-1、HTTP-x2F-2、HTTP-x2F-3-演变"><a href="#HTTP-x2F-1-1、HTTP-x2F-2、HTTP-x2F-3-演变" class="headerlink" title="HTTP&#x2F;1.1、HTTP&#x2F;2、HTTP&#x2F;3 演变"></a>HTTP&#x2F;1.1、HTTP&#x2F;2、HTTP&#x2F;3 演变</h3><h4 id="HTTP-x2F-1-1-相比-HTTP-x2F-1-0-提高了什么性能？"><a href="#HTTP-x2F-1-1-相比-HTTP-x2F-1-0-提高了什么性能？" class="headerlink" title="HTTP&#x2F;1.1 相比 HTTP&#x2F;1.0 提高了什么性能？"></a>HTTP&#x2F;1.1 相比 HTTP&#x2F;1.0 提高了什么性能？</h4><p>HTTP&#x2F;1.1 相比 HTTP&#x2F;1.0 性能上的改进：</p><ul><li>使用长连接的方式改善了 HTTP&#x2F;1.0 短连接造成的性能开销。</li><li>支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。</li></ul><p>但 HTTP&#x2F;1.1 还是有性能瓶颈：</p><ul><li>请求 &#x2F; 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 <code>Body</code> 的部分；</li><li>发送冗长的首部。每次互相发送相同的首部造成的浪费较多；</li><li>服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是<strong>队头阻塞</strong>；</li><li>没有请求优先级控制；</li><li>请求只能从客户端开始，服务器只能被动响应。</li></ul><h4 id="HTTP-x2F-2-做了什么优化？"><a href="#HTTP-x2F-2-做了什么优化？" class="headerlink" title="HTTP&#x2F;2 做了什么优化？"></a>HTTP&#x2F;2 做了什么优化？</h4><p>HTTP&#x2F;2 相比 HTTP&#x2F;1.1 性能上的改进：</p><p><em>1. 头部压缩</em></p><p>HTTP&#x2F;2 会<strong>压缩头</strong>（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你<strong>消除重复的部分</strong>。</p><p>这就是所谓的 <code>HPACK</code> 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就<strong>提高速度</strong>了。</p><p><em>2. 二进制格式</em></p><p>HTTP&#x2F;2 不再像 HTTP&#x2F;1.1 里的纯文本形式的报文，而是全面采用了<strong>二进制格式</strong>，头信息和数据体都是二进制，并且统称为帧（frame）：<strong>头信息帧（Headers Frame）和数据帧（Data Frame）</strong>。</p><p><em>3. 数据流</em></p><p>HTTP&#x2F;2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。</p><p>在 HTTP&#x2F;2 中每个请求或相应的所有数据包，称为一个数据流（<code>Stream</code>）。每个数据流都标记着一个独一无二的编号（Stream ID），<strong>不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）</strong>，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息</p><p>客户端和服务器<strong>双方都可以建立 Stream</strong>， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。</p><p>客户端还可以<strong>指定数据流的优先级</strong>。优先级高的请求，服务器就先响应该请求。</p><p><em>4. 多路复用</em></p><p>HTTP&#x2F;2 是可以在<strong>一个连接中并发多个请求或回应，而不用按照顺序一一对应</strong>。</p><p>移除了 HTTP&#x2F;1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，<strong>降低了延迟，大幅度提高了连接的利用率</strong>。</p><p><em>5. 服务器推送</em></p><p>HTTP&#x2F;2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以<strong>主动</strong>向客户端发送消息。</p><p>比如，客户端通过 HTTP&#x2F;1.1 请求从服务器那获取到了 HTML 文件，而 HTML 可能还需要依赖 CSS 来渲染页面，这时客户端还要再发起获取 CSS 文件的请求，需要两次消息往返，此时服务器可以直接主动推送 CSS 文件，减少了消息传递的次数。</p><p><em><strong>HTTP&#x2F;2 有什么缺陷？</strong></em></p><p>HTTP&#x2F;2 是基于 TCP 协议来传输数据的，一旦发生了丢包现象，就会触发 TCP 的重传机制，一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。<strong>这就是 HTTP&#x2F;2 队头阻塞问题。</strong></p><h4 id="HTTP-x2F-3-做了哪些优化？"><a href="#HTTP-x2F-3-做了哪些优化？" class="headerlink" title="HTTP&#x2F;3 做了哪些优化？"></a>HTTP&#x2F;3 做了哪些优化？</h4><p>前面我们知道了 HTTP&#x2F;1.1 和 HTTP&#x2F;2 都有队头阻塞的问题：</p><ul><li>HTTP&#x2F;1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是<strong>没有解决响应的队头阻塞</strong>，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等相应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。</li><li>HTTP&#x2F;2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是<strong>一旦发生丢包，就会阻塞住所有的 HTTP 请求</strong>，这属于 TCP 层队头阻塞。</li></ul><p>HTTP&#x2F;2 队头阻塞的问题是因为 TCP，所以 <strong>HTTP&#x2F;3 把 HTTP 下层的 TCP 协议改成了 UDP！</strong></p><p>UDP 发生是不管顺序，也不管丢包的，所以不会出现像 HTTP&#x2F;2 队头阻塞的问题</p><p>大家都知道 UDP 是不可靠传输的，但基于 UDP 的 <strong>QUIC 协议</strong> 可以实现类似 TCP 的可靠性传输。</p><p>QUIC 有以下 3 个特点。</p><p><em>1、无队头阻塞</em></p><p>QUIC 协议也有类似 HTTP&#x2F;2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。</p><p>QUIC 有自己的一套机制可以保证传输的可靠性的。<strong>当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题</strong>。这与 HTTP&#x2F;2 不同，HTTP&#x2F;2 只要某个流中的数据包丢失了，其他流也会因此受影响。</p><p>所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。</p><p><em>2、更快的连接建立</em></p><p>对于 HTTP&#x2F;1 和 HTTP&#x2F;2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。</p><p>HTTP&#x2F;3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。</p><p>但是 HTTP&#x2F;3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS&#x2F;1.3，因此仅需三次握手即 1 个 RTT 就可以「同时」完成建立连接与密钥协商</p><p><em>3、连接迁移</em></p><p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接，那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接</strong>。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p><p>而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong>来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p><h3 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h3><h4 id="HTTP-与-HTTPS-有哪些区别？"><a href="#HTTP-与-HTTPS-有哪些区别？" class="headerlink" title="HTTP 与 HTTPS 有哪些区别？"></a>HTTP 与 HTTPS 有哪些区别？</h4><ol><li>HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL&#x2F;TLS 安全协议，使得报文能够加密传输。</li><li>HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL&#x2F;TLS 的握手过程，才可进入加密报文传输。</li><li>HTTP 的端口号是 80，HTTPS 的端口号是 443。</li><li>HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。</li></ol><p>HTTP 由于是明文传输，所以安全上存在以下三个风险：</p><ul><li><strong>窃听风险</strong>，比如通信链路上可以获取通信内容</li><li><strong>篡改风险</strong>，比如强制植入垃圾广告，视觉污染</li><li><strong>冒充风险</strong>，比如冒充淘宝网站</li></ul><p>HTTPS 在 HTTP 与 TCP 层之间加入了 <code>SSL/TLS</code>（TLS是SSL的更新版本，SSL因为安全问题已被弃用） 协议，可以很好的解决了上述的风险</p><ul><li><strong>混合加密</strong>的方式实现信息的<strong>机密性</strong>，解决了窃听的风险。</li><li><strong>摘要算法</strong>的方式来实现<strong>完整性</strong>，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。</li><li>将服务器公钥放入到<strong>数字证书</strong>中，解决了冒充的风险。</li></ul><p><em>1. 混合加密</em></p><p>通过<strong>混合加密</strong>的方式可以保证信息的<strong>机密性</strong>，解决了窃听的风险。</p><p>HTTPS 采用的是<strong>对称加密</strong>和<strong>非对称加密</strong>结合的「混合加密」方式：</p><ul><li>在通信建立前采用<strong>非对称加密</strong>的方式交换「会话秘钥」，后续就不再使用非对称加密。</li><li>在通信过程中全部使用<strong>对称加密</strong>的「会话秘钥」的方式加密明文数据。</li></ul><p>采用「混合加密」的方式的原因：</p><ul><li><strong>对称加密</strong>只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。</li><li><strong>非对称加密</strong>使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。</li></ul><p><em>2. 摘要算法 + 数字签名</em></p><p>为了保证传输的内容不被篡改，我们需要对内容计算出一个「哈希值」，然后同内容一起传输给对方。</p><p>对方收到后，先是对内容也计算出一个「哈希值」，然后跟发送方发送的「哈希值」做一个比较，如果「哈希值」相同，说明内容没有被篡改，否则就可以判断出内容被篡改了。</p><p>但这方法<strong>仍有缺陷</strong>，因为哈希值可以确保内容不被篡改，<strong>但是并不能保证「内容 + 哈希值」不会被中间人篡改，</strong>因为这里缺少对客户端收到的消息是否来源于服务端的证明。</p><p>那为了避免这种情况，计算机里会用<strong>非对称加密算法</strong>来解决，共有两个密钥：</p><ul><li>一个是公钥，这个是可以公开给所有人的；</li><li>一个是私钥，这个必须由本人管理，不可泄露。</li></ul><p>这两个密钥可以<strong>双向加解密</strong>的，比如可以用公钥加密内容，然后用私钥解密，也可以用私钥加密内容，公钥解密内容。</p><p>流程的不同，意味着目的也不相同：</p><ul><li><strong>公钥加密，私钥解密</strong>。这个目的是为了<strong>保证内容传输的安全</strong>，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；</li><li><strong>私钥加密，公钥解密</strong>。这个目的是为了<strong>保证消息不会被冒充</strong>，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。</li></ul><p>所以非对称加密的用途主要在于<strong>通过「私钥加密，公钥解密」的方式，来确认消息的身份</strong>，我们常说的<strong>数字签名算法</strong>，就是用的是这种方式，不过私钥加密内容不是内容本身，而是<strong>对内容的哈希值加密</strong>。</p><p><em>3. 数字证书</em></p><p>前面可知</p><ul><li>可以通过哈希算法来保证消息的完整性；</li><li>可以通过数字签名来保证消息的来源可靠性（能确认消息是由持有私钥的一方发送的）；</li></ul><p>但<strong>仍有缺陷</strong>，<strong>缺少身份验证的环节</strong>，如中间人在客户端服务器交换公钥的时候可以伪造公钥，从而达到冒充服务器的目的。</p><p>解决办法是服务器提前将公钥注册到CA（数字证书认证机构），CA会颁发数字证书，只要证书是可信的，公钥就是可信的。</p><p>具体而言，服务器提前将公钥注册到CA，CA会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包并算得一个哈希值，这个哈希值用CA的私钥加密得到一份数字签名，将签名和之前的信息打包形成数字证书颁发给服务器，客户端和服务器通信时，服务器就将这份数字证书发送给客户端，客户端通过CA的公钥（已事先放在浏览器或操作系统中）解密就得到了服务器的公钥。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png"></p><h4 id="HTTPS建立连接过程"><a href="#HTTPS建立连接过程" class="headerlink" title="HTTPS建立连接过程"></a>HTTPS建立连接过程</h4><p>SSL&#x2F;TLS 协议基本流程：</p><ul><li>客户端向服务器索要并验证服务器的公钥。</li><li>双方协商生产「会话秘钥」。</li><li>双方采用「会话秘钥」进行加密通信。</li></ul><p>SSL&#x2F;TLS 的「握手阶段」涉及<strong>四次</strong>通信</p><p>SSL&#x2F;TLS 协议建立的详细流程：</p><p><em>1. ClientHello</em></p><p>首先，由客户端向服务器发起加密通信请求，也就是 <code>ClientHello</code> 请求。</p><p>在这一步，客户端主要向服务器发送以下信息：</p><p>（1）客户端支持的 SSL&#x2F;TLS 协议版本，如 TLS 1.2 版本。</p><p>（2）客户端生产的随机数（<code>Client Random</code>），后面用于生成「会话秘钥」条件之一。</p><p>（3）客户端支持的密码套件列表，如 RSA 加密算法。</p><p><em>2. SeverHello</em></p><p>服务器收到客户端请求后，向客户端发出响应，也就是 <code>SeverHello</code>。服务器回应的内容有如下内容：</p><p>（1）确认 SSL&#x2F; TLS 协议版本，如果浏览器不支持，则关闭加密通信。</p><p>（2）服务器生产的随机数（<code>Server Random</code>），也是后面用于生产「会话秘钥」条件之一。</p><p>（3）确认的密码套件列表，如 RSA 加密算法。</p><p>（4）服务器的数字证书。</p><p><em>3.客户端回应</em></p><p>客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。</p><p>如果证书没有问题，客户端会<strong>从数字证书中取出服务器的公钥</strong>，然后使用它加密报文，向服务器发送如下信息：</p><p>（1）一个随机数（<code>pre-master key</code>）。该随机数会被服务器公钥加密。</p><p>（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p><p>（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。</p><p>上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。</p><p><strong>服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」</strong>。</p><p><em>4. 服务器的最后回应</em></p><p>服务器收到客户端的第三个随机数（<code>pre-master key</code>）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。</p><p>然后，向客户端发送最后的信息：</p><p>（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p><p>（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。</p><p>至此，整个 SSL&#x2F;TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。</p><h4 id="RSA密钥交换算法缺陷"><a href="#RSA密钥交换算法缺陷" class="headerlink" title="RSA密钥交换算法缺陷"></a>RSA密钥交换算法缺陷</h4><p><strong>使用 RSA 密钥协商算法的最大问题是不支持前向保密</strong>。</p><p>因为客户端传递随机数（用于生成对称加密密钥的条件之一）给服务端时使用的是公钥加密的，服务端收到到后，会用私钥解密得到随机数。所以一旦服务端的私钥泄漏了，<strong>过去被第三方截获的所有 TLS 通讯密文都会被破解</strong>。</p><p>为了解决这个问题，后面就出现了 ECDHE 密钥协商算法，我们现在大多数网站使用的正是 ECDHE 密钥协商算法</p><h4 id="ECDHE-握手解析"><a href="#ECDHE-握手解析" class="headerlink" title="ECDHE 握手解析"></a>ECDHE 握手解析</h4><p>ECDHE是基于离散对数的，并且它的私钥每次通信都是随机生成的，这就保证了前向安全，即使某次通信的私钥泄密也不会导致之前的报文都被解密。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/%E7%A6%BB%E6%95%A3%E5%AF%B9%E6%95%B0.png" alt="离散对数"></p><p>客户端和服务器使用 ECDHE 密钥交换算法的过程：</p><ul><li>双方事先确定好使用哪种椭圆曲线，和曲线上的基点 G，这两个参数都是公开的；</li><li>双方各自随机生成一个随机数作为<strong>私钥d</strong>，并与基点 G相乘得到<strong>公钥Q</strong>（Q &#x3D; dG），此时客户端的公私钥为 Q1 和 d1，服务器的公私钥为 Q2 和 d2；</li><li>双方加密交换各自的公钥（通过CA证书中服务器的公钥加密），最后客户端计算点（x1，y1） &#x3D; d1Q2，服务器计算点（x2，y2） &#x3D; d2Q1，由于椭圆曲线上是可以满足乘法交换和结合律，所以 d1Q2 &#x3D; d1d2G &#x3D; d2d1G &#x3D; d2Q1 ，因此<strong>双方的 x 坐标是一样的，所以它是共享密钥，也就是会话密钥</strong>。</li></ul><p>对于ECDHE算法需要破解两次私钥（服务器私钥 + 椭圆曲线私钥），且椭圆曲线私钥每次握手都会随机生成，保证了向前安全性。</p><h3 id="解决http服务器端推送消息问题"><a href="#解决http服务器端推送消息问题" class="headerlink" title="解决http服务器端推送消息问题"></a>解决http服务器端推送消息问题</h3><h4 id="meta标签"><a href="#meta标签" class="headerlink" title="meta标签"></a>meta标签</h4><p>在 Web早期，通过配置meta标签让浏览器自动刷新，从而实现服务器端的推送</p><pre><code class="html"> &lt;META HTTP-RQUIV=&quot;Refresh&quot; CONTENT=12&gt;</code></pre><p>优点：使用方式简单，可以在JS禁用情况下使用<br>缺点：不是实时更新数据，对服务器造成的压力大，带宽浪费多。并且每次都会更新整个页面</p><h4 id="AJAX轮询"><a href="#AJAX轮询" class="headerlink" title="AJAX轮询"></a>AJAX轮询</h4><p>Ajax(Asynchronous JavaScript and XML)，即异步 JavaScript 和 XML。</p><p>它可以通过和服务器的交互实现网页中部分信息的更新，这就使得我们在只需要进行少数数据更新的情况下，避免整个网页数据的再次加载，提升了开发性能。</p><p>举个例子就是说；现在你要注册一个网站，成为正式用户，然后有一大堆的信息录入表等你填写，这个时候你已经填了好多内容了，有个地方需要你输入验证码，然后呢，你表示看不清楚想要换一张验证码，这个时候，如果用普通的数据刷新请求方式去处理获取新的验证码的话，随之而来的问题就是，验证码虽然刷新了，但是你之前好不容易填写的一堆个人信息也被刷新了，没了，是不是很无语。</p><p>这就是Web的运作原理：一次HTTP请求对应一个页面。</p><p>如果要让用户留在当前页面中，同时发出新的HTTP请求，就必须用JavaScript发送这个新请求，接收到数据后，再用JavaScript更新页面，这样一来，用户就感觉自己仍然停留在当前页面，但是数据却可以不断地更新。所以，这种情况下，我们就需要使用Ajax这种部分内容刷新的请求方式去进行数据请求，从而达到更加高效快捷的更新网页内容的效果。</p><p>AJAX轮询即定时的通过Ajax查询服务器端，客户端定时向服务器端发送ajax请求，服务器端接收到请求后马上响应信息并关闭连接。要求两次请求间隔时间必须尽可能的小，但若时间间隔减小，客户端浏览器在相同时间内就会发出更多的请求，这些请求中大部分都不会返回有用的数据，这会白白地浪费掉带宽和处理资源。。</p><p>当我们利用AJAX实现服务器推送时，其实质是客户端不停地向服务器询问”有没有给我的消息呀？”，然后服务器回答”有”或”没有”来达到的实现效果。</p><p><strong>优点:</strong><br>服务端逻辑简单，编码实现简单。<br><strong>缺点:</strong><br>这是通过模拟服务器发起的通信，<strong>不是实时通信</strong>，不顾及应用的状态改变而盲目检查更新，导致服务器资源的浪费，且会加重网络负载，拖累服务器。其中大多数请求可能是无效请求，在大量用户轮询很频繁的情况下对服务器的压力很大。</p><h4 id="comet"><a href="#comet" class="headerlink" title="comet"></a>comet</h4><p><strong>Comet</strong>是一种用于web的推送技术，能使服务器实时地将更新的信息传送到客户端，而无须客户端发出请求，目前有两种实现方式，长轮询和iframe流。</p><p> <strong>长轮询</strong></p><p>长轮询是在打开一条连接以后保持，等待服务器推送来数据再关闭的方式。</p><p><strong>iframe流</strong></p><p>iframe流方式是在页面中插入一个隐藏的iframe，利用其src属性在服务器和客户端之间建立一条长链接，服务器向iframe传输数据（通常是HTML，内有负责插入信息的javascript），来实时更新页面。 iframe流方式的优点是浏览器兼容好，Google公司在一些产品中使用了iframe流，如Google Talk。</p><h4 id="Server-Sent-Events"><a href="#Server-Sent-Events" class="headerlink" title="Server-Sent Events"></a>Server-Sent Events</h4><p>Server-Sent Events 是一种服务器推送技术, 使客户端可以通过 <strong>HTTP 连接</strong>从服务器自动接收更新. 每个通知以<strong>文本流(文本应该为 utf-8)\的形式发送, 并以一对换行符</strong>结尾. 与 WebSocket 相比:</p><ol><li>它不是全双工的, 只能服务器向浏览器发送, 因为流信息本质上就是下载, 一旦连接后不能再次发送请求(否则就变成了一次新的连接)</li><li>WebSocket 使用的 ws 协议, 而 SSE 使用的仍然是 HTTP 协议.</li></ol><h4 id="websocket"><a href="#websocket" class="headerlink" title="websocket"></a>websocket</h4><p>Comet和SSE仍然是单向通信（服务器向客户端），不能适应Web应用的飞速发展。于是，各种新技术不断涌现，其中WebSocket在Google的力推之下已经成为业界标准，并不断完善中。其基于TCP之上定义了帧协议，支持双向的通信。</p><p>WebSocket是一种全新的协议，不属于http无状态协议，协议名为ws协议或wss协议。ws不是http，所以传统的web服务器不一定支持。</p><h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><h3 id="tcp首部"><a href="#tcp首部" class="headerlink" title="tcp首部"></a>tcp首部</h3><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/tcphead.png" alt="TCP 头格式"></p><p>源端口和目的端口：端口范围为0~65535，该端口是传输层与应用层的服务端口，传输层的复用和分用都要通过端口来实现。</p><p>序列号：TCP是面向字节流的，所以TCP传送的时候每一个字节都编上一个序号，发送报文段的时候，序列号的值为该报文段第一个字节的序号。</p><p>确认号：是期待接收方下一个报文段的序号（即下一个报文段的第一个字节的序号）。若确认号为N，则表示期待下一个报文段发送序号为N开始的字节流过来（因为TCP是有序的，所以实际上现在0~N-1都已经接收到，所以期待发送N开始的字节流过来）。</p><p>首部长度：记录的是当前TCP报文段首部长度。该字段以4字节为单位，实际值范围5-15，表示TCP首部长度为20字节~60字节。</p><p>保留字段：在设计TCP首部时，保留为以后所用，但直到现在仍未用到，置为0.</p><p>URG紧急位：URG&#x3D;1表示紧急指针有效，表示该报文段中有紧急数据，应优先传送该报文段。<strong>URG需要和紧急指针配套使用，URG紧急位只是指示是否紧急，紧急指针指示实际的紧急数据大小</strong>（实际紧急数据是从第一个字节到紧急指针所指字节）。</p><p>ACK确认位：ACK&#x3D;1表示确认号字段有效，ACK&#x3D;0表示确认号字段无效。</p><blockquote><p>TCP规定，连接建立后所有报文段ACK确认位置为1。所以，<strong>可以通过ACK&#x3D;0&#x2F;1来判断当前是否已建立起TCP连接。</strong></p></blockquote><p>PSH推送位：PSH&#x3D;1表示某端接收到TCP报文段之后，应尽快交付给应用层，而不是等到接收缓存满了后再向上交付</p><p>RST复位位：RST&#x3D;1表示TCP连接中出现严重差错，必须释放当前连接，然后重新建立起连接。<strong>用RST终止连接只需要2次挥手</strong></p><p>SYN同步位：SYN&#x3D;1表示这是一个连接请求或连接接收报文。</p><blockquote><p>两者关系：某端发送连接请求报文,SYN&#x3D;1,ACK&#x3D;0，为第一次握手，<br>若对方同意建立连接，则发送响应报文(连接接收报文),SYN&#x3D;1,ACK&#x3D;1，为第二次握手。</p></blockquote><p>FIN终止位：FIN&#x3D;1表示此报文段的发送方的数据已发送完毕，并要求释放传输连接。</p><p>窗口字段：根据自己接收缓存（即接收窗口）剩余空间指示另一端可以发送的数据量，单位为字节。如：确认号为301，窗口字段为1000，则表示，从301号开始，发送此报文段的一端告诉另一端自己还可以接收1000个字节数据，且期待从301开始，即期待字节序号为301-1300。</p><p>检验和：TCP的检验同时检验首部和数据部分，在报文段前面加12个字节伪首部，用于检验之用。</p><blockquote><p>关于IP、IMCP、TCP和UDP的检验：<br>IP校验和只校验20字节的IP报头；而ICMP校验和覆盖整个报文（ICMP报头+ICMP数据）；UDP和TCP校验和不仅覆盖整个报文，而且还有12字节的IP伪首部，包括源IP地址(4字节)、目的IP地址(4字节)、协议(2字节，第一字节补0)和TCP&#x2F;UDP包长(2字节，包含协议头和数据)。</p></blockquote><p>紧急指针：指示出本报文段的紧急数据的范围，即紧急数据有多少个字节。</p><blockquote><p>紧急数据放在TCP报文段数据部分的最前面，紧急指针为16位，范围为0-65535，可以表示前0-66535个字节是紧急数据。</p></blockquote><p>选项字段：长度可变。功能：TCP最初只规定了一种选项，即最大报文段长度MSS,MSS表示TCP报文段中数据字段的最大长度。</p><p>填充字段：长度可变。功能：无意义，纯粹填充使TCP首部为4N个字节。</p><h3 id="tcp基本描述"><a href="#tcp基本描述" class="headerlink" title="tcp基本描述"></a>tcp基本描述</h3><p><em><strong>为什么需要 TCP 协议</strong></em></p><p><code>IP</code> 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 <code>TCP</code> 协议来负责。</p><p><em><strong>tcp定义</strong></em></p><p>TCP 是<strong>面向连接的、可靠的、基于字节流</strong>的传输层通信协议。</p><ul><li><strong>面向连接</strong>：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；</li><li><strong>可靠的</strong>：无论的网络链路中出现了怎样的链路变化，通过TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达接收端</li><li><strong>字节流</strong>：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的，因为用户消息被拆分成多个 TCP 报文后，并不能像 UDP 那样，一个 UDP 报文就能代表一个完整的用户消息。假设发送端陆续调用 send 函数先后发送 「hi.」和「how are you」 报文，那么实际的发送很有可能是这几种情况。1：hi how are you一起发送 2：先发hi how，再发are you 3: 先发h，再发i how are you</li></ul><p><em><strong>什么是tcp连接</strong></em></p><p>用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接。</p><p>所以我们可以知道，建立一个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识。</p><ul><li><strong>Socket</strong>：由 IP 地址和端口号组成</li><li><strong>序列号</strong>：用来解决乱序问题等</li><li><strong>窗口大小</strong>：用来做流量控制</li></ul><p>TCP 四元组可以唯一的确定一个连接，四元组包括源地址，源端口，目的地址，目的端口</p><p><em><strong>有一个 IP 的服务器监听了一个端口，它的 TCP 的最大连接数是多少？</strong></em></p><p>连接由四元组确定，只要四个中有一个不同就是不同的tcp连接，固定ip固定端口的服务器目的地址和目的端口是确定的，所以连接数取决于客户端ip和端口。</p><p>最大TCP连接数&#x3D;客户端ip数x客户端端口数</p><p>对 IPv4，客户端的 IP 数最多为 <code>2</code> 的 <code>32</code> 次方，客户端的端口数最多为 <code>2</code> 的 <code>16</code> 次方，也就是服务端单机最大 TCP 连接数，约为 <code>2</code> 的 <code>48</code> 次方。</p><p>当然，服务端最大并发 TCP 连接数远不能达到理论上限，会受以下因素影响：</p><ul><li><p>文件描述符限制</p><p>每个 TCP 连接都是一个文件，如果文件描述符被占满了，会发生 too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制：</p><ul><li><strong>系统级</strong>：当前系统可打开的最大数量，通过 cat &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;file-max 查看；</li><li><strong>用户级</strong>：指定用户可打开的最大数量，通过 cat &#x2F;etc&#x2F;security&#x2F;limits.conf 查看；</li><li><strong>进程级</strong>：单个进程可打开的最大数量，通过 cat &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;nr_open 查看；</li></ul></li><li><p><strong>内存限制</strong>，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。</p></li></ul><h3 id="tcp建立断开连接"><a href="#tcp建立断开连接" class="headerlink" title="tcp建立断开连接"></a>tcp建立断开连接</h3><p>一开始，客户端和服务端都处于 <code>CLOSED</code> 状态。先是服务端主动监听某个端口，处于 <code>LISTEN</code> 状态</p><p>客户端会随机初始化序号（<code>client_isn</code>），将此序号置于 TCP 首部的「序号」字段中，同时把 <code>SYN</code> 标志位置为 <code>1</code> ，表示 <code>SYN</code> 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 <code>SYN-SENT</code> 状态。</p><p>服务端收到客户端的 <code>SYN</code> 报文后，首先服务端也随机初始化自己的序号（<code>server_isn</code>），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 <code>client_isn + 1</code>, 接着把 <code>SYN</code> 和 <code>ACK</code> 标志位置为 <code>1</code>。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 <code>SYN-RCVD</code> 状态。</p><p>客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 <code>ACK</code> 标志位置为 <code>1</code> ，其次「确认应答号」字段填入 <code>server_isn + 1</code> ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 <code>ESTABLISHED</code> 状态。</p><p>服务器收到客户端的应答报文后，也进入 <code>ESTABLISHED</code> 状态。</p><p><strong>TCP 的连接状态查看</strong>，在 Linux 可以通过 <code>netstat -napt</code> 命令查看。</p><h4 id="为什么是三次握手？不是两次、四次？"><a href="#为什么是三次握手？不是两次、四次？" class="headerlink" title="为什么是三次握手？不是两次、四次？"></a><em><strong>为什么是三次握手？不是两次、四次？</strong></em></h4><p>三次握手的原因：</p><ul><li>三次握手才可以阻止历史连接的初始化（主要原因）</li><li>三次握手才可以同步双方的初始序列号</li></ul><p><em>原因一：避免历史连接</em></p><p>假设在<strong>网络拥堵</strong>情况下，客户端连续发送多次 SYN 建立连接的报文，此时会有</p><ul><li>一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端；</li><li>那么此时服务端就会回一个 <code>SYN + ACK</code> 报文给客户端；</li><li>客户端收到后根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 <code>RST</code> 报文给服务端，表示中止这一次连接。</li></ul><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/tcpthreehand.png" alt="三次握手避免历史连接"></p><p><strong>如果是两次握手连接，就无法阻止历史连接</strong></p><p>两次握手的情况下，「被动方」在收到 SYN 报文后，即第一次握手之后，就进入 ESTABLISHED 状态，意味着这时可以给对方发送数据。被动方并不知道这个是历史连接，导致「被动方」建立了一个历史连接，并白白给发送方发送了数据，浪费了「被动方」的资源。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/tcpthreehand2.png" alt="两次握手无法阻止历史连接"></p><p><em>原因二：同步双方初始序列号</em></p><p>TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素。</p><ul><li>接收方可以去除重复的数据；</li><li>接收方可以根据数据包的序列号按序接收；</li><li>可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；</li></ul><p>并且每次连接序列号都是不同的，所以要先同步序列号(序列号不能每次都从0开始，具体看后续笔记)</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/threehand3.png" alt="四次握手与三次握手"></p><p>当客户端发送携带「初始序列号」的 <code>SYN</code> 报文的时候，需要服务端回一个 <code>ACK</code> 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，<strong>这样一来一回，才能确保双方的初始序列号能被可靠的同步。</strong> <strong>如果不先同步序列号而直接传输报文，连接复用时无法分辨出序列号是延迟或者是旧连接的序列号，因此需要三次握手来约定确定双方的 ISN（初始 seq 序列号）。</strong></p><p><strong>而两次握手只保证了一方的初始序列号能被对方成功接收</strong>，没办法保证双方的初始序列号都能被确认接收。</p><p><strong>总结：</strong></p><p>TCP 建立连接时，通过三次握手<strong>能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号</strong>。序列号能够保证数据包不重复、不丢弃和按序传输。</p><p>不使用「两次握手」和「四次握手」的原因：</p><ul><li>「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；</li><li>「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。</li></ul><h4 id="tcp如何规避三次握手"><a href="#tcp如何规避三次握手" class="headerlink" title="tcp如何规避三次握手"></a><em><strong>tcp如何规避三次握手</strong></em></h4><p>为了减少 TCP 连接建立的时延，在 Linux 3.7 内核版本之后，提供了 TCP Fast Open 功能，它使得双方不需要握手就可以直接传输数据，但我认为这可能导致错误接收历史报文(有待查证)。<strong>要开启这个功能可以通过设置 tcp_fastopn 内核参数</strong></p><p>tcp_fastopn 各个值的意义:</p><ul><li>0 关闭</li><li>1 作为客户端使用 Fast Open 功能</li><li>2 作为服务端使用 Fast Open 功能</li><li>3 无论作为客户端还是服务器，都可以使用 Fast Open 功能</li></ul><p><strong>TCP Fast Open 功能需要客户端和服务端同时支持，才有效果。</strong></p><p>TCP Fast Open 功能的工作方式：</p><p>在客户端首次建立连接时的过程：</p><ol><li>客户端发送 SYN 报文，该报文<strong>tcp首部包含 Fast Open 选项</strong>，且该选项的 Cookie 为空，这表明客户端请求 Fast Open Cookie；</li><li>支持 TCP Fast Open 的服务器生成 Cookie(cookie包括客户端ip地址的加密)，并将其置于 SYN-ACK 数据包中的 Fast Open 选项以发回客户端；</li><li>客户端收到 SYN-ACK 后，本地缓存 Fast Open 选项中的 Cookie。</li></ol><p>所以，<strong>第一次发起 HTTP GET 请求的时候，还是需要正常的三次握手流程。</strong></p><p>之后，如果客户端再次向服务器建立连接时的过程：</p><ol><li>客户端发送 SYN 报文，该报文包含「数据」以及此前记录的 Cookie；</li><li>支持 TCP Fast Open 的服务器会对收到 Cookie 进行校验：如果 Cookie 有效，服务器将在 SYN-ACK 报文中对 SYN 和「数据」进行确认，服务器随后将「数据」递送至相应的应用程序；如果 Cookie 无效，服务器将丢弃 SYN 报文中包含的「数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；</li><li>如果服务器接受了 SYN 报文中的「数据」，服务器可在握手完成之前发送「数据」，<strong>这就减少了握手带来的 1 个 RTT 的时间消耗</strong>；</li><li>客户端将发送 ACK 确认服务器发回的 SYN 以及「数据」；但如果客户端在初始的 SYN 报文中发送的「数据」没有被确认，则客户端将重新发送「数据」，这与正常的三次握手一样；</li><li>此后的 TCP 连接的数据传输过程和非 TFO 的正常情况一致。</li></ol><h4 id="为什么每次建立-TCP-连接时，初始化的序列号都要求不一样呢？"><a href="#为什么每次建立-TCP-连接时，初始化的序列号都要求不一样呢？" class="headerlink" title="为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？"></a><em>为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？</em></h4><p>主要原因有两个方面：</p><ul><li>为了防止历史报文被下一个相同四元组的连接接收（主要方面）；</li><li>为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收(这就是序列号预测攻击，但仍无法阻止黑客截获报文得到序列号，tcp首部由内核生成，是明文传输的，程序员只能在应用层加密，无法加密tcp首部)；</li></ul><p>假设每次建立连接，客户端和服务端的初始化序列号都是从 0 开始：</p><p>过程如下：</p><ul><li>客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，而此时服务端的进程重启了，于是就会发送 RST 报文来断开连接。</li><li>紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接；</li><li>在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。</li></ul><p>可以看到，<strong>如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题</strong>。</p><p>但是tcp序号是会循环的，所以即使初始化序号随机，仍有可能会发生接收历史报文的情况，</p><p>为了解决这个问题，就需要有 TCP 时间戳。tcp_timestamps 参数是默认开启的，开启了 tcp_timestamps 参数，TCP 头部就会使用时间戳选项，它有两个好处，<strong>一个是便于精确计算 RTT ，另一个是能防止序列号回绕（PAWS）</strong>。</p><p>防回绕序列号算法要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 Recent TSval 值做比较，<strong>如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包</strong>。</p><h4 id="为什么ip层和tcp都需要分片"><a href="#为什么ip层和tcp都需要分片" class="headerlink" title="为什么ip层和tcp都需要分片"></a><em>为什么ip层和tcp都需要分片</em></h4><p>我们先来认识下 MTU 和 MSS</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/mtuandmss.png" alt="MTU 与 MSS"></p><ul><li><code>MTU</code>：<strong>Maximum Transmit Unit</strong>，最大传输单元，即物理接口（数据链路层）提供给其上层最大一次传输数据的大小，比如IP层、MPLS层等等，因为目前应用最多的接口是以太网，所以谈谈以太网口的MTU，假定其上层协议是IP，缺省MTU&#x3D;1500，意思是：整个IP包最大从这个接口发送出去的是1500个字节。可以通过配置修改成更大或更小的值，只要在系统的边界值以内即可，但是切记要在链路的两端都要修改，而且要大小一样，如果不一样，会造成大侧的数据被小侧丢弃！</li><li><code>MSS</code>：<strong>Maximum Segment Size</strong> ，最大TCP分段大小，不包含TCP头和 option，只包含TCP Payload ，TCP用来限制自己每次发送的最大分段尺寸。</li></ul><p>如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，会有什么异常呢？</p><p>当 IP 层有一个超过 <code>MTU</code> 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。</p><p>这看起来井然有序，但这存在隐患的，<strong>那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传</strong>。</p><p>因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。</p><p>当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。</p><p>因此，可以得知由 IP 层进行分片传输，是非常没有效率的。</p><p>所以，为了达到最佳的传输效能 TCP 协议在<strong>建立连接的时候通常要协商双方的 MSS 值</strong>，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。</p><h4 id="为什么要四次挥手"><a href="#为什么要四次挥手" class="headerlink" title="为什么要四次挥手"></a><em><strong>为什么要四次挥手</strong></em></h4><ul><li>客户端打算关闭连接，此时会发送一个 TCP 首部 <code>FIN</code> 标志位被置为 <code>1</code> 的报文，也即 <code>FIN</code> 报文，之后客户端进入 <code>FIN_WAIT_1</code> 状态。</li><li>服务端收到该报文后，就向客户端发送 <code>ACK</code> 应答报文，接着服务端进入 <code>CLOSED_WAIT</code> 状态。</li><li>客户端收到服务端的 <code>ACK</code> 应答报文后，之后进入 <code>FIN_WAIT_2</code> 状态。</li><li>等待服务端处理完数据后，也向客户端发送 <code>FIN</code> 报文，之后服务端进入 <code>LAST_ACK</code> 状态。</li><li>客户端收到服务端的 <code>FIN</code> 报文后，回一个 <code>ACK</code> 应答报文，之后进入 <code>TIME_WAIT</code> 状态</li><li>服务器收到了 <code>ACK</code> 应答报文后，就进入了 <code>CLOSED</code> 状态，至此服务端已经完成连接的关闭。</li><li>客户端在经过 <code>2MSL</code> 一段时间后，自动进入 <code>CLOSED</code> 状态，至此客户端也完成连接的关闭。</li></ul><p>你可以看到，每个方向都需要<strong>一个 FIN 和一个 ACK</strong>，因此通常被称为<strong>四次挥手</strong>。</p><p>这里一点需要注意是：<strong>主动关闭连接的，才有 TIME_WAIT 状态。</strong></p><p><em><strong>为什么挥手需要四次？</strong></em></p><ul><li>关闭连接时，客户端向服务端发送 <code>FIN</code> 时，仅仅表示客户端不再发送数据了但是还能接收数据。</li><li>服务器收到客户端的 <code>FIN</code> 报文时，先回一个 <code>ACK</code> 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 <code>FIN</code> 报文给客户端来表示同意现在关闭连接。</li></ul><p>从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 <code>ACK</code> 和 <code>FIN</code> 一般都会分开发送，从而比三次握手导致多了一次，<strong>如果服务器没有要发送的数据时， <code>ACK</code> 和 <code>FIN</code> 会一起发送，此时是三次挥手</strong></p><h4 id="为什么需要-TIME-WAIT-状态？"><a href="#为什么需要-TIME-WAIT-状态？" class="headerlink" title="为什么需要 TIME_WAIT 状态？"></a><em>为什么需要 TIME_WAIT 状态？</em></h4><p>主动发起关闭连接的一方，才会有 <code>TIME-WAIT</code> 状态。</p><p>需要 TIME-WAIT 状态，主要是两个原因：</p><ul><li>防止历史连接中的数据，被后面相同四元组的连接错误的接收；</li><li>保证「被动关闭连接」的一方，能被正确的关闭；</li></ul><p><em>原因一：防止历史连接中的数据，被后面相同四元组的连接错误的接收</em></p><ul><li>服务端在关闭连接之前发送的报文，被网络延迟了。</li><li>接着，服务端以相同的四元组重新打开了新连接，前面被延迟的报文这时抵达了客户端，而且该数据报文的序列号刚好在客户端接收窗口内，因此客户端会正常接收这个数据报文，但是这个数据报文是上一个连接残留下来的，这样就产生数据错乱等严重的问题。</li></ul><p>为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 <code>2MSL</code> 时长，这个时间<strong>足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。</strong></p><p><em>原因二：保证「被动关闭连接」的一方，能被正确的关闭</em></p><p>TIME-WAIT 作用是<strong>等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。</strong></p><p>如果客户端（主动关闭方）最后一次 ACK 报文（第四次挥手）在网络中丢失了，那么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。</p><p>假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSED 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。</p><p>服务端收到这个 RST 并将其解释为一个错误（Connection reset by peer），这对于一个可靠的协议来说不是一个优雅的终止方式。</p><p>为了防止这种情况出现，客户端必须等待足够长的时间确保对端收到 ACK，如果对端没有收到 ACK，那么就会触发 TCP 重传机制，服务端会重新发送一个 FIN，这样一去一来刚好两个 MSL 的时间。</p><h4 id="为什么-TIME-WAIT-等待的时间是-2MSL？"><a href="#为什么-TIME-WAIT-等待的时间是-2MSL？" class="headerlink" title="为什么 TIME_WAIT 等待的时间是 2MSL？"></a><em>为什么 TIME_WAIT 等待的时间是 2MSL？</em></h4><p><code>MSL</code> 是 Maximum Segment Lifetime，<strong>报文最大生存时间</strong>，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。</p><p><strong>TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了</strong>。</p><p><code>2MSL</code> 的时间是从<strong>客户端接收到 FIN 后发送 ACK 开始计时的</strong>。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 <strong>2MSL 时间将重新计时</strong>。</p><p>TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以<strong>一来一回需要等待 2 倍的时间</strong>。</p><p>比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 <code>FIN</code> 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL。</p><p>可以看到 <strong>2MSL时长</strong> 这其实是相当于<strong>至少允许报文丢失一次</strong>。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。</p><p>为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。</p><h4 id="如何优化-TIME-WAIT？"><a href="#如何优化-TIME-WAIT？" class="headerlink" title="如何优化 TIME_WAIT？"></a><em>如何优化 TIME_WAIT？</em></h4><p>过多的 TIME-WAIT 状态主要的危害有两种：</p><ul><li>第一是内存资源占用；</li><li>第二是对端口资源的占用，一个 TCP 连接至少消耗「发起连接方」的一个本地端口；</li></ul><p><strong>如果「发起连接方」的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。</strong>因为端口就 65536 个，被占满就会导致无法创建新的连接。</p><p><strong>以上只针对连接同一服务器的情况</strong>，如果客户端都是与同一个服务器（目标地址和目标端口一样）建立连接，那么如果客户端 TIME_WAIT 状态的连接过多，当端口资源被耗尽，就无法与这个服务器再建立连接了。但是，<strong>只要客户端连接的服务器不同，端口资源可以重复使用的</strong>。</p><p>处于TIME-WAIT状态的TCP连接，在链接表槽中存活1分钟，意味着另一个相同四元组（源地址，源端口，目标地址，目标端口）的连接不能出现，也就是说新的TCP（相同四元组）连接无法建立。</p><p>解决办法是，增加四元组的范围，这有很多方法去实现。（以下建议的顺序，实施难度从小到大排列）</p><ul><li>修改net.ipv4.ip_local_port_range参数，增加客户端端口可用范围。</li><li>增加服务端端口，多监听一些端口，比如81、82、83这些，web服务器前有负载均衡，对用户友好。</li><li>增加客户端IP，尤其是作为负载均衡服务器时，使用更多IP去跟后端的web服务器通讯。</li><li>增加服务端IP。</li></ul><p>其他优化 TIME-WAIT 的几个方式，都是有利有弊：</p><ul><li>打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；</li><li>net.ipv4.tcp_max_tw_buckets</li><li>程序中使用 SO_LINGER ，应用强制使用 RST 关闭。</li></ul><p><em>方式一：net.ipv4.tcp_tw_reuse 和 tcp_timestamps</em></p><p><code>net.ipv4.tcp_tw_reuse </code>Linux 内核参数开启后，则可以<strong>复用处于 TIME_WAIT 的 socket 为新的连接所用</strong>。</p><p>有一点需要注意的是，<strong>tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用。</strong></p><p>使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持，即<code>tcp_timestamps</code></p><p>这个时间戳的字段是在 TCP 头部的「选项」里，它由一共 8 个字节表示时间戳，其中第一个 4 字节字段用来保存发送该数据包的时间，第二个 4 字节字段用来保存最近一次接收对方发送到达数据的时间。</p><p>由于引入了时间戳，我们在前面提到的 <code>2MSL</code> 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。</p><p><em>方式二：net.ipv4.tcp_max_tw_buckets</em></p><p>这个值默认为 18000，<strong>当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置</strong>，这个方法比较暴力。</p><p><em>方式三：程序中使用 SO_LINGER</em></p><p>我们可以通过设置 socket 选项，来设置调用 close 关闭连接行为。</p><pre><code class="c">struct linger so_linger;so_linger.l_onoff = 1;so_linger.l_linger = 0;setsockopt(s, SOL_SOCKET, SO_LINGER, &amp;so_linger,sizeof(so_linger));</code></pre><p>如果<code>l_onoff</code>为非 0， 且<code>l_linger</code>值为 0，那么调用<code>close</code>后，会立该发送一个<code>RST</code>标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了<code>TIME_WAIT</code>状态，直接关闭。</p><p>但这为跨越<code>TIME_WAIT</code>状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。</p><h4 id="为什么tcp-tw-reuse默认关闭"><a href="#为什么tcp-tw-reuse默认关闭" class="headerlink" title="为什么tcp_tw_reuse默认关闭"></a><em>为什么tcp_tw_reuse默认关闭</em></h4><p>tcp_tw_reuse加上时间戳选项，看起来已经解决了可能会接收历史报文的问题，不再需要TIME_WAIT了，那么为什么不默认开启tcp_tw_reuse呢？</p><p>tcp_tw_reuse 的作用是让客户端快速复用处于 TIME_WAIT 状态的端口，相当于跳过了 TIME_WAIT 状态，这可能会出现这样的两个问题：</p><ul><li>历史 RST 报文可能会终止后面相同四元组的连接，因为 PAWS检查RST 报文时， <strong>RST 报文的时间戳即使过期了，只要 RST 报文的序列号在对方的接收窗口内，也是能被接受的</strong>。</li><li>如果第四次挥手的 ACK 报文丢失了，有可能被动关闭连接的一方不能被正常的关闭;</li></ul><h4 id="tcp保活机制"><a href="#tcp保活机制" class="headerlink" title="tcp保活机制"></a><em>tcp保活机制</em></h4><p>TCP 有一个机制是<strong>保活机制</strong>。这个机制的原理是这样的：</p><p>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</p><p>在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：</p><pre><code class="shell">net.ipv4.tcp_keepalive_time=7200net.ipv4.tcp_keepalive_intvl=75  net.ipv4.tcp_keepalive_probes=9</code></pre><ul><li>tcp_keepalive_time&#x3D;7200：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制</li><li>tcp_keepalive_intvl&#x3D;75：表示每次检测间隔 75 秒；</li><li>tcp_keepalive_probes&#x3D;9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。</li></ul><p>也就是说在 Linux 系统中，<strong>最少需要经过 2 小时 11 分 15 秒</strong>才可以发现一个「死亡」连接。</p><p>注意，应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 <code>SO_KEEPALIVE</code> 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。</p><p>如果开启了 TCP 保活，需要考虑以下几种情况：</p><ul><li>第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 <strong>TCP 保活时间会被重置</strong>，等待下一个 TCP 保活时间的到来。</li><li>第二种，对端程序崩溃并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，<strong>会产生一个 RST 报文</strong>，这样很快就会发现 TCP 连接已经被重置。</li><li>第三种，是对端程序崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，<strong>TCP 会报告该 TCP 连接已经死亡</strong>。</li></ul><p>TCP 保活的这个机制检测的时间是有点长，我们可以自己在应用层实现一个心跳机制。</p><p>比如，web 服务软件一般都会提供 <code>keepalive_timeout</code> 参数，用来指定 HTTP 长连接的超时时间。如果设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会<strong>启动一个定时器</strong>，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，<strong>定时器的时间一到，就会触发回调函数来释放该连接。</strong></p><h3 id="socket编程"><a href="#socket编程" class="headerlink" title="socket编程"></a>socket编程</h3><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/socket.png" alt="基于 TCP 协议的客户端和服务器工作"></p><ul><li>服务端和客户端初始化 <code>socket</code>，得到文件描述符；</li><li>服务端调用 <code>bind</code>，将绑定在 IP 地址和端口;</li><li>服务端调用 <code>listen</code>，进行监听；</li><li>服务端调用 <code>accept</code>，等待客户端连接；</li><li>客户端调用 <code>connect</code>，向服务器端的地址和端口发起连接请求；</li><li>服务端 <code>accept</code> 返回用于传输的 <code>socket</code> 的文件描述符；</li><li>客户端调用 <code>write</code> 写入数据；服务端调用 <code>read</code> 读取数据；</li><li>客户端断开连接时，会调用 <code>close</code>，向对端发送FIN包，服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 <code>EOF</code> 到接收缓冲区中，那么服务端 <code>read</code> 读取数据的时候，就会读取到了 <code>EOF</code>，待处理完数据后，服务端调用 <code>close</code>，表示连接关闭。</li></ul><p>这里需要注意的是，服务端调用 <code>accept</code> 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。</p><p>所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作<strong>监听 socket</strong>，一个叫作<strong>已完成连接 socket</strong>。</p><p>成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。</p><h4 id="listen-时候参数-backlog-的意义？"><a href="#listen-时候参数-backlog-的意义？" class="headerlink" title="listen 时候参数 backlog 的意义？"></a><em>listen 时候参数 backlog 的意义？</em></h4><p>Linux内核中会维护两个队列：</p><ul><li>半连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态；</li><li>全连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态；</li></ul><pre><code class="c">int listen (int socketfd, int backlog)</code></pre><p><strong>全连接队列（icsk_accept_queue）是个链表</strong>，而<strong>半连接队列（syn_table）是个哈希表</strong>。</p><p>先对比下<strong>全连接里队列</strong>，他本质是个链表，因为也是线性结构，说它是个队列也没毛病。它里面放的都是已经建立完成的连接，这些连接正等待被取走。而服务端取走连接的过程中，并不关心具体是哪个连接，只要是个连接就行，所以直接从队列头取就行了。这个过程算法复杂度为<code>O(1)</code>。</p><p>而<strong>半连接队列</strong>却不太一样，因为队列里的都是不完整的连接，嗷嗷等待着第三次握手的到来。那么现在有一个第三次握手来了，则需要从队列里把相应IP端口的连接取出，<strong>如果半连接队列还是个链表，那我们就需要依次遍历，才能拿到我们想要的那个连接，算法复杂度就是O(n)。</strong>而如果将半连接队列设计成哈希表，那么查找半连接的算法复杂度就回到<code>O(1)</code>了。</p><p>因此出于效率考虑，全连接队列被设计成链表，而半连接队列被设计为哈希表。</p><p>在早期 Linux 内核 backlog 是 SYN 队列大小，也就是未完成的队列大小。</p><p>在 Linux 内核 2.2 之后，backlog 变成 accept 队列，也就是已完成连接建立的队列长度，<strong>所以现在通常认为 backlog 是 accept 队列。</strong></p><p><strong>但是上限值是内核参数 somaxconn 的大小，也就说 accpet 队列长度 &#x3D; min(backlog, somaxconn)。</strong></p><h4 id="connect和accept-发生在三次握手的哪一步？"><a href="#connect和accept-发生在三次握手的哪一步？" class="headerlink" title="connect和accept 发生在三次握手的哪一步？"></a><em>connect和accept 发生在三次握手的哪一步？</em></h4><p>客户端协议栈收到 服务器的ACK 之后，使得应用程序从 <code>connect</code> 调用返回，表示客户端到服务器端的单向连接建立成功，客户端的状态为 ESTABLISHED</p><p>客户端的ACK 应答包到达服务器端后，服务器端的 TCP 连接进入 ESTABLISHED 状态，同时服务器端协议栈使得 <code>accept</code> 阻塞调用返回，这个时候服务器端到客户端的单向连接也建立成功。至此，客户端与服务端两个方向的连接都建立成功。</p><p>从上面的描述过程，我们可以得知<strong>客户端 connect 成功返回是在第二次握手之后，服务端 accept 成功返回是在三次握手成功之后。</strong></p><h4 id="SYN-报文什么时候情况下会被丢弃？"><a href="#SYN-报文什么时候情况下会被丢弃？" class="headerlink" title="SYN 报文什么时候情况下会被丢弃？"></a><em>SYN 报文什么时候情况下会被丢弃？</em></h4><ul><li>开启 tcp_tw_recycle 参数，并且在 NAT 环境下，造成 SYN 报文被丢弃</li><li>TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃</li></ul><p>1.<strong>开启 tcp_tw_recycle 参数</strong></p><p>net.ipv4.tcp_tw_recycle，如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收；但是tcp_tw_recycle 在使用了 NAT 的网络下是不安全的，具体如下：</p><p>开启了 recycle 和 timestamps 选项，就会开启一种叫 per-host 的 PAWS 机制。<strong>per-host 是对「对端 IP 做 PAWS 检查」</strong>，而非对「IP + 端口」四元组做 PAWS 检查。</p><p>但是如果客户端网络环境是用了 NAT 网关，那么客户端环境的每一台机器通过 NAT 网关后，都会是相同的 IP 地址，在服务端看来，就好像只是在跟一个客户端打交道一样，无法区分出来。</p><p>当客户端 A 通过 NAT 网关和服务器建立 TCP 连接，然后服务器主动关闭并且快速回收 TIME-WAIT 状态的连接后，客户端 B 也通过 NAT 网关和服务器建立 TCP 连接，<strong>注意客户端 A 和 客户端 B 因为经过相同的 NAT 网关，所以是用相同的 IP 地址与服务端建立 TCP 连接</strong>，如果客户端 B 的 timestamp 比 客户端 A 的 timestamp 小，那么由于服务端的 per-host 的 PAWS 机制的作用，服务端就会丢弃客户端主机 B 发来的 SYN 包。</p><p>tcp_tw_recycle 在 <strong>Linux 4.12 版本后，直接取消了这一参数</strong>。</p><p>2.<strong>TCP 两个队列满了</strong></p><p>服务端收到客户端发起的 SYN 请求后，<strong>内核会把该连接存储到半连接队列</strong>，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，<strong>内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。</strong></p><p>若半连接队列满了，这时后面来的 syn 包都会被丢弃。 </p><p>若全连接队列满了，且没有重传 SYN+ACK 包的连接请求多于 1 个，则会丢弃；</p><p><em>解决办法</em></p><p><em>方式一：增大半连接队列</em></p><p>半连接队列的值跟 tcp_max_syn_backlog ， somaxconn，backlog都有关系</p><p><strong>要想增大半连接队列，我们得知不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大全连接队列</strong>。否则，只单纯增大 tcp_max_syn_backlog 是无效的。</p><p>增大 tcp_max_syn_backlog 和 somaxconn 的方法是修改 Linux 内核参数</p><p><em>方式二：开启 tcp_syncookies 功能</em></p><p>开启 tcp_syncookies 功能的方式也很简单，修改 Linux 内核参数。</p><p><strong>如果开启了syncookies 功能，半连接队列满后，后续的请求就不会存放到半连接队列了，因此也不会丢弃syn 包</strong>。</p><p>syncookies 是这么做的：服务器收到TCP SYN包时，服务器会返回适当的SYN+ACK 响应，但会丢弃 SYN 队列条目。这个响应包中的序号是按照某种算法将时间戳，MSS， IP 地址和端口号等信息编码得到的，这个序号就是所谓的 <em>SYN cookie</em>。服务器接收到客户端随后的ACK响应，就能够解码在 TCP 序号内的信息重构 SYN 队列条目。</p><p><em>方式三：减少 SYN+ACK 重传次数</em></p><p>当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。</p><p>那么针对 SYN 攻击的场景，我们可以减少 SYN+ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。</p><h4 id="shutdown和close有什么区别"><a href="#shutdown和close有什么区别" class="headerlink" title="shutdown和close有什么区别"></a><em>shutdown和close有什么区别</em></h4><p>总结：</p><ol><li>close 会关闭连接，<strong>并释放所有连接对应的资源，而 shutdown 并不会释放掉套接字和所有的资源。</strong></li><li><strong>close 存在引用计数的概念，在多进程共享socket时并不一定会关闭连接；shutdown 则不管引用计数，直接关闭连接，如果有别的进程企图使用该socket，将会受到影响。</strong></li><li>close是双向关闭，而shutdown可以控制单向关闭</li></ol><p><em>shutdown函数</em> </p><pre><code class="c">int shutdown(int sockfd, int howto)</code></pre><p>howto 是这个函数的设置选项，它的设置有三个主要选项：</p><ul><li>SHUT_RD(0)：关闭连接的“读”这个方向，对该套接字进行读操作直接返回 EOF。从数据角度来看，套接字上<strong>接收缓冲区已有的数据将被丢弃</strong>，如果再有新的数据流到达，会对数据进行 ACK，然后悄悄地丢弃。也就是说，对端还是会接收到 ACK，在这种情况下根本不知道数据已经被丢弃了。</li><li>SHUT_WR(1)：关闭连接的“写”这个方向，这就是常被称为”半关闭“的连接。此时，不管套接字引用计数的值是多少，都会直接关闭连接的写方向。套接字上<strong>发送缓冲区已有的数据将被立即发送出去</strong>，并发送一个 FIN 报文给对端。应用程序如果对该套接字进行写操作会报错。</li><li>SHUT_RDWR(2)：相当于 SHUT_RD 和 SHUT_WR 操作各一次，关闭套接字的读和写两个方向。</li></ul><p><em>close函数</em></p><pre><code class="c">int close(int sockfd)</code></pre><p>这个函数会对套接字引用计数减一，一旦发现套接字引用计数到 0，就会对套接字进行彻底释放，<strong>并且会关闭 TCP 两个方向的数据流</strong>。</p><p>在输入方向，系统内核会将该套接字设置为不可读，任何读操作都会返回异常。</p><p>在输出方向，系统内核尝试将发送缓冲区的数据发送给对端，并最后向对端发送一个 FIN 报文，接下来如果再对该套接字进行写操作会返回异常。</p><p>如果对端没有检测到套接字已关闭，还继续发送报文，就会收到一个 RST 报文，告诉对端：“Hi, 我已经关闭了，别再给我发数据了。”</p><h4 id="TCP-和-UDP-可以同时绑定相同的端口吗？"><a href="#TCP-和-UDP-可以同时绑定相同的端口吗？" class="headerlink" title="TCP 和 UDP 可以同时绑定相同的端口吗？"></a><strong>TCP 和 UDP 可以同时绑定相同的端口吗？</strong></h4><p>可以。</p><p>当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP&#x2F;UDP，所以可以根据这个信息确定送给哪个模块（TCP&#x2F;UDP）处理，送给 TCP&#x2F;UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。</p><p>因此， TCP&#x2F;UDP 各自的端口号也相互独立，如 TCP 有一个 80 号端口，UDP 也可以有一个 80 号端口，二者并不冲突。</p><h4 id="多个-TCP-服务进程可以绑定同一个端口吗？"><a href="#多个-TCP-服务进程可以绑定同一个端口吗？" class="headerlink" title="多个 TCP 服务进程可以绑定同一个端口吗？"></a><strong>多个 TCP 服务进程可以绑定同一个端口吗？</strong></h4><p>如果两个 TCP 服务进程<strong>同时绑定的 IP 地址和端口都相同</strong>，那么执行 bind() 时候就会出错，错误是“Address already in use”。</p><p>如果两个 TCP 服务进程绑定的 IP 地址不同，而端口相同的话，也是可以绑定成功的。</p><p>注意，如果 TCP 服务进程 A 绑定的地址是 0.0.0.0 和端口 8888，而如果 TCP 服务进程 B 绑定的地址是 192.168.1.100 地址（或者其他地址）和端口 8888，那么执行 bind() 时候也会出错。</p><p>这是因为 <strong>0.0.0.0 地址比较特殊，代表任意地址</strong>，意味着绑定了 0.0.0.0 地址，相当于把主机上的所有 IP 地址都绑定了。(这个问题可以由 SO_REUSEADDR 解决)</p><p>如果想多个进程绑定相同的 IP 地址和端口，也是有办法的，就是对 socket 设置 SO_REUSEPORT 属性</p><h4 id="客户端的端口可以重复使用吗？"><a href="#客户端的端口可以重复使用吗？" class="headerlink" title="客户端的端口可以重复使用吗？"></a><strong>客户端的端口可以重复使用吗？</strong></h4><p>可以。</p><p>客户端在执行 connect 函数的时候，会在内核里随机选择一个端口，然后向服务端发起 SYN 报文，然后与服务端进行三次握手。</p><p>所以，客户端的端口选择的发生在 connect 函数，内核在选择端口的时候，会从 <code>net.ipv4.ip_local_port_range</code> 这个内核参数指定的范围来选取一个端口作为客户端端口。该参数的默认值是 32768 61000，意味着端口总可用的数量是 61000 - 32768 &#x3D; 28232 个。</p><p>TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的，只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接。所以<strong>如果客户端已使用端口 64992 与服务端 A 建立了连接，那么客户端要与服务端 B 建立连接，还是可以使用端口 64992 的</strong>，因为内核是通过四元组信息来定位一个 TCP 连接的，并不会因为客户端的端口号相同，而导致连接冲突的问题。</p><h4 id="客户端可以bind吗"><a href="#客户端可以bind吗" class="headerlink" title="客户端可以bind吗"></a>客户端可以bind吗</h4><p>bind 函数虽然常用于服务端网络编程中，但是它也是可以用于客户端的。</p><p>前面我们知道，客户端是在调用 connect 函数的时候，由内核随机选取一个端口作为连接的端口。</p><p>而如果我们想自己指定连接的端口，就可以用 bind 函数来实现：客户端先通过 bind 函数绑定一个端口，然后调用 connect 函数就会跳过端口选择的过程了，转而使用 bind 时确定的端口。</p><h4 id="多个客户端可以-bind-同一个端口吗？"><a href="#多个客户端可以-bind-同一个端口吗？" class="headerlink" title="多个客户端可以 bind 同一个端口吗？"></a>多个客户端可以 bind 同一个端口吗？</h4><p>跟服务端一样，要看多个客户端绑定的 IP + PORT 是否都相同，如果都是相同的，那么在执行 bind() 时候就会出错，错误是“Address already in use”。</p><h4 id="没有-listen，能建立-TCP-连接吗？"><a href="#没有-listen，能建立-TCP-连接吗？" class="headerlink" title="没有 listen，能建立 TCP 连接吗？"></a>没有 listen，能建立 TCP 连接吗？</h4><p><strong>服务端如果只 bind 了 IP 地址和端口，而没有调用 listen 的话，然后客户端对服务端发起了连接建立，服务端会回 RST 报文。</strong></p><p>但没有listen，客户端可以建立tcp自连接，也就是自己连自己。</p><p>我们知道执行 listen 方法时，会创建半连接队列和全连接队列。三次握手的过程中会在这两个队列中暂存连接信息。所以形成连接，前提是你得有个地方存放着，方便握手的时候能根据 IP + 端口等信息找到对应的 socket。</p><p>因为客户端没有执行listen，所以没有半连接队列和全连接队列。但内核还有个全局 hash 表，可以用于存放 sock 连接的信息。</p><p><strong>在 TCP 自连接的情况中，客户端在 connect 方法时，最后会将自己的连接信息放入到这个全局 hash 表中，然后将信息发出，消息在经过回环地址重新回到 TCP 传输层的时候，就会根据 IP + 端口信息，再一次从这个全局 hash 中取出信息。于是握手包一来一回，最后成功建立连接</strong>。</p><h4 id="没有-accept，能建立-TCP-连接吗？"><a href="#没有-accept，能建立-TCP-连接吗？" class="headerlink" title="没有 accept，能建立 TCP 连接吗？"></a>没有 accept，能建立 TCP 连接吗？</h4><p>accept方法只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎<strong>毫无关系</strong>。</p><p><strong>就算不执行accept()方法，三次握手照常进行，并顺利建立连接。</strong> <strong>并且在服务端执行accept()前，如果客户端发送消息给服务端，服务端是能够正常回复ack确认包的。</strong></p><h3 id="tcp是怎么保证可靠性传输的"><a href="#tcp是怎么保证可靠性传输的" class="headerlink" title="tcp是怎么保证可靠性传输的"></a>tcp是怎么保证可靠性传输的</h3><p>通过TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达接收端</p><h4 id="差错检测"><a href="#差错检测" class="headerlink" title="差错检测"></a><em>差错检测</em></h4><p>每个TCP报文段都包括检验和字段，校验和用来检查报文段是否出现传输错误，如果报文段出现传输错误，TCP检查出错就丢弃该报文段。</p><h4 id="序列号，确认应答和重传"><a href="#序列号，确认应答和重传" class="headerlink" title="序列号，确认应答和重传"></a><em>序列号，确认应答和重传</em></h4><p>TCP 连接中，为传送的字节流（数据）中的每一个字节按顺序编号。当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。</p><p>但在错综复杂的网络，并不一定能如上图那么顺利能正常的数据传输，万一数据在传输过程中丢失了呢？</p><p>所以 TCP 针对数据包丢失的情况，会用<strong>重传机制</strong>解决。</p><p>接下来说说常见的重传机制：</p><ul><li>超时重传</li><li>快速重传</li><li>SACK</li><li>D-SACK</li></ul><p><em>超时重传</em></p><p>重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 <code>ACK</code> 确认应答报文，就会重发该数据，也就是我们常说的<strong>超时重传</strong>。</p><p>数据包会触发超时重传，而单独的ACK报文丢失则不会，因为收到ACK报文后是不需要确认的。</p><p>超时重传时间是以 <code>RTO</code> （Retransmission Timeout 超时重传时间）表示。因为我们的网络也是时常变化的。也就因为「报文往返 RTT 的值」 是经常波动变化的，所以「超时重传时间 RTO 的值」应该是一个<strong>动态变化的值</strong>。实际中，RTO是通过RTT的加权平均值和方差计算而得。</p><p><strong>每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。</strong></p><p>超时触发重传存在的问题是，超时周期可能相对较长。</p><p><em>快速重传</em></p><p>TCP 还有另外一种<strong>快速重传（Fast Retransmit）机制</strong>，它<strong>不以时间为驱动，而是以数据驱动重传</strong>。</p><p>快速重传的工作方式是当收到三个重复冗余ACK（其实是收到4个同样的ACK，第一个是正常的，后三个才是冗余的），会在<strong>定时器过期之前</strong>，重传丢失的报文段。</p><p>快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是<strong>重传的时候，是重传丢失的这个报文，还是重传这个时间段发送的所有报文的问题。</strong></p><p>根据 TCP 不同的实现，以上两种情况都是有可能的。可见，这是一把双刃剑。</p><p>为了解决不知道该重传哪些 TCP 报文，于是就有 <code>SACK</code> 方法。SACK是选择性重传，解决快速重传不知道重传哪些报文的缺点</p><p><em>SACK 方法</em></p><p>还有一种实现重传机制的方式叫：<code>SACK</code>（ Selective Acknowledgment 选择性确认）。如果要支持 <code>SACK</code>，必须双方都要支持。在 Linux 下，可以通过 <code>net.ipv4.tcp_sack</code> 参数打开这个功能（Linux 2.4 后默认打开）。</p><p>这种方式会在 TCP 头部「选项」字段里加一个 <code>SACK</code> 的东西，接收方<strong>可以将已经接收的数据信息发送给发送方</strong>，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以<strong>只重传丢失的数据</strong>。</p><p>如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 <code>SACK</code> 信息发现只有 <code>200~299</code> 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/sack.jpg" alt="选择性确认"></p><p><em>Duplicate SACK</em></p><p>RFC2883对SACK进行了扩展，称为D-SACK：使得扩展后的SACK具有通知发送端哪些数据被重复接收了。</p><p>下面举例两个例子，来说明 <code>D-SACK</code> 的作用。</p><p><em>1：ACK 丢包</em></p><ul><li>「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）</li><li><strong>于是「接收方」发现数据是重复收到的，于是回了一个 SACK &#x3D; 3000~3500</strong>，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 <code>D-SACK</code>。</li><li>这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。</li></ul><p><em>2：网络延时</em></p><ul><li>数据包（1000~1499） 被网络延迟了，导致「接收方」没有第一时间收到数据包。</li><li>而后「接收方」给「发送方」发了三个冗余ACK，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；</li><li><strong>所以「接收方」回了一个 SACK&#x3D;1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。</strong></li><li>这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。</li></ul><p>可见，<code>D-SACK</code> 可以让发送方更好的了解网络状态</p><ol><li>可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;</li><li>可以知道是不是「发送方」的数据包被网络延迟了;</li><li>可以知道网络中是不是把「发送方」的数据包给复制了;</li></ol><p>在 Linux 下可以通过 <code>net.ipv4.tcp_dsack</code> 参数开启&#x2F;关闭这个功能（Linux 2.4 后默认打开）。</p><h4 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a><em><strong>滑动窗口</strong></em></h4><p>为什么要引入窗口：如果没有窗口，发送方每发送一个数据包后必须收到接收方的确认应答才能发送下一个包，效率十分低下。为解决这个问题，TCP 引入了<strong>窗口</strong>这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。有了窗口，就可以指定窗口大小，窗口大小就是指<strong>无需等待确认应答，而可以继续发送数据的最大值</strong>。</p><p>窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。</p><blockquote><p>窗口大小由哪一方决定？</p></blockquote><p>TCP 头里有一个字段叫 <code>Window</code>，也就是窗口大小。</p><p><strong>这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。</strong></p><p>所以，通常窗口的大小是由接收方的窗口大小来决定的。</p><p>发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。</p><blockquote><p>接收窗口和发送窗口的大小是相等的吗？</p></blockquote><p>并不是完全相等，接收窗口的大小是<strong>约等于</strong>发送窗口的大小的。</p><p>因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。</p><blockquote><p>窗口大小和序号空间大小的关系</p></blockquote><p>窗口大小和序号空间大小一样时会出现新的问题，即接收方无法确定收到的分组是新的分组还是老的分组（老的分组在网络中传输了很久才到达接收方），因为它们的序号一样，要解决这个问题只能使用不重复的序号，但序号空间是有限的，通常我们强制窗口小于等于序号空间大小的二分之一，这可以避免绝大部分的情况，即假定绕一圈之后超过了网络的TTL，但仍无法避免那种窝藏在中途延缓很久发送出来的古老循环段造成的影响。</p><h4 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a><em>流量控制</em></h4><p>发送方不能无脑的发数据给接收方，要考虑接收方处理能力。</p><p>如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。</p><p>为了解决这种现象发生，<strong>TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。</strong>TCP 通过让接收方指明希望从发送方接收的数据大小（窗口大小）来进行流量控制。</p><p>发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会<strong>被操作系统调整</strong>。</p><p>当接收方应用进程没办法及时读取缓冲区的内容时，就会减少窗口大小并通知发送方。</p><p>若接收方操作系统先减少缓冲区大小，再通知对方就会造成丢包问题。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/flowcontrol.jpg" alt="img"></p><p>所以，如果发生了先减少缓存，再收缩窗口，就会出现丢包的现象。</p><p><strong>为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。</strong></p><p><em>窗口关闭</em></p><p>如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。</p><blockquote><p>窗口关闭潜在的危险</p></blockquote><p>接收方向发送方通告窗口大小时，是通过 <code>ACK</code> 报文来通告的。</p><p>那么，当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，那麻烦就大了。</p><p>这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。</p><blockquote><p>TCP 是如何解决窗口关闭时，潜在的死锁现象呢？</p></blockquote><p>为了解决这个问题，TCP 为每个连接设有一个持续定时器，<strong>只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。</strong></p><p>如果持续计时器超时，就会发送<strong>窗口探测 ( Window probe ) 报文</strong>，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。</p><ul><li>如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；</li><li>如果接收窗口不是 0，那么死锁的局面就可以被打破了。</li></ul><p>窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 <code>RST</code> 报文来中断连接。</p><p><em>糊涂窗口综合症</em></p><p>如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。</p><p>到最后，<strong>如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症</strong>。</p><p>要知道，我们的 <code>TCP + IP</code> 头有 <code>40</code> 个字节，为了传输那几个字节的数据，要达上这么大的开销，这太不经济了。</p><p>所以，糊涂窗口综合症的现象是可以发生在发送方和接收方：</p><ul><li>接收方可以通告一个小的窗口</li><li>而发送方可以发送小数据</li></ul><p>于是，要解决糊涂窗口综合症，就解决上面两个问题就可以了</p><ul><li>让接收方不通告小窗口给发送方</li><li>让发送方避免发送小数据</li></ul><blockquote><p>怎么让接收方不通告小窗口呢？</p></blockquote><p>接收方通常的策略如下:</p><p>当「窗口大小」小于 min( MSS，缓存空间&#x2F;2 ) ，也就是小于 MSS 与 1&#x2F;2 缓存大小中的最小值时，就会向发送方通告窗口为 <code>0</code>，也就阻止了发送方再发数据过来。</p><p>等到接收方处理了一些数据后，窗口大小 &gt;&#x3D; MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。</p><blockquote><p>怎么让发送方避免发送小数据呢？</p></blockquote><p>发送方通常的策略:</p><p>使用 Nagle 算法，该算法的思路是延时处理，它满足以下两个条件中的一条才可以发送数据：</p><ul><li>要等到窗口大小 &gt;&#x3D; <code>MSS</code> 或是 数据大小 &gt;&#x3D; <code>MSS</code></li><li>收到之前发送数据的 <code>ack</code> 回包</li></ul><p>只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。</p><p>另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。</p><p>可以在 Socket 设置 <code>TCP_NODELAY</code> 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）</p><pre><code class="c">setsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (char *)&amp;value, sizeof(int));</code></pre><h4 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a><em>拥塞控制</em></h4><p>前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络状态。</p><p><strong>在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….</strong></p><p>所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。</p><p>于是，就有了<strong>拥塞控制</strong>，控制的目的就是<strong>避免「发送方」的数据填满整个网络。</strong></p><p>为了在「发送方」调节所要发送数据的量，定义了一个叫做「<strong>拥塞窗口</strong>」的概念。</p><blockquote><p>什么是拥塞窗口？和发送窗口有什么关系呢？</p></blockquote><p><strong>拥塞窗口 cwnd</strong>是发送方维护的一个的状态变量，它会根据<strong>网络的拥塞程度动态变化的</strong>。</p><p>我们在前面提到过发送窗口 <code>swnd</code> 和接收窗口 <code>rwnd</code> 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd &#x3D; min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。</p><p>拥塞窗口 <code>cwnd</code> 变化的规则：</p><ul><li>只要网络中没有出现拥塞，<code>cwnd</code> 就会增大；</li><li>但网络中出现了拥塞，<code>cwnd</code> 就减少；</li></ul><blockquote><p>那么怎么知道当前网络是否出现了拥塞呢？</p></blockquote><p>其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是<strong>发生了超时重传，就会认为网络出现了拥塞。</strong></p><blockquote><p>拥塞控制有哪些控制算法？</p></blockquote><p>拥塞控制主要是四个算法：</p><ul><li>慢启动</li><li>拥塞避免</li><li>拥塞发生</li><li>快速恢复</li></ul><p><em>慢启动</em></p><p>TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？</p><p>慢启动的算法记住一个规则就行：<strong>当发送方每收到一个MSS段的ACK，拥塞窗口 cwnd 的大小就会加 1。</strong></p><p>这里假定拥塞窗口 <code>cwnd</code> 和发送窗口 <code>swnd</code> 相等，下面举个栗子：</p><ul><li>连接建立完成后，一开始初始化 <code>cwnd = 1</code>，表示可以传一个 <code>MSS</code> 大小的数据。</li><li>当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个</li><li>当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个</li><li>当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。</li></ul><p>可以看出慢启动算法，发包的个数是随时间<strong>指数性的增长</strong>。</p><blockquote><p>那慢启动涨到什么时候是个头呢？</p></blockquote><p>有一个叫慢启动门限 <code>ssthresh</code> （slow start threshold）状态变量。</p><ul><li>当 <code>cwnd</code> &lt; <code>ssthresh</code> 时，使用慢启动算法。</li><li>当 <code>cwnd</code> &gt;&#x3D; <code>ssthresh</code> 时，就会使用「拥塞避免算法」。</li></ul><p><em>拥塞避免算法</em></p><p>前面说道，当拥塞窗口 <code>cwnd</code> 「超过」慢启动门限 <code>ssthresh</code> 就会进入拥塞避免算法。</p><p>一般来说 <code>ssthresh</code> 的大小是 <code>65535</code> 字节。</p><p>那么进入拥塞避免算法后，它的规则是：<strong>每当收到一个 ACK 时，cwnd 增加 1&#x2F;cwnd。</strong></p><p>接上前面的慢启动的栗子，现假定 <code>ssthresh</code> 为 <code>8</code>：</p><ul><li>当 8 个 ACK 应答确认到来时，每个确认增加 1&#x2F;8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 <code>MSS</code> 大小的数据，变成了<strong>线性增长。</strong></li></ul><p>所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。</p><p>就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。</p><p>当触发了重传机制，也就进入了「拥塞发生算法」。</p><p><em>拥塞发生</em></p><p>当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：</p><ul><li>超时重传</li><li>快速重传</li></ul><p>这两种使用的拥塞发送算法是不同的，接下来分别来说说。</p><blockquote><p>发生超时重传的拥塞发生算法</p></blockquote><p>当发生了「超时重传」，则就会使用拥塞发生算法。</p><p>这个时候，ssthresh 和 cwnd 的值会发生变化：</p><ul><li><code>ssthresh</code> 设为 <code>cwnd/2</code>，</li><li><code>cwnd</code> 重置为 初始值（我们可以用 ss -nli 命令查看每一个 TCP 连接的 cwnd 初始化值，默认10）</li></ul><p>接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。</p><blockquote><p>发生快速重传的拥塞发生算法</p></blockquote><p>还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次冗余 ACK，于是发送端就会快速地重传，不必等待超时再重传。</p><p>TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 <code>ssthresh</code> 和 <code>cwnd</code> 变化如下：</p><ul><li><code>cwnd = 原cwnd/2</code> ，也就是设置为原来的一半;</li><li><code>ssthresh = 原cwnd/2</code>，跟超时重传一致，变为原拥塞窗口大小的一半</li><li>进入快速恢复算法</li></ul><p><em>快速恢复</em></p><p>快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 <code>RTO</code> 超时那么强烈。</p><p>正如前面所说，进入快速恢复之前，<code>cwnd</code> 和 <code>ssthresh</code> 已被更新了：</p><ul><li><code>cwnd = cwnd/2</code> ，也就是设置为原来的一半;</li><li><code>ssthresh = 原cwnd/2</code>;</li></ul><p>然后，进入快速恢复算法如下：</p><ul><li>拥塞窗口 <code>cwnd = ssthresh + 3</code> （ 3 的意思是确认有 3 个数据包被收到了）；</li><li>重传丢失的数据包；</li><li>如果再收到重复的 ACK，那么 cwnd 增加 1；</li><li>如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；</li></ul><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/fastrecover.png" alt="快速重传和快速恢复"></p><p><strong>总结：</strong>发生超时重传时先慢启动再拥塞避免，发生快速重传时先快速恢复再拥塞避免。</p><h3 id="tcp为什么是面向字节流的"><a href="#tcp为什么是面向字节流的" class="headerlink" title="tcp为什么是面向字节流的"></a>tcp为什么是面向字节流的</h3><blockquote><p>先来说说为什么 UDP 是面向报文的协议？</p></blockquote><p>当用户消息通过 UDP 协议传输时，<strong>操作系统不会对消息进行拆分</strong>，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是<strong>每个 UDP 报文就是一个用户消息的边界</strong>，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。</p><blockquote><p>再来说说为什么 TCP 是面向字节流的协议？</p></blockquote><p>当用户消息通过 TCP 协议传输时，<strong>发送的报文最小单位是字节而不是以消息为单位</strong>。<strong>消息可能会被操作系统分组成多个的 TCP 报文</strong>，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。</p><p>这时，接收方的程序如果不知道发送方发送的消息的长度，也就是不知道消息的边界时，是无法读出一个有效的用户消息的，因为用户消息被拆分成多个 TCP 报文后，并不能像 UDP 那样，一个 UDP 报文就能代表一个完整的用户消息。假设发送端陆续调用 send 函数先后发送 「hi.」和「how are you」 报文，那么实际的发送很有可能是这几种情况。1：hi how are you一起发送 2：先发hi how，再发are you 3: 先发h，再发i how are you</p><p>当两个消息的某个部分内容被分到同一个 TCP 报文时，就是我们常说的 TCP 粘包问题，这时接收方不知道消息的边界的话，是无法读出有效的消息。</p><p>要解决这个问题，要交给<strong>应用程序</strong>。</p><h4 id="如何解决粘包"><a href="#如何解决粘包" class="headerlink" title="如何解决粘包"></a><em>如何解决粘包</em></h4><p>粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。</p><p>一般有三种方式分包的方式：</p><ul><li>固定长度的消息；</li><li>特殊字符作为边界；</li><li>自定义消息结构。</li></ul><p><em>固定长度的消息</em></p><p>这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。</p><p>但是这种方式灵活性不高，实际中很少用。</p><p><em>特殊字符作为边界</em></p><p>我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。</p><p>HTTP 是一个非常好的例子。</p><p>HTTP 通过设置空格、回车符、换行符作为 HTTP 报文协议的边界。</p><p>有一点要注意，这个作为边界点的特殊字符，如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。</p><p><em>自定义消息结构</em></p><p>我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。</p><p>比如这个消息结构体，首先 4 个字节大小的变量来表示数据长度，真正的数据则在后面。</p><pre><code class="c">struct &#123;     u_int32_t message_length;     char message_data[]; &#125; message;</code></pre><p>当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。</p><h3 id="tcp中的各种异常情况"><a href="#tcp中的各种异常情况" class="headerlink" title="tcp中的各种异常情况"></a>tcp中的各种异常情况</h3><h4 id="已建立连接的TCP，收到SYN会发生什么？"><a href="#已建立连接的TCP，收到SYN会发生什么？" class="headerlink" title="已建立连接的TCP，收到SYN会发生什么？"></a><em>已建立连接的TCP，收到SYN会发生什么？</em></h4><p>TCP 连接是由「四元组」唯一确认的。这个场景中，客户端的IP、服务端IP、目的端口并没有变化，所以这个问题关键要看客户端发送的 <strong>SYN 报文中的源端口是否和上一次连接的源端口相同</strong>。</p><p><strong>1. 客户端的 SYN 报文里的端口号与历史连接不相同</strong></p><p>如果客户端恢复后发送的 SYN 报文中的源端口号跟上一次连接的源端口号不一样，此时服务端会认为是新的连接要建立，于是就<strong>会通过三次握手来建立新的连接。</strong></p><p>那旧连接里处于 establish 状态的服务端最后会怎么样呢？</p><p>如果服务端发送了数据包给客户端，由于客户端的连接已经被关闭了，此时客户的内核就会回 RST 报文，服务端收到后就会释放连接。</p><p>如果服务端一直没有发送数据包给客户端，在超过一段时间后， TCP 保活机制就会启动，检测到客户端没有存活后，接着服务端就会释放掉该连接。</p><p><strong>2. 客户端的 SYN 报文里的端口号与历史连接相同</strong></p><p>如果客户端恢复后，发送的 SYN 报文中的源端口号跟上一次连接的源端口号一样，也就是处于 establish 状态的服务端收到了这个 SYN 报文。</p><p>处于 establish 状态的服务端如果收到了客户端的 SYN 报文（注意此时的 SYN 报文其实是乱序的，因为 SYN 报文的初始化序列号其实是一个随机数），**会回复一个携带了正确序列号和确认号的 ACK 报文(也就是之前连接中最后发送的ACK报文)**，这个 ACK 被称之为 Challenge ACK。</p><p>接着，客户端收到这个 Challenge ACK，发现序列号并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接。</p><p><strong>这个有漏洞，可能会导致黑客伪造RST报文进行攻击</strong>，因为黑客可以伪造成跟客户端一样的端口和ip地址发送一个SYN报文，按照上述所说服务端会回复一个携带了正确序列号和确认号的 ACK 报文，<strong>说白了，就是可以通过这一步拿到服务端下一次预期接收的序列号。</strong></p><p>然后黑客用这个确认号作为 RST 报文的序列号，发送给服务端，此时服务端会认为这个 RST 报文里的序列号是合法的，于是就会释放跟客户端的连接</p><h4 id="在-TCP-正常挥手过程中，处于-TIME-WAIT-状态的连接，收到相同四元组的-SYN-后会发生什么？"><a href="#在-TCP-正常挥手过程中，处于-TIME-WAIT-状态的连接，收到相同四元组的-SYN-后会发生什么？" class="headerlink" title="在 TCP 正常挥手过程中，处于 TIME_WAIT 状态的连接，收到相同四元组的 SYN 后会发生什么？"></a><em>在 TCP 正常挥手过程中，处于 TIME_WAIT 状态的连接，收到相同四元组的 SYN 后会发生什么？</em></h4><p>如果双方开启了时间戳机制：</p><ul><li>如果客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>大</strong>，<strong>并且</strong>SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要<strong>大</strong>。那么就会重用该四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程。</li><li>如果客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>小</strong>，<strong>或者</strong>SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要<strong>小</strong>。那么就会<strong>再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号，就回 RST 报文给服务端</strong>。</li></ul><p>在 TIME_WAIT 状态，收到 RST 会断开连接吗？</p><ul><li>如果 <code>net.ipv4.tcp_rfc1337</code> 参数为 0，则提前结束 TIME_WAIT 状态，释放连接。</li><li>如果 <code>net.ipv4.tcp_rfc1337</code> 参数为 1，则会丢掉该 RST 报文。</li></ul><h4 id="拔网线，断电，进程崩溃时会发生什么"><a href="#拔网线，断电，进程崩溃时会发生什么" class="headerlink" title="拔网线，断电，进程崩溃时会发生什么"></a><em>拔网线，断电，进程崩溃时会发生什么</em></h4><p><em>拔网线，断电等主机宕机情况</em></p><p>若服务端没有要向客户端发送的报文，过一段时间后会触发保活机制，当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，<strong>TCP 会报告该 TCP 连接已经死亡并断开连接</strong>。应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 <code>SO_KEEPALIVE</code> 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。</p><p>若服务端有要向客户端发送的报文并且客户端没有重启，在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发<strong>超时重传</strong>机制，重传未得到响应的报文。<strong>在重传报文且一直没有收到对方响应的情况时，先达到「最大重传次数」或者「最大超时时间」这两个的其中一个条件后，就会停止重传并断开连接</strong>。</p><p>若客户端宕机后重启，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程：</p><ul><li>如果客户端主机上<strong>没有</strong>进程监听该 TCP 报文的目标端口号，那么客户端内核就会<strong>回复 RST 报文，重置该 TCP 连接</strong>；</li><li>如果客户端主机上<strong>有</strong>进程监听该 TCP 报文的目标端口号，由于客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会<strong>回复 RST 报文，重置该 TCP 连接</strong>。</li></ul><p>所以，只要有一方重启完成后，收到之前 TCP 连接的报文，都会<strong>回复 RST 报文，以断开连接</strong></p><p><em>进程崩溃情况</em></p><p><strong>在 kill 掉进程后，服务端会发送 FIN 报文，与客户端进行四次挥手</strong>。即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃，这个过程操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手。</p><h4 id="重启-TCP-服务进程时，为什么会有“Address-in-use”的报错信息？"><a href="#重启-TCP-服务进程时，为什么会有“Address-in-use”的报错信息？" class="headerlink" title="重启 TCP 服务进程时，为什么会有“Address in use”的报错信息？"></a>重启 TCP 服务进程时，为什么会有“Address in use”的报错信息？</h4><p>当我们重启 TCP 服务进程的时候，意味着通过服务器端发起了关闭连接操作，于是就会经过四次挥手，而对于主动关闭方，会在 TIME_WAIT 这个状态里停留一段时间，这个时间大约为 2MSL。</p><p><strong>当 TCP 服务进程重启时，服务端会出现 TIME_WAIT 状态的连接，TIME_WAIT 状态的连接使用的 IP+PORT 仍然被认为是一个有效的 IP+PORT 组合，相同机器上不能够在该 IP+PORT 组合上进行绑定，那么执行 bind() 函数的时候，就会返回了 Address already in use 的错误</strong>。</p><p>而等 TIME_WAIT 状态的连接结束后，重启 TCP 服务进程就能成功。</p><p>解决办法：</p><p>我们可以在调用 bind 前，对 socket 设置 SO_REUSEADDR 属性，可以解决这个问题。(<strong>跟net.ipv4.tcp_tw_reuse不同</strong>，那个用于客户端connect，这个用于服务端bind)</p><p>SO_REUSEADDR 作用是<strong>：如果当前启动进程绑定的 IP+PORT 与处于TIME_WAIT 状态的连接占用的 IP+PORT 存在冲突，但是新启动的进程使用了 SO_REUSEADDR 选项，那么该进程就可以绑定成功。</strong></p><h3 id="tcp的缺陷"><a href="#tcp的缺陷" class="headerlink" title="tcp的缺陷"></a>tcp的缺陷</h3><h4 id="升级-TCP-的工作很困难"><a href="#升级-TCP-的工作很困难" class="headerlink" title="升级 TCP 的工作很困难"></a>升级 TCP 的工作很困难</h4><p> TCP 协议是在内核中实现的，应用程序只能使用不能修改，如果要想升级 TCP 协议，那么只能升级内核。</p><p>而升级内核这个工作是很麻烦的事情，麻烦的事情不是说升级内核这个操作很麻烦，而是由于内核升级涉及到底层软件和运行库的更新，我们的服务程序就需要回归测试是否兼容新的内核版本，所以服务器的内核升级也比较保守和缓慢。</p><p>很多 TCP 协议的新特性，都是需要客户端和服务端同时支持才能生效的，比如 TCP Fast Open 这个特性，虽然在2013 年就被提出了，但是 Windows 很多系统版本依然不支持它，这是因为 PC 端的系统升级滞后很严重，Windows Xp 现在还有大量用户在使用，尽管它已经存在快 20 年。</p><p>所以，即使 TCP 有比较好的特性更新，也很难快速推广，用户往往要几年或者十年才能体验到。</p><h4 id="TCP-建立连接的延迟"><a href="#TCP-建立连接的延迟" class="headerlink" title="TCP 建立连接的延迟"></a>TCP 建立连接的延迟</h4><p>基于 TCP 实现的应用协议，都是需要先建立三次握手才能进行数据传输，比如 HTTP 1.0&#x2F;1.1、HTTP&#x2F;2、HTTPS。</p><p>现在大多数网站都是使用 HTTPS 的，这意味着在 TCP 三次握手之后，还需要经过 TLS 四次握手后，才能进行 HTTP 数据的传输，这在一定程序上增加了数据传输的延迟。</p><p>解决方法：开启TCP FAST OPEN，使用TLS1.3</p><h4 id="TCP-存在队头阻塞问题"><a href="#TCP-存在队头阻塞问题" class="headerlink" title="TCP 存在队头阻塞问题"></a>TCP 存在队头阻塞问题</h4><p>TCP 是字节流协议，<strong>TCP 层必须保证收到的字节数据是完整且有序的</strong>，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，而必须等到丢失的TCP段重传并接收后才可以。</p><p>这就是 TCP 队头阻塞问题，但这也不能怪 TCP ，因为只有这样做才能保证数据的有序性。</p><p>HTTP&#x2F;2 多个请求是跑在一个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求，所以 HTTP&#x2F;2 队头阻塞问题就是因为 TCP 协议导致的。</p><h4 id="网络迁移需要重新建立-TCP-连接"><a href="#网络迁移需要重新建立-TCP-连接" class="headerlink" title="网络迁移需要重新建立 TCP 连接"></a>网络迁移需要重新建立 TCP 连接</h4><p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。</p><p>那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接</strong>。</p><p>而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p><h2 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h2><p><img src="C:\Users\hufei\Desktop\udp.png" alt="UDP 头部格式"></p><ul><li>目标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。</li><li>包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。</li><li>校验和：校验和是为了提供可靠的 UDP 首部和数据而设计，防止收到在网络传输中受损的 UDP包。</li></ul><h3 id="udp和tcp区别"><a href="#udp和tcp区别" class="headerlink" title="udp和tcp区别"></a>udp和tcp区别</h3><p><em>1. 连接</em></p><ul><li>TCP 是面向连接的传输层协议，传输数据前先要建立连接。</li><li>UDP 是不需要连接，即刻传输数据。</li></ul><p><em>2. 服务对象</em></p><ul><li>TCP 是一对一的两点服务，即一条连接只有两个端点。</li><li>UDP 支持一对一、一对多、多对多的交互通信</li></ul><p><em>3. 可靠性</em></p><ul><li>TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。</li><li>UDP 是尽最大努力交付，不保证可靠交付数据。</li></ul><p><em>4. 拥塞控制、流量控制</em></p><ul><li>TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。</li><li>UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。</li></ul><p><em>5. 首部开销</em></p><ul><li>TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 <code>20</code> 个字节，如果使用了「选项」字段则会变长的。</li><li>UDP 首部只有 8 个字节，并且是固定不变的，开销较小。</li></ul><p><em>6. 传输方式</em></p><ul><li>TCP 是流式传输，没有边界，但保证顺序和可靠。</li><li>UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。</li></ul><p><em>7. 分片不同</em></p><ul><li>TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。</li><li>UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。</li></ul><p><em>应用场景差别：</em></p><p>由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：</p><ul><li><code>FTP</code> 文件传输；</li><li>HTTP &#x2F; HTTPS；</li></ul><p>由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：</p><ul><li>包总量较少的通信，如 <code>DNS</code> 、<code>SNMP</code> 等(udp包长度16位，加上首部最多只能传65535字节数据)；</li><li>视频、音频等多媒体通信；</li><li>广播通信；</li></ul><h3 id="如何基于udp实现可靠传输"><a href="#如何基于udp实现可靠传输" class="headerlink" title="如何基于udp实现可靠传输"></a>如何基于udp实现可靠传输</h3><p>把 TCP 可靠传输的特性（序列号、确认应答、超时重传、流量控制、拥塞控制）在应用层实现一遍。</p><p>实现的思路确实这样没错，<strong>但既然 TCP 天然支持可靠传输，为什么还需要基于 UDP 实现可靠传输呢？这不是重复造轮子吗？</strong></p><p>现在市面上已经有基于 UDP 协议实现的可靠传输协议的成熟方案了，那就是 QUIC 协议，已经应用在了 HTTP&#x2F;3。QUIC解决了TCP的几个缺陷</p><h4 id="QUIC协议"><a href="#QUIC协议" class="headerlink" title="QUIC协议"></a>QUIC协议</h4><p><em>QUIC首部</em></p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/http3-over-quic-protocol-works.png" alt="img"></p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/packet%20header.png" alt="Packet Header"></p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/QUICPACKET.png" alt="img"></p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/frame%20header.png" alt="img"></p><p><em>QUIC实现可靠传输</em></p><p>QUIC也有序列号，确认应答和重传机制，但相比TCP做了一些改进。</p><p>QUIC新增连接ID字段用于区分不同的连接，QUIC 也是需要三次握手来建立连接的，主要目的是为了协商连接 ID。协商出连接 ID 后，后续传输时，双方只需要固定住连接 ID，从而实现连接迁移功能。</p><p>QUIC新增 <code>Packet Number</code>用于区别不同报文，这 是每个报文独一无二的编号，它是<strong>严格递增</strong>的，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。</p><p>这样设计有两个好处：</p><ul><li>可以更加精确计算 RTT，没有 TCP 重传的歧义性问题；(tcp「原始报文的响应」和「重传报文的响应」确认号一致，客户端无法判断，这样在计算 RTT 时应该选择从发送原始报文开始计算，还是重传原始报文开始计算呢)</li><li>可以支持乱序确认，因为丢包重传将当前窗口阻塞在原地，而 TCP 必须是顺序确认的，丢包时会导致窗口不滑动；</li></ul><p>QUIC新增Stream ID，Offset用于给数据排序，每个数据包首部包括Stream ID，Offset，Length</p><ul><li>Stream ID 作用：多个并发传输的 HTTP 消息，通过不同的 Stream ID 加以区别，类似于 HTTP2 的 Stream ID；</li><li>Offset 作用：类似于 TCP 协议中的 Seq 序号，<strong>保证数据的顺序性和可靠性</strong>；</li><li>Length 作用：指明了 Frame 数据的长度。</li></ul><p><strong>通过 Stream ID + Offset 字段信息实现数据的有序性</strong>，通过比较两个数据包的 Stream ID 与 Stream Offset ，如果都是一致，就说明这两个数据包的内容一致。</p><p><em>QUIC如何解决队头阻塞</em></p><p>TCP 发送出去的数据，都是需要按序确认的，只有在数据都被按顺序确认完后，发送窗口才会往前滑动。</p><p>同理TCP接收窗口收到有序数据时，接收窗口才能往前滑动，然后那些已经接收并且被确认的「有序」数据就可以被应用层读取。</p><ul><li>停留「发送窗口」会使得发送方无法继续发送数据。</li><li>停留「接收窗口」会使得应用层无法读取新的数据。</li></ul><p>这就是TCP的队头阻塞问题</p><p>QUIC 借鉴 HTTP&#x2F;2 里的 Stream 的概念，一个 Stream 就代表 HTTP&#x2F;1.1 里的请求和响应，在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (Stream)。</p><p>但是 <strong>QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口</strong>。</p><p>假如 Stream2 丢了一个 UDP 包，也只会影响 Stream2 的处理，不会影响其他 Stream，与 HTTP&#x2F;2 不同，HTTP&#x2F;2 只要某个流中的数据包丢失了，其他流也会因此受影响。</p><p><em>QUIC建立连接更快</em></p><p>对于 HTTP&#x2F;1 和 HTTP&#x2F;2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手（1RTT），再 TLS 握手（2RTT），所以需要 3RTT 的延迟才能传输数据，就算 Session 会话服用，也需要至少 2 个 RTT。</p><p>HTTP&#x2F;3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。</p><p>但是 HTTP&#x2F;3 的 QUIC 协议并不是与 TLS 分层，而是<strong>QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果</strong>。</p><p><em>QUIC迁移连接</em></p><p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接</strong>。</p><p>QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong>来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p><h2 id="IP"><a href="#IP" class="headerlink" title="IP"></a>IP</h2><h3 id="ip首部"><a href="#ip首部" class="headerlink" title="ip首部"></a>ip首部</h3><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/ipheader.png" alt="img"></p><p>第一行：<br>（1）版本号（Version），4位；用于标识IP协议版本，IPv4是0100，IPv6是0110，也就是二进制的4和6。<br>（2）首部长度（Internet Header Length），4位；用于标识首部的长度，单位为4字节，所以首部长度最大值为：(2^4 - 1) * 4 &#x3D; 60字节，但一般只推荐使用20字节的固定长度。<br>（3）服务类型（Type Of Service），8位；用于标识IP包的优先级，但现在并未使用。<br>（4）总长度（Total Length），16位；标识IP数据报的总长度，最大为：2^16 -1 &#x3D; 65535字节。<br>第二行：<br>（1）标识（Identification），16位；用于标识IP数据报，如果因为数据链路层帧数据段长度限制（也就是MTU，支持的最大传输单元），IP数据报需要进行分片发送，则每个分片的IP数据报标识都是一致的。<br>（2）标志（Flag），3位，但目前只有2位有意义；最低位为MF，MF&#x3D;1代表后面还有分片的数据报，MF&#x3D;0代表当前数据报已是最后的数据报。次低位为DF，DF&#x3D;1代表不能分片，DF&#x3D;0代表可以分片。<br>（3）片偏移（Fragment Offset），13位；代表某个分片在原始数据中的相对位置。<br>第三行：<br>（1）生存时间（TTL），8位；以前代表IP数据报最大的生存时间，现在标识IP数据报可以经过的路由器数。<br>（2）协议（Protocol），8位；代表上层传输层协议的类型，1代表ICMP，2代表IGMP，6代表TCP，17代表UDP。<br>（3）校验和（Header Checksum），16位；用于**验证首部(不包括数据)**完整性，计算方法为，首先将校验和位置零，然后将每16位二进制反码求和即为校验和，最后写入校验和位置。<br>第四行：源IP地址<br>第五行：目的IP地址</p><h4 id="为什么数据链路层做了差错检测，ip还要做"><a href="#为什么数据链路层做了差错检测，ip还要做" class="headerlink" title="为什么数据链路层做了差错检测，ip还要做"></a>为什么数据链路层做了差错检测，ip还要做</h4><p>从现在看来，这确实是个多余的设计，ipv6已经取消了差错检测</p><p>但设计之初数据链路层的协议并未统一用以太网，ip不知道数据链路层是否会做差错检测，所以ip进行了差错检测。</p><h3 id="ip地址"><a href="#ip地址" class="headerlink" title="ip地址"></a>ip地址</h3><h4 id="ipv4"><a href="#ipv4" class="headerlink" title="ipv4"></a>ipv4</h4><p>IP 地址（IPv4 地址）由 <code>32</code> 位正整数来表示，IP 地址在计算机是以二进制的方式处理的。</p><p>而人类为了方便记忆采用了<strong>点分十进制</strong>的标记方式，也就是将 32 位 IP 地址以每 8 位为组，共分为 <code>4</code> 组，每组以「<code>.</code>」隔开，再将每组转换成十进制。</p><h5 id="IP-地址的分类"><a href="#IP-地址的分类" class="headerlink" title="IP 地址的分类"></a>IP 地址的分类</h5><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/ipaddress.jpg" alt="IP 地址分类"></p><p>其中对于 A、B、C 类主要分为两个部分，分别是<strong>网络号和主机号</strong>。</p><p>而 D 类和 E 类地址是没有主机号的，所以不可用于主机 IP，D 类常被用于<strong>多播</strong>，E 类是预留的分类，暂时未使用。</p><h5 id="特殊的地址"><a href="#特殊的地址" class="headerlink" title="特殊的地址"></a>特殊的地址</h5><p>主机号全为 1 指定某个网络下的所有主机，用于广播</p><p>主机号全为 0 指定某个网络</p><p>0.0.0.0。它表示的是这样一个集合：所有不清楚的主机和目的网络。这里的“不清楚”是指在本机的路由表里没有特定条目指明如何到达。对本机来说，它就是一个“收容所”，所有不认识的“三无”人员，一律送进去。如果你在网络设置中设置了缺省网关，那么Windows系统会自动产生一个目的地址为0.0.0.0的缺省路由。</p><p>255.255.255.255。限制广播地址，对本机来说，这个地址指本网段内(同一广播域)的所有主机。这个地址不能被路由器转发</p><p>127.0.0.1。本地回环地址，主要用于测试。在Windows系统中，这个地址有一个别名“Localhost”。这个地址只用于本机测试，不会发送到网络上。</p><h5 id="广播和多播"><a href="#广播和多播" class="headerlink" title="广播和多播"></a>广播和多播</h5><blockquote><p>广播地址用于什么？</p></blockquote><p>广播地址用于在<strong>同一个链路中相互连接的主机之间发送数据包</strong>。</p><p>学校班级中就有广播的例子，在准备上课的时候，通常班长会喊：“上课， 全体起立！”，班里的同学听到这句话是不是全部都站起来了？这个句话就有广播的含义。</p><p>当主机号全为 1 时，就表示该网络的广播地址。</p><p>广播地址可以分为本地广播和直接广播两种。</p><ul><li><strong>在本网络内广播的叫做本地广播</strong>。例如网络地址为 192.168.0.0&#x2F;24 的情况下，广播地址是 192.168.0.255 。因为这个广播地址的 IP 包会被路由器屏蔽，所以不会到达 192.168.0.0&#x2F;24 以外的其他链路上。</li><li><strong>在不同网络之间的广播叫做直接广播</strong>。例如网络地址为 192.168.0.0&#x2F;24 的主机向 192.168.1.255&#x2F;24 的目标地址发送 IP 包。收到这个包的路由器，将数据转发给 192.168.1.0&#x2F;24，从而使得所有 192.168.1.1~192.168.1.254 的主机都能收到这个包（由于直接广播有一定的安全问题，多数情况下会在路由器上设置为不转发。） 。</li></ul><blockquote><p>多播地址用于什么？</p></blockquote><p>多播用于<strong>将包发送给特定组内的所有主机。</strong></p><p>还是举班级的栗子，老师说：“最后一排的同学，上来做这道数学题。”，老师指定的是最后一排的同学，也就是多播的含义了。</p><p>由于<strong>广播无法穿透路由，若想给其他网段发送同样的包，就可以使用可以穿透路由的多播</strong>。</p><p>多播使用的 D 类地址，其前四位是 <code>1110</code> 就表示是多播地址，而剩下的 28 位是多播的组编号。</p><p>从 224.0.0.0 ~ 239.255.255.255 都是多播的可用范围，其划分为以下三类：</p><ul><li>224.0.0.0 ~ 224.0.0.255 为预留的组播地址，只能在局域网中，路由器是不会进行转发的。</li><li>224.0.1.0 ~ 238.255.255.255 为用户可用的组播地址，可以用于 Internet 上。</li><li>239.0.0.0 ~ 239.255.255.255 为本地管理组播地址，可供内部网在内部使用，仅在特定的本地范围内有效。</li></ul><p><strong>组播地址不是用于机器ip地址</strong>的，因为组播地址没有网络号和主机号，所以跟dhcp没关系。组播地址一般是用于udp协议，机器发送UDP组播数据时，目标地址填的是组播地址，那么在组播组内的机器都能收到数据包。</p><p>是否加入组播组和离开组播组，是由socket一个接口实现的，<strong>主机ip是不用改变的</strong>。</p><h5 id="无分类地址-CIDR和子网"><a href="#无分类地址-CIDR和子网" class="headerlink" title="无分类地址 CIDR和子网"></a>无分类地址 CIDR和子网</h5><p>IP 分类存在许多缺点，如主机分配不够灵活，C 类地址能包含的最大主机数量实在太少了，而 B 类地址能包含的最大主机数量又太多了。同时，同一网络下没有地址层次，比如一个公司里用了 B 类地址，但是可能需要根据生产环境、测试环境、开发环境来划分地址层次，而这种 IP 分类是没有地址层次划分的功能</p><p>所以后面提出了无分类地址的方案，即 <code>CIDR</code>，以及子网。</p><p>这种方式不再有分类地址的概念，32 比特的 IP 地址被划分为两部分，前面是<strong>网络号</strong>，后面是<strong>主机号</strong>。表示形式 <code>a.b.c.d/x</code>，其中 <code>/x</code> 表示前 x 位属于<strong>网络号</strong>， x 的范围是 <code>0 ~ 32</code>，这就使得 IP 地址更加具有灵活性。</p><p>还有另一种划分网络号与主机号形式，那就是<strong>子网掩码</strong>，掩码的意思就是掩盖掉主机号，剩余的就是网络号。<strong>将子网掩码和 IP 地址按位计算 AND，就可得到网络号。</strong></p><p>子网掩码还有一个作用，那就是<strong>划分子网</strong>。将主机地址分为两个部分：子网网络地址和子网主机地址</p><h5 id="NAT"><a href="#NAT" class="headerlink" title="NAT"></a>NAT</h5><p>IPv4 的地址是非常紧缺的，在前面我们也提到可以通过无分类地址来减缓 IPv4 地址耗尽的速度，但是互联网的用户增速是非常惊人的，所以 IPv4 地址依然有被耗尽的危险。</p><p>于是，提出了一种<strong>网络地址转换 NAT</strong> 的方法，再次缓解了 IPv4 地址耗尽的问题。</p><p>简单的来说 NAT 就是同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。多个私有地址统一用同一个公有地址来传输数据。</p><p>由于绝大多数的网络应用都是使用传输层协议 TCP 或 UDP 来传输数据的，因此可用端口号来对不同的私有地址进行区分，在通信时给不同的私有地址分配不同的端口号。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/nat.jpg" alt="NAPT"></p><p>由于 NAT&#x2F;NAPT 都依赖于自己的转换表，因此会有以下的问题：</p><ul><li>外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。</li><li>转换表的生成与转换操作都会产生性能开销。</li><li>通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。</li></ul><p>解决的方法主要有两种方法。</p><p><em>第一种就是改用 IPv6</em></p><p>IPv6 可用范围非常大，以至于每台设备都可以配置一个公有 IP 地址，就不搞那么多花里胡哨的地址转换了，但是 IPv6 普及速度还需要一些时间。</p><p><em>第二种 NAT 内网穿透技术</em></p><p>借助一个有公网ip的云服务器。</p><p>内网机器向云服务器建立一个长连接，然后云服务器就可以主动向内网机器传数据。云服务器将自己某端口的数据转发到内网机器上，然后客户端访问云服务器的那个端口就可以访问内网机器了。</p><h5 id="DHCP"><a href="#DHCP" class="headerlink" title="DHCP"></a>DHCP</h5><p>DHCP 在生活中我们是很常见的了，我们的电脑通常都是通过 DHCP 动态获取 IP 地址，大大省去了配 IP 信息繁琐的过程。</p><ul><li>客户端首先发起 <strong>DHCP 发现报文（DHCP DISCOVER）</strong> 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP <strong>广播</strong>通信，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。</li><li>DHCP 服务器收到 DHCP 发现报文时，用 <strong>DHCP 提供报文（DHCP OFFER）</strong> 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 <strong>IP 地址租用期</strong>。</li><li>客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 <strong>DHCP 请求报文（DHCP REQUEST</strong>进行响应，回显配置的参数。</li><li>最后，服务端用 <strong>DHCP ACK 报文</strong>对 DHCP 请求报文进行响应，应答所要求的参数。</li></ul><p>DHCP 交互中，<strong>全程都是使用 UDP 广播通信</strong>，而路由器不会转发广播包，为了解决这个问题就出现了 <strong>DHCP 中继代理</strong>。有了 DHCP 中继代理以后，<strong>对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理。</strong></p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/dhcprelay.jpg" alt=" DHCP 中继代理"></p><ul><li>DHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以<strong>单播</strong>的形式发给 DHCP 服务器。</li><li>服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包广播给 DHCP 客户端 。</li></ul><p>因此，DHCP 服务器即使不在同一个链路上也可以实现统一分配和管理IP地址。</p><p><em>DHCP和RARP的区别</em></p><p>1.RARP可以满足主机IP地址配置的部分要求，但是不能完全满足</p><p>包括但不限于以下配置：网络掩码，网关地址，静态路由，DNS服务器，以及私有的，公有的option功能。</p><p>2.RARP是二层协议，无法穿透子网，DHCP可以穿透子网。如果用RARP来分配地址的话，需要在每个网段(子网)内部署一台RARP Server,管理难度太大。</p><p>3.RARP只能对地址进行识别，无法进行地址的统一规划和分配。</p><h5 id="ICMP"><a href="#ICMP" class="headerlink" title="ICMP"></a>ICMP</h5><p>ICMP 全称是 <strong>Internet Control Message Protocol</strong>，也就是<strong>互联网控制报文协议</strong>。</p><p>网络包在复杂的网络传输环境里，常常会遇到各种问题。</p><p>当遇到问题的时候，总不能死个不明不白，没头没脑的作风不是计算机网络的风格。所以<strong>需要传出消息，报告遇到了什么问题</strong>，这样才可以调整传输策略，以此来控制整个局面。</p><p><code>ICMP</code> 主要的功能包括：<strong>确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。</strong></p><p>在 <code>IP</code> 通信中如果某个 <code>IP</code> 包因为某种原因未能达到目标地址，那么这个具体的原因将<strong>由 ICMP 负责通知</strong>。</p><blockquote><p>ICMP 类型</p></blockquote><p>ICMP 大致可以分为两大类：</p><ul><li>一类是用于诊断的查询消息，也就是「<strong>查询报文类型</strong>」</li><li>另一类是通知出错原因的错误消息，也就是「<strong>差错报文类型</strong>」</li></ul><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/icmp.jpg" alt="常见的 ICMP 类型"></p><h5 id="IGMP"><a href="#IGMP" class="headerlink" title="IGMP"></a>IGMP</h5><p>在前面我们知道了组播地址，也就是 D 类地址，既然是组播，那就说明是只有一组的主机能收到数据包，不在一组的主机不能收到数组包，怎么管理是否是在一组呢？那么，就需要 <code>IGMP</code> 协议了。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/igmp.jpg" alt="组播模型"></p><p><strong>IGMP 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间</strong>，如上图中的蓝色部分。同网络的路由器负责管理主机加入和退出组播组</p><ul><li>IGMP 报文向路由器申请加入和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除非主机通过 IGMP 加入到组播组，主机申请加入到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转发组播包到对应的主机了。</li><li>IGMP 报文采用 IP 封装，IP 头部的协议号为 2，而且 TTL 字段值通常为 1，因为 IGMP 是工作在主机与连接的路由器之间。</li></ul><h4 id="ipv6"><a href="#ipv6" class="headerlink" title="ipv6"></a>ipv6</h4><p>IPv4 的地址是 32 位的，大约可以提供 42 亿个地址，但是早在 2011 年 IPv4 地址就已经被分配完了。</p><p>但是 IPv6 的地址是 <code>128</code> 位的，这可分配的地址数量是大的惊人，说个段子 <strong>IPv6 可以保证地球上的每粒沙子都能被分配到一个 IP 地址。</strong></p><p>但 IPv6 除了有更多的地址之外，还有更好的安全性和扩展性，说简单点就是 IPv6 相比于 IPv4 能带来更好的网络体验。</p><p>但是因为 <strong>IPv4 和 IPv6 不能相互兼容</strong>，所以不但要我们电脑、手机之类的设备支持，还需要网络运营商对现有的设备进行升级，所以这可能是 IPv6 普及率比较慢的一个原因。</p><h5 id="ipv6和ipv4的差别"><a href="#ipv6和ipv4的差别" class="headerlink" title="ipv6和ipv4的差别"></a>ipv6和ipv4的差别</h5><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/ipv4andipv6.jpg" alt="IPv4 首部与 IPv6 首部的差异"></p><p>IPv4 地址长度共 32 位，是以每 8 位作为一组，并用点分十进制的表示方式。IPv6 地址长度是 128 位，是以每 16 位作为一组，每组用冒号 「:」 隔开。</p><p>IPv6 的地址主要有以下类型地址：</p><ul><li>单播地址，用于一对一的通信</li><li>组播地址，用于一对多的通信</li><li>任播地址，用于通信最近的节点，最近的节点是由路由协议决定</li><li><strong>没有广播地址</strong></li></ul><p>对于一对一通信的 IPv6 地址，主要划分了三类单播地址，每类地址的有效范围都不同。</p><ul><li>在同一链路单播通信，不经过路由器，可以使用<strong>链路本地单播地址</strong>，IPv4 没有此类型</li><li>在内网里单播通信，可以使用<strong>唯一本地地址</strong>，相当于 IPv4 的私有 IP</li><li>在互联网通信，可以使用<strong>全局单播地址</strong>，相当于 IPv4 的公有 IP</li></ul><p>IPv6 相比 IPv4 的首部改进：</p><ul><li><strong>取消了首部校验和字段。</strong> 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。</li><li><strong>取消了分片&#x2F;重新组装相关字段。</strong> 分片与重组是耗时的过程，IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提高了路由器转发的速度。</li><li><strong>取消选项字段。</strong> 选项字段不再是标准 IP 首部的一部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下一个首部」指出的位置上。删除该选项字段使的 IPv6 的首部成为固定长度的 <code>40</code> 字节。</li></ul><h5 id="ipv6优点"><a href="#ipv6优点" class="headerlink" title="ipv6优点"></a>ipv6优点</h5><ul><li><p>可分配地址变多，可以保证地球上的每粒沙子都能被分配到一个 IP 地址</p></li><li><p>IPv6 可自动配置，即使没有 DHCP 服务器也可以实现自动分配IP地址，<strong>便捷到即插即用</strong>。</p></li><li><p>IPv6 包头包首部长度采用固定的值 <code>40</code> 字节，去掉了差错检测，简化了首部结构，禁止分片，减轻了路由器负荷，大大<strong>提高了传输的性能</strong>。</p></li><li><p>IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大<strong>提升了安全性</strong>。</p></li></ul><h2 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h2><p>RPC（Remote Procedure Call），又叫做远程过程调用。它本身并不是一个具体的协议，而是一种调用方式，一种思想。</p><p>举个例子，我们平时调用一个本地方法就像下面这样。</p><pre><code class="c++">res = localFunc(req)1.</code></pre><p>如果现在这不是个本地方法，而是个远端服务器暴露出来的一个方法remoteFunc，如果我们还能像调用本地方法那样去调用它，这样就可以屏蔽掉一些网络细节，用起来更方便，岂不美哉？</p><pre><code class="c++">res = remoteFunc(req)</code></pre><p>这样跨机器调用必须用到网络编程才能实现，RPC 帮助我们屏蔽网络编程细节，实现调用远程方法就跟调用本地一样的体验，我们不需要因为这个方法是远程调用就需要编写很多与业务无关的代码。</p><p>RPC 是一个远程调用，需要通过网络来传输数据，并且 RPC 常用于业务系统之间的数据交互，需要保证其可靠性，所以 RPC 一般默认采用 TCP 来传输。我们常用的 HTTP 协议也是建立在 TCP 之上的。</p><p>调用方持续地把请求参数序列化成二进制后，经过 TCP 传输给了服务提供方。服务提供方从 TCP 通道里面收到二进制数据，那如何知道一个请求的数据到哪里结束，是一个什么类型的请求呢？这里就需要用到相关协议，而协议的作用就是做相关规定和约束。</p><p>将对象保存到文件，或者通过网络传输给对方，都是需要将对象转换二进制数据才能完成，那么<strong>对象转二进制数据的过程就是序列化</strong>，相反的，<strong>二进制数据转对象的过程就是反序列化的过程</strong>。</p><p>JSON 序列化大多数语言都支持，JSON 优势是使用起来简单，容易阅读，应用广泛，缺点就是不适合大数据量的场景；</p><p>ProtoBuf 使用需要定义 IDL 文件，序列化后体积相比 JSON 小很多，现在很多大公司都在用，gRPC 框架使用 protobuf 序列化。</p><p>大多数的协议会分成两部分，分别是数据头和消息体。数据头一般用于身份识别，包括协议标识、数据大小、请求类型、序列化类型等信息；消息体主要是请求的业务参数信息和扩展属性等。</p><p>根据协议格式，服务提供方就可以正确地从二进制数据中分割出不同的请求来，同时根据请求类型和序列化类型，把二进制的消息体逆向还原成请求对象。这个过程叫作“反序列化”。</p><p>服务提供方再根据反序列化出来的请求对象找到对应的实现类，完成真正的方法调用，然后把执行结果序列化后，回写到对应的 TCP 通道里面。调用方获取到应答的数据包后，再反序列化成应答对象，这样调用方就完成了一次 RPC 调用。</p><h2 id="网络攻击"><a href="#网络攻击" class="headerlink" title="网络攻击"></a>网络攻击</h2><p>浏览器安全可以分为三大块：<strong>Web页面安全、浏览器网络安全、浏览器系统安全</strong></p><p>Web页面安全主要就是同源策略限制</p><p><strong>什么是同源策略</strong></p><p>最初，它的含义是指，A网页设置的 Cookie，B网页不能打开，除非这两个网页”同源”。所谓”同源”指的是”三个相同”，也就是我们访问站点的：<code>协议</code>、<code>域名</code>、<code>端口号</code>必须一至，才叫<code>同源</code>。</p><p>同源策略的目的，是为了保证用户信息的安全，防止恶意的网站窃取数据。设想这样一种情况：A网站是一家银行，用户登录以后，又去浏览其他网站。如果其他网站可以读取A网站的 Cookie，会发生什么？很显然，如果 Cookie 包含隐私（比如存款总额），这些信息就会泄漏。更可怕的是，Cookie 往往用来保存用户的登录状态，如果用户没有退出登录，其他网站就可以冒充用户，为所欲为。</p><p>随着互联网的发展，”同源政策”越来越严格。目前，如果非同源，共有三种行为受到限制。</p><ol><li><strong>DOM层面</strong>：不同源站点之间不能相互访问和操作DOM</li><li><strong>数据层面</strong>：不能获取不同源站点的Cookie、LocalStorage、indexDB等数据</li><li><strong>网络层面</strong>：不能向不同源站点发送ajax请求</li></ol><p>浏览器收到响应数据之后，会判断响应回数据的源和当前页面的源是否是属于同源。针对不同源，如果后端没有对响应字段进行处理，则响应回的数据会被浏览器直接过滤掉。</p><p>当然<strong>同源策略限制也不是绝对隔离不同源的站点</strong>，比如link、img、script标签都没有跨域限制，这让我们开发更灵活了，但是也同样带来了一些安全问题，也就是<strong>浏览器网络安全</strong>问题，最典型的就是XSS攻击和CSRF攻击</p><h3 id="XSS攻击"><a href="#XSS攻击" class="headerlink" title="XSS攻击"></a>XSS攻击</h3><h4 id="什么是-XSS"><a href="#什么是-XSS" class="headerlink" title="什么是 XSS"></a><strong>什么是 XSS</strong></h4><p>Cross-Site Scripting（跨站脚本攻击）简称 XSS，是一种代码注入攻击。攻击者通过在目标网站上注入恶意脚本，使之在用户的浏览器上运行。利用这些恶意脚本，攻击者可获取用户的敏感信息如 Cookie、SessionID 等，进而危害数据安全。为了和 CSS 区分，这里把攻击的第一个字母改成了 X，于是叫做 XSS。</p><p>XSS 的本质是：恶意代码未经过滤，与网站正常的代码混在一起；浏览器无法分辨哪些脚本是可信的，导致恶意脚本被执行。而由于直接在用户的终端执行，恶意代码能够直接获取用户的信息，或者利用这些信息冒充用户向网站发起攻击者定义的请求。在部分情况下，由于输入的限制，注入的恶意脚本比较短。但可以通过引入外部的脚本，并由浏览器执行，来完成比较复杂的攻击策略。</p><p>这里有一个问题：用户是通过哪种方法“注入”恶意脚本的呢？</p><p>不仅仅是业务上的“用户的 UGC 内容”可以进行注入，包括 URL 上的参数等都可以是攻击的来源。在处理输入时，以下内容都不可信：</p><ul><li>来自用户的 UGC 信息</li><li>来自第三方的链接</li><li>URL 参数</li><li>POST 参数</li><li>Referer （可能来自不可信的来源）</li><li>Cookie （可能来自其他子域注入）</li></ul><h4 id="XSS-分类"><a href="#XSS-分类" class="headerlink" title="XSS 分类"></a><strong>XSS 分类</strong></h4><p>根据攻击的来源，XSS 攻击可分为存储型、反射型和 DOM 型三种</p><p>XSS攻击有三种类型：<strong>存储型</strong>、<strong>反射型</strong>、<strong>DOM型</strong></p><p><strong>存储型 XSS</strong></p><p>存储型 XSS 的攻击步骤：</p><ol><li>攻击者将恶意代码提交到目标网站的数据库中。如<code>&lt;script src=&quot;http://恶意网站&quot;&gt;&lt;/script&gt;</code></li><li>用户打开目标网站时，网站服务端将恶意代码从数据库取出，拼接在 HTML 中返回给浏览器。</li><li>用户浏览器接收到响应后解析执行，混在其中的恶意代码也被执行。</li><li>恶意代码窃取用户数据并发送到攻击者的网站，或者冒充用户的行为，调用目标网站接口执行攻击者指定的操作。</li></ol><p>这种攻击常见于带有用户保存数据的网站功能，如论坛发帖、商品评论、用户私信等。</p><p><strong>反射型XSS</strong></p><p>反射型 XSS 的攻击步骤：</p><ol><li>攻击者构造出特殊的 URL，其中包含恶意代码。</li><li>用户打开带有恶意代码的 URL 时，网站服务端将恶意代码从 URL 中取出，拼接在 HTML 中返回给浏览器。</li><li>用户浏览器接收到响应后解析执行，混在其中的恶意代码也被执行。</li><li>恶意代码窃取用户数据并发送到攻击者的网站，或者冒充用户的行为，调用目标网站接口执行攻击者指定的操作。</li></ol><p>反射型 XSS 跟存储型 XSS 的区别是：存储型 XSS 的恶意代码存在数据库里，反射型 XSS 的恶意代码存在 URL 里。</p><p>反射型 XSS 漏洞常见于通过 URL 传递参数的功能，如网站搜索、跳转等。由于需要用户主动打开恶意的 URL 才能生效，攻击者往往会结合多种手段诱导用户点击。</p><p><strong>DOM 型 XSS</strong></p><p>DOM 型 XSS 的攻击步骤：</p><ol><li>攻击者构造出特殊的 URL，其中包含恶意代码。</li><li>用户打开带有恶意代码的 URL。</li><li>用户浏览器接收到响应后解析执行，前端 JavaScript 取出 URL 中的恶意代码并执行。</li><li>恶意代码窃取用户数据并发送到攻击者的网站，或者冒充用户的行为，调用目标网站接口执行攻击者指定的操作。</li></ol><p>DOM 型 XSS 跟前两种 XSS 的区别：DOM 型 XSS 攻击中，取出和执行恶意代码由浏览器端完成，属于前端 JavaScript 自身的安全漏洞，而其他两种 XSS 都属于服务端的安全漏洞。</p><h4 id="XSS-攻击的预防"><a href="#XSS-攻击的预防" class="headerlink" title="XSS 攻击的预防"></a><strong>XSS 攻击的预防</strong></h4><p>通过前面的介绍可以得知，XSS 攻击有两大要素：</p><ol><li>攻击者提交恶意代码。</li><li>浏览器执行恶意代码。</li></ol><p>针对第一个要素：我们是否能够在用户输入的过程，过滤掉用户输入的恶意代码呢？</p><h5 id="输入过滤"><a href="#输入过滤" class="headerlink" title="输入过滤"></a><strong>输入过滤</strong></h5><p>在用户提交时，由前端过滤输入，然后提交到后端。这样做是否可行呢？答案是不可行。一旦攻击者绕过前端过滤，直接构造请求，就可以提交恶意代码了。</p><p>那么，换一个过滤时机：后端在写入数据库前，对输入进行过滤，然后把“安全的”内容，返回给前端。这样是否可行呢？</p><p>我们举一个例子，一个正常的用户输入了 <code>5 &lt; 7</code> 这个内容，在写入数据库前，被转义，变成了 &#96;&#96;。问题是：在提交阶段，我们并不确定内容要输出到哪里。</p><p>这里的“并不确定内容要输出到哪里”有两层含义：</p><ol><li><p>用户的输入内容可能同时提供给前端和客户端，而一旦经过了 <code>escapeHTML()</code>，客户端显示的内容就变成了乱码( <code>5 &lt; 7</code> )。</p></li><li><p>在前端中，不同的位置所需的编码也不同。</p><ul><li>当 <code>5 &amp;lt; 7</code> 作为 HTML 拼接页面时，可以正常显示：</li></ul><pre><code class="html">&lt;div title=&quot;comment&quot;&gt;5 &amp;lt; 7&lt;/div&gt;</code></pre><ul><li>当 <code>5 &amp;lt; 7</code> 通过 Ajax 返回，然后赋值给 JavaScript 的变量时，前端得到的字符串就是转义后的字符。这个内容不能直接用于 Vue 等模板的展示，也不能直接用于内容长度计算。不能用于标题、alert 等。</li></ul></li></ol><p>所以，输入侧过滤能够在某些情况下解决特定的 XSS 问题，但会引入很大的不确定性和乱码问题。<strong>在防范 XSS 攻击时应避免此类方法</strong>。</p><p>当然，对于明确的输入类型，例如数字、URL、电话号码、邮件地址等等内容，进行输入过滤还是必要的。</p><h5 id="防止浏览器执行恶意代码"><a href="#防止浏览器执行恶意代码" class="headerlink" title="防止浏览器执行恶意代码"></a><strong>防止浏览器执行恶意代码</strong></h5><p>既然输入过滤并非完全可靠，我们就要通过“防止浏览器执行恶意代码”来防范 XSS。这部分分为两类：</p><ul><li>防止 HTML 中出现注入。</li><li>防止 JavaScript 执行时，执行恶意代码。</li></ul><p><strong>预防存储型和反射型 XSS 攻击</strong></p><p>存储型和反射型 XSS 都是在服务端取出恶意代码后，插入到响应 HTML 里的，攻击者刻意编写的“数据”被内嵌到“代码”中，被浏览器所执行。</p><p>预防这两种漏洞，有两种常见做法：</p><ul><li>改成纯前端渲染，把代码和数据分隔开。</li><li>对 HTML 做充分转义。</li></ul><p><strong>纯前端渲染</strong></p><p>纯前端渲染的过程：</p><ol><li>浏览器先加载一个静态 HTML，此 HTML 中不包含任何跟业务相关的数据。</li><li>然后浏览器执行 HTML 中的 JavaScript。</li><li>JavaScript 通过 Ajax 加载业务数据，调用 DOM API 更新到页面上。</li></ol><p>在纯前端渲染中，我们会明确的告诉浏览器：下面要设置的内容是文本（<code>.innerText</code>），还是属性（<code>.setAttribute</code>），还是样式（<code>.style</code>）等等。浏览器不会被轻易的被欺骗，执行预期外的代码了。</p><p>但纯前端渲染还需注意避免 DOM 型 XSS 漏洞（例如 <code>onload</code> 事件和 <code>href</code> 中的 <code>javascript:xxx</code> 等，请参考下文”预防 DOM 型 XSS 攻击“部分）。</p><p>在很多内部、管理系统中，采用纯前端渲染是非常合适的。但对于性能要求高，或有 SEO 需求的页面，我们仍然要面对拼接 HTML 的问题。</p><p><strong>转义 HTML</strong></p><p>如果拼接 HTML 是必要的，就需要采用合适的转义库，对 HTML 模板各处插入点进行充分的转义。</p><p>常用的模板引擎，如 doT.js、ejs、FreeMarker 等，对于 HTML 转义通常只有一个规则，就是把 <code>&amp; &lt; &gt; &quot; &#39; /</code> 这几个字符转义掉，确实能起到一定的 XSS 防护作用，但并不完善，我们要使用更完善更细致的转义策略。例如 Java 工程里，常用的转义库为 <code>org.owasp.encoder</code>。</p><p><strong>预防 DOM 型 XSS 攻击</strong></p><p>DOM 型 XSS 攻击，实际上就是网站前端 JavaScript 代码本身不够严谨，把不可信的数据当作代码执行了。</p><p>在使用 <code>.innerHTML</code>、<code>.outerHTML</code>、<code>document.write()</code> 时要特别小心，不要把不可信的数据作为 HTML 插到页面上，而应尽量使用 <code>.textContent</code>、<code>.setAttribute()</code> 等。</p><p>如果用 Vue&#x2F;React 技术栈，并且不使用 <code>v-html</code>&#x2F;<code>dangerouslySetInnerHTML</code> 功能，就在前端 render 阶段避免 <code>innerHTML</code>、<code>outerHTML</code> 的 XSS 隐患。</p><p>DOM 中的内联事件监听器，如 <code>location</code>、<code>onclick</code>、<code>onerror</code>、<code>onload</code>、<code>onmouseover</code> 等，<code>&lt;a&gt;</code> 标签的 <code>href</code> 属性，JavaScript 的 <code>eval()</code>、<code>setTimeout()</code>、<code>setInterval()</code> 等，都能把字符串作为代码运行。如果不可信的数据拼接到字符串中传递给这些 API，很容易产生安全隐患，请务必避免。</p><p><strong>其他安全措施</strong></p><ul><li>HTTP-only Cookie: 禁止 JavaScript 读取某些敏感 Cookie，攻击者完成 XSS 注入后也无法窃取此 Cookie。</li><li>验证码：防止脚本冒充用户提交危险操作。</li><li>输入内容长度控制：对于不受信任的输入，都应该限定一个合理的长度。虽然无法完全防止 XSS 发生，但可以增加 XSS 攻击的难度。</li></ul><h3 id="CSRF攻击"><a href="#CSRF攻击" class="headerlink" title="CSRF攻击"></a>CSRF攻击</h3><p>CSRF（Cross-site request forgery）跨站请求伪造：攻击者诱导受害者进入第三方网站，在第三方网站中，向被攻击网站发送跨站请求。利用受害者在被攻击网站已经获取的注册凭证，绕过后台的用户验证，达到冒充用户对被攻击的网站执行某项操作的目的。</p><p>一个典型的CSRF攻击有着如下的流程：</p><ul><li>受害者登录a.com，并保留了登录凭证（Cookie）。</li><li>攻击者引诱受害者访问了b.com。</li><li>b.com 向 a.com 发送了一个请求：a.com&#x2F;act&#x3D;xx。浏览器会默认携带a.com的Cookie。</li><li>a.com接收到请求后，对请求进行验证，并确认是受害者的凭证，误以为是受害者自己发送的请求。</li><li>a.com以受害者的名义执行了act&#x3D;xx。</li><li>攻击完成，攻击者在受害者不知情的情况下，冒充受害者，让a.com执行了自己定义的操作。</li></ul><h4 id="常见的攻击类型"><a href="#常见的攻击类型" class="headerlink" title="常见的攻击类型"></a><strong>常见的攻击类型</strong></h4><p><strong>GET类型的CSRF</strong></p><p>GET类型的CSRF利用非常简单，只需要一个HTTP请求，一般会这样利用：</p><pre><code class="html"> ![](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2018b/ff0cdbee.example/withdraw?amount=10000&amp;for=hacker) </code></pre><p>在受害者访问含有这个img的页面后，浏览器会自动向<code>http://bank.example/withdraw?account=xiaoming&amp;amount=10000&amp;for=hacker</code>发出一次HTTP请求。bank.example就会收到包含受害者登录信息的一次跨域请求。</p><p><strong>POST类型的CSRF</strong></p><p>这种类型的CSRF利用起来通常使用的是一个自动提交的表单，如：</p><pre><code class="html"> &lt;form action=&quot;http://bank.example/withdraw&quot; method=POST&gt;    &lt;input type=&quot;hidden&quot; name=&quot;account&quot; value=&quot;xiaoming&quot; /&gt;    &lt;input type=&quot;hidden&quot; name=&quot;amount&quot; value=&quot;10000&quot; /&gt;    &lt;input type=&quot;hidden&quot; name=&quot;for&quot; value=&quot;hacker&quot; /&gt;&lt;/form&gt;&lt;script&gt; document.forms[0].submit(); &lt;/script&gt; </code></pre><p>访问该页面后，表单会自动提交，相当于模拟用户完成了一次POST操作。</p><p>POST类型的攻击通常比GET要求更加严格一点，但仍并不复杂。任何个人网站、博客，被黑客上传页面的网站都有可能是发起攻击的来源，后端接口不能将安全寄托在仅允许POST上面。</p><p><strong>链接类型的CSRF</strong></p><p>链接类型的CSRF并不常见，比起其他两种用户打开页面就中招的情况，这种需要用户点击链接才会触发。这种类型通常是在论坛中发布的图片中嵌入恶意链接，或者以广告的形式诱导用户中招，攻击者通常会以比较夸张的词语诱骗用户点击，例如：</p><pre><code class="html">  &lt;a href=&quot;http://test.com/csrf/withdraw.php?amount=1000&amp;for=hacker&quot; taget=&quot;_blank&quot;&gt;  重磅消息！！  &lt;a/&gt;</code></pre><p>由于之前用户登录了信任的网站A，并且保存登录状态，只要用户主动访问上面的这个PHP页面，则表示攻击成功。</p><h4 id="CSRF的特点"><a href="#CSRF的特点" class="headerlink" title="CSRF的特点"></a>CSRF的特点</h4><ul><li>攻击一般发起在第三方网站，而不是被攻击的网站。被攻击的网站无法防止攻击发生。</li><li>攻击利用受害者在被攻击网站的登录凭证，冒充受害者提交操作；而不是直接窃取数据。</li><li>整个过程攻击者并不能获取到受害者的登录凭证，仅仅是“冒用”。</li><li>跨站请求可以用各种方式：图片URL、超链接、CORS、Form提交等等。部分请求方式可以直接嵌入在第三方论坛、文章中，难以进行追踪。</li></ul><p>CSRF通常是跨域的，因为外域通常更容易被攻击者掌控。但是如果本域下有容易被利用的功能，比如可以发图和链接的论坛和评论区，攻击可以直接在本域下进行，而且这种攻击更加危险。</p><h4 id="防护策略"><a href="#防护策略" class="headerlink" title="防护策略"></a>防护策略</h4><p>CSRF通常从第三方网站发起，被攻击的网站无法防止攻击发生，只能通过增强自己网站针对CSRF的防护能力来提升安全性。</p><p>上文中讲了CSRF的两个特点：</p><ul><li>CSRF（通常）发生在第三方域名。</li><li>CSRF攻击者不能获取到Cookie等信息，只是使用。</li></ul><p>针对这两点，我们可以专门制定防护策略，如下：</p><ul><li>阻止不明外域的访问<ul><li>同源检测</li><li>Samesite Cookie</li></ul></li><li>提交时要求附加本域才能获取的信息<ul><li>CSRF Token</li><li>双重Cookie验证</li></ul></li></ul><p>以下我们对各种防护方法做详细说明。</p><p><strong>同源检测</strong></p><p>既然CSRF大多来自第三方网站，那么我们就直接禁止外域（或者不受信任的域名）对我们发起请求。</p><p>那么问题来了，我们如何判断请求是否来自外域呢？</p><p>在HTTP协议中，每一个异步请求都会携带两个Header，用于标记来源域名：</p><ul><li>Origin Header</li><li>Referer Header</li></ul><p>这两个Header在浏览器发起请求时，大多数情况会自动带上，并且不能由前端自定义内容。 服务器可以通过解析这两个Header中的域名，确定请求的来源域。</p><p>当Origin和Referer头文件不存在时该怎么办？如果Origin和Referer都不存在，建议直接进行阻止，特别是如果您没有使用随机CSRF Token（参考下方）作为第二次检查。</p><p><em>如何阻止外域请求</em></p><p>通过Header的验证，我们可以知道发起请求的来源域名，这些来源域名可能是网站本域，或者子域名，或者有授权的第三方域名，又或者来自不可信的未知域名。</p><p>我们已经知道了请求域名是否是来自不可信的域名，我们直接阻止掉这些的请求，就能防御CSRF攻击了吗？</p><p>且慢！当一个请求是页面请求（比如网站的主页），而来源是搜索引擎的链接（例如百度的搜索结果），也会被当成疑似CSRF攻击。所以在判断的时候需要过滤掉页面请求情况。</p><p>但相应的，页面请求就暴露在了CSRF的攻击范围之中。如果你的网站中，在页面的GET请求中对当前用户做了什么操作的话，防范就失效了。</p><p>例如，下面的页面请求：</p><pre><code>GET https://example.com/addComment?comment=XXX&amp;dest=orderId</code></pre><p>注：这种严格来说并不一定存在CSRF攻击的风险，但仍然有很多网站经常把主文档GET请求挂上参数来实现产品功能，但是这样做对于自身来说是存在安全风险的。</p><p>另外，前面说过，CSRF大多数情况下来自第三方域名，但并不能排除本域发起。如果攻击者有权限在本域发布评论（含链接、图片等，统称UGC），那么它可以直接在本域发起攻击，这种情况下同源策略无法达到防护的作用。</p><p>综上所述：同源验证是一个相对简单的防范方法，能够防范绝大多数的CSRF攻击。但这并不是万无一失的，对于安全性要求较高，或者有较多用户输入内容的网站，我们就要对关键的接口做额外的防护措施。</p><p><strong>CSRF Token</strong></p><p>前面讲到CSRF的另一个特征是，攻击者无法直接窃取到用户的信息（Cookie，Header，网站内容等），仅仅是冒用Cookie中的信息。</p><p>而CSRF攻击之所以能够成功，是因为服务器误把攻击者发送的请求当成了用户自己的请求。那么我们可以要求所有的用户请求都携带一个CSRF攻击者无法获取到的Token。服务器通过校验请求是否携带正确的Token，来把正常的请求和攻击的请求区分开，也可以防范CSRF的攻击。</p><p>用户打开页面的时候，服务器需要给这个用户生成一个Token，该Token通过加密算法对数据进行加密，一般Token都包括随机字符串和时间戳的组合，显然在提交时Token不能再放在Cookie中了，否则又会被攻击者冒用。因此，为了安全起见Token最好还是存在服务器的Session中，之后在每次页面加载时，使用JS遍历整个DOM树，对于DOM中所有的a和form标签后加入Token。这样可以解决大部分的请求，但是对于在页面加载之后动态生成的HTML代码，这种方法就没有作用，还需要程序员在编码时手动添加Token。</p><p>Token是一个比较有效的CSRF防护方法，只要页面没有XSS漏洞泄露Token，那么接口的CSRF攻击就无法成功。</p><p>但是此方法的实现比较复杂，需要给每一个页面都写入Token（前端无法使用纯静态页面），每一个Form及Ajax请求都携带这个Token，后端对每一个接口都进行校验，并保证页面Token及请求Token一致。这就使得这个防护策略不能在通用的拦截上统一拦截处理，而需要每一个页面和接口都添加对应的输出和校验。这种方法工作量巨大，且有可能遗漏。</p><!--验证码和密码其实也可以起到CSRF Token的作用哦，而且更安全。为什么很多银行等网站会要求已经登录的用户在转账时再次输入密码，现在是不是有一定道理了？--><p><strong>双重Cookie验证</strong></p><p>在会话中存储CSRF Token比较繁琐，而且不能在通用的拦截上统一处理所有的接口。</p><p>那么另一种防御措施是使用双重提交Cookie。利用CSRF攻击不能获取到用户Cookie的特点，我们可以要求Ajax和表单请求携带一个Cookie中的值。</p><p>双重Cookie采用以下流程：</p><ul><li>在用户访问网站页面时，向请求域名注入一个Cookie字段，内容为随机字符串（例如<code>csrfcookie=v8g9e4ksfhw</code>）。</li><li>在前端向后端发起请求时，取出Cookie字段，并添加到URL的参数中（接上例<code>POST https://www.a.com/comment?csrfcookie=v8g9e4ksfhw</code>）。</li><li>后端接口验证Cookie中的字段与URL参数中的字段是否一致，不一致则拒绝。</li></ul><p>此方法相对于CSRF Token就简单了许多。可以直接通过前后端拦截的的方法自动化实现。后端校验也更加方便，只需进行请求中字段的对比，而不需要再进行查询和存储Token。</p><p>当然，此方法并没有大规模应用，其在大型网站上的安全性还是没有CSRF Token高，原因我们举例进行说明。</p><p>由于任何跨域都会导致前端无法获取Cookie中的字段（包括子域名之间），于是发生了如下情况：</p><ul><li>如果用户访问的网站为<code>www.a.com</code>，而后端的api域名为<code>api.a.com</code>。那么在<code>www.a.com</code>下，前端拿不到<code>api.a.com</code>的Cookie，也就无法完成双重Cookie认证。</li><li>于是这个认证Cookie必须被种在<code>a.com</code>下，这样每个子域都可以访问。</li><li>任何一个子域都可以修改<code>a.com</code>下的Cookie。</li><li>某个子域名存在漏洞被XSS攻击（例如<code>upload.a.com</code>）。虽然这个子域下并没有什么值得窃取的信息。但攻击者修改了<code>a.com</code>下的Cookie。</li><li>攻击者可以直接使用自己配置的Cookie，对XSS中招的用户再向<code>www.a.com</code>下，发起CSRF攻击。</li></ul><p><strong>总结：</strong></p><p><strong>用双重Cookie防御CSRF的优点：</strong></p><ul><li>无需使用Session，适用面更广，易于实施。</li><li>cookie储存于客户端中，不会给服务器带来压力。</li><li>相对于Token，实施成本更低，可以在前后端统一拦截校验，而不需要一个个接口和页面添加。</li></ul><p><strong>缺点：</strong></p><ul><li>Cookie中增加了额外的字段。</li><li>如果有其他漏洞（例如XSS），攻击者可以注入Cookie，那么该防御方式失效。</li><li>难以做到子域名的隔离。</li><li>为了确保Cookie传输安全，采用这种防御方式的最好确保用整站HTTPS的方式，如果还没切HTTPS的使用这种方式也会有风险。</li></ul><p><strong>Samesite Cookie属性</strong></p><p>防止CSRF攻击的办法已经有上面的预防措施。为了从源头上解决这个问题，Google起草了一份草案来改进HTTP协议，那就是为Set-Cookie响应头新增Samesite属性，它用来标明这个 Cookie是个“同站 Cookie”，同站Cookie只能作为第一方Cookie，不能作为第三方Cookie，Samesite 有两个属性值，分别是 Strict 和 Lax。</p><p>如果SamesiteCookie被设置为Strict，浏览器在任何跨域请求中都不会携带Cookie，新标签重新打开也不携带，所以说CSRF攻击基本没有机会。假如淘宝网站用来识别用户登录与否的 Cookie 被设置成了 Samesite&#x3D;Strict，那么用户从百度搜索页面甚至天猫页面的链接点击进入淘宝后，淘宝都不会是登录状态，因为淘宝的服务器不会接受到那个 Cookie，其它网站发起的对淘宝的任意请求都不会带上那个 Cookie。</p><p>这样跳转子域名或者是新标签重新打开刚登陆的网站，之前的Cookie都不会存在。尤其是有登录的网站，那么我们新打开一个标签进入，或者跳转到子域名的网站，都需要重新登录。对于用户来讲，可能体验不会很好。</p><p>如果SamesiteCookie被设置为Lax，假如这个请求是这种请求（改变了当前页面或者打开了新页面）且同时是个GET请求，则这个Cookie可以作为第三方Cookie。那么其他网站通过页面跳转过来的时候可以使用Cookie，可以保障外域连接打开页面时用户的登录状态。但相应的，其安全性也比较低。</p><p>另外一个问题是Samesite的兼容性不是很好，现阶段除了从新版Chrome和Firefox支持以外，Safari以及iOS Safari都还不支持，现阶段看来暂时还不能普及。</p><p>而且，SamesiteCookie目前有一个致命的缺陷：不支持子域。例如，种在topic.a.com下的Cookie，并不能使用a.com下种植的SamesiteCookie。这就导致了当我们网站有多个子域名时，不能使用SamesiteCookie在主域名存储用户登录信息。每个子域名都需要用户重新登录一次。</p><p>总之，SamesiteCookie是一个可能替代同源验证的方案，但目前还并不成熟，其应用场景有待观望。</p><h3 id="DDoS攻击"><a href="#DDoS攻击" class="headerlink" title="DDoS攻击"></a>DDoS攻击</h3><p>DDoS 攻击，全称是 Distributed Denial of Service，中文是分布式拒绝服务。一般来说是指攻击者利用“肉鸡”对目标网站在较短的时间内发起大量请求，大规模消耗目标网站的主机资源，让它无法正常服务。在线游戏、互联网金融等领域是 DDoS 攻击的高发行业。</p><h4 id="常见的DDoS攻击类型"><a href="#常见的DDoS攻击类型" class="headerlink" title="常见的DDoS攻击类型"></a>常见的DDoS攻击类型</h4><table><thead><tr><th align="left">DDoS攻击分类</th><th align="left">攻击子类</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">畸形报文</td><td align="left">畸形报文主要包括Frag Flood、Smurf、Stream Flood、Land Flood、IP畸形报文、TCP畸形报文、UDP畸形报文等。</td><td align="left">畸形报文攻击指通过向目标系统发送有缺陷的IP报文，使得目标系统在处理这样的报文时出现崩溃，从而达到拒绝服务的攻击目的。</td></tr><tr><td align="left">传输层DDoS攻击</td><td align="left">传输层DDoS攻击主要包括Syn Flood、Ack Flood、UDP Flood、ICMP Flood、RstFlood等。</td><td align="left">以Syn Flood攻击为例，它利用了TCP协议的三次握手机制，当服务端接收到一个Syn请求时，服务端必须使用一个监听队列将该连接保存一定时间。因此，通过向服务端不停发送Syn请求，但不响应Syn+Ack报文，从而消耗服务端的资源。当监听队列被占满时，服务端将无法响应正常用户的请求，达到拒绝服务攻击的目的。</td></tr><tr><td align="left">DNS DDoS攻击</td><td align="left">DNS DDoS攻击主要包括DNS Request Flood、DNS Response Flood、虚假源+真实源DNS Query Flood、权威服务器攻击和Local服务器攻击等。</td><td align="left">以DNS Query Flood攻击为例，其本质上执行的是真实的Query请求，属于正常业务行为。但如果多台傀儡机同时发起海量的域名查询请求，服务端无法响应正常的Query请求，从而导致拒绝服务。</td></tr><tr><td align="left">连接型DDoS攻击</td><td align="left">连接型DDoS攻击主要是指TCP慢速连接攻击、连接耗尽攻击、Loic、Hoic、Slowloris、 Pyloris、Xoic等慢速攻击。</td><td align="left">以Slowloris攻击为例，其攻击目标是Web服务器的并发上限。当Web服务器的连接并发数达到上限后，Web服务即无法接受新的请求。Web服务接收到新的HTTP请求时，建立新的连接来处理请求，并在处理完成后关闭这个连接。如果该连接一直处于连接状态，收到新的HTTP请求时则需要建立新的连接进行处理。而当所有连接都处于连接状态时，Web将无法处理任何新的请求。Slowloris攻击利用HTTP协议的特性来达到攻击目的。HTTP请求以<code>\r\n\r\n</code>标识Headers的结束，如果Web服务端只收到<code>\r\n</code>，则认为HTTP Headers部分没有结束，将保留该连接并等待后续的请求内容。</td></tr><tr><td align="left">Web应用层DDoS攻击</td><td align="left">Web应用层攻击主要是指HTTP Get Flood、HTTP Post Flood、CC等攻击。</td><td align="left">通常应用层攻击完全模拟用户请求，类似于各种搜索引擎和爬虫一样，这些攻击行为和正常的业务并没有严格的边界，难以辨别。Web服务中一些资源消耗较大的事务和页面。例如，Web应用中的分页和分表，如果控制页面的参数过大，频繁的翻页将会占用较多的Web服务资源。尤其在高并发频繁调用的情况下，类似这样的事务就成了早期CC攻击的目标。由于现在的攻击大都是混合型的，因此模拟用户行为的频繁操作都可以被认为是CC攻击。例如，各种刷票软件对网站的访问，从某种程度上来说就是CC攻击。CC攻击瞄准的是Web应用的后端业务，除了导致拒绝服务外，还会直接影响Web应用的功能和性能，包括Web响应时间、数据库服务、磁盘读写等。</td></tr></tbody></table><h3 id="sql注入"><a href="#sql注入" class="headerlink" title="sql注入"></a>sql注入</h3><p>SQL注入是属于注入式攻击，这种攻击是因为在项目中没有将代码与数据（比如用户敏感数据）隔离，在读取数据的时候，错误的将数据作为代码的一部分执行而导致的。</p><p>典型的例子就是当对SQL语句进行字符串拼接的时候，直接使用未转义的用户输入内容作为变量。这时，只要在sql语句的中间做修改，比如加上drop、delete等关键字，执行之后后果不堪设想。</p><p>说到这里，那么该怎么处理这种情况呢？三个方面：</p><p>1、过滤用户输入参数中的特殊字符，降低风险。</p><p>2、禁止通过字符串拼接sql语句，要严格使用参数绑定来传入参数。</p><p>3、合理使用数据库框架提供的机制。就比如Mybatis提供的传入参数的方式 #{}，禁止使用${}，后者相当于是字符串拼接sql，要使用参数化的语句。</p><p>总结下，就是要正确使用参数化绑定sql变量。</p><h2 id="CDN"><a href="#CDN" class="headerlink" title="CDN"></a>CDN</h2><p>CDN主要功能是在不同的地点缓存内容，通过负载均衡技术，将用户的请求定向到最合适的缓存服务器上去获取内容，比如说，是北京的用户，我们让他访问北京的节点，深圳的用户，我们让他访问深圳的节点。通过就近访问，加速用户对网站的访问。解决Internet网络拥堵状况，提高用户访问网络的响应速度。</p><p>最简单的CDN网络由一个DNS服务器和几台缓存服务器组成：</p><ol><li>当用户点击网站页面上的内容URL，经过本地DNS系统解析，DNS系统会最终将域名的解析权交给CNAME指向的CDN专用DNS服务器。</li><li>CDN的DNS服务器将CDN的全局负载均衡设备IP地址返回用户。</li><li>用户向CDN的全局负载均衡设备发起内容URL访问请求。</li><li>CDN全局负载均衡设备根据用户IP地址，以及用户请求的内容URL，选择一台用户所属区域的区域负载均衡设备，告诉用户向这台设备发起请求。</li><li>区域负载均衡设备会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：根据用户IP地址，判断哪一台服务器距用户最近；根据用户所请求的URL中携带的内容名称，判断哪一台服务器上有用户所需内容；查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。基于以上这些条件的综合分析之后，区域负载均衡设备会向全局负载均衡设备返回一台缓存服务器的IP地址。</li><li>全局负载均衡设备把服务器的IP地址返回给用户。</li><li>用户向缓存服务器发起请求，缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，而区域均衡设备依然将它分配给了用户，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。</li></ol><h2 id="VPN和加速器"><a href="#VPN和加速器" class="headerlink" title="VPN和加速器"></a>VPN和加速器</h2><p>VPN 全称为虚拟私人网络(Virtual Private Network)，常用于连接中、大型企业或团体间私人网络的通讯方法，利用隧道协议（Tunneling Protocol）来达到发送端认证、消息保密与准确性等功能。</p><p>比如多地办公的公司，可以使用 VPN 将不同地区连接在同一内网下；或者在家办公的时候也可以通过 VPN 接入公司内网中。</p><p>VPN 以 CS 架构运行，工作流程如下：</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/vpn.png" alt="vpn"></p><p>1.VPN工作流程</p><p>在外网的用户可以使用 <code>vpn client</code> 连接组织搭建的 <code>vpn server</code> 以建立通信隧道，随后便建立了虚拟的私人网络，处于外网的 <code>worker</code> 和内网中的 <code>server</code> 可以相互通信。</p><p>那么我们可以简单理解 VPN，由 <code>VPN client</code> 捕获用户发出的报文，封装报文后通过物理网络通信链路将报文发给 <code>VPN server</code>，<code>VPN server</code> 接收到报文后进行解包，再将其转发给实际的目标，反之同理； VPN 在逻辑层面构建了虚拟网络。</p><h2 id="I-x2F-O多路复用"><a href="#I-x2F-O多路复用" class="headerlink" title="I&#x2F;O多路复用"></a>I&#x2F;O多路复用</h2><p>服务器基于多进程或者多线程模型的，新到来一个 TCP 连接，就需要分配一个进程或者线程，那么如果要达到 C10K，意味着要一台机器维护 1 万个连接，相当于要维护 1 万个进程&#x2F;线程，操作系统就算死扛也是扛不住的。</p><p>既然为每个请求分配一个进程&#x2F;线程的方式不合适，那有没有可能只使用一个进程来维护多个 Socket 呢？答案是有的，那就是 <strong>I&#x2F;O 多路复用</strong>技术。</p><p>一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。</p><p>我们熟悉的 select&#x2F;poll&#x2F;epoll 内核提供给用户态的多路复用系统调用，<strong>进程可以通过一个系统调用函数从内核中获取多个事件</strong>。</p><p>select&#x2F;poll&#x2F;epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。</p><p>select&#x2F;poll&#x2F;epoll 这是三个多路复用接口，都能实现 C10K 吗？接下来，我们分别说说它们。</p><h3 id="select-x2F-poll"><a href="#select-x2F-poll" class="headerlink" title="select&#x2F;poll"></a>select&#x2F;poll</h3><p>select 实现多路复用的方式是，将已连接的 Socket 都放到一个<strong>文件描述符集合</strong>，然后调用 select 函数将文件描述符集合<strong>拷贝</strong>到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过<strong>遍历</strong>文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合<strong>拷贝</strong>回用户态里，然后用户态还需要再通过<strong>遍历</strong>的方法找到可读或可写的 Socket，然后再对其处理。</p><p>所以，对于 select 这种方式，需要进行 <strong>2 次「遍历」文件描述符集合</strong>，一次是在内核态里，一个次是在用户态里 ，而且还会发生 <strong>2 次「拷贝」文件描述符集合</strong>，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。</p><p>select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 <code>1024</code>，只能监听 0~1023 的文件描述符。</p><p>poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。</p><p>但是 poll 和 select 并没有太大的本质区别，<strong>都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合</strong>，这种方式随着并发数上来，性能的损耗会呈指数级增长。</p><h3 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h3><p>先复习下 epoll 的用法。如下的代码中，先用epoll_create 创建一个 epoll对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到epfd中，最后调用 epoll_wait 等待数据。</p><pre><code class="c">int s = socket(AF_INET, SOCK_STREAM, 0);bind(s, ...);listen(s, ...)int epfd = epoll_create(...);epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中while(1) &#123;    int n = epoll_wait(...);    for(接收到数据的socket)&#123;        //处理    &#125;&#125;</code></pre><p>epoll 通过两个方面，很好解决了 select&#x2F;poll 的问题。</p><p><em>第一点</em>，epoll 在内核里使用<strong>红黑树来跟踪进程所有待检测的文件描述字</strong>，把需要监控的 socket 通过 <code>epoll_ctl()</code> 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 <code>O(logn)</code>。而 select&#x2F;poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select&#x2F;poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。</p><p><em>第二点</em>， epoll 使用<strong>事件驱动</strong>的机制，内核里<strong>维护了一个链表来记录就绪事件</strong>，当某个 socket 有事件发生时，通过<strong>回调函数</strong>内核会将其加入到这个就绪事件列表中，当用户调用 <code>epoll_wait()</code> 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select&#x2F;poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。(<strong>文件需要支持poll接口，也就是支持回调才可以使用epoll进行监听，常用的文件系统如ext3无法使用epoll</strong>)</p><p>从下图你可以看到 epoll 相关的接口作用：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/epoll.png" alt="img"></p><p>epoll 的方式即使监听的 Socket 数量越多的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了，上限就为系统定义的进程打开的最大文件描述符个数。因而，<strong>epoll 被称为解决 C10K 问题的利器</strong>。</p><p>插个题外话，网上文章不少说，<code>epoll_wait</code> 返回时，对于就绪的事件，epoll 使用的是共享内存的方式，即用户态和内核态都指向了就绪链表，所以就避免了内存拷贝消耗。</p><p>这是错的！看过 epoll 内核源码的都知道，<strong>压根就没有使用共享内存这个玩意</strong>。</p><p>epoll惊群问题：</p><p>现象：当多个进程&#x2F;线程调用<code>epoll_wait</code>时会阻塞等待，当内核触发可读写事件，<strong>所有进程&#x2F;线程都会进行相应</strong>，但<strong>实际</strong>只有一个进程&#x2F;线程真实处理这些事件。</p><p>解决方案。</p><ol><li>配置<code>SO_REUSEPORT</code>实现内核级的负载均衡</li><li>增加<code>EPOLLEXCLUSIVE</code>标识，保证一个事件发生时只有一个线程被唤醒【linux 4.5 内核】</li></ol><h3 id="select和epoll对比"><a href="#select和epoll对比" class="headerlink" title="select和epoll对比"></a>select和epoll对比</h3><p>1.用户态怎么将文件句柄传递到内核态?</p><ul><li><strong>Selector</strong>。select 创建 3 个文件描述符集，并将这些文件描述符拷贝到内核中，这里限制了文件句柄的最大的数量为 1024（注意是全部传入—第一次拷贝）</li><li><strong>Epoll</strong>。首先执行 epoll_create 在内核专属于 epoll 的高速 cache 区，并在该缓冲区建立红黑树和就绪链表，用户态传入的文件句柄将被放到红黑树中（第一次拷贝）</li></ul><p>2.内核态怎么判断 I&#x2F;O 流可读可写？</p><ul><li><strong>Selector</strong>。内核针对读缓冲区和写缓冲区来判断是否可读可写,这个动作和 select 无关</li><li><strong>Epoll</strong>。内核针对读缓冲区和写缓冲区来判断是否可读可写，这个动作与 epoll 无关</li></ul><p>3.内核怎么通知监控者有 I&#x2F;O 流可读可写？</p><ul><li><p><strong>Selector</strong>。内核在检测到文件句柄可读&#x2F;可写时就产生中断通知监控者 select，select 被内核触发之后，就返回可读可写的文件句柄的总数</p></li><li><p><strong>Epoll</strong>。epoll_ctl 执行 add 动作时除了将文件句柄放到红黑树上之外，还向内核注册了该文件句柄的回调函数，内核在检测到某句柄可读可写时则调用该回调函数，回调函数将文件句柄放到就绪链表</p></li></ul><p>4.监控者如何找到可读可写的 I&#x2F;O 流并传递给用户态应用程序？</p><ul><li><strong>Selector</strong>。select 会将之前传递给内核的文件句柄再次从内核传到用户态（第 2 次拷贝），select 返回给用户态的只是可读可写的文件句柄总数，再使用 FD_ISSET 宏函数来检测哪些文件 I&#x2F;O 可读可写（遍历）</li><li><strong>Epoll</strong>。epoll_wait 只监控就绪链表就可以，如果就绪链表有文件句柄，则表示该文件句柄可读可写，并返回到用户态（少量的拷贝）</li></ul><p>5.继续循环时监控者怎样重复上述步骤？</p><ul><li><strong>Selector</strong>。select 对于事件的监控是建立在内核的修改之上的，也就是说经过一次监控之后，内核会修改位，因此再次监控时需要再次从用户态向内核态进行拷贝（第 N 次拷贝）</li><li><strong>Epoll</strong>。由于内核不修改文件句柄的位，因此只需要在第一次传入就可以重复监控，直到使用 epoll_ctl 删除，否则不需要重新传入，因此无多次拷贝</li></ul><h3 id="边缘触发和水平触发"><a href="#边缘触发和水平触发" class="headerlink" title="边缘触发和水平触发"></a>边缘触发和水平触发</h3><p>epoll 支持两种事件触发模式，分别是<strong>边缘触发（edge-triggered，ET和水平触发（level-triggered，LT）</strong>。</p><p>这两个术语还挺抽象的，其实它们的区别还是很好理解的。</p><ul><li>使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，<strong>服务器端只会从 epoll_wait 中苏醒一次</strong>，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；</li><li>使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，<strong>服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束</strong>，目的是告诉我们有数据需要读取；</li></ul><p>举个例子，你的快递被放到了一个快递箱里，如果快递箱只会通过短信通知你一次，即使你一直没有去取，它也不会再发送第二条短信提醒你，这个方式就是边缘触发；如果快递箱发现你的快递没有被取出，它就会不停地发短信通知你，直到你取出了快递，它才消停，这个就是水平触发的方式。</p><p>这就是两者的区别，水平触发的意思是只要满足事件的条件，比如内核中有数据需要读，就一直不断地把这个事件传递给用户；而边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。</p><p>如果使用水平触发模式，当内核通知文件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要一次执行尽可能多的读写操作。</p><p>如果使用边缘触发模式，I&#x2F;O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会<strong>循环</strong>从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，<strong>边缘触发模式一般和非阻塞 I&#x2F;O 搭配使用</strong>，程序会一直执行 I&#x2F;O 操作，直到系统调用（如 <code>read</code> 和 <code>write</code>）返回错误，错误类型为 <code>EAGAIN</code> 或 <code>EWOULDBLOCK</code>。</p><p>一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。</p><p>select&#x2F;poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。</p><p>另外，使用 I&#x2F;O 多路复用时，最好搭配非阻塞 I&#x2F;O 一起使用，Linux 手册关于 select 的内容中有如下说明：</p><blockquote><p>Under Linux, select() may report a socket file descriptor as “ready for reading”, while nevertheless a subsequent read blocks. This could for example happen when data has arrived but upon examination has wrong checksum and is discarded. There may be other circumstances in which a file descriptor is spuriously reported as ready. Thus it may be safer to use O_NONBLOCK on sockets that should not block.</p></blockquote><p>我谷歌翻译的结果：</p><blockquote><p>在Linux下，select() 可能会将一个 socket 文件描述符报告为 “准备读取”，而后续的读取块却没有。例如，当数据已经到达，但经检查后发现有错误的校验和而被丢弃时，就会发生这种情况。也有可能在其他情况下，文件描述符被错误地报告为就绪。因此，在不应该阻塞的 socket 上使用 O_NONBLOCK 可能更安全。</p></blockquote><p>简单点理解，就是<strong>多路复用 API 返回的事件并不一定可读写的</strong>，如果使用阻塞 I&#x2F;O， 那么在调用 read&#x2F;write 时则会发生程序阻塞，因此最好搭配非阻塞 I&#x2F;O，以便应对极少数的特殊情况。</p><p>总结：</p><p>epoll 是解决 C10K 问题的利器，通过两个方面解决了 select&#x2F;poll 的问题。</p><ul><li>epoll 在内核里使用「红黑树」来关注进程所有待检测的 Socket，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)，通过对这棵黑红树的管理，不需要像 select&#x2F;poll 在每次操作时都传入整个 Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。</li><li>epoll 使用事件驱动的机制，内核里维护了一个「链表」来记录就绪事件，只将有事件发生的 Socket 集合传递给应用程序，不需要像 select&#x2F;poll 那样轮询扫描整个集合（包含有和无事件的 Socket ），大大提高了检测的效率。</li></ul><p>而且，epoll 支持边缘触发和水平触发的方式，而 select&#x2F;poll 只支持水平触发，一般而言，边缘触发的方式会比水平触发的效率高。</p><h2 id="Reactor和Proactor"><a href="#Reactor和Proactor" class="headerlink" title="Reactor和Proactor"></a>Reactor和Proactor</h2><h3 id="演进"><a href="#演进" class="headerlink" title="演进"></a>演进</h3><p>如果要让服务器服务多个客户端，那么最直接的方式就是为每一条连接创建线程。</p><p>其实创建进程也是可以的，原理是一样的，进程和线程的区别在于线程比较轻量级些，线程的创建和线程间切换的成本要小些，为了描述简述，后面都以线程为例。</p><p>处理完业务逻辑后，随着连接关闭后线程也同样要销毁了，但是这样不停地创建和销毁线程，不仅会带来性能开销，也会造成浪费资源，而且如果要连接几万条连接，创建几万个线程去应对也是不现实的。</p><p>要这么解决这个问题呢？我们可以使用「资源复用」的方式。</p><p>也就是不用再为每个连接创建线程，而是创建一个「线程池」，将连接分配给线程，然后一个线程可以处理多个连接的业务。</p><p>不过，这样又引来一个新的问题，线程怎样才能高效地处理多个连接的业务？</p><p>当一个连接对应一个线程时，线程一般采用「read -&gt; 业务处理 -&gt; send」的处理流程，如果当前连接没有数据可读，那么线程会阻塞在 <code>read</code> 操作上（ socket 默认情况是阻塞 I&#x2F;O），不过这种阻塞方式并不影响其他线程。</p><p>但是引入了线程池，那么一个线程要处理多个连接的业务，线程在处理某个连接的 <code>read</code> 操作时，如果遇到没有数据可读，就会发生阻塞，那么线程就没办法继续处理其他连接的业务。</p><p>要解决这一个问题，最简单的方式就是将 socket 改成非阻塞，然后线程不断地轮询调用 <code>read</code> 操作来判断是否有数据，这种方式虽然该能够解决阻塞的问题，但是解决的方式比较粗暴，因为轮询是要消耗 CPU 的，而且随着一个线程处理的连接越多，轮询的效率就会越低。</p><p>上面的问题在于，线程并不知道当前连接是否有数据可读，从而需要每次通过 <code>read</code> 去试探。</p><p>那有没有办法在只有当连接上有数据的时候，线程才去发起读请求呢？答案是有的，实现这一技术的就是 I&#x2F;O 多路复用。</p><p>I&#x2F;O 多路复用技术会用一个系统调用函数来监听我们所有关心的连接，也就说可以在一个监控线程里面监控很多的连接。</p><p>我们熟悉的 select&#x2F;poll&#x2F;epoll 就是内核提供给用户态的多路复用系统调用，线程可以通过一个系统调用函数从内核中获取多个事件。select&#x2F;poll&#x2F;epoll 是如何获取网络事件的呢？</p><p>在获取事件时，先把我们要关心的连接传给内核，再由内核检测：</p><ul><li>如果没有事件发生，线程只需阻塞在这个系统调用，而无需像前面的线程池方案那样轮训调用 read 操作来判断是否有数据。</li><li>如果有事件发生，内核会返回产生了事件的连接，线程就会从阻塞状态返回，然后在用户态中再处理这些连接对应的业务即可。</li></ul><p>大佬们基于面向对象的思想，对 I&#x2F;O 多路复用作了一层封装，让使用者不用考虑底层网络 API 的细节，只需要关注应用代码的编写。</p><p>大佬们还为这种模式取了个让人第一时间难以理解的名字：<strong>Reactor 模式</strong>。</p><p>Reactor 翻译过来的意思是「反应堆」，可能大家会联想到物理学里的核反应堆，实际上并不是的这个意思。</p><p>这里的反应指的是「<strong>对事件反应</strong>」，也就是<strong>来了一个事件，Reactor 就有相对应的反应&#x2F;响应</strong>。</p><p>事实上，Reactor 模式也叫 <code>Dispatcher</code> 模式，我觉得这个名字更贴合该模式的含义，即 <strong>I&#x2F;O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 &#x2F; 线程</strong>。</p><p>Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：</p><ul><li>Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；</li><li>处理资源池负责处理事件，如 read -&gt; 业务逻辑 -&gt; send；</li></ul><p>Reactor 模式是灵活多变的，可以应对不同的业务场景，灵活在于：</p><ul><li>Reactor 的数量可以只有一个，也可以有多个；</li><li>处理资源池可以是单个进程 &#x2F; 线程，也可以是多个进程 &#x2F;线程；</li></ul><p>将上面的两个因素排列组设一下，理论上就可以有 4 种方案选择：</p><ul><li>单 Reactor 单进程 &#x2F; 线程；</li><li>单 Reactor 多进程 &#x2F; 线程；</li><li>多 Reactor 单进程 &#x2F; 线程；</li><li>多 Reactor 多进程 &#x2F; 线程；</li></ul><p>其中，「多 Reactor 单进程 &#x2F; 线程」实现方案相比「单 Reactor 单进程 &#x2F; 线程」方案，不仅复杂而且也没有性能优势，因此实际中并没有应用。</p><p>剩下的 3 个方案都是比较经典的，且都有应用在实际的项目中：</p><ul><li>单 Reactor 单进程 &#x2F; 线程；</li><li>单 Reactor 多线程 &#x2F; 进程；</li><li>多 Reactor 多进程 &#x2F; 线程；</li></ul><p>方案具体使用进程还是线程，要看使用的编程语言以及平台有关：</p><ul><li>Java 语言一般使用线程，比如 Netty;</li><li>C 语言使用进程和线程都可以，例如 Nginx 使用的是进程，Memcache 使用的是线程。</li></ul><p>接下来，分别介绍这三个经典的 Reactor 方案。</p><h3 id="Reactor"><a href="#Reactor" class="headerlink" title="Reactor"></a>Reactor</h3><h4 id="单Reactor-单进程-x2F-线程"><a href="#单Reactor-单进程-x2F-线程" class="headerlink" title="单Reactor 单进程 &#x2F; 线程"></a>单Reactor 单进程 &#x2F; 线程</h4><p>一般来说，C 语言实现的是「<strong>单 Reactor 单进程</strong>」的方案，因为 C 语言编写完的程序，运行后就是一个独立的进程，不需要在进程中再创建线程。</p><p>而 Java 语言实现的是「<strong>单 Reactor 单线程</strong>」的方案，因为 Java 程序是跑在 Java 虚拟机这个进程上面的，虚拟机中有很多线程，我们写的 Java 程序只是其中的一个线程而已。</p><p>我们来看看「<strong>单 Reactor 单进程</strong>」的方案示意图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Reactor/%E5%8D%95Reactor%E5%8D%95%E8%BF%9B%E7%A8%8B.png" alt="img"></p><p>可以看到进程里有 <strong>Reactor、Acceptor、Handler</strong> 这三个对象：</p><ul><li>Reactor 对象的作用是监听和分发事件；</li><li>Acceptor 对象的作用是获取连接；</li><li>Handler 对象的作用是处理业务；</li></ul><p>对象里的 select、accept、read、send 是系统调用函数，dispatch 和 「业务处理」是需要完成的操作，其中 dispatch 是分发事件操作。</p><p>接下来，介绍下「单 Reactor 单进程」这个方案：</p><ul><li>Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；</li><li>如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；</li><li>如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；</li><li>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li></ul><p>单 Reactor 单进程的方案因为全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。</p><p>但是，这种方案存在 2 个缺点：</p><ul><li>第一个缺点，因为只有一个进程，<strong>无法充分利用多核 CPU 的性能</strong>；</li><li>第二个缺点，Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，<strong>如果业务处理耗时比较长，那么就造成响应的延迟</strong>；</li></ul><p>所以，单 Reactor 单进程的方案<strong>不适用计算密集型的场景，只适用于业务处理非常快速的场景</strong>。</p><p>Redis 是由 C 语言实现的，在 Redis 6.0 版本之前采用的正是「单 Reactor 单进程」的方案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。</p><h4 id="单-Reactor-多线程-x2F-多进程"><a href="#单-Reactor-多线程-x2F-多进程" class="headerlink" title="单 Reactor 多线程 &#x2F; 多进程"></a>单 Reactor 多线程 &#x2F; 多进程</h4><p>如果要克服「单 Reactor 单线程 &#x2F; 进程」方案的缺点，那么就需要引入多线程 &#x2F; 多进程，这样就产生了<strong>单 Reactor 多线程 &#x2F; 多进程</strong>的方案。</p><p>闻其名不如看其图，先来看看「单 Reactor 多线程」方案的示意图如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Reactor/%E5%8D%95Reactor%E5%A4%9A%E7%BA%BF%E7%A8%8B.png" alt="img"></p><p>详细说一下这个方案：</p><ul><li>Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；</li><li>如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；</li><li>如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；</li></ul><p>上面的三个步骤和单 Reactor 单线程方案是一样的，接下来的步骤就开始不一样了：</p><ul><li>Handler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后，会将数据发给子线程里的 Processor 对象进行业务处理；</li><li>子线程里的 Processor 对象就进行业务处理，处理完后，将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send 方法将响应结果发送给 client；</li></ul><p>单 Reator 多线程的方案优势在于<strong>能够充分利用多核 CPU 的能</strong>，那既然引入多线程，那么自然就带来了多线程竞争资源的问题。</p><p>例如，子线程完成业务处理后，要把结果传递给主线程的 Handler 进行发送，这里涉及共享数据的竞争。</p><p>要避免多线程由于竞争共享资源而导致数据错乱的问题，就需要在操作共享资源前加上互斥锁，以保证任意时间里只有一个线程在操作共享资源，待该线程操作完释放互斥锁后，其他线程才有机会操作共享数据。</p><p>聊完单 Reactor 多线程的方案，接着来看看单 Reactor 多进程的方案。</p><p>事实上，单 Reactor 多进程相比单 Reactor 多线程实现起来很麻烦，主要因为要考虑子进程 &lt;-&gt; 父进程的双向通信，并且父进程还得知道子进程要将数据发送给哪个客户端。</p><p>而多线程间可以共享数据，虽然要额外考虑并发问题，但是这远比进程间通信的复杂度低得多，<strong>因此实际应用中也看不到单 Reactor 多进程的模式</strong>。</p><p>另外，「单 Reactor」的模式还有个问题，<strong>因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方</strong>。</p><h4 id="多-Reactor-多进程-x2F-线程"><a href="#多-Reactor-多进程-x2F-线程" class="headerlink" title="多 Reactor 多进程 &#x2F; 线程"></a>多 Reactor 多进程 &#x2F; 线程</h4><p>要解决「单 Reactor」的问题，就是将「单 Reactor」实现成「多 Reactor」，这样就产生了第 <strong>多 Reactor 多进程 &#x2F; 线程</strong>的方案。</p><p>老规矩，闻其名不如看其图。多 Reactor 多进程 &#x2F; 线程方案的示意图如下（以线程为例）：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Reactor/%E4%B8%BB%E4%BB%8EReactor%E5%A4%9A%E7%BA%BF%E7%A8%8B.png" alt="img"></p><p>方案详细说明如下：</p><ul><li>主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept 获取连接，将新的连接分配给某个子线程；</li><li>子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听，并创建一个 Handler 用于处理连接的响应事件。</li><li>如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应。</li><li>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li></ul><p>多 Reactor 多线程的方案虽然看起来复杂的，但是实际实现时比单 Reactor 多线程的方案要简单的多，原因如下：</p><ul><li>主线程和子线程分工明确，<strong>主线程只负责接收新连接，子线程负责完成后续的业务处理。</strong></li><li>主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端。</li></ul><p>大名鼎鼎的两个开源软件 Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案。</p><p>采用了「多 Reactor 多进程」方案的开源软件是 Nginx，不过方案与标准的多 Reactor 多进程有些差异。</p><p>具体差异表现在主进程中仅仅用来初始化 socket，并没有创建 mainReactor 来 accept 连接，而是由子进程的 Reactor 来 accept 连接，通过锁来控制一次只有一个子进程进行 accept（防止出现惊群现象），子进程 accept 新连接后就放到自己的 Reactor 进行处理，不会再分配给其他子进程。</p><h3 id="Proactor"><a href="#Proactor" class="headerlink" title="Proactor"></a>Proactor</h3><p>前面提到的 Reactor 是非阻塞同步网络模式，而 <strong>Proactor 是异步网络模式</strong>。</p><ul><li><strong>Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件</strong>。在每次感知到有事件发生（比如可读就绪事件）后，就需要应用进程主动调用 read 方法来完成数据的读取，也就是要应用进程主动将 socket 接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。</li><li><strong>Proactor 是异步网络模式， 感知的是已完成的读写事件</strong>。在发起异步读写请求时，需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全程由操作系统来做，并不需要像 Reactor 那样还需要应用进程主动发起 read&#x2F;write 来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。</li></ul><p>因此，<strong>Reactor 可以理解为「来了事件操作系统通知应用进程，让应用进程来处理」</strong>，而 <strong>Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应用进程」</strong>。这里的「事件」就是有新连接、有数据可读、有数据可写的这些 I&#x2F;O 事件这里的「处理」包含从驱动读取到内核以及从内核读取到用户空间。</p><p>无论是 Reactor，还是 Proactor，都是一种基于「事件分发」的网络编程模式，区别在于 <strong>Reactor 模式是基于「待完成」的 I&#x2F;O 事件，而 Proactor 模式则是基于「已完成」的 I&#x2F;O 事件</strong>。</p><p>可惜的是，在 Linux 下的异步 I&#x2F;O 是不完善的， <code>aio</code> 系列函数是由 POSIX 定义的异步操作接口，不是真正的操作系统级别支持的，而是在用户空间模拟出来的异步，并且仅仅支持基于本地文件的 aio 异步操作，网络编程中的 socket 是不支持的，这也使得<strong>基于 Linux 的高性能网络程序都是使用 Reactor 方案</strong>。</p><p>而 Windows 里实现了一套完整的支持 socket 的异步编程接口，这套接口就是 <code>IOCP</code>，是由操作系统级别实现的异步 I&#x2F;O，真正意义上异步 I&#x2F;O，因此在 Windows 里实现高性能网络程序可以使用效率更高的 Proactor 方案。</p><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>大多数网站背后肯定不是只有一台服务器提供服务，因为单机的并发量和数据量都是有限的，所以都会用多台服务器构成集群来对外提供服务。</p><p>但是问题来了，现在有那么多个节点（后面统称服务器为节点，因为少一个字），要如何分配客户端的请求呢？</p><p>其实这个问题就是「负载均衡问题」。解决负载均衡问题的算法很多，不同的负载均衡算法，对应的就是不同的分配策略，适应的业务场景也不同。</p><p>最简单的方式，引入一个中间的负载均衡层，让它将外界的请求「轮流」的转发给内部的集群。比如集群有 3 个节点，外界请求有 3 个，那么每个节点都会处理 1 个请求，达到了分配请求的目的。</p><p>考虑到每个节点的硬件配置有所区别，我们可以引入权重值，将硬件配置更好的节点的权重值设高，然后根据各个节点的权重值，按照一定比重分配在不同的节点上，让硬件配置更好的节点承担更多的请求，<strong>这种算法叫做加权轮询</strong>。</p><p><strong>加权轮询算法使用场景是建立在每个节点存储的数据都是相同的前提</strong>。所以，每次读数据的请求，访问任意一个节点都能得到结果。</p><p>但是，加权轮询算法是无法应对「分布式系统（数据分片的系统）」的，因为分布式系统中，每个节点存储的数据是不同的。</p><p>当我们想提高系统的容量，就会将数据水平切分到不同的节点来存储，也就是将数据分布到了不同的节点。比如<strong>一个分布式 KV（key-valu） 缓存系统，某个 key 应该到哪个或者哪些节点上获得，应该是确定的</strong>，不是说任意访问一个节点都可以得到缓存结果的。</p><p>因此，我们要想一个能应对分布式系统的负载均衡算法。</p><h3 id="使用哈希算法有什么问题？"><a href="#使用哈希算法有什么问题？" class="headerlink" title="使用哈希算法有什么问题？"></a>使用哈希算法有什么问题？</h3><p>有的同学可能很快就想到了：<strong>哈希算法</strong>。因为对同一个关键字进行哈希计算，每次计算都是相同的值，这样就可以将某个 key 确定到一个节点了，可以满足分布式系统的负载均衡需求。</p><p>哈希算法最简单的做法就是进行取模运算，比如分布式系统中有 3 个节点，基于 <code>hash(key) % 3</code> 公式对数据进行了映射。</p><p>如果客户端要获取指定 key 的数据，通过下面的公式可以定位节点：</p><pre><code class="text">hash(key) % 3</code></pre><p>如果经过上面这个公式计算后得到的值是 0，就说明该 key 需要去第一个节点获取。</p><p>但是有一个很致命的问题，<strong>如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据</strong>，否则会出现查询不到数据的问题。</p><p>举个例子，假设我们有一个由 A、B、C 三个节点组成分布式 KV 缓存系统，基于计算公式 <code>hash(key) % 3</code> 将数据进行了映射，每个节点存储了不同的数据。</p><p>现在有 3 个查询 key 的请求，分别查询 key-01，key-02，key-03 的数据，这三个 key 分别经过 hash() 函数计算后的值为 hash( key-01) &#x3D; 6、hash( key-02) &#x3D; 7、hash(key-03) &#x3D; 8，然后再对这些值进行取模运算。通过这样的哈希算法，每个 key 都可以定位到对应的节点。</p><p>当 3 个节点不能满足业务需求了，这时我们增加了一个节点，节点的数量从 3 变化为 4，意味取模哈希函数中基数的变化，这样会导致<strong>大部分映射关系改变</strong></p><p>比如，之前的 hash(key-01) % <code>3</code> &#x3D; 0，就变成了 hash(key-01) % <code>4</code> &#x3D; 2，查询 key-01 数据时，寻址到了节点 C，而 key-01 的数据是存储在节点 A 上的，不是在节点 C，所以会查询不到数据。</p><p>同样的道理，如果我们对分布式系统进行缩容，比如移除一个节点，也会因为取模哈希函数中基数的变化，可能出现查询不到数据的问题。</p><p>要解决这个问题的办法，就需要我们进行<strong>迁移数据</strong>，比如节点的数量从 3 变化为 4 时，要基于新的计算公式 hash(key) % 4 ，重新对数据和节点做映射。</p><p>假设总数据条数为 M，哈希算法在面对节点数量变化时，**最坏情况下所有数据都需要迁移，所以它的数据迁移规模是 O(M)**，这样数据的迁移成本太高了。</p><p>所以，我们应该要重新想一个新的算法，来避免分布式系统在扩容或者缩容时，发生过多的数据迁移。</p><h3 id="使用一致性哈希算法有什么问题？"><a href="#使用一致性哈希算法有什么问题？" class="headerlink" title="使用一致性哈希算法有什么问题？"></a>使用一致性哈希算法有什么问题？</h3><p>一致性哈希算法就很好地解决了分布式系统在扩容或者缩容时，发生过多的数据迁移的问题。</p><p>一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而<strong>一致哈希算法是对 2^32 进行取模运算，是一个固定的值</strong>。</p><p>我们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环，就像钟表一样，钟表的圆可以理解成由 60 个点组成的圆，而此处我们把这个圆想象成由 2^32 个点组成的圆，这个圆环被称为<strong>哈希环</strong>，如下图：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/0ea3960fef48d4cbaeb4bec4345301e7.png" alt="img"></p><p>一致性哈希要进行两步哈希：</p><ul><li>第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；</li><li>第二步：当对数据进行存储或访问时，对数据进行哈希映射；</li></ul><p>所以，<strong>一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上</strong>。</p><p>问题来了，对「数据」进行哈希映射得到一个结果要怎么找到存储该数据的节点呢？</p><p>答案是，映射的结果值往<strong>顺时针的方向的找到第一个节点</strong>，就是存储该数据的节点。</p><p>举个例子，有 3 个节点经过哈希计算，映射到了如下图的位置：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/83d7f363643353c92d252e34f1d4f687.png" alt="img"></p><p>接着，对要查询的 key-01 进行哈希计算，确定此 key-01 映射在哈希环的位置，然后从这个位置往顺时针的方向找到第一个节点，就是存储该 key-01 数据的节点。</p><p>比如，下图中的 key-01 映射的位置，往顺时针的方向找到第一个节点就是节点 A。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/30c2c70721c12f9c140358fbdc5f2282.png" alt="img"></p><p>所以，当需要对指定 key 的值进行读写的时候，要通过下面 2 步进行寻址：</p><ul><li>首先，对 key 进行哈希计算，确定此 key 在环上的位置；</li><li>然后，从这个位置沿着顺时针方向走，遇到的第一节点就是存储 key 的节点。</li></ul><p>知道了一致哈希寻址的方式，我们来看看，如果增加一个节点或者减少一个节点会发生大量的数据迁移吗？</p><p>假设节点数量从 3 增加到了 4，新的节点 D 经过哈希计算后映射到了下图中的位置：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/f8909edef2f3949f8945bb99380baab3.png" alt="img"></p><p>你可以看到，key-01、key-03 都不受影响，只有 key-02 需要被迁移节点 D。</p><p>假设节点数量从 3 减少到了 2，比如将节点 A 移除：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/31485046f1303b57d8aaeaab103ea7ab.png" alt="img"></p><p>你可以看到，key-02 和 key-03 不会受到影响，只有 key-01 需要被迁移节点 B。</p><p>因此，<strong>在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响</strong>。</p><p>上面这些图中 3 个节点映射在哈希环还是比较分散的，所以看起来请求都会「均衡」到每个节点。</p><p>但是<strong>一致性哈希算法并不保证节点能够在哈希环上分布均匀</strong>，这样就会带来一个问题，会有大量的请求集中在一个节点上。</p><p>比如，下图中 3 个节点的映射位置都在哈希环的右半边：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/d528bae6fcec2357ba2eb8f324ad9fd5.png" alt="img"></p><p>这时候有一半以上的数据的寻址都会找节点 A，也就是访问请求主要集中的节点 A 上，这肯定不行的呀，说好的负载均衡呢，这种情况一点都不均衡。</p><p>另外，在这种节点分布不均匀的情况下，进行容灾与扩容时，哈希环上的相邻节点容易受到过大影响，容易发生雪崩式的连锁反应。</p><p>比如，上图中如果节点 A 被移除了，当节点 A 宕机后，根据一致性哈希算法的规则，其上数据应该全部迁移到相邻的节点 B 上，这样，节点 B 的数据量、访问量都会迅速增加很多倍，一旦新增的压力超过了节点 B 的处理能力上限，就会导致节点 B 崩溃，进而形成雪崩式的连锁反应。</p><p>所以，<strong>一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题</strong>。</p><h3 id="如何通过虚拟节点提高均衡度？"><a href="#如何通过虚拟节点提高均衡度？" class="headerlink" title="如何通过虚拟节点提高均衡度？"></a>如何通过虚拟节点提高均衡度？</h3><p>要想解决节点能在哈希环上分配不均匀的问题，就是要有大量的节点，节点数越多，哈希环上的节点分布的就越均匀。</p><p>但问题是，实际中我们没有那么多节点。所以这个时候我们就加入<strong>虚拟节点</strong>，也就是对一个真实节点做多个副本。</p><p>具体做法是，<strong>不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。</strong></p><p>比如对每个节点分别设置 3 个虚拟节点：</p><ul><li>对节点 A 加上编号来作为虚拟节点：A-01、A-02、A-03</li><li>对节点 B 加上编号来作为虚拟节点：B-01、B-02、B-03</li><li>对节点 C 加上编号来作为虚拟节点：C-01、C-02、C-03</li></ul><p>引入虚拟节点后，原本哈希环上只有 3 个节点的情况，就会变成有 9 个虚拟节点映射到哈希环上，哈希环上的节点数量多了 3 倍。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/dbb57b8d6071d011d05eeadd93269e13.png" alt="img"></p><p>你可以看到，<strong>节点数量多了后，节点在哈希环上的分布就相对均匀了</strong>。这时候，如果有访问请求寻址到「A-01」这个虚拟节点，接着再通过「A-01」虚拟节点找到真实节点 A，这样请求就能访问到真实节点 A 了。</p><p>上面为了方便你理解，每个真实节点仅包含 3 个虚拟节点，这样能起到的均衡效果其实很有限。而在实际的工程中，虚拟节点的数量会大很多，比如 Nginx 的一致性哈希算法，每个权重为 1 的真实节点就含有160 个虚拟节点。</p><p>另外，虚拟节点除了会提高节点的均衡度，还会提高系统的稳定性。<strong>当节点变化时，会有不同的节点共同分担系统的变化，因此稳定性更高</strong>。</p><p>比如，当某个节点被移除时，对应该节点的多个虚拟节点均会移除，而这些虚拟节点按顺时针方向的下一个虚拟节点，可能会对应不同的真实节点，即这些不同的真实节点共同分担了节点变化导致的压力。</p><p>而且，有了虚拟节点后，还可以为硬件配置更好的节点增加权重，比如对权重更高的节点增加更多的虚拟机节点即可。</p><p>因此，<strong>带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景</strong>。</p><h2 id="网络性能查看"><a href="#网络性能查看" class="headerlink" title="网络性能查看"></a>网络性能查看</h2><h3 id="性能指标有哪些？"><a href="#性能指标有哪些？" class="headerlink" title="性能指标有哪些？"></a>性能指标有哪些？</h3><p>通常是以 4 个指标来衡量网络的性能，分别是带宽、延时、吞吐率、PPS（Packet Per Second），它们表示的意义如下：</p><ul><li><em>带宽</em>，表示链路的最大传输速率，单位是 b&#x2F;s （比特 &#x2F; 秒），带宽越大，其传输能力就越强。</li><li><em>延时</em>，表示请求数据包发送后，收到对端响应，所需要的时间延迟。不同的场景有着不同的含义，比如可以表示建立 TCP 连接所需的时间延迟，或一个数据包往返所需的时间延迟。</li><li><em>吞吐率</em>，表示单位时间内成功传输的数据量，单位是 b&#x2F;s（比特 &#x2F; 秒）或者 B&#x2F;s（字节 &#x2F; 秒），吞吐受带宽限制，带宽越大，吞吐率的上限才可能越高。</li><li><em>PPS</em>，全称是 Packet Per Second（包 &#x2F; 秒），表示以网络包为单位的传输速率，一般用来评估系统对于网络的转发能力。</li></ul><p>当然，除了以上这四种基本的指标，还有一些其他常用的性能指标，比如：</p><ul><li><em>网络的可用性</em>，表示网络能否正常通信；</li><li><em>并发连接数</em>，表示 TCP 连接数量；</li><li><em>丢包率</em>，表示所丢失数据包数量占所发送数据组的比率；</li><li><em>重传率</em>，表示重传网络包的比例；</li></ul><p>你可能会问了，如何观测这些性能指标呢？不急，继续往下看。</p><h3 id="网络配置查看"><a href="#网络配置查看" class="headerlink" title="网络配置查看"></a>网络配置查看</h3><p>要想知道网络的配置和状态，我们可以使用 <code>ifconfig</code> 或者 <code>ip</code> 命令来查看。</p><p>这两个命令功能都差不多，不过它们属于不同的软件包，<code>ifconfig</code> 属于 <code>net-tools</code> 软件包，<code>ip</code> 属于 <code>iproute2</code> 软件包，我的印象中 <code>net-tools</code> 软件包没有人继续维护了，而 <code>iproute2</code> 软件包是有开发者依然在维护，所以更推荐你使用 <code>ip</code> 工具。</p><p>虽然这两个命令输出的格式不尽相同，但是输出的内容基本相同，比如都包含了 IP 地址、子网掩码、MAC 地址、网关地址、MTU 大小、网口的状态以及网络包收发的统计信息，下面就来说说这些信息，它们都与网络性能有一定的关系。</p><p>第一，网口的连接状态标志。其实也就是表示对应的网口是否连接到交换机或路由器等设备，如果 <code>ifconfig</code> 输出中看到有 <code>RUNNING</code>，或者 <code>ip</code> 输出中有 <code>LOWER_UP</code>，则说明物理网络是连通的，如果看不到，则表示网口没有接网线。</p><p>第二，MTU 大小。默认值是 <code>1500</code> 字节，其作用主要是限制网络包的大小，如果 IP 层有一个数据报要传，而且网络包的长度比链路层的 MTU 还大，那么 IP 层就需要进行分片，即把数据报分成若干片，这样每一片就都小于 MTU。事实上，每个网络的链路层 MTU 可能会不一样，所以你可能需要调大或者调小 MTU 的数值。</p><p>第三，网口的 IP 地址、子网掩码、MAC 地址、网关地址。这些信息必须要配置正确，网络功能才能正常工作。</p><p>第四，网络包收发的统计信息。通常有网络收发的字节数、包数、错误数以及丢包情况的信息，如果 <code>TX</code>（发送） 和 <code>RX</code>（接收） 部分中 errors、dropped、overruns、carrier 以及 collisions 等指标不为 0 时，则说明网络发送或者接收出问题了，这些出错统计信息的指标意义如下：</p><ul><li><em>errors</em> 表示发生错误的数据包数，比如校验错误、帧同步错误等；</li><li><em>dropped</em> 表示丢弃的数据包数，即数据包已经收到了 Ring Buffer（这个缓冲区是在内核内存中，更具体一点是在网卡驱动程序里），但因为系统内存不足等原因而发生的丢包；</li><li><em>overruns</em> 表示超限数据包数，即网络接收&#x2F;发送速度过快，导致 Ring Buffer 中的数据包来不及处理，而导致的丢包，因为过多的数据包挤压在 Ring Buffer，这样 Ring Buffer 很容易就溢出了；</li><li><em>carrier</em> 表示发生 carrirer 错误的数据包数，比如双工模式不匹配、物理电缆出现问题等；</li><li><em>collisions</em> 表示冲突、碰撞数据包数；</li></ul><p><code>ifconfig</code> 和 <code>ip</code> 命令只显示的是网口的配置以及收发数据包的统计信息，而看不到协议栈里的信息，那接下来就来看看如何查看协议栈里的信息。</p><h3 id="socket信息查看"><a href="#socket信息查看" class="headerlink" title="socket信息查看"></a>socket信息查看</h3><p>我们可以使用 <code>netstat</code> 或者 <code>ss</code>，这两个命令查看 socket、网络协议栈、网口以及路由表的信息。</p><p>虽然 <code>netstat</code> 与 <code>ss</code> 命令查看的信息都差不多，但是如果在生产环境中要查看这类信息的时候，尽量不要使用 <code>netstat</code> 命令，因为它的性能不好，在系统比较繁忙的情况下，如果频繁使用 <code>netstat</code> 命令则会对性能的开销雪上加霜，所以更推荐你使用性能更好的 <code>ss</code> 命令。</p><p>从下面这张图，你可以看到这两个命令的输出内容：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BD%91%E7%BB%9C/showsocket.png" alt="img"></p><p>可以发现，输出的内容都差不多， 比如都包含了 socket 的状态（<em>State</em>）、接收队列（<em>Recv-Q</em>）、发送队列（<em>Send-Q</em>）、本地地址（<em>Local Address</em>）、远端地址（<em>Foreign Address</em>）、进程 PID 和进程名称（<em>PID&#x2F;Program name</em>）等。</p><p>使用netstat -s或ss -s可以查看统计信息。</p><p><code>ss</code> 命令输出的统计信息相比 <code>netsat</code> 比较少，<code>ss</code> 只显示已经连接（<em>estab</em>）、关闭（<em>closed</em>）、孤儿（<em>orphaned</em>） socket 等简要统计。</p><p>而 <code>netstat</code> 则有更详细的网络协议栈信息，比如上面显示了 TCP 协议的主动连接（<em>active connections openings</em>）、被动连接（<em>passive connection openings</em>）、失败重试（<em>failed connection attempts</em>）、发送（<em>segments send out</em>）和接收（<em>segments received</em>）的分段数量等各种信息。</p><h3 id="网络吞吐率和-PPS-如何查看？"><a href="#网络吞吐率和-PPS-如何查看？" class="headerlink" title="网络吞吐率和 PPS 如何查看？"></a>网络吞吐率和 PPS 如何查看？</h3><p>可以使用 <code>sar</code> 命令当前网络的吞吐率和 PPS，用法是给 <code>sar</code> 增加 <code>-n</code> 参数就可以查看网络的统计信息，比如</p><ul><li>sar -n DEV，显示网口的统计数据；</li><li>sar -n EDEV，显示关于网络错误的统计数据；</li><li>sar -n TCP，显示 TCP 的统计数据</li></ul><p>比如，我通过 <code>sar</code> 命令获取了网口的统计信息：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BD%91%E7%BB%9C/sar.png" alt="img"></p><p>它们的含义：</p><ul><li><code>rxpck/s</code> 和 <code>txpck/s</code> 分别是接收和发送的 PPS，单位为包 &#x2F; 秒。</li><li><code>rxkB/s</code> 和 <code>txkB/s</code> 分别是接收和发送的吞吐率，单位是 KB&#x2F; 秒。</li><li><code>rxcmp/s</code> 和 <code>txcmp/s</code> 分别是接收和发送的压缩数据包数，单位是包 &#x2F; 秒。</li></ul><p>对于带宽，我们可以使用 <code>ethtool</code> 命令来查询，它的单位通常是 <code>Gb/s</code> 或者 <code>Mb/s</code>，不过注意这里小写字母 <code>b</code> ，表示比特而不是字节。我们通常提到的千兆网卡、万兆网卡等，单位也都是比特（<em>bit</em>）。如下你可以看到， eth0 网卡就是一个千兆网卡：</p><pre><code class="bash">$ ethtool eth0 | grep Speed  Speed: 1000Mb/s</code></pre><h3 id="连通性和延时如何查看？"><a href="#连通性和延时如何查看？" class="headerlink" title="连通性和延时如何查看？"></a>连通性和延时如何查看？</h3><p>要测试本机与远程主机的连通性和延时，通常是使用 <code>ping</code> 命令，它是基于 ICMP 协议的，工作在网络层。</p><p>不过，需要注意的是，<code>ping</code> 不通服务器并不代表 HTTP 请求也不通，因为有的服务器的防火墙是会禁用 ICMP 协议的。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E8%B0%B7%E6%AD%8Cc++%E9%A3%8E%E6%A0%BC/"/>
      <url>/2023/01/22/%E8%B0%B7%E6%AD%8Cc++%E9%A3%8E%E6%A0%BC/</url>
      
        <content type="html"><![CDATA[<h1 id="谷歌c-风格"><a href="#谷歌c-风格" class="headerlink" title="谷歌c++风格"></a>谷歌c++风格</h1><h2 id="头文件"><a href="#头文件" class="headerlink" title="头文件"></a>头文件</h2><h3 id="self-contained头文件"><a href="#self-contained头文件" class="headerlink" title="self-contained头文件"></a>self-contained头文件</h3><p>所有头文件要能够自给自足（self-contained,也就是可以作为第一个头文件被引入）。换言之，用户和重构工具不需要为特别场合而包含额外的头文件。</p><h3 id="define保护"><a href="#define保护" class="headerlink" title="define保护"></a>define保护</h3><p>所有头文件都应该有 <code>#define</code> 保护来防止头文件被多重包含, 命名格式当是: <code>&lt;PROJECT&gt;_&lt;PATH&gt;_&lt;FILE&gt;_H_</code> .</p><p>例如, 项目 <code>foo</code> 中的头文件 <code>foo/src/bar/baz.h</code> 可按如下方式保护:</p><pre><code class="cpp">#ifndef FOO_BAR_BAZ_H_#define FOO_BAR_BAZ_H_...#endif // FOO_BAR_BAZ_H_</code></pre><h3 id="前置声明"><a href="#前置声明" class="headerlink" title="前置声明"></a>前置声明</h3><p>尽可能地避免使用前置声明。使用 <code>#include</code> 包含需要的头文件即可。</p><p><strong>优点：</strong></p><blockquote><ul><li>前置声明能够节省编译时间，多余的 <code>#include</code> 会迫使编译器展开更多的文件，处理更多的输入。</li><li>前置声明能够节省不必要的重新编译的时间。 <code>#include</code> 使代码因为头文件中无关的改动而被重新编译多次。</li></ul></blockquote><p><strong>缺点：</strong></p><blockquote><ul><li><p>前置声明隐藏了依赖关系，头文件改动时，用户的代码会跳过必要的重新编译过程。</p></li><li><p>前置声明可能会被库的后续更改所破坏。前置声明函数或模板有时会妨碍头文件开发者变动其 API. 例如扩大形参类型，加个自带默认参数的模板形参等等。</p></li><li><p>前置声明来自命名空间 <code>std::</code> 的 symbol 时，经常会产生“未定义”的报错。</p></li><li><p>很难判断什么时候该用前置声明，什么时候该用 <code>#include</code> 。极端情况下，用前置声明代替 <code>#include</code> 甚至都会暗暗地改变代码的含义：</p><blockquote><pre><code class="cpp">// b.h:struct B &#123;&#125;;struct D : B &#123;&#125;;// good_user.cc:#include &quot;b.h&quot;void f(B*);void f(void*);void test(D* x) &#123; f(x); &#125;  // calls f(B*)</code></pre></blockquote></li></ul><blockquote><p>如果 <code>#include</code> 被 <code>B</code> 和 <code>D</code> 的前置声明替代， <code>test()</code> 就会调用 <code>f(void*)</code> .</p></blockquote><ul><li>前置声明了不少来自头文件的 symbol 时，就会比单单一行的 <code>include</code> 冗长。</li><li>仅仅为了能前置声明而重构代码（比如用指针成员代替对象成员）会使代码变得更慢更复杂.</li></ul></blockquote><h3 id="内联函数"><a href="#内联函数" class="headerlink" title="内联函数"></a>内联函数</h3><p>不要内联超过 10 行的函数. 谨慎对待析构函数, 析构函数往往比其表面看起来要更长, 因为有隐含的成员和基类析构函数被调用!</p><p>另一个实用的经验准则: 内联那些包含循环或 <code>switch</code> 语句的函数常常是得不偿失 (除非在大多数情况下, 这些循环或 <code>switch</code> 语句从不被执行).</p><p>有些函数即使声明为内联的也不一定会被编译器内联, 这点很重要; 比如虚函数和递归函数就不会被正常内联.。通常, 递归函数不应该声明成内联函数。虚函数内联的主要原因则是想把它的函数体放在类定义内, 为了图个方便, 抑或是当作文档描述其行为, 比如精短的存取函数。</p><h3 id="include顺序"><a href="#include顺序" class="headerlink" title="include顺序"></a>include顺序</h3><p>使用标准的头文件包含顺序可增强可读性, 避免隐藏依赖: 相关头文件, C 库, C++ 库, 其他库的 .h, 本项目内的 .h.</p><p><strong>可以在 <code>#include</code> 中插入空行以分割</strong>相关头文件, C 库, C++ 库, 其他库的 <code>.h</code> 和本项目内的 <code>.h</code> 是个好习惯。</p><p><strong>按字母顺序分别对每种类型的头文件进行二次排序</strong>是不错的主意。</p><p>项目内头文件应按照项目源代码目录树结构排列, 避免使用 UNIX 特殊的快捷目录 <code>.</code> (当前目录) 或 <code>..</code> (上级目录). 例如, </p><p><code>google-awesome-project/src/base/logging.h</code> 应该按如下方式包含:</p><pre><code>#include &quot;base/logging.h&quot;</code></pre><p>又如, <code>dir/foo.cc</code> 或 <code>dir/foo_test.cc</code> 的主要作用是实现或测试 <code>dir2/foo2.h</code> 的功能, <code>foo.cc</code> 中包含头文件的次序如下:</p><blockquote><ol><li><code>dir2/foo2.h</code> (优先位置, 详情如下)</li><li>C 系统文件</li><li>C++ 系统文件</li><li>其他库的 <code>.h</code> 文件</li><li>本项目内 <code>.h</code> 文件</li></ol></blockquote><p>首选的头文件是为了减少隐藏依赖，同时确保头文件和实现文件是匹配的。</p><p>隐藏依赖，即一个头文件依赖其它头文件。例如：</p><pre><code class="cpp">//A.hstruct BS bs;...//B.hstruct BS&#123;....&#125;;//在A.c中，这样会报错#include A.h #include B.h//先包含B.h就可以#include B.h#include A.h</code></pre><p>这样就叫”隐藏依赖”。如果先包含A.h就可以发现隐藏依赖，所以各种规范都要求自身的头文件放在第一个，就能发现隐藏依赖。解决办法就是在A.h中包含B.h，而不是在A.c中再包含。</p><p>您所依赖的符号 (symbols) 被哪些头文件所定义，您就应该包含（include）哪些头文件。比如您要用到 <code>bar.h</code> 中的某个符号, 哪怕您所包含的 <code>foo.h</code> 已经包含了 <code>bar.h</code>, 也照样得包含 <code>bar.h</code>, 除非 <code>foo.h</code> 有明确说明它会自动向您提供 <code>bar.h</code> 中的 symbol. 不过，凡是 cc 文件所对应的「相关头文件」已经包含的，就不用再重复包含进其 cc 文件里面了，就像 <code>foo.cc</code> 只包含 <code>foo.h</code> 就够了，不用再管后者所包含的其它内容。</p><p>举例来说, <code>google-awesome-project/src/foo/internal/fooserver.cc</code> 的包含次序如下:</p><blockquote><pre><code class="cpp">#include &quot;foo/public/fooserver.h&quot; // 优先位置#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;hash_map&gt;#include &lt;vector&gt;#include &quot;base/basictypes.h&quot;#include &quot;base/commandlineflags.h&quot;#include &quot;foo/public/bar.h&quot;</code></pre></blockquote><p><strong>例外：</strong></p><p>有时，平台特定（system-specific）代码需要条件编译（conditional includes），这些代码可以放到其它 includes 之后。当然，您的平台特定代码也要够简练且独立，比如：</p><blockquote><pre><code class="cpp">#include &quot;foo/public/fooserver.h&quot;#include &quot;base/port.h&quot;  // For LANG_CXX11.#ifdef LANG_CXX11#include &lt;initializer_list&gt;#endif  // LANG_CXX11</code></pre></blockquote><h2 id="作用域"><a href="#作用域" class="headerlink" title="作用域"></a>作用域</h2><h3 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a>命名空间</h3><p>1.使用具名的命名空间时, 其名称可基于项目名或相对路径</p><p>2.在命名空间的最后注释出命名空间的名字。</p><p>3.用命名空间把文件中的#include,以及类的前置声明以外的整个源文件封装起来, 以区别于其它命名空间</p><p>4.不要在命名空间 <code>std</code> 内声明任何东西, 包括标准库的类前置声明.。</p><p>5.不应该使用 using引入整个命名空间的标识符号，如using namespace std;</p><p>6.不要在头文件中使用命名空间别名除非显式标记内部命名空间使用。如namespace baz &#x3D; ::foo::bar::baz;</p><p>7.禁止使用内联命名空间</p><pre><code class="cpp">// .h 文件namespace mynamespace &#123;// 所有声明都置于命名空间中// 注意不要使用缩进class MyClass &#123;    public:    ...    void Foo();&#125;;&#125; // namespace mynamespace// .cc 文件namespace mynamespace &#123;// 函数定义都置于命名空间中void MyClass::Foo() &#123;    ...&#125;&#125; // namespace mynamespace</code></pre><h3 id="匿名命名空间"><a href="#匿名命名空间" class="headerlink" title="匿名命名空间"></a>匿名命名空间</h3><p>在 <code>.cc</code> 文件中定义一个不需要被外部引用的变量时，可以将它们放在匿名命名空间或声明为 <code>static</code> 。但是不要在 <code>.h</code> 文件中这么做。</p><p>匿名命名空间的声明和具名的格式相同，在最后注释上 <code>namespace</code> :</p><pre><code>namespace &#123;...&#125;  // namespace</code></pre><h3 id="非成员函数，静态函数和全局函数"><a href="#非成员函数，静态函数和全局函数" class="headerlink" title="非成员函数，静态函数和全局函数"></a>非成员函数，静态函数和全局函数</h3><p>尽量不要用全局函数，应该使用静态成员函数或命名空间内的非成员函数替代。类的静态函数应当和类的实例或静态数据紧密相关，不相关的函数可以放入命名空间。</p><p>相比单纯为了封装若干不共享任何静态数据的静态成员函数而创建类, 不如使用命名空间</p><p>举例而言，对于头文件 <code>myproject/foo_bar.h</code> , 应当使用</p><pre><code class="cpp">namespace myproject &#123;namespace foo_bar &#123;void Function1();void Function2();&#125;  // namespace foo_bar&#125;  // namespace myproject</code></pre><p>而非</p><pre><code class="cpp">namespace myproject &#123;class FooBar &#123; public:  static void Function1();  static void Function2();&#125;;&#125;  // namespace myproject</code></pre><p>如果函数作用域仅限于本文件，可使用匿名命名空间或 <code>static</code> 链接关键字 (如 <code>static int Foo() &#123;...&#125;</code>) 限定其作用域。</p><h3 id="局部变量"><a href="#局部变量" class="headerlink" title="局部变量"></a>局部变量</h3><p>将函数变量尽可能置于最小作用域内, 并在变量声明时进行初始化。</p><p>我们提倡在尽可能小的作用域中声明变量, 离第一次使用越近越好。这使得代码浏览者更容易定位变量声明的位置, 了解变量的类型和初始值。特别是，应使用初始化的方式替代声明再赋值</p><pre><code class="cpp">int j = g(); // 好——初始化时声明</code></pre><p>属于 <code>if</code>, <code>while</code> 和 <code>for</code> 语句的变量应当在这些语句中正常地声明，这样子这些变量的作用域就被限制在这些语句中了，举例而言:</p><blockquote><pre><code class="cpp">while (const char* p = strchr(str, &#39;/&#39;)) str = p + 1;</code></pre></blockquote><p><strong>有一个例外</strong>, 如果变量是一个对象, 每次进入作用域都要调用其构造函数, 每次退出作用域都要调用其析构函数. 这会导致效率降低.</p><pre><code class="cpp">// 低效的实现for (int i = 0; i &lt; 1000000; ++i) &#123;    Foo f;                  // 构造函数和析构函数分别调用 1000000 次!    f.DoSomething(i);&#125;</code></pre><p>在循环作用域外面声明这类变量要高效的多:</p><pre><code class="cpp">Foo f;                      // 构造函数和析构函数只调用 1 次for (int i = 0; i &lt; 1000000; ++i) &#123;    f.DoSomething(i);&#125;</code></pre><h3 id="静态和全局变量"><a href="#静态和全局变量" class="headerlink" title="静态和全局变量"></a>静态和全局变量</h3><p>禁止使用 class 类型的静态或全局变量: 它们会导致很难发现的 bug 和不确定的构造和析构函数调用顺序。因为不同的编译单元之间初始化和销毁顺序属于未明确行为 (unspecified behaviour)。比如，在程序结束时某静态变量已经被析构了，但代码还在跑——比如其它线程——并试图访问它且失败；再比如，一个静态 string 变量也许会在一个引用了前者的其它变量析构之前被析构掉。</p><p>静态生存周期的对象, 包括全局变量, 静态变量, 静态类成员变量, 以及函数静态变量, 都必须是原生数据类型 (POD : Plain Old Data): 只能是 int, char, float, 和 void, 以及 POD 类型的数组&#x2F;结构体&#x2F;指针。</p><p>不要使用函数返回值初始化静态变量，除非该函数不涉及任何全局变量。函数作用域里的静态变量除外，毕竟它的初始化顺序是有明确定义的，而且只会在指令执行到它的声明那里才会发生。</p><p>综上所述，我们只允许 POD 类型的静态变量，即完全禁用 <code>vector</code> (使用 C 数组替代) 和 <code>string</code> (使用 <code>const char []</code>)。</p><h2 id="类"><a href="#类" class="headerlink" title="类"></a>类</h2><h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><p>构造函数不允许调用虚函数，因为不会重定向到子类的虚函数实现。</p><p>在构造函数中, 直接终止程序是一个合适的处理错误的方式。如果要报告错误, 考虑用 <code>Init()</code> 方法或工厂函数。</p><h3 id="隐式类型转换"><a href="#隐式类型转换" class="headerlink" title="隐式类型转换"></a>隐式类型转换</h3><p>类型转换运算符和单参数构造函数都应当用 <code>explicit</code>进行标记，因为可能会发生隐式类型转换。 <code>explicit</code>会禁用隐式类型转换和c++11的列表初始化。一个例外是, <strong>拷贝和移动构造函数不应当被标记为</strong> <code>explicit</code>, 因为它们并不会发生类型转换。 对于设计目的就是用于对其他类型进行透明包装的类来说, 隐式类型转换有时是必要且合适的. 这时应当联系项目组长并说明特殊情况.</p><p>不能以一个参数进行调用的构造函数不应当加上 <code>explicit</code>。(<strong>多参数构造函数不会发生隐式转换</strong>)接受一个 <code>std::initializer_list</code> 作为参数的构造函数也应当省略 <code>explicit</code>, 以便支持拷贝初始化 (例如 <code>MyType m = &#123;1, 2&#125;;</code>)。</p><pre><code class="cpp">class MyInt&#123;public:    MyInt( int num)    &#123;        dNum=num;    &#125;&#125;;MyInt objMyInt = 10; //不同类型对象的隐式转换</code></pre><ul><li>隐式类型转换会隐藏类型不匹配的错误。 有时, 目的类型并不符合用户的期望, 甚至用户根本没有意识到发生了类型转换.</li><li>隐式类型转换会让代码难以阅读, 尤其是在有函数重载的时候, 因为这时很难判断到底是哪个函数被调用.</li></ul><p><strong>隐式转换危害</strong></p><pre><code class="cpp">class MyInt&#123;public:    MyInt(int* pdNum)    &#123;        m_pdNum=pdNum;    &#125;    ~MyInt()    &#123;        if(m_pdNum)        &#123;            delete m_pdNum;        &#125;    &#125;private:    int* m_pdNum;&#125;;void print(MyInt objMyInt)&#123;    cout&lt;&lt;&quot;in print_MyInt&quot;&lt;&lt;endl;&#125;int main()&#123;    int* pdNum=new int(666);    print(pdNum);               //意外的被隐式转换为MyInt对象，print结束后被析构&#125;</code></pre><p>如上所示，print函数将int* 隐式转换成了MyInt类型对象，然后在print函数结束后MyInt析构意外将指针给delete了。</p><h3 id="拷贝和移动"><a href="#拷贝和移动" class="headerlink" title="拷贝和移动"></a>拷贝和移动</h3><p>编译器会自动生成拷贝构造函数, 也就是说, 这些调用很容易被忽略，可能会造成问题。</p><p>如果让类型可拷贝, 一定要同时给出拷贝构造函数和赋值操作的定义。同样，如果让类型可移动, 同时移动操作的效率高于拷贝操作, 那么就把移动的两个操作 (移动构造函数和赋值操作) 也给出定义。</p><p>由于存在对象切割的风险(子类对象被复制到父类对象就是对象切割，子类中特有的变量不会出现在父类中), 不要为任何有可能有派生类的对象提供赋值操作或者拷贝 &#x2F; 移动构造函数 (当然也不要继承有这样的成员函数的类)。如果你的基类需要可复制属性, 请提供一个 <code>public virtual Clone()</code> 和一个 <code>protected</code> 的拷贝构造函数以供派生类实现.</p><p>如果你的类不需要拷贝 &#x2F; 移动操作, 请显式地通过在 <code>public</code> 域中使用 <code>= delete</code> 或其他手段禁用之。</p><pre><code class="cpp">// MyClass is neither copyable nor movable.MyClass(const MyClass&amp;) = delete;MyClass&amp; operator=(const MyClass&amp;) = delete;</code></pre><h3 id="结构体和类"><a href="#结构体和类" class="headerlink" title="结构体和类"></a>结构体和类</h3><p>仅当只有数据成员时使用 <code>struct</code>(不应该包括构造和析构以外的函数), 其它一概使用 <code>class</code>。为了和 STL 保持一致, 对于仿函数等特性可以不用 <code>class</code> 而是使用 <code>struct</code>.</p><h3 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h3><p>所有继承必须是 <code>public</code> 的. 如果你想使用私有继承, 你应该使用把基类的实例作为成员对象的方式.</p><p>不要过度使用实现继承. 组合常常更合适一些. 尽量做到只在 “is-a” (“has-a” 情况请使用组合) 的情况下使用继承: 如果 <code>Bar</code> 的确 “是一种” <code>Foo</code>, <code>Bar</code> 才能继承 <code>Foo</code>。对于继承, 由于子类的实现代码散布在父类和子类间之间, 要理解其实现变得更加困难. 子类不能重写父类的非虚函数, 当然也就不能修改其实现. 基类也可能定义了一些数据成员, 因此还必须区分基类的实际布局.</p><p>必要的话, 析构函数声明为 <code>virtual</code>. 如果你的类有虚函数, 则析构函数也应该为虚函数.</p><p>对于可能被子类访问的成员函数, 不要过度使用 <code>protected</code> 关键字. 注意, 数据成员都必须是私有的。</p><p>对于重载的虚函数或虚析构函数, 使用 <code>override</code>, 或  <code>final</code> 关键字显式地进行标记。标记为 <code>override</code> 或 <code>final</code> 的析构函数如果不是对基类虚函数的重载的话, 编译会报错, 这有助于捕获常见的错误. 这些标记起到了文档的作用, 因为如果省略这些关键字, 代码阅读者不得不检查所有父类, 以判断该函数是否是虚函数.</p><h3 id="多重继承"><a href="#多重继承" class="headerlink" title="多重继承"></a>多重继承</h3><p>只有当所有父类除第一个外都是纯接口类时, 才允许使用多重继承.。为确保它们是纯接口, 这些类必须以 <code>Interface</code> 为后缀.</p><h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p>当一个类满足以下要求时, 称之为纯接口:</p><ul><li>只有纯虚函数 (”<code>=0</code>”) 和静态函数 (除了下文提到的析构函数).</li><li>没有非静态数据成员.</li><li>没有定义任何构造函数. 如果有, 也不能带有参数, 并且必须为 <code>protected</code>.</li><li>如果它是一个子类, 也只能从满足上述条件并以 <code>Interface</code> 为后缀的类继承.</li></ul><p>接口类不能被直接实例化, 因为它声明了纯虚函数. 为确保接口类的所有实现可被正确销毁, 必须为之声明虚析构函数 (作为上述第 1 条规则的特例, 析构函数不能是纯虚函数)</p><p>以 <code>Interface</code> 为后缀可以提醒其他人不要为该接口类增加函数实现或非静态数据成员. 这一点对于多重继承尤其重要. 另外, 对于 Java 程序员来说, 接口的概念已是深入人心.</p><h3 id="重载"><a href="#重载" class="headerlink" title="重载"></a>重载</h3><p>为降低复杂性, 尽量不重载操作符, 模板, 标准类中使用时提供文档说明;</p><ul><li>要提供正确, 一致, 不出现异常行为的操作符运算需要花费不少精力, 而且如果达不到这些要求的话, 会导致令人迷惑的 Bug.</li><li>过度使用运算符会带来难以理解的代码, 尤其是在重载的操作符的语义与通常的约定不符合时.</li><li>函数重载有多少弊端, 运算符重载就至少有多少.</li><li>运算符重载会混淆视听, 让你误以为一些耗时的操作和操作内建类型一样轻巧.</li><li>对重载运算符的调用点的查找需要的可就不仅仅是像 grep 那样的程序了, 这时需要能够理解 C++ 语法的搜索工具.</li><li>如果重载运算符的参数写错, 此时得到的可能是一个完全不同的重载而非编译错误. 例如: <code>foo &lt; bar</code> 执行的是一个行为, 而 <code>&amp;foo &lt; &amp;bar</code> 执行的就是完全不同的另一个行为了.</li><li>重载某些运算符本身就是有害的. 例如, 重载一元运算符 <code>&amp;</code> 会导致同样的代码有完全不同的含义, 这取决于重载的声明对某段代码而言是否是可见的. 重载诸如 <code>&amp;&amp;</code>, <code>||</code> 和 <code>,</code> 会导致运算顺序和内建运算的顺序不一致.</li><li>运算符从通常定义在类的外部, 所以对于同一运算, 可能出现不同的文件引入了不同的定义的风险. 如果两种定义都链接到同一二进制文件, 就会导致未定义的行为, 有可能表现为难以发现的运行时错误.</li><li>用户定义字面量所创建的语义形式对于某些有经验的 C++ 程序员来说都是很陌生的.</li></ul><p>只有在意义明显, 不会出现奇怪的行为并且与对应的内建运算符的行为一致时才定义重载运算符. 例如, <code>|</code> 要作为位或或逻辑或来使用, 而不是作为 shell 中的管道.</p><p>只对自己定义的类型重载运算符，不要对他人的类型重载运算符。更准确地说, 将类型的重载运算符定义在同一个头文件, <code>.cc</code> 文件和命名空间中。 这样做无论类型在哪里都能够使用定义的运算符, 并且最大程度上避免了多重定义的风险。</p><p>如果可能的话, 请避免将运算符定义为模板, 因为此时它们必须对任何模板参数都能够作用。 如果你定义了一个运算符, 请将其相关且有意义的运算符都进行定义, 并且保证这些定义的语义是一致的。 例如, 如果你重载了 <code>&lt;</code>, 那么请将所有的比较运算符都进行重载, 并且保证对于同一组参数, <code>&lt;</code> 和 <code>&gt;</code> 不会同时返回 <code>true</code>.</p><p><strong>建议不要将不进行修改的二元运算符定义为成员函数</strong>。 如果一个二元运算符被定义为类成员, 这时隐式转换会作用域右侧的参数却不会作用于左侧. 这时会出现 <code>a &lt; b</code> 能够通过编译而 <code>b &lt; a</code> 不能的情况, 这是很让人迷惑的.</p><p>不要为了避免重载操作符而走极端. 比如说, 应当定义 <code>==</code>, <code>=</code>, 和 <code>&lt;&lt;</code> 而不是 <code>Equals()</code>, <code>CopyFrom()</code> 和 <code>PrintTo()</code>. 反过来说, 不要只是为了满足函数库需要而去定义运算符重载. 比如说, 如果你的类型没有自然顺序, 而你要将它们存入 <code>std::set</code> 中, 最好还是定义一个自定义的比较运算符而不是重载 <code>&lt;</code>.</p><p>不要重载 <code>&amp;&amp;</code>, <code>||</code>, <code>,</code> 或一元运算符 <code>&amp;</code>. 不要重载 <code>operator&quot;&quot;</code>, 也就是说, 不要引入用户定义字面量.</p><h3 id="成员变量"><a href="#成员变量" class="headerlink" title="成员变量"></a>成员变量</h3><p>将所有数据成员声明为 <code>private</code>, 除非是 <code>static const</code> 类型成员 </p><h3 id="声明顺序"><a href="#声明顺序" class="headerlink" title="声明顺序"></a>声明顺序</h3><p>类定义一般应以 <code>public:</code> 开始, 后跟 <code>protected:</code>, 最后是 <code>private:</code>。省略空部分.</p><p>在各个部分中, 建议将类似的声明放在一起, 并且建议以如下的顺序: 类型 (包括 <code>typedef</code>, <code>using</code> 和嵌套的结构体与类), 常量, 工厂函数, 构造函数, 赋值运算符, 析构函数, 其它函数, 数据成员。</p><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="输入和输出"><a href="#输入和输出" class="headerlink" title="输入和输出"></a>输入和输出</h3><p>我们倾向于按值返回， 否则按引用返回。 避免返回指针， 除非它可以为空。</p><p>输入参数指不会改变原实参的参数，如按值传递或按const 引用&#x2F;指针传递。输出参数则是指原实参有可能改变的参数，如引用和指针。</p><p>可选参数指存在默认值的参数，如缺省参数，此时可以选择不传参。</p><p><strong>一般规定</strong>非可选输入参数是值参或 <code>const</code> 引用&#x2F;指针, 非可选输出参数为非const指针。<code>std::optional</code> 来表示可选的按值输入，指针表示可选的输入&#x2F;输出参数</p><p><strong>函数参数排序</strong>时， 将所有输入参数放在所有输出参数之前.</p><h3 id="编写简短函数"><a href="#编写简短函数" class="headerlink" title="编写简短函数"></a>编写简短函数</h3><p>我们倾向于编写简短, 凝练的函数，如果函数超过 40 行, 可以思索一下能不能在不影响程序结构的前提下对其进行分割.</p><h3 id="引用参数"><a href="#引用参数" class="headerlink" title="引用参数"></a>引用参数</h3><p>函数形参表中，所有的引用必须加const。这么做是为了防止引用引起的误解，因为引用在语法上是值，却有指针的意义。</p><p>如果要修改实参使用指针</p><h3 id="函数重载"><a href="#函数重载" class="headerlink" title="函数重载"></a>函数重载</h3><p>若要使用函数重载, 则必须能让读者一看调用点就胸有成竹, 而不用花心思猜测调用的重载函数到底是哪一种. 这一规则也适用于构造函数.</p><p>如果打算重载一个函数, 可以试试改在函数名里加上参数信息. 例如, 用 <code>AppendString()</code> 和 <code>AppendInt()</code> 等, 而不是一口气重载多个 <code>Append()</code>. 如果重载函数的目的是为了支持不同数量的同一类型参数, 则优先考虑使用 <code>std::vector</code> 以便使用者可以用列表初始化指定参数.</p><h3 id="缺省参数"><a href="#缺省参数" class="headerlink" title="缺省参数"></a>缺省参数</h3><p>对于虚函数, 不允许使用缺省参数, 因为在虚函数中缺省参数不一定能正常工作(虚函数运行时确定，缺省编译时确定。虚函数使用缺省最终调用的是一个定义在派生类，但使用了基类中的缺省参数值的虚函数)。</p><p>如果在每个调用点缺省参数的值都有可能不同, 在这种情况下缺省函数也不允许使用。 (例如, 不要写像 <code>void f(int n = counter++);</code> 这样的代码.)</p><p>缺省参数实际上是函数重载语义的另一种实现方式, 因此所有不应当使用函数重载的理由也都适用于缺省参数.</p><p>尽可能改用函数重载，除了少数情况不允许使用缺省函数参数。</p><p><strong>可以使用缺省参数的情况</strong></p><p>其一，位于 <code>.cc</code> 文件里的静态函数或匿名空间函数，毕竟都只能在局部文件里调用该函数了。</p><p>其二，可以在构造函数里用缺省参数，毕竟不可能取得它们的地址。</p><p>其三，可以用来模拟变长数组。</p><blockquote><pre><code class="cpp">// 通过空 AlphaNum 以支持四个形参string StrCat(const AlphaNum &amp;a,              const AlphaNum &amp;b = gEmptyAlphaNum,              const AlphaNum &amp;c = gEmptyAlphaNum,              const AlphaNum &amp;d = gEmptyAlphaNum);</code></pre></blockquote><p><strong>缺点</strong></p><p><strong>缺省参数会干扰函数指针</strong>，害得后者的函数签名（function signature）往往对不上所实际要调用的函数签名。即在一个现有函数添加缺省参数，就会改变它的类型，那么调用其地址的代码可能会出错，不过函数重载就没这问题了。此外，缺省参数会造成臃肿的代码，毕竟它们在每一个调用点（call site）都有重复</p><h3 id="函数返回类型后置语法"><a href="#函数返回类型后置语法" class="headerlink" title="函数返回类型后置语法"></a>函数返回类型后置语法</h3><p>C++11 引入了函数返回类型后置语法。 现在可以在函数名前使用 <code>auto</code> 关键字, 在参数列表之后后置返回类型. 例如:</p><pre><code>auto foo(int x) -&gt; int;</code></pre><p>后置返回类型是显式地指定Lambda 表达式的返回值的唯一方式</p><p>后置返回类型相对来说是非常新的语法, 而且在 C 和 Java 中都没有相似的写法, 因此可能对读者来说比较陌生.</p><p>只有在常规写法 (返回类型前置) 不便于书写或不便于阅读时使用返回类型后置语法.</p><h2 id="智能指针"><a href="#智能指针" class="headerlink" title="智能指针"></a>智能指针</h2><p>如果必须使用动态分配, 那么更倾向于将所有权保持在分配者手中. 如果其他地方要使用这个对象, 最好传递它的拷贝或者用<code>std::unique_ptr</code> </p><p>如果没有很好的理由, 则不要使用共享所有权。只有当性能提升非常明显, 并且操作的对象是不可变的（比如说 <code>std::shared_ptr&lt;const Foo&gt;</code> ）时候, 才能这么做。</p><h2 id="代码风格检查"><a href="#代码风格检查" class="headerlink" title="代码风格检查"></a>代码风格检查</h2><p>使用 <code>cpplint.py</code> 检查风格错误.</p><h2 id="其他c-特性"><a href="#其他c-特性" class="headerlink" title="其他c++特性"></a>其他c++特性</h2><h3 id="右值引用"><a href="#右值引用" class="headerlink" title="右值引用"></a>右值引用</h3><p>只在定义移动构造函数与移动赋值操作时使用右值引用, 不要使用 <code>std::forward</code> 功能函数. 你可能会使用 <code>std::move</code> 来表示将值从一个对象移动而不是复制到另一个对象.</p><p>右值引用是一个相对比较新的特性 (由 C++11 引入), 它尚未被广泛理解. 类似引用崩溃, 移动构造函数的自动推导这样的规则都是很复杂的.</p><h3 id="变长数组"><a href="#变长数组" class="headerlink" title="变长数组"></a>变长数组</h3><p>不允许使用变长数组和 <code>alloca()</code>。改用更安全的分配器（allocator），就像 <code>std::vector</code> 或 <code>std::unique_ptr&lt;T[]&gt;</code>。</p><p>变长数组和 <code>alloca()</code> 不是标准 C++ 的组成部分. 更重要的是, 它们根据数据大小动态分配堆栈内存, 会引起难以发现的内存越界 bugs: “在我的机器上运行的好好的, 发布后却莫名其妙的挂掉了”.</p><h3 id="友元"><a href="#友元" class="headerlink" title="友元"></a>友元</h3><p>我们允许合理的使用友元类及友元函数.</p><p>通常友元应该定义在同一文件内, 避免代码读者跑到其它文件查找使用该私有成员的类. 经常用到友元的一个地方是将 <code>FooBuilder</code> 声明为 <code>Foo</code> 的友元, 以便 <code>FooBuilder</code> 正确构造 <code>Foo</code> 的内部状态, 而无需将该状态暴露出来. 某些情况下, 将一个单元测试类声明成待测类的友元会很方便.</p><p>友元扩大了 (但没有打破) 类的封装边界. 某些情况下, 相对于将类成员声明为 <code>public</code>, 使用友元是更好的选择, 尤其是如果你只允许另一个类访问该类的私有成员时. 当然, 大多数类都只应该通过其提供的公有成员进行互操作.</p><h3 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h3><p>不使用 C++ 异常.</p><p>缺点:</p><blockquote><ul><li>在现有函数中添加 <code>throw</code> 语句时，您必须检查所有调用点。要么让所有调用点统统具备最低限度的异常安全保证，要么眼睁睁地看异常一路欢快地往上跑，最终中断掉整个程序。举例，<code>f()</code> 调用 <code>g()</code>, <code>g()</code> 又调用 <code>h()</code>, 且 <code>h</code> 抛出的异常被 <code>f</code> 捕获。当心 <code>g</code>, 否则会没妥善清理好。</li><li>还有更常见的，异常会彻底扰乱程序的执行流程并难以判断，函数也许会在您意料不到的地方返回。您或许会加一大堆何时何处处理异常的规定来降低风险，然而开发者的记忆负担更重了。</li><li>异常安全需要RAII和不同的编码实践. 要轻松编写出正确的异常安全代码需要大量的支持机制. 更进一步地说, 为了避免读者理解整个调用表, 异常安全必须隔绝从持续状态写到 “提交” 状态的逻辑. 这一点有利有弊 (因为你也许不得不为了隔离提交而混淆代码). 如果允许使用异常, 我们就不得不时刻关注这样的弊端, 即使有时它们并不值得.</li><li>启用异常会增加二进制文件数据，延长编译时间（或许影响小），还可能加大地址空间的压力。</li><li>滥用异常会变相鼓励开发者去捕捉不合时宜，或本来就已经没法恢复的「伪异常」。比如，用户的输入不符合格式要求时，也用不着抛异常。如此之类的伪异常列都列不完。</li></ul></blockquote><h3 id="运行时类型识别"><a href="#运行时类型识别" class="headerlink" title="运行时类型识别"></a>运行时类型识别</h3><p>在单元测试中可以使用 RTTI, 但是在其他代码中请尽量避免</p><p>RTTI 允许程序员在运行时识别 C++ 类对象的类型. 它通过使用 <code>typeid</code> 或者 <code>dynamic_cast</code> 完成.</p><p>缺点:</p><blockquote><p>在运行时判断类型通常意味着设计问题. 如果你需要在运行期间确定一个对象的类型, 这通常说明你需要考虑重新设计你的类.</p><p>随意地使用 RTTI 会使你的代码难以维护. 它使得基于类型的判断树或者 switch 语句散布在代码各处. 如果以后要进行修改, 你就必须检查它们.</p></blockquote><p>如果你的代码需要根据不同的对象类型执行不同的行为的话, 请考虑用以下的两种替代方案之一</p><p>查询类型:虚函数可以根据子类类型的不同而执行不同代码. 这是把工作交给了对象本身去处理.</p><p>如果这一工作需要在对象之外完成, 可以考虑使用双重分发的方案, 例如使用访问者设计模式. 这就能够在对象之外进行类型判断.</p><p>如果程序能够保证给定的基类实例实际上都是某个派生类的实例, 那么就可以自由使用 dynamic_cast. 在这种情况下, 使用 dynamic_cast 也是一种替代方案.</p><h3 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h3><p>使用 C++ 的类型转换, 如 <code>static_cast&lt;&gt;()</code>. 不要使用 <code>int y = (int)x</code> 或 <code>int y = int(x)</code> 等转换方式;</p><p>C 语言的类型转换问题在于模棱两可的操作; 有时是在做强制转换 (如 <code>(int)3.5</code>), 有时是在做类型转换 (如 <code>(int)&quot;hello&quot;</code>). 另外, C++ 的类型转换在查找时更醒目.</p><h3 id="流"><a href="#流" class="headerlink" title="流"></a>流</h3><p>只在记录日志时使用流。采用 <code>printf + read/write</code>代替。</p><p>流使得 <code>pread()</code> 等功能函数很难执行. 如果不使用 <code>printf</code> 风格的格式化字符串, 某些格式化操作 (尤其是常用的格式字符串 <code>%.*s</code>) 用流处理性能是很低的. 流不支持字符串操作符重新排序 (%1s), 而这一点对于软件国际化很有用.</p><h3 id="前置自增-x2F-自减"><a href="#前置自增-x2F-自减" class="headerlink" title="前置自增&#x2F;自减"></a>前置自增&#x2F;自减</h3><p>对简单数值 (非对象), 前置&#x2F;后置都无所谓。对迭代器和模板类型, 使用前置自增 (自减)。</p><p>不考虑返回值的话, 前置自增 (<code>++i</code>) 通常要比后置自增 (<code>i++</code>) 效率更高. 因为后置自增 (或自减) 需要对表达式的值 <code>i</code> 进行一次拷贝. 如果 <code>i</code> 是迭代器或其他非数值类型, 拷贝的代价是比较大的. 既然两种自增方式实现的功能一样, 为什么不总是使用前置自增呢?</p><h3 id="const"><a href="#const" class="headerlink" title="const"></a>const</h3><p>在任何可能的情况下都要使用 <code>const</code>. 此外有时改用 C++11 推出的 constexpr 更好。</p><p><code>const</code> 变量, 数据成员, 函数和参数为编译时类型检测增加了一层保障; 便于尽早发现错误. 因此, 我们强烈建议在任何可能的情况下使用 <code>const</code></p><h3 id="constexpr"><a href="#constexpr" class="headerlink" title="constexpr"></a>constexpr</h3><p>在 C++11 里，用 constexpr 来定义真正的常量，或实现常量初始化。</p><p>靠 constexpr 特性，方才实现了 C++ 在接口上打造真正常量机制的可能。好好用 constexpr 来定义真・常量以及支持常量的函数。避免复杂的函数定义，以使其能够与constexpr一起使用。 千万别痴心妄想地想靠 constexpr 来强制代码「内联」</p><h3 id="整型"><a href="#整型" class="headerlink" title="整型"></a>整型</h3><p>C++ 中整型大小因编译器和体系结构的不同而不同.</p><p><code>&lt;stdint.h&gt;</code> 定义了 <code>int16_t</code>, <code>uint32_t</code>, <code>int64_t</code> 等整型, 在需要确保整型大小时可以使用它们代替 <code>short</code>, <code>unsigned long long</code> 等. 在 C 整型中, 只使用 <code>int</code>. 在合适的情况下, 推荐使用标准类型如 <code>size_t</code> 和 <code>ptrdiff_t</code>.</p><p>不要使用 <code>uint32_t</code> 等无符号整型, 除非你是在表示一个位组而不是一个数值, 或是你需要定义二进制补码溢出。 尤其是不要为了指出数值永不会为负, 而使用无符号类型. 相反, 你应该使用断言来保护数据.</p><h3 id="64位下的可移植性"><a href="#64位下的可移植性" class="headerlink" title="64位下的可移植性"></a>64位下的可移植性</h3><p>代码应该对 64 位和 32 位系统友好。 处理打印, 比较, 结构体对齐时应切记。</p><ul><li><p>对于某些类型, <code>printf()</code> 的指示符在 32 位和 64 位系统上可移植性不是很好. C99 标准定义了一些可移植的格式化指示符. 不幸的是, MSVC 7.1 并非全部支持, 而且标准中也有所遗漏, 所以有时我们不得不自己定义一个丑陋的版本 (头文件 <code>inttypes.h</code> 仿标准风格):</p></li><li><p>记住 <code>sizeof(void *) != sizeof(int)</code>. 如果需要一个指针大小的整数要用 <code>intptr_t</code>.</p></li><li><p>你要非常小心的对待结构体对齐, 尤其是要持久化到磁盘上的结构体 (持久化 - 将数据按字节流顺序保存在磁盘文件或数据库中). 在 64 位系统中, 任何含有 <code>int64_t</code>&#x2F;<code>uint64_t</code> 成员的类&#x2F;结构体, 缺省都以 8 字节在结尾对齐. 如果 32 位和 64 位代码要共用持久化的结构体, 需要确保两种体系结构下的结构体对齐一致. 大多数编译器都允许调整结构体对齐. gcc 中可使用 <code>__attribute__((packed))</code>. MSVC 则提供了 <code>#pragma pack()</code> 和 <code>__declspec(align())</code></p></li><li><p>创建 64 位常量时使用 LL 或 ULL 作为后缀, 如:</p><blockquote><pre><code class="c++">int64_t my_value = 0x123456789LL;uint64_t my_mask = 3ULL &lt;&lt; 48;</code></pre></blockquote></li><li><p>如果你确实需要 32 位和 64 位系统具有不同代码, 可以使用 <code>#ifdef _LP64</code> 指令来切分 32&#x2F;64 位代码. (尽量不要这么做, 如果非用不可, 尽量使修改局部化)</p></li></ul><h3 id="宏"><a href="#宏" class="headerlink" title="宏"></a>宏</h3><p>使用宏时要非常谨慎, 尽量以内联函数, 枚举和常量代替之.</p><p>宏意味着你和编译器看到的代码是不同的. 这可能会导致异常行为, 尤其因为宏具有全局作用域.</p><p>C++ 中, 宏不像在 C 中那么必不可少. 以往用宏展开性能关键的代码, 现在可以用内联函数替代. 用宏表示常量可被 <code>const</code> 变量代替. 用宏 “缩写” 长变量名可被引用代替. 用宏进行条件编译… 这个, 千万别这么做, 会令测试更加痛苦 (<code>#define</code> 防止头文件重包含当然是个特例).</p><p>下面给出的用法模式可以避免使用宏带来的问题; 如果你要宏, 尽可能遵守:</p><blockquote><ul><li>不要在 <code>.h</code> 文件中定义宏.</li><li>在马上要使用时才进行 <code>#define</code>, 使用后要立即 <code>#undef</code>.</li><li>不要只是对已经存在的宏使用#undef，选择一个不会冲突的名称；</li><li>不要试图使用展开后会导致 C++ 构造不稳定的宏, 不然也至少要附上文档说明其行为.</li><li>不要用 <code>##</code> 处理函数，类和变量的名字。</li></ul></blockquote><h3 id="nullptr"><a href="#nullptr" class="headerlink" title="nullptr"></a>nullptr</h3><p>整数用 <code>0</code>, 实数用 <code>0.0</code>, 指针用 <code>nullptr</code>,字符 (串) 用 <code>&#39;\0&#39;</code>.</p><h3 id="sizeof"><a href="#sizeof" class="headerlink" title="sizeof"></a>sizeof</h3><p>尽可能用 <code>sizeof(varname)</code> 代替 <code>sizeof(type)</code>.</p><p>使用 <code>sizeof(varname)</code> 是因为当代码中变量类型改变时会自动更新. 您或许会用 <code>sizeof(type)</code> 处理不涉及任何变量的代码，比如处理来自外部或内部的数据格式，这时用变量就不合适了。</p><h3 id="auto"><a href="#auto" class="headerlink" title="auto"></a>auto</h3><p><code>auto</code> 只能用在局部变量里用。别用在文件作用域变量，命名空间作用域变量和类数据成员里。永远别列表初始化 <code>auto</code> 变量。</p><h3 id="列表初始化"><a href="#列表初始化" class="headerlink" title="列表初始化"></a>列表初始化</h3><p>可以用列表初始化。</p><p>C++11 中，任何对象类型都可以被列表初始化。示范如下：</p><pre><code class="cpp">// Vector 接收了一个初始化列表。vector&lt;string&gt; v&#123;&quot;foo&quot;, &quot;bar&quot;&#125;;// 不考虑细节上的微妙差别，大致上相同。// 您可以任选其一。vector&lt;string&gt; v = &#123;&quot;foo&quot;, &quot;bar&quot;&#125;;// 可以配合 new 一起用。auto p = new vector&lt;string&gt;&#123;&quot;foo&quot;, &quot;bar&quot;&#125;;// map 接收了一些 pair, 列表初始化大显神威。map&lt;int, string&gt; m = &#123;&#123;1, "one"&#125;, &#123;2, "2"&#125;&#125;;// 初始化列表也可以用在返回类型上的隐式转换。vector&lt;int&gt; test_function() &#123; return &#123;1, 2, 3&#125;; &#125;// 初始化列表可迭代。for (int i : &#123;-1, -2, -3&#125;) &#123;&#125;// 在函数调用里用列表初始化。void TestFunction2(vector&lt;int&gt; v) &#123;&#125;TestFunction2(&#123;1, 2, 3&#125;);</code></pre><p>用户自定义类型也可以定义接收 <code>std::initializer_list&lt;T&gt;</code> 的构造函数和赋值运算符，以自动列表初始化：</p><pre><code class="cpp">class MyType &#123; public:  // std::initializer_list 专门接收 init 列表。  // 得以值传递。  MyType(std::initializer_list&lt;int&gt; init_list) &#123;    for (int i : init_list) append(i);  &#125;  MyType&amp; operator=(std::initializer_list&lt;int&gt; init_list) &#123;    clear();    for (int i : init_list) append(i);  &#125;&#125;;MyType m&#123;2, 3, 5, 7&#125;;</code></pre><p>最后，列表初始化也适用于常规数据类型的构造，哪怕没有接收 <code>std::initializer_list&lt;T&gt;</code> 的构造函数。</p><pre><code class="cpp">double d&#123;1.23&#125;;// MyOtherType 没有 std::initializer_list 构造函数， // 直接上接收常规类型的构造函数。class MyOtherType &#123; public:  explicit MyOtherType(string);  MyOtherType(int, string);&#125;;MyOtherType m = &#123;1, &quot;b&quot;&#125;;// 不过如果构造函数是显式的（explict），您就不能用 `= &#123;&#125;` 了。MyOtherType m&#123;&quot;b&quot;&#125;;</code></pre><p>千万别直接列表初始化 auto 变量，看下一句，估计没人看得懂：</p><pre><code class="cpp">auto d = &#123;1.23&#125;;        // d 即是 std::initializer_list&lt;double&gt;</code></pre><h3 id="lambda"><a href="#lambda" class="headerlink" title="lambda"></a>lambda</h3><p>适当使用 lambda 表达式。别用默认 lambda 捕获，所有捕获都要显式写出来。</p><blockquote><ul><li>禁用默认捕获，捕获都要显式写出来。打比方，比起 <code>[=](int x) &#123;return x + n;&#125;</code>, 您该写成 <code>[n](int x) &#123;return x + n;&#125;</code> 才对，这样读者也好一眼看出 <code>n</code> 是被捕获的值。</li><li>匿名函数始终要简短，如果函数体超过了五行，那么还不如起名（即把 lambda 表达式赋值给对象），或改用函数。</li><li>如果可读性更好，就显式写出 lambda 的尾置返回类型，就像auto.</li></ul></blockquote><h3 id="模板编程"><a href="#模板编程" class="headerlink" title="模板编程"></a>模板编程</h3><p>不要使用复杂的模板编程</p><p>模板编程有时候能够实现更简洁更易用的接口, 但是更多的时候却适得其反. 因此模板编程最好只用在少量的基础组件, 基础数据结构上, 因为模板带来的额外的维护成本会被大量的使用给分担掉</p><p>在使用模板编程或者其他复杂的模板技巧的时候, 你一定要再三考虑一下. 考虑一下你们团队成员的平均水平是否能够读懂并且能够维护你写的模板代码.或者一个非c++ 程序员和一些只是在出错的时候偶尔看一下代码的人能够读懂这些错误信息或者能够跟踪函数的调用流程. 如果你使用递归的模板实例化, 或者类型列表, 或者元函数, 又或者表达式模板, 或者依赖SFINAE, 或者sizeof 的trick 手段来检查函数是否重载, 那么这说明你模板用的太多了, 这些模板太复杂了, 我们不推荐使用</p><p>如果你使用模板编程, 你必须考虑尽可能的把复杂度最小化, 并且尽量不要让模板对外暴露. 你最好只在实现里面使用模板, 然后给用户暴露的接口里面并不使用模板, 这样能提高你的接口的可读性. 并且你应该在这些使用模板的代码上写尽可能详细的注释. 你的注释里面应该详细的包含这些代码是怎么用的, 这些模板生成出来的代码大概是什么样子的. 还需要额外注意在用户错误使用你的模板代码的时候需要输出更人性化的出错信息. 因为这些出错信息也是你的接口的一部分, 所以你的代码必须调整到这些错误信息在用户看起来应该是非常容易理解, 并且用户很容易知道如何修改这些错误</p><h2 id="命名"><a href="#命名" class="headerlink" title="命名"></a>命名</h2><h3 id="通用命名规则"><a href="#通用命名规则" class="headerlink" title="通用命名规则"></a>通用命名规则</h3><p>函数命名, 变量命名, 文件命名要有描述性; 少用缩写.</p><p>尽可能使用描述性的命名, 别心疼空间, 毕竟相比之下让代码易于新读者理解更重要. 不要用只有项目开发者能理解的缩写, 也不要通过砍掉几个字母来缩写单词.</p><h3 id="文件名命名"><a href="#文件名命名" class="headerlink" title="文件名命名"></a>文件名命名</h3><p>文件名要全部小写, 可以包含下划线 (<code>_</code>)</p><p>不要使用已经存在于 <code>/usr/include</code> 下的文件名 (即编译器搜索系统头文件的路径), 如 <code>db.h</code>.</p><p>通常应尽量让文件名更加明确. <code>http_server_logs.h</code> 就比 <code>logs.h</code> 要好. 定义类时文件名一般成对出现, 如 <code>foo_bar.h</code> 和 <code>foo_bar.cc</code>, 对应于类 <code>FooBar</code>.</p><h3 id="类命名"><a href="#类命名" class="headerlink" title="类命名"></a>类命名</h3><p>所有类型命名 —— 类, 结构体, 类型定义 (<code>typedef</code>), 枚举, 类型模板参数 —— 均使用相同约定, 即以大写字母开始, 每个单词首字母均大写, 不包含下划线. 例如:</p><pre><code class="cpp">// 类和结构体class UrlTable &#123; ...class UrlTableTester &#123; ...struct UrlTableProperties &#123; ...// 类型定义typedef hash_map&lt;UrlTableProperties *, string&gt; PropertiesMap;// using 别名using PropertiesMap = hash_map&lt;UrlTableProperties *, string&gt;;// 枚举enum UrlTableErrors &#123; ...</code></pre><h3 id="变量命名"><a href="#变量命名" class="headerlink" title="变量命名"></a>变量命名</h3><p>变量 (包括函数参数) 和数据成员名一律小写, 单词之间用下划线连接. 类的成员变量以下划线结尾, 但结构体的就不用, 如: <code>a_local_variable</code>, <code>a_struct_data_member</code>, <code>a_class_data_member_</code>.</p><p><strong>普通变量命名</strong></p><p>举例:</p><pre><code class="cpp">string table_name;  // 好 - 用下划线.string tablename;   // 好 - 全小写.string tableName;  // 差 - 混合大小写</code></pre><p><strong>类数据成员</strong></p><p>不管是静态的还是非静态的, 类数据成员都可以和普通变量一样, 但要接下划线.</p><pre><code class="cpp">class TableInfo &#123;  ... private:  string table_name_;  // 好 - 后加下划线.  string tablename_;   // 好.  static Pool&lt;TableInfo&gt;* pool_;  // 好.&#125;;</code></pre><p><strong>结构体变量</strong></p><p>不管是静态的还是非静态的, 结构体数据成员都可以和普通变量一样, 不用像类那样接下划线:</p><pre><code class="cpp">struct UrlTableProperties &#123;  string name;  int num_entries;  static Pool&lt;UrlTableProperties&gt;* pool;&#125;;</code></pre><h3 id="常量命名"><a href="#常量命名" class="headerlink" title="常量命名"></a>常量命名</h3><p>声明为 <code>constexpr</code> 或 <code>const</code> 的变量, 或在程序运行期间其值始终保持不变的, 命名时以 “k” 开头, 大小写混合. 例如:</p><pre><code class="cpp">const int kDaysInAWeek = 7;</code></pre><h3 id="函数命名"><a href="#函数命名" class="headerlink" title="函数命名"></a>函数命名</h3><p>一般来说, 函数名的每个单词首字母大写 (即 “驼峰变量名” 或 “帕斯卡变量名”), 没有下划线. 对于首字母缩写的单词, 更倾向于将它们视作一个单词进行首字母大写 (例如, 写作 <code>StartRpc()</code> 而非 <code>StartRPC()</code>).</p><pre><code class="c++">AddTableEntry()DeleteUrl()OpenFileOrDie()</code></pre><p>(同样的命名规则同时适用于类作用域与命名空间作用域的常量, 因为它们是作为 API 的一部分暴露对外的, 因此应当让它们看起来像是一个函数, 因为在这时, 它们实际上是一个对象而非函数的这一事实对外不过是一个无关紧要的实现细节.)</p><p>取值和设值函数的命名与变量一致. 一般来说它们的名称与实际的成员变量对应, 但并不强制要求. 例如 <code>int count()</code> 与 <code>void set_count(int count)</code>.</p><h3 id="命名空间命名"><a href="#命名空间命名" class="headerlink" title="命名空间命名"></a>命名空间命名</h3><p>命名空间以小写字母命名. 最高级命名空间的名字取决于项目名称. 要注意避免嵌套命名空间的名字之间和常见的顶级命名空间的名字之间发生冲突.</p><p>顶级命名空间的名称应当是项目名或者是该命名空间中的代码所属的团队的名字. 命名空间中的代码, 应当存放于和命名空间的名字匹配的文件夹或其子文件夹中.</p><p>注意不使用缩写作为名称的规则同样适用于命名空间. 命名空间中的代码极少需要涉及命名空间的名称, 因此没有必要在命名空间中使用缩写.</p><p>要避免嵌套的命名空间与常见的顶级命名空间发生名称冲突. 由于名称查找规则的存在, 命名空间之间的冲突完全有可能导致编译失败. 尤其是, 不要创建嵌套的 <code>std</code> 命名空间. 建议使用更独特的项目标识符 (<code>websearch::index</code>, <code>websearch::index_util</code>) 而非常见的极易发生冲突的名称 (比如 <code>websearch::util</code>).</p><p>对于 <code>internal</code> 命名空间, 要当心加入到同一 <code>internal</code> 命名空间的代码之间发生冲突 (由于内部维护人员通常来自同一团队, 因此常有可能导致冲突). 在这种情况下, 请使用文件名以使得内部名称独一无二 (例如对于 <code>frobber.h</code>, 使用 <code>websearch::index::frobber_internal</code>).</p><h3 id="枚举命名"><a href="#枚举命名" class="headerlink" title="枚举命名"></a>枚举命名</h3><p>枚举的命名应当和常量一致: <code>kEnumName</code> </p><p>单独的枚举值应该优先采用常量的命名方式. 枚举名 <code>UrlTableErrors</code>是类型, 所以要用大小写混合的方式.</p><pre><code class="cpp">enum UrlTableErrors &#123;    kOK = 0,    kErrorOutOfMemory,    kErrorMalformedInput,&#125;;</code></pre><h3 id="宏命名"><a href="#宏命名" class="headerlink" title="宏命名"></a>宏命名</h3><p>全部大写，以下划线分隔</p><p> <code>MY_MACRO_THAT_SCARES_SMALL_CHILDREN</code>.</p><h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><h3 id="注释风格"><a href="#注释风格" class="headerlink" title="注释风格"></a>注释风格</h3><p><code>//</code> 或 <code>/* */</code> 都可以; 但 <code>//</code> <em>更</em> 常用. 要在如何注释及注释风格上确保统一.</p><h3 id="文件注释"><a href="#文件注释" class="headerlink" title="文件注释"></a>文件注释</h3><p>在每一个文件开头加入版权公告.</p><p>文件注释描述了该文件的内容. 如果一个文件只声明, 或实现, 或测试了一个对象, 并且这个对象已经在它的声明处进行了详细的注释, 那么就没必要再加上文件注释. 除此之外的其他文件都需要文件注释.</p><p><strong>法律公告和作者信息</strong></p><p>每个文件都应该包含许可证引用. 为项目选择合适的许可证版本.(比如, Apache 2.0, BSD, LGPL, GPL)</p><p>如果你对原始作者的文件做了重大修改, 请考虑删除原作者信息.</p><p><strong>文件内容</strong></p><p>如果一个 <code>.h</code> 文件声明了多个概念, 则文件注释应当对文件的内容做一个大致的说明, 同时说明各概念之间的联系. 一个一到两行的文件注释就足够了, 对于每个概念的详细文档应当放在各个概念中, 而不是文件注释中.</p><p>不要在 <code>.h</code> 和 <code>.cc</code> 之间复制注释, 这样的注释偏离了注释的实际意义.</p><h3 id="类注释"><a href="#类注释" class="headerlink" title="类注释"></a>类注释</h3><p>每个类的定义都要附带一份注释, 描述类的功能和用法, 除非它的功能相当明显.</p><p>类注释应当为读者理解如何使用与何时使用类提供足够的信息, 同时应当提醒读者在正确使用此类时应当考虑的因素. 如果类有任何同步前提, 请用文档说明. 如果该类的实例可被多线程访问, 要特别注意文档说明多线程环境下相关的规则和常量使用.</p><p>如果你想用一小段代码演示这个类的基本用法或通常用法, 放在类注释里也非常合适.</p><p>如果类的声明和定义分开了(例如分别放在了 <code>.h</code> 和 <code>.cc</code> 文件中), 此时, 描述类用法的注释应当和接口定义放在一起, 描述类的操作和实现的注释应当和实现放在一起.</p><h3 id="函数注释"><a href="#函数注释" class="headerlink" title="函数注释"></a>函数注释</h3><p>函数声明处的注释描述函数功能; 定义处的注释描述函数实现.</p><p><strong>函数声明处注释的内容:</strong></p><ul><li>函数的输入输出.</li><li>对类成员函数而言: 函数调用期间对象是否需要保持引用参数, 是否会释放这些参数.</li><li>函数是否分配了必须由调用者释放的空间.</li><li>参数是否可以为空指针.</li><li>是否存在函数使用上的性能隐患.</li><li>如果函数是可重入的, 其同步前提是什么?</li></ul><p>注释函数重载时, 注释的重点应该是函数中被重载的部分, 而不是简单的重复被重载的函数的注释. 多数情况下, 函数重载不需要额外的文档, 因此也没有必要加上注释.</p><p>注释构造&#x2F;析构函数时, 切记读代码的人知道构造&#x2F;析构函数的功能, 所以 “销毁这一对象” 这样的注释是没有意义的. 你应当注明的是注明构造函数对参数做了什么 (例如, 是否取得指针所有权) 以及析构函数清理了什么. 如果都是些无关紧要的内容, 直接省掉注释. 析构函数前没有注释是很正常的.</p><p><strong>函数定义处注释的内容:</strong><br>如果函数的实现过程中用到了很巧妙的方式, 那么在函数定义处应当加上解释性的注释. 例如, 你所使用的编程技巧, 实现的大致步骤, 或解释如此实现的理由. 举个例子, 你可以说明为什么函数的前半部分要加锁而后半部分不需要.</p><p><em>不要</em> 从 <code>.h</code> 文件或其他地方的函数声明处直接复制注释. 简要重述函数功能是可以的, 但注释重点要放在如何实现上.</p><h3 id="变量注释"><a href="#变量注释" class="headerlink" title="变量注释"></a>变量注释</h3><p>通常变量名本身足以很好说明变量用途. 某些情况下, 也需要额外的注释说明.</p><p><strong>成员变量</strong></p><p>每个类数据成员 (也叫实例变量或成员变量) 都应该用注释说明用途. 如果有非变量的参数(例如特殊值, 数据成员之间的关系, 生命周期等)不能够用类型与变量名明确表达, 则应当加上注释. 然而, 如果变量类型与变量名已经足以描述一个变量, 那么就不再需要加上注释.</p><p>特别地, 如果变量可以接受 <code>NULL</code> 或 <code>-1</code> 等警戒值, 须加以说明. </p><p><strong>全局变量</strong></p><p>所有全局变量也要注释说明含义及用途, 以及作为全局变量的原因. </p><h3 id="实现注释"><a href="#实现注释" class="headerlink" title="实现注释"></a>实现注释</h3><p>对于代码中巧妙的, 晦涩的, 有趣的, 重要的地方加以注释.</p><p><strong>代码前注释</strong></p><p>巧妙或复杂的代码段前要加注释. 比如:</p><p><strong>行注释</strong></p><p>比较隐晦的地方要在行尾加入注释. 在行尾空两格进行注释. 比如:</p><p><strong>函数参数注释</strong></p><p>如果函数参数的意义不明显, 考虑用下面的方式进行弥补:</p><ul><li>如果参数是一个字面常量, 并且这一常量在多处函数调用中被使用, 用以推断它们一致, 你应当用一个常量名让这一约定变得更明显, 并且保证这一约定不会被打破.</li><li>考虑更改函数的签名, 让某个 <code>bool</code> 类型的参数变为 <code>enum</code> 类型, 这样可以让这个参数的值表达其意义.</li><li>如果某个函数有多个配置选项, 你可以考虑定义一个类或结构体以保存所有的选项, 并传入类或结构体的实例. 这样的方法有许多优点, 例如这样的选项可以在调用处用变量名引用, 这样就能清晰地表明其意义. 同时也减少了函数参数的数量, 使得函数调用更易读也易写. 除此之外, 以这样的方式, 如果你使用其他的选项, 就无需对调用点进行更改.</li><li>用具名变量代替大段而复杂的嵌套表达式.</li><li>万不得已时, 才考虑在调用点用注释阐明参数的意义.</li></ul><p>比如下面的示例的对比:</p><pre><code class="c++">// What are these arguments?const DecimalNumber product = CalculateProduct(values, 7, false, nullptr);</code></pre><p>和</p><pre><code class="c++">ProductOptions options;options.set_precision_decimals(7);options.set_use_cache(ProductOptions::kDontUseCache);const DecimalNumber product =    CalculateProduct(values, options, /*completion_callback=*/nullptr);</code></pre><h3 id="不允许的注释"><a href="#不允许的注释" class="headerlink" title="不允许的注释"></a>不允许的注释</h3><p>不要描述显而易见的现象, 永远不要用自然语言翻译代码作为注释, 除非代码的行为对深入理解 C++ 的读者来说都是不明显的. 要假设读代码的人 C++ 水平比你高</p><p>你所提供的注释应当解释代码 <em>为什么</em> 要这么做和代码的目的, 或者最好是让代码自文档化.</p><p>比较这样的注释:</p><pre><code class="c++">// Find the element in the vector.  &lt;-- 差: 这太明显了!auto iter = std::find(v.begin(), v.end(), element);if (iter != v.end()) &#123;  Process(element);&#125;</code></pre><p>和这样的注释:</p><pre><code class="c++">// Process &quot;element&quot; unless it was already processed.auto iter = std::find(v.begin(), v.end(), element);if (iter != v.end()) &#123;  Process(element);&#125;</code></pre><p>自文档化的代码根本就不需要注释. 上面例子中的注释对下面的代码来说就是毫无必要的:</p><pre><code class="c++">if (!IsAlreadyProcessed(element)) &#123;  Process(element);&#125;</code></pre><h3 id="TODO-注释"><a href="#TODO-注释" class="headerlink" title="TODO 注释"></a>TODO 注释</h3><p>对那些临时的, 短期的解决方案, 或已经够好但仍不完美的代码使用 <code>TODO</code> 注释.</p><p><code>TODO</code> 注释要使用全大写的字符串 <code>TODO</code>, 在随后的圆括号里写上你的名字, 邮件地址, bug ID, 或其它身份标识和与这一 <code>TODO</code> 相关的 issue. 主要目的是让添加注释的人 (也是可以请求提供更多细节的人) 可根据规范的 <code>TODO</code> 格式进行查找. 添加 <code>TODO</code> 注释并不意味着你要自己来修正, 因此当你加上带有姓名的 <code>TODO</code> 时, 一般都是写上自己的名字.</p><pre><code class="c++">// TODO(kl@gmail.com): Use a &quot;*&quot; here for concatenation operator.// TODO(Zeke) change this to use relations.// TODO(bug 12345): remove the &quot;Last visitors&quot; feature</code></pre><p>如果加 <code>TODO</code> 是为了在 “将来某一天做某事”, 可以附上一个非常明确的时间 “Fix by November 2005”), 或者一个明确的事项 (“Remove this code when all clients can handle XML responses.”).</p><h3 id="弃用注释"><a href="#弃用注释" class="headerlink" title="弃用注释"></a>弃用注释</h3><p>您可以写上包含全大写的 <code>DEPRECATED</code> 的注释, 以标记某接口为弃用状态. 注释可以放在接口声明前, 或者同一行.</p><p>在 <code>DEPRECATED</code> 一词后, 在括号中留下您的名字, 邮箱地址以及其他身份标识.</p><p>弃用注释应当包涵简短而清晰的指引, 以帮助其他人修复其调用点. 在 C++ 中, 你可以将一个弃用函数改造成一个内联函数, 这一函数将调用新的接口.</p><h2 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h2><h3 id="行长度"><a href="#行长度" class="headerlink" title="行长度"></a>行长度</h3><p>每一行代码字符数不超过 80.如果无法在不伤害易读性的条件下进行断行, 那么注释行可以超过 80 个字符, 这样可以方便复制粘贴. 例如, 带有命令示例或 URL 的行可以超过 80 个字符.</p><p>包含长路径的 <code>#include</code> 语句可以超出80。</p><h3 id="ASCII"><a href="#ASCII" class="headerlink" title="ASCII"></a>ASCII</h3><p>尽量不使用非 ASCII 字符, 使用时必须使用 UTF-8 编码.</p><p>别用 C++11 的 <code>char16_t</code> 和 <code>char32_t</code>, 它们和 UTF-8 文本没有关系, <code>wchar_t</code> 同理, 除非你写的代码要调用 Windows API, 后者广泛使用了 <code>wchar_t</code>.</p><h3 id="缩进"><a href="#缩进" class="headerlink" title="缩进"></a>缩进</h3><p>只使用空格, 每次缩进 2 个空格.</p><h3 id="函数声明和定义"><a href="#函数声明和定义" class="headerlink" title="函数声明和定义"></a>函数声明和定义</h3><p>返回类型和函数名在同一行, 参数也尽量放在同一行, 如果放不下就对形参分行</p><p>函数看上去像这样:</p><pre><code class="c++">ReturnType ClassName::FunctionName(Type par_name1, Type par_name2) &#123;  DoSomething();  ...&#125;</code></pre><p>如果同一行文本太多, 放不下所有参数:</p><pre><code class="c++">ReturnType ClassName::ReallyLongFunctionName(Type par_name1, Type par_name2,                                             Type par_name3) &#123;  DoSomething();  ...&#125;</code></pre><p>甚至连第一个参数都放不下:</p><pre><code class="c++">ReturnType LongClassName::ReallyReallyReallyLongFunctionName(    Type par_name1,  // 4 space indent    Type par_name2,    Type par_name3) &#123;  DoSomething();  // 2 space indent  ...&#125;</code></pre><ul><li><p>左圆括号总是和函数名在同一行.</p></li><li><p>参数也可以放在次行, 缩进四格</p></li><li><p>函数名和左圆括号间永远没有空格.</p></li><li><p>圆括号与参数间没有空格.</p></li><li><p>左大括号总在最后一个参数同一行的末尾处, 不另起新行.</p></li><li><p>右大括号总是单独位于函数最后一行, 或者与左大括号同一行.</p></li><li><p>右圆括号和左大括号间总是有一个空格.</p></li></ul><h3 id="Lambda-表达式"><a href="#Lambda-表达式" class="headerlink" title="Lambda 表达式"></a>Lambda 表达式</h3><p>Lambda 表达式对形参和函数体的格式化和其他函数一致; 捕获列表同理, 表项用逗号隔开.</p><p>若用引用捕获, 在变量名和 <code>&amp;</code> 之间不留空格.</p><pre><code class="c++">int x = 0;auto add_to_x = [&amp;x](int n) &#123; x += n; &#125;;</code></pre><p>短 lambda 就写得和内联函数一样.</p><pre><code class="c++">std::set&lt;int&gt; blacklist = &#123;7, 8, 9&#125;;std::vector&lt;int&gt; digits = &#123;3, 9, 1, 8, 4, 7, 1&#125;;digits.erase(std::remove_if(digits.begin(), digits.end(), [&amp;blacklist](int i) &#123;               return blacklist.find(i) != blacklist.end();             &#125;),             digits.end());</code></pre><h3 id="函数调用"><a href="#函数调用" class="headerlink" title="函数调用"></a>函数调用</h3><p>与函数声明和定义相同</p><h3 id="列表初始化-1"><a href="#列表初始化-1" class="headerlink" title="列表初始化"></a>列表初始化</h3><p>与函数相同。</p><p>如果列表初始化伴随着名字, 比如类型或变量名, 格式化时将将名字视作函数调用名, {} 视作函数调用的括号. 如果没有名字, 就视作名字长度为零.</p><h3 id="条件语句"><a href="#条件语句" class="headerlink" title="条件语句"></a>条件语句</h3><p>倾向于不在圆括号内使用空格. 关键字 <code>if</code> 和 <code>else</code> 另起一行.</p><pre><code class="c++">if (condition) &#123;  // 圆括号里没有空格.  ...  // 2 空格缩进.&#125; else if (...) &#123;  // else 与 if 的右括号同一行.  ...&#125; else &#123;  ...&#125;</code></pre><p>注意所有情况下 <code>if</code> 和左圆括号间都有个空格. 右圆括号和左大括号之间也要有个空格:</p><p>如果能增强可读性, 简短的条件语句允许写在同一行. 只有当语句简单并且没有使用 <code>else</code> 子句时使用:</p><pre><code class="c++">if (x == kFoo) return new Foo();if (x == kBar) return new Bar();</code></pre><p>如果语句中某个 <code>if-else</code> 分支使用了大括号的话, 其它分支也必须使用:</p><pre><code class="c++">// 不可以这样子 - IF 有大括号 ELSE 却没有.if (condition) &#123;  foo;&#125; else  bar;// 不可以这样子 - ELSE 有大括号 IF 却没有.if (condition)  foo;else &#123;  bar;&#125;</code></pre><h3 id="循环和开关语句"><a href="#循环和开关语句" class="headerlink" title="循环和开关语句"></a>循环和开关语句</h3><p>如果有不满足 <code>case</code> 条件的枚举值, <code>switch</code> 应该总是包含一个 <code>default</code> 匹配 (如果有输入值没有 case 去处理, 编译器将给出 warning). 如果 <code>default</code> 应该永远执行不到, 简单的加条 <code>assert</code>:</p><pre><code class="c++">switch (var) &#123;  case 0: &#123;  // 2 空格缩进    ...      // 4 空格缩进    break;  &#125;  case 1: &#123;    ...    break;  &#125;  default: &#123;    assert(false);  &#125;&#125;</code></pre><p>空循环体应使用 <code>&#123;&#125;</code> 或 <code>continue</code>, 而不是一个简单的分号.</p><pre><code class="c++">while (condition) &#123;  // 反复循环直到条件失效.&#125;for (int i = 0; i &lt; kSomeNumber; ++i) &#123;&#125;  // 可 - 空循环体.while (condition) continue;  // 可 - contunue 表明没有逻辑.</code></pre><h3 id="指针和引用表达式"><a href="#指针和引用表达式" class="headerlink" title="指针和引用表达式"></a>指针和引用表达式</h3><p>句点或箭头前后不要有空格. 指针&#x2F;地址操作符 (<code>*, &amp;</code>) 之后不能有空格.</p><p>下面是指针和引用表达式的正确使用范例:</p><pre><code class="c++">x = *p;p = &amp;x;x = r.y;x = r-&gt;y;</code></pre><p>在声明指针变量或参数时, 星号与类型或变量名紧挨都可以:</p><pre><code class="c++">// 好, 空格前置.char *c;const string &amp;str;// 好, 空格后置.char* c;const string&amp; str;</code></pre><h3 id="布尔表达式"><a href="#布尔表达式" class="headerlink" title="布尔表达式"></a>布尔表达式</h3><p>如果一个布尔表达式超过标准行宽，断行方式要统一一下.</p><p>下例中, 逻辑与 (<code>&amp;&amp;</code>) 操作符总位于行尾:</p><pre><code class="c++">if (this_one_thing &gt; this_other_thing &amp;&amp;    a_third_thing == a_fourth_thing &amp;&amp;    yet_another &amp;&amp; last_one) &#123;  ...&#125;</code></pre><h3 id="函数返回值"><a href="#函数返回值" class="headerlink" title="函数返回值"></a>函数返回值</h3><p>不要在 <code>return</code> 表达式里加上非必须的圆括号.</p><p>只有在写 <code>x = expr</code> 要加上括号的时候才在 <code>return expr;</code> 里使用括号.</p><pre><code class="c++">return result;                  // 返回值很简单, 没有圆括号.// 可以用圆括号把复杂表达式圈起来, 改善可读性.return (some_long_condition &amp;&amp;        another_condition);</code></pre><h3 id="变量及数组初始化"><a href="#变量及数组初始化" class="headerlink" title="变量及数组初始化"></a>变量及数组初始化</h3><p>用 <code>=</code>, <code>()</code> 和 <code>&#123;&#125;</code> 均可.</p><p>您可以用 <code>=</code>, <code>()</code> 和 <code>&#123;&#125;</code>, 以下的例子都是正确的：</p><pre><code class="c++">int x = 3;int x(3);int x&#123;3&#125;;string name(&quot;Some Name&quot;);string name = &quot;Some Name&quot;;string name&#123;&quot;Some Name&quot;&#125;;</code></pre><h3 id="预处理指令"><a href="#预处理指令" class="headerlink" title="预处理指令"></a>预处理指令</h3><p>预处理指令不要缩进, 从行首开始.</p><p>即使预处理指令位于缩进代码块中, 指令也应从行首开始.</p><pre><code class="c++">// 好 - 指令从行首开始  if (lopsided_score) &#123;#if DISASTER_PENDING      // 正确 - 从行首开始    DropEverything();# if NOTIFY               // 非必要 - # 后跟空格    NotifyClient();# endif#endif    BackToNormal();  &#125;</code></pre><h3 id="类格式"><a href="#类格式" class="headerlink" title="类格式"></a>类格式</h3><p><strong>总述</strong></p><p>访问控制块的声明依次序是 <code>public:</code>, <code>protected:</code>, <code>private:</code>, 每个都缩进 1 个空格.</p><p><strong>说明</strong></p><p>类声明的基本格式如下:</p><pre><code class="c++">class MyClass : public OtherClass &#123; public:      // 注意有一个空格的缩进  MyClass();  // 标准的两空格缩进  explicit MyClass(int var);  ~MyClass() &#123;&#125;  void SomeFunction();  void SomeFunctionThatDoesNothing() &#123;  &#125;  void set_some_var(int var) &#123; some_var_ = var; &#125;  int some_var() const &#123; return some_var_; &#125; private:  bool SomeInternalFunction();  int some_var_;  int some_other_var_;&#125;;</code></pre><p>注意事项:</p><ul><li>所有基类名应在 80 列限制下尽量与子类名放在同一行.</li><li>关键词 <code>public:</code>, <code>protected:</code>, <code>private:</code> 要缩进 1 个空格.</li><li>除第一个关键词 (一般是 <code>public</code>) 外, 其他关键词前要空一行. 如果类比较小的话也可以不空.</li><li>这些关键词后不要保留空行.</li><li><code>public</code> 放在最前面, 然后是 <code>protected</code>, 最后是 <code>private</code>.</li><li>关于声明顺序的规则请参考声明顺序一节.</li></ul><h3 id="构造函数初始值列表"><a href="#构造函数初始值列表" class="headerlink" title="构造函数初始值列表"></a>构造函数初始值列表</h3><p><strong>总述</strong></p><p>构造函数初始化列表放在同一行或按四格缩进并排多行.</p><p><strong>说明</strong></p><p>下面两种初始值列表方式都可以接受:</p><pre><code class="c++">// 如果所有变量能放在同一行:MyClass::MyClass(int var) : some_var_(var) &#123;  DoSomething();&#125;// 如果不能放在同一行,// 必须置于冒号后, 并缩进 4 个空格MyClass::MyClass(int var)    : some_var_(var), some_other_var_(var + 1) &#123;  DoSomething();&#125;// 如果初始化列表需要置于多行, 将每一个成员放在单独的一行// 并逐行对齐MyClass::MyClass(int var)    : some_var_(var),             // 4 space indent      some_other_var_(var + 1) &#123;  // lined up  DoSomething();&#125;// 右大括号 &#125; 可以和左大括号 &#123; 放在同一行// 如果这样做合适的话MyClass::MyClass(int var)    : some_var_(var) &#123;&#125;</code></pre><h3 id="命名空间格式化"><a href="#命名空间格式化" class="headerlink" title="命名空间格式化"></a>命名空间格式化</h3><p><strong>总述</strong></p><p>命名空间内容不缩进.</p><p><strong>说明</strong></p><p>命名空间不要增加额外的缩进层次, 例如:</p><pre><code class="c++">namespace &#123;void foo() &#123;  // 正确. 命名空间内没有额外的缩进.  ...&#125;&#125;  // namespace</code></pre><p>不要在命名空间内缩进:</p><pre><code class="c++">namespace &#123;  // 错, 缩进多余了.  void foo() &#123;    ...  &#125;&#125;  // namespace</code></pre><p>声明嵌套命名空间时, 每个命名空间都独立成行.</p><pre><code class="c++">namespace foo &#123;namespace bar &#123;</code></pre><h3 id="水平留白"><a href="#水平留白" class="headerlink" title="水平留白"></a>水平留白</h3><p><strong>总述</strong></p><p>水平留白的使用根据在代码中的位置决定. 永远不要在行尾添加没意义的留白.</p><p><strong>说明</strong></p><p><strong>通用</strong></p><pre><code class="c++">void f(bool b) &#123;  // 左大括号前总是有空格.  ...int i = 0;  // 分号前不加空格.// 列表初始化中大括号内的空格是可选的.// 如果加了空格, 那么两边都要加上.int x[] = &#123; 0 &#125;;int x[] = &#123;0&#125;;// 继承与初始化列表中的冒号前后恒有空格.class Foo : public Bar &#123; public:  // 对于单行函数的实现, 在大括号内加上空格  // 然后是函数实现  Foo(int b) : Bar(), baz_(b) &#123;&#125;  // 大括号里面是空的话, 不加空格.  void Reset() &#123; baz_ = 0; &#125;  // 用空格把大括号与实现分开.  ...</code></pre><p><strong>循环和条件语句</strong></p><pre><code class="c++">if (b) &#123;          // if 条件语句和循环语句关键字后均有空格.&#125; else &#123;          // else 前后有空格.&#125;while (test) &#123;&#125;   // 圆括号内部不紧邻空格.switch (i) &#123;for (int i = 0; i &lt; 5; ++i) &#123; // 循环里内 ; 后恒有空格switch (i) &#123;  case 1:         // switch case 的冒号前无空格.    ...  case 2: break;  // 如果冒号有代码, 加个空格.</code></pre><p><strong>操作符</strong></p><pre><code class="c++">// 赋值运算符前后总是有空格.x = 0;// 其它二元操作符也前后恒有空格, 不过对于表达式的子式可以不加空格.// 圆括号内部没有紧邻空格.v = w * x + y / z;v = w*x + y/z;v = w * (x + z);// 在参数和一元操作符之间不加空格.x = -5;++x;if (x &amp;&amp; !y)  ...</code></pre><p><strong>模板和转换</strong></p><pre><code class="c++">// 尖括号(&lt; and &gt;) 不与空格紧邻, &lt; 前没有空格, &gt; 和 ( 之间也没有.vector&lt;string&gt; x;y = static_cast&lt;char*&gt;(x);// 在类型与指针操作符之间留空格也可以, 但要保持一致.vector&lt;char *&gt; x;</code></pre><h3 id="垂直留白"><a href="#垂直留白" class="headerlink" title="垂直留白"></a>垂直留白</h3><p><strong>总述</strong></p><p>垂直留白越少越好.</p><p><strong>说明</strong></p><p>这不仅仅是规则而是原则问题了: 不在万不得已, 不要使用空行. 尤其是: 两个函数定义之间的空行不要超过 2 行, 函数体首尾不要留空行, 函数体中也不要随意添加空行.</p><p>基本原则是: 同一屏可以显示的代码越多, 越容易理解程序的控制流. 当然, 过于密集的代码块和过于疏松的代码块同样难看, 这取决于你的判断. 但通常是垂直留白越少越好.</p><p>下面的规则可以让加入的空行更有效:</p><ul><li>函数体内开头或结尾的空行可读性微乎其微.</li><li>在多重 if-else 块里加空行或许有点可读性.</li></ul><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\googlestyle.png" alt="googlestyle"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E9%98%B2%E5%BE%A1%E5%BC%8F%E7%BC%96%E7%A8%8B%E5%92%8C%E5%A5%91%E7%BA%A6%E5%BC%8F%E7%BC%96%E7%A8%8B%EF%BC%8C%E6%96%AD%E8%A8%80%E5%92%8C%E5%BC%82%E5%B8%B8/"/>
      <url>/2023/01/22/%E9%98%B2%E5%BE%A1%E5%BC%8F%E7%BC%96%E7%A8%8B%E5%92%8C%E5%A5%91%E7%BA%A6%E5%BC%8F%E7%BC%96%E7%A8%8B%EF%BC%8C%E6%96%AD%E8%A8%80%E5%92%8C%E5%BC%82%E5%B8%B8/</url>
      
        <content type="html"><![CDATA[<h1 id="防御式编程和契约式编程，断言和异常"><a href="#防御式编程和契约式编程，断言和异常" class="headerlink" title="防御式编程和契约式编程，断言和异常"></a>防御式编程和契约式编程，断言和异常</h1><h2 id="防御式编程"><a href="#防御式编程" class="headerlink" title="防御式编程"></a>防御式编程</h2><p>防御式编程，说白了，就是人类都是不安全、不值得信任的，所有的人，都会犯错误，而你写的代码，应该考虑到所有可能发生的错误，让你的程序不会因为他人的错误而发生错误。</p><p>在《代码大全》中，作者告诉我们，程序需要对可能的错误输入，做出兼容，例如一个除法的函数，你必须判断分母可能为0的情况，从而给调用者返回错误提示。另外，一般的高级编程语言，都提供了断言和异常两种方式来进行错误处理。</p><p>简而言之，防御式编程，就是持怀疑态度审视所有的代码。<strong>但是如果用每一种方法检测传入的参数合法性，那么程序会变得臃肿而缓慢。因此要考虑好在什么地方进行防御</strong></p><h2 id="契约式编程"><a href="#契约式编程" class="headerlink" title="契约式编程"></a>契约式编程</h2><p>契约式编程，简单的说，契约作用于两方，每一方都会完成一些任务，从而促成契约的达成，但同时，每一方也会接受一些义务，作为制定契约的前提，有任意一方无视了必尽义的义务，则契约失败。</p><p>契约式编程要求我们在前提条件、后继条件和不变量条件进行契约的检查。类似的，例如检查参数，一旦参数不对，当即撕毁契约。</p><p>契约所约束的，是一个为了确保程序正常运行的条件，一旦契约被损毁，只有一个原因，那就是程序出了Bug，例如一个数据字段，在我处理的时候，必须保证是不为空的，那么谁来保证这一点呢，一定是我的调用方（或者说是其它模块），<strong>所以，一旦出现问题，应该有调用方来检查，确保调用的时候，必须是不为空的。</strong></p><h2 id="断言和异常的区别"><a href="#断言和异常的区别" class="headerlink" title="断言和异常的区别"></a>断言和异常的区别</h2><p>assert只在DEBUG版本有效，在RELEASE版本失效。</p><p>断言表示程序写错了，只要断言失败，意味着至少有一个人得修改代码。它的性质如同编译错误。</p><p>例如一个函数规定某输入参数非空，来个断言。如果调用者送了空参数触发断言失败，要么调用方改代码不传空参数，要么被调用方改代码允许空参数处理。</p><p>如果代码书写完全正确，但因外界环境或者用户操作仍然可能发生的事件，都不适合用断言，可以使用异常，或者条件判断处理。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E5%A4%9A%E7%BB%B4%E6%95%B0%E7%BB%84/"/>
      <url>/2023/01/22/%E5%A4%9A%E7%BB%B4%E6%95%B0%E7%BB%84/</url>
      
        <content type="html"><![CDATA[<h1 id="多维数组"><a href="#多维数组" class="headerlink" title="多维数组"></a>多维数组</h1><p>C&#x2F;C++不存在多维数组的数据结构，在C&#x2F;C++仅存在数组的数组的说法。</p><p>数组名代表数组首元素的地址(即<strong>数组名都是一个指针</strong>，但指向的类型不同)，a[5] [5]中a和a[0]的值是一样的，但意义不同，具体体现在a+1和a[0]+1的步长不同。a 是首行地址，步长是整个一维数组；a[0] 就是首行首元素地址，+1 跳过一个元素</p><p>因为数组名是一个指针，所以int a[5] [5]中的a代表的是int (*)[5]类型，而不是int **类型，需要强制类型转换才能转为二维指针。</p><p>c++不能返回一个数组</p><p>c++没有引用数组，但有数组的引用</p><h2 id="二维数组的创建"><a href="#二维数组的创建" class="headerlink" title="二维数组的创建"></a>二维数组的创建</h2><h3 id="静态创建"><a href="#静态创建" class="headerlink" title="静态创建"></a>静态创建</h3><p>int *a[10]; &#x2F;&#x2F;定义一个数组，有十个元素，每个元素是一个int*指针。</p><p>int (*a)[10]; &#x2F;&#x2F;定义一个指针，指向一个含有10个整数的数组。</p><pre><code class="cpp">int a[5][6];vector&lt;vector&lt;int&gt;&gt; a(5,vector&lt;int&gt;(6));int (*a)[6]=new int[5][6];//申请堆区</code></pre><h3 id="动态创建"><a href="#动态创建" class="headerlink" title="动态创建"></a>动态创建</h3><pre><code class="cpp">vector&lt;vector&lt;int&gt;&gt; a(m,vector&lt;int&gt;(n));int** a = new int*[m];//二维数组也是数组，创建一个数组，数组内元素是int*for(int i = 0;i&lt;m;i++)&#123;    a[i] = new int[n];//为每一行分配空间&#125;//用一维数组代替二维数组int* a = new int[m*n];for(int i = 0 ; i&lt;m ; ++i)&#123;    for(int j = 0 ; j&lt;n ; ++j)    &#123;        a[i*n+j] = i+j;    &#125;&#125;</code></pre><h2 id="二维数组的传参"><a href="#二维数组的传参" class="headerlink" title="二维数组的传参"></a>二维数组的传参</h2><p>多维数组传参时，形参需要指定后面维度的大小，否则因为编译器只知道数组传来起始地址，不知道列数，这样导致无法确定元素位置：</p><h3 id="固定维度"><a href="#固定维度" class="headerlink" title="固定维度"></a>固定维度</h3><pre><code class="cpp">void subfun(int n, char subargs[][5]) //或者void subfun(int n, char (*subargs)[5])void main()&#123;    char args[][5] = &#123;&quot;abc&quot;, &quot;def&quot;, &quot;ghi&quot;&#125;;    subfun(3, args);&#125;</code></pre><h3 id="不固定维度"><a href="#不固定维度" class="headerlink" title="不固定维度"></a>不固定维度</h3><p>此时并不能使用nums[i] [j]这种方式来进行数组取值，因为指针没有重载operator[]。要想访问元素的值我们需要手工寻址</p><pre><code class="cpp">//传递一级指针void testArray(int* dp,int m,int n)//m为行数，n为列数&#123;    for(int i=0;i&lt;m;++i)&#123;        for(int j=0;j&lt;n;++j)&#123;            cout&lt;&lt;*(d+i*n+j)&lt;&lt;&quot; &quot;;//手工寻址        &#125;        cout&lt;&lt;endl;    &#125;    &#125;int main()&#123;    int dp[3][2]=&#123;&#123;1,2&#125;,&#123;3,4&#125;,&#123;5,6&#125;&#125;;    testArray(*dp,3,2);//这里传递的一维数组的首元素地址    return 0;&#125;//传递二级指针void testArray(int** d,int m,int n)&#123;    for(int i=0;i&lt;m;++i)&#123;        for(int j=0;j&lt;n;++j)&#123;            cout&lt;&lt;*((int*)d+i*n+j)&lt;&lt;&quot; &quot;;//d需要类型转换为int*        &#125;        cout&lt;&lt;endl;    &#125;    &#125;int main()&#123;    int dp[3][2]=&#123;&#123;1,2&#125;,&#123;3,4&#125;,&#123;5,6&#125;&#125;;    testArray((int**)dp,3,2);//dp需要进行类型转换    return 0;&#125;</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB%E7%AC%94%E8%AE%B0%EF%BC%88%E7%B1%BB%E4%BC%BCcsapp%E7%9A%84%E4%B9%A6%EF%BC%89/"/>
      <url>/2023/01/22/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB%E7%AC%94%E8%AE%B0%EF%BC%88%E7%B1%BB%E4%BC%BCcsapp%E7%9A%84%E4%B9%A6%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="程序员的自我修养笔记（类似csapp的书）"><a href="#程序员的自我修养笔记（类似csapp的书）" class="headerlink" title="程序员的自我修养笔记（类似csapp的书）"></a>程序员的自我修养笔记（类似csapp的书）</h1><p>POSIX表示可移植操作系统接口（Portable Operating System Interface of UNIX，缩写为 POSIX ），POSIX标准定义了操作系统应该为应用程序提供的接口标准，是IEEE为要在各种UNIX操作系统上运行的软件而定义的一系列API标准的总称</p><p>完成同一功能，不同内核提供的系统调用（也就是一个函数）是不同的，例如创建进程，linux下是fork函数，windows下是creatprocess函数。好，我现在在linux下写一个程序，用到fork函数，那么这个程序该怎么往windows上移植？我需要把源代码里的fork通通改成creatprocess，然后重新编译…</p><p>posix标准的出现就是为了解决这个问题。linux和windows都要实现基本的posix标准，linux把fork函数封装成posix_fork（随便说的），windows把creatprocess函数也封装成posix_fork，都声明在unistd.h里。这样，程序员编写普通应用时候，只用包含unistd.h，调用posix_fork函数，程序就在源代码级别可移植了</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220309000515982.png" alt="image-20220309000515982"></p><p>应用程序与运行库之间的接口是API(应用程序编程接口)，API的提供者是运行库，什么样的运行库提供什么样的API，如Linux下的Glibc提供的API是POSIX，而最早的32位WINDOWS提供的则是WIN32。</p><p>运行库和操作系统之间的接口是系统调用</p><p>操作系统和硬件之间的接口是硬件规格，由硬件厂商提供，驱动程序开发者根据硬件规格来编写驱动程序</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E5%B8%B8%E7%94%A8api%E5%92%8C%E5%A4%B4%E6%96%87%E4%BB%B6/"/>
      <url>/2023/01/22/%E5%B8%B8%E7%94%A8api%E5%92%8C%E5%A4%B4%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="常用api和头文件"><a href="#常用api和头文件" class="headerlink" title="常用api和头文件"></a>常用api和头文件</h1><h2 id="常用头文件"><a href="#常用头文件" class="headerlink" title="常用头文件"></a>常用头文件</h2><pre><code class="cpp">#include&lt;iostream&gt;#include &lt;sstream&gt; //istringstream等字符串流#include&lt;algorithm&gt; //max,min,sort,swap等函数#include&lt;vector&gt;#include&lt;set&gt;#include&lt;unordered_set&gt;#include&lt;map&gt; //map中涉及pair，添加map头文件的同时会自动添加pair头文件 #include&lt;unordered_map&gt;#include&lt;stack&gt; #include&lt;queue&gt; #include&lt;deque&gt; #include&lt;string&gt; //可以定义string s；不可以用到strcpy等函数#include &lt;cstring&gt; //不可以定义string s；可以用到strcpy等函数#include&lt;cmath&gt; //pow,sqrt,abs,fabs等函数#include&lt;cstdlib&gt; //atoi,malloc等函数#include&lt;cctype&gt; //isdigit，toupper等函数#include&lt;climits&gt; //包括INT_MIN,INT_MAX等#include&lt;memory&gt;//智能指针#include&lt;thread&gt;//多线程#include&lt;mutex&gt;//锁#include &lt;future&gt;#include&lt;condition_variable&gt;#include&lt;stdint.h&gt;//具有特定位宽的整形，如int64_t，int16_t#include&lt;chrono&gt;//定时#include&lt;bits/stdc++.h&gt; //万能头文件，包括GNU C++几乎所有库</code></pre><h2 id="常用api"><a href="#常用api" class="headerlink" title="常用api"></a>常用api</h2><h3 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h3><h4 id="字符串转整型"><a href="#字符串转整型" class="headerlink" title="字符串转整型"></a>字符串转整型</h4><pre><code class="c++">stoi(s,start,base) //s是要转换的字符串，start是起始位置，base是要转换的整数进制，默认是从0位置开始，转换为10进制    string str = &quot;123&quot;;int res = stoi(str);//相当于int res = stoi(str,0,10);</code></pre><h4 id="数值转字符串"><a href="#数值转字符串" class="headerlink" title="数值转字符串"></a>数值转字符串</h4><pre><code class="c++">to_string(val) //val可以是任何数值类型</code></pre><h4 id="强制类型转换"><a href="#强制类型转换" class="headerlink" title="强制类型转换"></a>强制类型转换</h4><pre><code class="c++">static_cast&lt;new type&gt;(expression)</code></pre><h3 id="字符串处理"><a href="#字符串处理" class="headerlink" title="字符串处理"></a>字符串处理</h3><h4 id="判断字符是否为数字、字母"><a href="#判断字符是否为数字、字母" class="headerlink" title="判断字符是否为数字、字母"></a>判断字符是否为数字、字母</h4><pre><code class="cpp">isalpha(char c)//判断是否为字母* isdigit(char c)//判断是否为数字* isalnum(char c)//判断是否为数字或字母</code></pre><h4 id="字母的大小写转换"><a href="#字母的大小写转换" class="headerlink" title="字母的大小写转换"></a>字母的大小写转换</h4><pre><code class="cpp">tolower(char c)//变成小写字母toupper(char c)//变成大写字母</code></pre><h4 id="格式化字符串"><a href="#格式化字符串" class="headerlink" title="格式化字符串"></a>格式化字符串</h4><pre><code>int sprintf(char *str, const char *format, ...)char str[256] = &#123; 0 &#125;;int data = 1024;sprintf(str,&quot;%d&quot;,data);//将data转换为字符串</code></pre><h4 id="字符串分割"><a href="#字符串分割" class="headerlink" title="字符串分割"></a>字符串分割</h4><pre><code class="cpp">/* strtok()在参数s的字符串中发现到参数delim的分隔字符时，则会将该字符改为&#39;\0&#39;字符 在第一次调用时，strtok()必需给予参数s字符串，往后的调用则将参数s设置成NULL.每次调用成功则返回被分隔片段的首元素指针。*/char *strtok(char *s,const char *delim)while((p[in]=strtok(buf,&quot;,&quot;))!=NULL)   &#123;      in++;      buf=NULL;&#125;</code></pre><h4 id="字符串流用于数据转换和字符串分割"><a href="#字符串流用于数据转换和字符串分割" class="headerlink" title="字符串流用于数据转换和字符串分割"></a>字符串流用于数据转换和字符串分割</h4><pre><code class="cpp">//初始化stringstream stream(&quot;1234&quot;); stream.str(&quot;1234&quot;);//把字符串&quot;1234&quot;存入字符串流中//字符串变doubledouble n;  string str = &quot;12.5&quot;;  stream &lt;&lt; str;  stream &gt;&gt; n;//输出cout&lt;&lt;stream.str()&lt;&lt;endl;stream.clear();//多次使用stringstream，要先清空下//处理用逗号分隔的字符串string str;while(getline(cin,str))&#123;  stringstream s(str);  while(getline(s,str,&#39;,&#39;))  &#123;     cout&gt;&gt;str&gt;&gt;endl;  &#125;&#125;</code></pre><h3 id="输入输出"><a href="#输入输出" class="headerlink" title="输入输出"></a>输入输出</h3><pre><code>//从流中读取字符串到str中，遇到delim时停止，默认读取一行istream&amp; getline ( istream &amp;is , string &amp;str , char delim );getline(cin,str)//读取一行数据到str中//字符串分割读取，如a,b,c,dstring str;getline(cin,str);stringstream stream(str);while(getline(stream,str,&#39;,&#39;))&#123;    cout&lt;&lt;str&lt;&lt;endl;&#125;</code></pre><h3 id="stl数据结构"><a href="#stl数据结构" class="headerlink" title="stl数据结构"></a>stl数据结构</h3><h4 id="vector"><a href="#vector" class="headerlink" title="vector"></a>vector</h4><pre><code class="cpp">//初始化vector&lt;int&gt; v0(10); //初始空间为10vector&lt;int&gt; v1 = &#123; 1,2,3,4 &#125;; vector&lt;int&gt; v2(10, 2); //初始空间为10，且值都为2vector&lt;int&gt; v4(v1);vector&lt;int&gt; v5(v1.begin()+2,v1.end()-1);//增v1.push_back(1);v1.insert(v1.begin()+2,20);//在指定位置loc前插入值为val的元素,返回指向这个元素的迭代器v1.insert(v1.begin()+2,2,100);//在指定位置loc前插入2个值为100的元素v1.insert(v1.begin()+2,v2.begin(),v2.end());//在指定位置loc前插入一个区间内所有的元素//删v1.pop_back();v1.erase(v1.begin()+3);//删除指定元素，返回下一个元素的迭代器v1.erase(v1.begin(),v1.begin()+3);//删除指定范围内元素，返回下一个元素的迭代器v1.clear();//重新分配v1.assign(3,100)//分配3个值为100的元素到容器中，清除原来的元素v1.assign(v1.begin(),v1.begin()+3)//分配某个区间的元素到容器中，清除原来的元素//调整大小v1.resize(5)//调整大小到5个元素，多出的会被销毁v1.resize(5,10)//调整大小到5个元素，多出的会被销毁，插入的新元素默认值为10</code></pre><h4 id="string"><a href="#string" class="headerlink" title="string"></a>string</h4><pre><code class="cpp">//初始化string s;string s(s1);string s(&quot;yangwen&quot;);string s(10, &#39;c&#39;);//增s.append(c,3); // 把c类型字符串s的前n个字符连接到当前字符串结尾s.append(s2);//向string的后面加strings.append(s2, 5, 5); ////把字符串s2中从pos=5开始的5个字符连接到当前字符串的结尾s.append(s2.begin()+5, s2.end()); //把s2的迭代器begin()+5和end()之间的部分连接到当前字符串的结尾s.append(4,’!’); //在当前字符串结尾添加4个字符!s.insert (5, s2);//把s2插入到s的pos=5的地方//删s.erase (10,8);//把字符串从pos=10开始的8个字符删除s.clear()//删除字符串的内容//查s.find(&quot;abc&quot;)//查找成功返回size_t类型的位置，失败返回string::nposs.find(str2,5)//从pos=5开始查找str2//其他    str1.swap(str2)//交换字符串的内容str.substr(3,5)//子串，从pos=3开始的5个字符str.compare(str2)//返回负数,0,正数    //转为c字符串char * cstr = new char [str.length()+1];std::strcpy (cstr, str.c_str());//自动在字符串后加&#39;\0&#39;</code></pre><h4 id="list"><a href="#list" class="headerlink" title="list"></a>list</h4><pre><code class="cpp">//初始化std::list&lt;int&gt; first;std::list&lt;int&gt; second (4,100);                       // 初始化4个值为100的的元素std::list&lt;int&gt; third (second.begin(),second.end());  // 通过迭代器范围初始化std::list&lt;int&gt; fourth (third);                       // 通过另一个list初始化//增//list迭代器不是随机访问迭代器，只能it++或者it--，不能it+3lt.push_front(1);lt.push_back(1);lt.insert(lt.begin(),20);//在指定位置loc前插入值为val的元素,返回原来元素的迭代器lt.insert(lt.begin(),2,100);//在指定位置loc前插入2个值为100的元素lt.insert(lt.begin(),lt2.begin(),lt2.end());//在指定位置loc前插入一个区间内所有的元素//删lt.pop_front();lt.pop_back();lt.erase(lt.begin());lt.erase(lt.begin(),lt.end());lt.remove(1)//移除所有值为1的元素//重新分配    lt.assign(3,100)//分配3个值为100的元素到容器中，清除原来的元素lt.assign(v1.begin(),v1.begin()+3)//分配某个区间的元素到容器中，清除原来的元素//调整大小lt.resize(5)//调整大小到5个元素，多出的会被销毁lt.resize(5,10)//调整大小到5个元素，多出的会被销毁，插入的新元素默认值为10//其他lt.reverse();//倒置所有元素</code></pre><h4 id="map"><a href="#map" class="headerlink" title="map"></a>map</h4><pre><code class="cpp">/* map内部本身就是按序存储的，在我们插入&lt;key, value&gt;键值对时，就会按照key的大小顺序进行存储，默认升序。因此作为key的类型必须能够进行&lt;运算比较，所以要用map存储自定义对象需要对象重载&lt;运算符 *///初始化map&lt;string,int&gt; mp;map&lt;string,int&gt; mp2 (mp.begin(),mp.end());map&lt;string,int&gt; mp3 (mp);map&lt;string,int&gt; m3 = &#123;&#123;"string",1&#125;, &#123;"sec",2&#125;, &#123;"trd",3&#125;&#125;;//高于c++11可使用map&lt;string, int, greater&lt;string&gt; &gt; mp;//降序存储，默认是less&lt;string&gt;升序存储//增mp.insert(pair&lt;string,int&gt;(&quot;apple&quot;,2));mp.insert(map&lt;string, int&gt;::value_type(&quot;orange&quot;,3));mp[&quot;banana&quot;] = 6;//删mp.erase (mp.begin()+2);mp.erase (mp.begin()+2, mp.begin()+4);mp.erase(&quot;banana&quot;); //通过关键字删除//遍历for(auto it=dict.begin();it!=dict.end();it++)&#123;    cout&lt;&lt;it-&gt;first&lt;&lt;it-&gt;second&lt;&lt;endl;//first是key,second是value&#125;//查mp.find(&quot;banana&quot;)//成功返回迭代器，失败返回mp.end()if((it=mp.find(&quot;banana&quot;))!=mp.end())    </code></pre><h4 id="set"><a href="#set" class="headerlink" title="set"></a>set</h4><pre><code class="cpp">//与map api类似，key唯一自动去重，自动按key排序</code></pre><h4 id="stack"><a href="#stack" class="headerlink" title="stack"></a>stack</h4><pre><code>//初始化stack &lt;int&gt; st;stack &lt;int,list&lt;int&gt;&gt; st;//指定底层容器为list，默认为deque//增st.push(1);//删st.pop();//访问st.top();</code></pre><h4 id="queue"><a href="#queue" class="headerlink" title="queue"></a>queue</h4><pre><code class="cpp">//初始化queue&lt;int&gt; q;queue &lt;int,list&lt;int&gt;&gt; q;//指定底层容器为list，默认为deque//增q.push(1);//删q.pop();//访问q.front();q.back();</code></pre><h4 id="priority-queue"><a href="#priority-queue" class="headerlink" title="priority_queue"></a>priority_queue</h4><pre><code class="cpp">//初始化priority_queue&lt;int&gt; pq//第二个参数指定底层容器可为deque或vector,默认为vector；第三个参数指定顺序默认为less&lt;int&gt;大根堆，greater&lt;int&gt;则为小根堆priority_queue&lt;int, vector&lt;int&gt;, less&lt;int&gt;&gt; pq;//增pq.push(1);//删pq.pop();//访问pq.top();//排序需使用仿函数或者decltype(lambda)</code></pre><h4 id="deque"><a href="#deque" class="headerlink" title="deque"></a>deque</h4><pre><code class="cpp">//初始化deque&lt;int&gt; dq;//增dq.push_back(1);dq.push_front(1);//删dq.pop_back();dq.pop_front();//访问dq.front();dq.back();</code></pre><h3 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h3><h4 id="reverse"><a href="#reverse" class="headerlink" title="reverse"></a>reverse</h4><h4 id="swap"><a href="#swap" class="headerlink" title="swap"></a>swap</h4><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><p>sort() 函数受到底层实现方式的限制，它仅适用于普通数组和部分类型的容器。换句话说，只有普通数组和具备以下条件的容器，才能使用 sort() 函数：容器支持的迭代器类型必须为随机访问迭代器。这意味着，<strong>sort() 只对 array、vector、deque 这 3 个容器提供支持</strong>。</p><ol><li><p>如果对容器中指定区域的元素做默认升序排序，则元素类型必须支持&lt;小于运算符；</p></li><li><p>同样，如果选用标准库提供的其它排序规则，元素类型也必须支持该规则底层实现所用的比较运算符；</p></li><li><p>sort() 函数在实现排序时，需要交换容器中元素的存储位置。这种情况下，如果容器中存储的是自定义的类对象，则该类的内部必须提供拷贝构造函数和赋值运算符。</p></li><li><pre><code class="cpp">sort(myvector.begin(), myvector.begin() + 4, std::greater&lt;int&gt;());//降序排序，默认升序bool mycomp(int i, int j) &#123;return (i &lt; j);&#125;sort(myvector.begin(), myvector.end(), mycomp);//以提供的函数进行排序//对list排序list定义了自己的 sort() 函数。无参 sort() 函数将所有元素升序排列。第二个版本的 sort() 接受一个函数对象或lambda表达式作为参数，这两种参数都定义一个断言用来比较两个元素。ls.sort([](const string&amp; a, const string&amp; b)&#123;        return a &lt; b;&#125;);/*对map的value进行排序。sort不支持map，所以先将map转换为vector，调用sort函数中传入一个函数对象，则可以实现对value 的排序。*/struct cmp &#123;bool operator()(const pair&lt;string,int&gt;&amp; p1, const pair&lt;string,int&gt;&amp; p2) &#123;    return p1.second&gt;p2.second;&#125;&#125;或者bool cmp(pair&lt;string,int&gt; p1,pair&lt;string,int&gt; p2)&#123;    return p1.second&gt;p2.second;&#125;map&lt;string, int&gt; mp;vector&lt;pair&lt;string,int&gt;&gt; vec(mp.begin(), mp.end());sort(vec.begin(), vec.end(), cmp());//函数的话就是sort(vec.begin(), vec.end(), cmp)</code></pre></li></ol><h3 id="智能指针"><a href="#智能指针" class="headerlink" title="智能指针"></a>智能指针</h3><h4 id="shared-ptr"><a href="#shared-ptr" class="headerlink" title="shared_ptr"></a>shared_ptr</h4><pre><code class="cpp">//初始化shared_ptr&lt;int&gt; p(new int(5));auto pointer = std::make_shared&lt;int&gt;(10);auto pointer = p//p是另一个shared_ptr，引用计数加1//其他int *p = pointer.get(); // 获取原始指针，这样不会增加引用计数pointer.reset();//销毁这个引用，引用计数减1pointer.reset(new int(1));//原智能指针引用计数减1，将新对象交给智能指针保管p.use_count()//返回引用计数//智能指针管理数组auto sp = std::shared_ptr(new int[len], [](char *p)&#123;delete []p;&#125;);//需要指定一个删除器auto sp = std::make_shared&lt;int[]&gt;(64);//c++20之后可以直接用make_shared管理数组不要用一个原始指针初始化多个shared_ptr，原因在于，会造成二次销毁，如下所示：int *p5 = new int;std::shared_ptr&lt;int&gt; p6(p5);std::shared_ptr&lt;int&gt; p7(p5);// logic error不要在函数实参中创建shared_ptr。因为C++的函数参数的计算顺序在不同的编译器下是不同的。正确的做法是先创建好，然后再传入。function(shared_ptr&lt;int&gt;(new int), g());禁止通过shared_from_this()返回this指针，这样做可能也会造成二次析构。避免循环引用。智能指针最大的一个陷阱是循环引用，循环引用会导致内存泄漏。</code></pre><h4 id="unique-ptr"><a href="#unique-ptr" class="headerlink" title="unique_ptr"></a>unique_ptr</h4><pre><code class="cpp">//初始化auto p = std::make_unique&lt;int&gt;(10);//c++14之后unique_ptr&lt;int&gt; p(new int(5));//转移所有权unique_ptr&lt;int&gt; p2(std::move(p1));//销毁p1，转移所有权给p2</code></pre><h4 id="weak-ptr"><a href="#weak-ptr" class="headerlink" title="weak_ptr"></a>weak_ptr</h4><pre><code class="cpp">//初始化weak_ptr&lt;string&gt; w;weak_ptr&lt;string&gt; w(p);//用shared_ptr初始化weak_ptr&lt;string&gt; w2 = w;//用其他weak_ptr初始化//std::weak_ptr 没有 * 运算符和 -&gt; 运算符，所以不能够对资源进行操作，它可以用于检查 std::shared_ptr 是否存在shared_ptr&lt;string&gt;  p = wp.lock()//wp.lock()返回指向的shared_ptr，当指向的shared_ptr已释放时返回nullptrwp.expired()//资源未释放返回false,否则返回truewp.use_count()//返回引用计数    </code></pre><h3 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h3><h4 id="thread"><a href="#thread" class="headerlink" title="thread"></a>thread</h4><pre><code class="cpp">//初始化，线程创建好之后就开始运行了thread th(t1);//t1是创建好的函数thread t([]()&#123;        std::cout &lt;&lt; &quot;hello world.&quot; &lt;&lt; std::endl;    &#125;);//控制线程th.join();//主线程会阻塞直到th这个子线程结束th.detach();//将子线程分离，失去对它的控制，主线程结束时子线程不会结束th.get_id();//获取所创建线程的线程ID//获取线程返回值1.将子线程返回值存在一个全局变量或共享指针中;2.使用future;//futurestd::packaged_task&lt;int()&gt; task([]()&#123;return 7;&#125;);std::future&lt;int&gt; result = task.get_future();std::thread(std::move(task)).detach();// 在一个线程中执行 taskresult.wait(); // 在此设置屏障，阻塞到期物的完成result.get();//获取返回值</code></pre><h4 id="mutex"><a href="#mutex" class="headerlink" title="mutex"></a>mutex</h4><pre><code class="cpp">//初始化mutex m;m.lock()m.unlock()    //用lock_guard管理,不能显式的调用lock和unlockmutex m;lock_guard&lt;mutex&gt; lg(m);//创建后自动调用m.lock(),销毁lockguard时调用m.unlock()//用unique_lock管理，可以显示调用，更加灵活，推荐使用mutex m;unique_lock&lt;mutex&gt; ug(m);//unique_lock独占mutex对象。创建后自动调用m.lock(),销毁时调用m.unlock()ug.lock();ug.unlock();</code></pre><h4 id="condition-variable"><a href="#condition-variable" class="headerlink" title="condition_variable"></a>condition_variable</h4><p>std::condition_variable 对象通常使用 std::unique_lock&lt;std::mutex&gt; 来等待，如果需要使用另外的 lockable 类型，可以使用 std::condition_variable_any 类</p><pre><code class="cpp">#include &lt;mutex&gt;            #include &lt;condition_variable&gt;std::mutex mtx; // 全局互斥锁.std::condition_variable cv; // 全局条件变量.bool ready = false; // 全局标志位.void do_print_id(int id)&#123;    std::unique_lock &lt;std::mutex&gt; lck(mtx);    while (!ready) // 如果标志位不为 true, 则等待...        cv.wait(lck); // 当前线程被阻塞, 当全局标志位变为 true 之后,    // 线程被唤醒, 继续往下执行打印线程编号id.    std::cout &lt;&lt; &quot;thread &quot; &lt;&lt; id &lt;&lt; &#39;\n&#39;;&#125;void go()&#123;    std::unique_lock &lt;std::mutex&gt; lck(mtx);    ready = true; // 设置全局标志位为 true.    cv.notify_all(); // 唤醒所有线程.&#125;</code></pre><h4 id="原子操作"><a href="#原子操作" class="headerlink" title="原子操作"></a>原子操作</h4><p>为整数或浮点数的原子类型提供了基本的数值成员函数，举例来说， 包括 <code>fetch_add</code>, <code>fetch_sub</code> 等，同时通过重载方便的提供了对应的 <code>+</code>，<code>-</code> 版本</p><p>并非所有的类型都能提供原子操作，这是因为原子操作的可行性取决于具体的 CPU 架构，以及所实例化的类型结构是否能够满足该 CPU 架构对内存对齐 条件的要求，因而我们总是可以通过 <code>std::atomic&lt;T&gt;::is_lock_free</code> 来检查该原子类型是否需支持原子操作，</p><pre><code class="c++">#include &lt;atomic&gt;std::atomic&lt;int&gt; counter;std::atomic&lt;A&gt; a;std::cout &lt;&lt; std::boolalpha &lt;&lt; a.is_lock_free() &lt;&lt; std::endl;</code></pre><h3 id="定时"><a href="#定时" class="headerlink" title="定时"></a>定时</h3><p>chrono是一个模版库，提供关于日期和时间的一些功能。<br>先举个例子，如果我想知道看这篇笔记花了多长时间：<br>（1）首先需要有一个能提供时钟（clock）的设备（电脑、手机、手表、挂钟等）<br>（2）记录开始阅读和结束阅读的时间点（time_point）；<br>（3）计算两次的时间之差就是阅读持续时间（duration）。<br>chrono的模板库常用的3个模板也是这3个：duration、time_point、clock。在使用时，需要引用chrono头文件：#include <chrono></p><h4 id="clock"><a href="#clock" class="headerlink" title="clock"></a>clock</h4><p>既然谈到时间，总需要找一个时钟作为参照吧，就像我们想知道当前时间，可以看墙上的挂钟，可以看手表，可以看手机。clock就是这个时钟，在计算机中一般都会有一套或多套时钟系统供程序使用。<br>在std::chrono库中，有3种时钟：</p><ul><li>system_clock</li><li>steady_clock</li><li>hight_definition_clock</li></ul><p>一般情况下，他们3个没有太大的区别，hight_definition_clock、steady_clock仅仅是system_clock的typedef，但是有为什么要区分呢，因为在有些情况下，他们是存在差异的。</p><p>情况1：system_clock和steady_clock的差异<br>比如windows系统可以提供时钟，如果认为时间不准，我们还可以进行调整。在没有调整时间前，system_clock和steady_clck是一样的，他们的读数都是单调匀速增加的；但是如果调整时间后，它们两者的读数就会出现差异，system_clock的读数就会出现跳变，而steady_clock依然保持线性单调递增，不受clock调整的影响，这个特点非常方便我们统计时间耗时（duration）。</p><p>情况2：system_clock与hight_definition_clock的差异<br>如果系统提供的时钟（clock）不止一种，有的时钟精度高（分辨率），有的精度低，hight_definition_clock使用时精度最高的clock，但是system_clock就不一定了。</p><p>system_clock的主要方法有3个，分别是：</p><ol><li>now，用来获取当前时间。</li><li>to_time_t，用来将系统时间转变为std::time_t类型。</li><li>from_time_t，用来将std::time_t类型转换为系统时间点。</li></ol><p>current_time的时间数据是一个数字，表示当前时间是经过了多少个计时单位了。为了让不同地区、不同国家、不同的设备有一个统一标准，可以通过time_since_epoch().count()计算以 1970 年 1 月 1 日 00:00 UTC 为起点的时间。</p><pre><code class="c++">std::chrono::system_clock::time_point current_time = std::chrono::system_clock::now();cout &lt;&lt; &quot;current_time = &quot; &lt;&lt; current_time.time_since_epoch().count() &lt;&lt; endl;auto tt = std::chrono::system_clock::to_time_t(time);std::cout &lt;&lt; std::put_time(std::localtime(&amp;tt), &quot;%Y-%m-%d %H:%M:%S&quot;) &lt;&lt; std::endl;</code></pre><h4 id="time-point"><a href="#time-point" class="headerlink" title="time_point"></a>time_point</h4><p>time_point是具体的时间，比如某年某月某日几点几分几秒，time_point依赖于clock的计时。</p><h4 id="duration"><a href="#duration" class="headerlink" title="duration"></a>duration</h4><p>duration表示一段时间，也就是持续时间，是一个时间的长度，比如1个小时、35秒、33毫秒。<br>它的模板类如下，包含两个参数，Rep是必需要指定的，Period是可选择输入的，简单的说Rep表示数据的类型，如int、float等；Period可以理解为时间的单位，默认是1秒，自己也可自定义修改，就是duration每增加1与之对应的时间是多少。</p><pre><code class="c++">template &lt;class Rep, class Period = ratio&lt;1&gt; &gt; class duration;</code></pre><p>默认1秒作为计量单位</p><pre><code class="c++">// duration每增加1，表示的时间的变化量为1秒typedef std::chrono::duration&lt;int&gt; t_int;typedef std::chrono::duration&lt;double&gt; t_float;</code></pre><p>使用自定义的值作为计量单位</p><pre><code class="c++">//ratio有两个参数ratio&lt;num, den&gt;，那么实际的单位为num/den秒。// duration每增加1，时间的变化为0.001秒typedef std::chrono::duration&lt;float, std::ratio&lt;1,1000&gt;&gt; mSec_float; // 1/1000秒作为计量单位，也就毫秒// duration每增加1，时间的变化为60秒typedef std::chrono::duration&lt;int, std::ratio&lt;60, 1&gt;&gt; minute_int; // 60/1秒为计量电位，也就是1分钟//也可以使用std库中预定义好的变量，本质上也是使用ratio定义好的。std::chrono::duration&lt;int, std::milli&gt;  // 毫秒std::chrono::duration&lt;int, std::micro&gt;  // 微秒std::chrono::duration&lt;int, std::nano&gt;   // 纳秒</code></pre><p>如何定义、修改duration的变量</p><pre><code class="c++">typedef std::chrono::duration&lt;int, std::milli&gt; mSec_t;mSec_t t1(2000);cout &lt;&lt; &quot;t1 = &quot; &lt;&lt; t1.count() &lt;&lt; endl;// t1 = 3000; // 不能这样赋值t1 = mSec_t(3000); // 修改变量cout &lt;&lt; &quot;t1 = &quot; &lt;&lt; t1.count() &lt;&lt; endl;</code></pre><p>获取两个时刻的时间，然后计算时间长度。</p><pre><code class="c++">using namespace std;using namespace std::chrono;// Step one: 定义一个clocktypedef system_clock sys_clk_t;// Step two: 分别获取两个时刻的时间typedef system_clock::time_point time_point_t;// 第1个时间time_point_t time01 = sys_clk_t::now();// 延时5秒std::this_thread::sleep_for(std::chrono::duration&lt;int&gt;(5));// 第2个时间time_point_t time02 = sys_clk_t::now();// Step three: 计算时间差cout &lt;&lt; &quot;dt_time(system_clock period) = &quot; &lt;&lt; (time02 - time01).count() &lt;&lt; endl;</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
      <url>/2023/01/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h1><h2 id="硬件结构"><a href="#硬件结构" class="headerlink" title="硬件结构"></a>硬件结构</h2><h3 id="存储器层次结构"><a href="#存储器层次结构" class="headerlink" title="存储器层次结构"></a>存储器层次结构</h3><p>以hello程序执行为例：</p><p>先由C语言的源文件<code>hello.c</code>编译得到了可执行目标文件<code>hello</code></p><ol><li>shell读入我们输入的字符<code>./hello</code>后，将其逐一读入到CPU的寄存器中，然后再将其存放到主存中。</li><li>输入回车后，shell执行一系列指令将hello目标文件中的代码和数据从磁盘复制到主存。</li><li>CPU开始执行hello的main程序中的机器指令，它将<code>hello, world\n</code>字符串中的字节从主存复制到CPU寄存器，再从CPU寄存器复制到显示设备。</li></ol><p>由此可见执行代码时，会花费大量时间将代码和数据进行复制。而<strong>不同设备之间运行速度差距极大</strong>，在等待复制的过程中cpu浪费了大量的时间，为了加快复制速度和提高cpu利用率，引入了存储器体系结构。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/image-20220512235134334.png" alt="image-20220512235134334"></p><p>根据<strong>局部性原理</strong>可知，程序具有访问局部区域内的数据和代码的趋势，所以在处理器和一个较大较慢的设备之间插入一个更小更快的存储设备，来暂时保存处理器近期可能会需要的数据，使得大部分的内存操作都能在高速缓存内完成，就能极大提高系统速度了。</p><p>存储器层次结构的<strong>主要思想</strong>是将上一层的存储器作为下一层存储器的高速缓存。</p><p>从 寄存器、CPU Cache，到内存、硬盘，这样一层层下来的存储器，访问速度越来越慢，存储容量越来越大，价格也越来越便宜，而且每个存储器只和相邻的一层存储器设备打交道，于是这样就形成了存储器的层次结构。</p><p>那机械硬盘、固态硬盘、内存这三个存储器，到底和 <code>CPU L1 Cache</code> 相比速度差多少倍呢？</p><p>CPU L1 Cache 随机访问延时是 1 纳秒，内存则是 100 纳秒，所以 <strong>CPU L1 Cache 比内存快 <code>100</code> 倍左右</strong>。</p><p>SSD 随机访问延时是 150 微秒，所以 <strong>CPU L1 Cache 比 SSD 快 <code>150000</code> 倍左右</strong>。</p><p>最慢的机械硬盘随机访问延时已经高达 10 毫秒，我们来看看机械硬盘到底有多龟速：</p><ul><li><strong>SSD 比机械硬盘快 70 倍左右；</strong></li><li><strong>内存比机械硬盘快 100000 倍左右；</strong></li><li><strong>CPU L1 Cache 比机械硬盘快 10000000 倍左右；</strong></li></ul><h3 id="如何写出让-CPU-跑得更快的代码"><a href="#如何写出让-CPU-跑得更快的代码" class="headerlink" title="如何写出让 CPU 跑得更快的代码"></a>如何写出让 CPU 跑得更快的代码</h3><p>CPU Cache 通常分为大小不等的三级缓存，分别是 <strong>L1 Cache、L2 Cache 和 L3 Cache</strong>。如果 CPU 运算时，直接从 CPU Cache 读取数据，而不是从内存的话，运算速度就会很快。</p><p>其中，<strong>L1 Cache 通常会分为「数据缓存」和「指令缓存」</strong>，这意味着数据和指令在 L1 Cache 这一层是分开缓存的</p><p>另外，L3 Cache 比 L1 Cache 和 L2 Cache 大很多，这是因为 <strong>L1 Cache 和 L2 Cache 都是每个 CPU 核心独有的，而 L3 Cache 是多个 CPU 核心共享的。</strong></p><p>程序执行时，会先将内存中的数据加载到共享的 L3 Cache 中，再加载到每个核心独有的 L2 Cache，最后进入到最快的 L1 Cache，之后才会被 CPU 读取。它们之间的层级关系，如下图：</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/CPU-Cache.png" alt="CPU-Cache"></p><p>越靠近 CPU 核心的缓存其访问速度越快，CPU 访问 L1 Cache 只需要 <code>2~4</code> 个时钟周期，访问 L2 Cache 大约 <code>10~20</code> 个时钟周期，访问 L3 Cache 大约 <code>20~60</code> 个时钟周期，而访问内存速度大概在 <code>200~300</code> 个 时钟周期之间。</p><p>CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的，而不是按照单个数组元素来读取数据的，在 CPU Cache 中的，这样一小块一小块的数据，称为 <strong>Cache Line（缓存块）</strong>。</p><p>于是，如何写出让 CPU 跑得更快的代码这个问题，可以<strong>改成如何写出 CPU 缓存命中率高</strong>的代码。</p><p>在前面提到， L1 Cache 通常分为数据缓存和指令缓存，这是因为 CPU 会分别处理数据和指令，比如 <code>1+1=2</code> 这个运算，<code>+</code> 就是指令，会被放在指令缓存中，而输入数字 <code>1</code> 则会被放在数据缓存里。</p><p>因此，<strong>我们要分开来看数据缓存和指令缓存的缓存命中率</strong>。</p><h4 id="如何提升数据缓存的命中率"><a href="#如何提升数据缓存的命中率" class="headerlink" title="如何提升数据缓存的命中率"></a>如何提升数据缓存的命中率</h4><p>Cache一块块地批量将数据从内存读到Cache，<strong>遇到遍历数组的情况时，按照内存布局顺序访问而不是跳跃性访问，将可以有效的利用 CPU Cache 带来的好处，这样我们代码的性能就会得到很大的提升</strong></p><h4 id="如何提升指令缓存的命中率"><a href="#如何提升指令缓存的命中率" class="headerlink" title="如何提升指令缓存的命中率"></a>如何提升指令缓存的命中率</h4><p>我们以一个例子来看看，假设有一个元素为 0 到 100 之间随机数字组成的一维数组：</p><p>接下来，对这个数组做两个操作：</p><ul><li>第一个操作，循环遍历数组，把小于 50 的数组元素置为 0；</li><li>第二个操作，将数组排序；</li></ul><p>那么问题来了，你觉得先遍历再排序速度快，还是先排序再遍历速度快呢？</p><p>在回答这个问题之前，我们先了解 CPU 的<strong>分支预测器</strong>。对于 if 条件语句，意味着此时至少可以选择跳转到两段不同的指令执行，也就是 if 还是 else 中的指令。那么，<strong>如果分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快</strong>。</p><p>当数组中的元素是随机的，分支预测就无法有效工作，而当数组元素都是是顺序的，分支预测器会动态地根据历史命中数据对未来进行预测，这样命中率就会很高。</p><p>因此，先排序再遍历速度会更快，这是因为排序之后，数字是从小到大的，那么前几次循环命中 <code>if &lt; 50</code> 的次数会比较多，于是分支预测就会缓存 <code>if</code> 里的 <code>array[i] = 0</code> 指令到 Cache 中，后续 CPU 执行该指令就只需要从 Cache 读取就好了。</p><p>所以对于指令缓存，有规律的条件分支语句能够让 CPU 的分支预测器发挥作用，进一步提高执行的效率；</p><h4 id="如何提升多核-CPU-的缓存命中率"><a href="#如何提升多核-CPU-的缓存命中率" class="headerlink" title="如何提升多核 CPU 的缓存命中率"></a>如何提升多核 CPU 的缓存命中率</h4><p>在单核 CPU，虽然只能执行一个线程，但是操作系统给每个线程分配了一个时间片，时间片用完了，就调度下一个线程，于是各个线程就按时间片交替地占用 CPU，从宏观上看起来各个线程同时在执行。</p><p>而现代 CPU 都是多核心的，线程可能在不同 CPU 核心来回切换执行，这对 CPU Cache 不是有利的，虽然 L3 Cache 是多核心之间共享的，但是 L1 和 L2 Cache 都是每个核心独有的，<strong>如果一个线程在不同核心来回切换，各个核心的缓存命中率就会受到影响</strong>，相反如果线程都在同一个核心上执行，那么其数据的 L1 和 L2 Cache 的缓存命中率可以得到有效提高，缓存命中率高就意味着 CPU 可以减少访问 内存的频率。</p><p><strong>当有多个同时执行「计算密集型」的线程</strong>，为了防止因为切换到不同的核心，而导致缓存命中率下降的问题，我们可以把<strong>线程绑定在某一个 CPU 核心上</strong>，这样性能可以得到非常可观的提升。</p><p>在 Linux 上提供了 <code>sched_setaffinity</code> 方法，来实现将线程绑定到某个 CPU 核心这一功能。</p><h3 id="CPU缓存一致性"><a href="#CPU缓存一致性" class="headerlink" title="CPU缓存一致性"></a>CPU缓存一致性</h3><p>CPU 在读写数据的时候，都是在 CPU Cache 读写数据的，原因是 Cache 离 CPU 很近，读写性能相比内存高出很多。对于 Cache 里没有缓存 CPU 所需要读取的数据的这种情况，CPU 则会从内存读取数据，并将数据缓存到 Cache 里面，最后 CPU 再从 Cache 读取数据。</p><p>而对于数据的写入，CPU 都会先写入到 Cache 里面，然后再在找个合适的时机写入到内存，那就有「写直达」和「写回」这两种策略来保证 Cache 与内存的数据一致性：</p><ul><li>写直达，只要有数据写入，都会直接把数据写入到内存里面，这种方式简单直观，但是性能就会受限于内存的访问速度；</li><li>写回，对于已经缓存在 Cache 的数据的写入，只需要更新其数据就可以，不用写入到内存，只有在需要把缓存里面的脏数据交换出去的时候，才把数据同步到内存里，这种方式在缓存命中率高的情况，性能会更好；</li></ul><p>但是在当今 CPU 都是多核的，每个核心都有各自独立的 L1&#x2F;L2 Cache，只有 L3 Cache 是多个核心之间共享的。写回法中内存存储的值不一定是最新值，这可能会导致多核间的缓存不一致。</p><p>假设 A 号核心和 B 号核心同时运行两个线程，都操作共同的变量 i（初始值为 0 ）。</p><p>这时如果 A 号核心执行了 <code>i++</code> 语句的时候，为了考虑性能，使用了我们前面所说的写回策略，先把值为 <code>1</code> 的执行结果写入到 L1&#x2F;L2 Cache 中，然后把 L1&#x2F;L2 Cache 中对应的 Block 标记为脏的，这个时候数据其实没有被同步到内存中的，因为写回策略，只有在 A 号核心中的这个 Cache Block 要被替换的时候，数据才会写入到内存里。</p><p>如果这时旁边的 B 号核心尝试从内存读取 i 变量的值，则读到的将会是错误的值，因为刚才 A 号核心更新 i 值还没写入到内存中，内存中的值还依然是 0。<strong>这个就是所谓的缓存一致性问题，A 号核心和 B 号核心的缓存，在这个时候是不一致，从而会导致执行结果的错误。</strong></p><p>要想实现缓存一致性，关键是要满足 2 点：</p><ul><li>第一点是<strong>写传播</strong>，也就是当某个 CPU 核心发生写入操作时，需要把该事件广播通知给其他核心；</li><li>第二点是<strong>事务的串行化</strong>，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个很重要，只有保证了这个，才能保障我们的数据是真正一致的，我们的程序在各个不同的核心上运行的结果也是一致的；</li></ul><p>举个例子来理解事务的串行化：</p><p>假设我们有一个含有 4 个核心的 CPU，这 4 个核心都操作共同的变量 i（初始值为 0 ）。A 号核心先把 i 值变为 100，而此时同一时间，B 号核心先把 i 值变为 200，这里两个修改，都会「传播」到 C 和 D 号核心。</p><p>那么问题就来了，C 号核心先收到了 A 号核心更新数据的事件，再收到 B 号核心更新数据的事件，因此 C 号核心看到的变量 i 是先变成 100，后变成 200。而如果 D 号核心收到的事件是反过来的，则 D 号核心看到的是变量 i 先变成 200，再变成 100，虽然是做到了写传播，但是各个 Cache 里面的数据还是不一致的。</p><p>所以，我们要保证 C 号核心和 D 号核心都能看到<strong>相同顺序的数据变化</strong>，比如变量 i 都是先变成 100，再变成 200，这样的过程就是事务的串行化。</p><p>基于总线嗅探机制的 MESI 协议，就满足上面了这两点，因此它是保障缓存一致性的协议。总线嗅探指 CPU核心 需要每时每刻监听总线上的一切活动，同时当核心更新了 Cache 中的数据时，要把该事件广播通知到其他核心，不管别的核心的 Cache 是否缓存相同的数据。</p><p>MESI 协议，是已修改、独占、共享、已失效这四个状态的英文缩写的组合(Modified,Exclusive,Shared,Invalidated)。这四个状态来标记 Cache Line 四个不同的状态。</p><p>「已修改」状态就是我们前面提到的脏标记，代表该 Cache Block 上的数据已经被更新过，但是还没有写到内存里。而「已失效」状态，表示的是这个 Cache Block 里的数据已经失效了，不可以读取该状态的数据。</p><p>「独占」和「共享」状态都代表 Cache Block 里的数据是干净的，也就是说，这个时候 Cache Block 里的数据和内存里面的数据是一致性的。</p><p>「独占」和「共享」的差别在于，独占状态的时候，数据只存储在一个 CPU 核心的 Cache 里，而其他 CPU 核心的 Cache 没有该数据。这个时候，如果要向独占的 Cache 写数据，就可以直接自由地写入，而不需要通知其他 CPU 核心，因为只有你这有这个数据，就不存在缓存一致性的问题了，于是就可以随便操作该数据。</p><p>另外，在「独占」状态下的数据，如果有其他核心从内存读取了相同的数据到各自的 Cache ，那么这个时候，独占状态下的数据就会变成共享状态。</p><p>那么，「共享」状态代表着相同的数据在多个 CPU 核心的 Cache 里都有，所以当我们要更新 Cache 里面的数据的时候，不能直接修改，而是要先向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后再更新当前 Cache 里面的数据。</p><p>我们举个具体的例子来看看这四个状态的转换：</p><ol><li>当 A 号 CPU 核心从内存读取变量 i 的值，数据被缓存在 A 号 CPU 核心自己的 Cache 里面，此时其他 CPU 核心的 Cache 没有缓存该数据，于是标记 Cache Line 状态为「独占」，此时其 Cache 中的数据与内存是一致的；</li><li>然后 B 号 CPU 核心也从内存读取了变量 i 的值，此时会发送消息给其他 CPU 核心，由于 A 号 CPU 核心已经缓存了该数据，所以会把数据返回给 B 号 CPU 核心。在这个时候， A 和 B 核心缓存了相同的数据，Cache Line 的状态就会变成「共享」，并且其 Cache 中的数据与内存也是一致的；</li><li>当 A 号 CPU 核心要修改 Cache 中 i 变量的值，发现数据对应的 Cache Line 的状态是共享状态，则要向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后 A 号 CPU 核心才更新 Cache 里面的数据，同时标记 Cache Line 为「已修改」状态，此时 Cache 中的数据就与内存不一致了。</li><li>如果 A 号 CPU 核心「继续」修改 Cache 中 i 变量的值，由于此时的 Cache Line 是「已修改」状态，因此不需要给其他 CPU 核心发送消息，直接更新数据即可。</li><li>如果 A 号 CPU 核心的 Cache 里的 i 变量对应的 Cache Line 要被「替换」，发现 Cache Line 状态是「已修改」状态，就会在替换前先把数据同步到内存。</li></ol><p>所以，可以发现当 Cache Line 状态是「已修改」或者「独占」状态时，修改更新其数据不需要发送广播给其他 CPU 核心，这在一定程度上减少了总线带宽压力。</p><p>整个 MESI 的状态可以用一个有限状态机来表示它的状态流转。还有一点，对于不同状态触发的事件操作，可能是来自本地 CPU 核心发出的广播事件，也可以是来自其他 CPU 核心通过总线发出的广播事件。</p><h3 id="伪共享问题"><a href="#伪共享问题" class="headerlink" title="伪共享问题"></a>伪共享问题</h3><p>多核心CPU会出现伪共享的问题，即Cache失效的问题。</p><p>现在假设有一个双核心的 CPU，这两个 CPU 核心并行运行着两个不同的线程，它们同时从内存中读取两个不同的数据，分别是变量 A 和 B，这个两个数据的地址在物理内存上是<strong>连续</strong>的，如果 Cahce Line 的大小是 64 字节，并且变量 A 在 Cahce Line 的开头位置，那么这两个数据是位于<strong>同一个 Cache Line 中</strong>，又因为 CPU Line 是 CPU 从内存读取数据到 Cache 的单位，所以这两个数据会被同时读入到了两个 CPU 核心中各自 Cache 中。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/cacheline.png" alt="cacheline"></p><p>如果这两个不同核心的线程分别修改不同的数据，比如 1 号 CPU 核心的线程只修改了 变量 A，或 2 号 CPU 核心的线程的线程只修改了变量 B，会发生什么呢？</p><p>①. 最开始变量 A 和 B 都还不在 Cache 里面，假设 1 号核心绑定了线程 A，2 号核心绑定了线程 B，线程 A 只会读写变量 A，线程 B 只会读写变量 B。</p><p>②. 1 号核心读取变量 A，由于 CPU 从内存读取数据到 Cache 的单位是 Cache Line，也正好变量 A 和 变量 B 的数据归属于同一个 Cache Line，所以 A 和 B 的数据都会被加载到 Cache，并将此 Cache Line 标记为「独占」状态。</p><p>③. 接着，2 号核心开始从内存里读取变量 B，同样的也是读取 Cache Line 大小的数据到 Cache 中，此 Cache Line 中的数据也包含了变量 A 和 变量 B，此时 1 号和 2 号核心的 Cache Line 状态变为「共享」状态。</p><p>④. 1 号核心需要修改变量 A，发现此 Cache Line 的状态是「共享」状态，所以先需要通过总线发送消息给 2 号核心，通知 2 号核心把 Cache 中对应的 Cache Line 标记为「已失效」状态，然后 1 号核心对应的 Cache Line 状态变成「已修改」状态，并且修改变量 A。</p><p>⑤. 之后，2 号核心需要修改变量 B，此时 2 号核心的 Cache 中对应的 Cache Line 是已失效状态，另外由于 1 号核心的 Cache 也有此相同的数据，且状态为「已修改」状态，所以要先把 1 号核心的 Cache 对应的 Cache Line 写回到内存，然后 2 号核心再从内存读取 Cache Line 大小的数据到 Cache 中，最后把变量 B 修改到 2 号核心的 Cache 中，并将状态标记为「已修改」状态。</p><p>所以，可以发现如果 1 号和 2 号 CPU 核心这样持续交替的分别修改变量 A 和 B，就会重复 ④ 和 ⑤ 这两个步骤，Cache 并没有起到缓存的效果，虽然变量 A 和 B 之间其实并没有任何的关系，但是因为同时归属于一个 Cache Line ，这个 Cache Line 中的任意数据被修改后，都会相互影响，从而出现 ④ 和 ⑤ 这两个步骤。</p><p>因此，这种因为多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象称为<strong>伪共享（False Sharing）</strong>。</p><h4 id="避免伪共享的方法"><a href="#避免伪共享的方法" class="headerlink" title="避免伪共享的方法"></a>避免伪共享的方法</h4><p>因此，对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同一个 Cache Line 中，否则就会出现为伪共享的问题。</p><p>在 Linux 内核中存在 <code>__cacheline_aligned_in_smp</code> 宏定义，是用于解决伪共享的问题。</p><ul><li>如果在多核（MP）系统里，该宏定义是 <code>__cacheline_aligned</code>，也就是 Cache Line 的大小；</li><li>而如果在单核系统里，该宏定义是空的；</li></ul><p>针对在同一个 Cache Line 中的共享的数据，如果在多核之间竞争比较严重，为了防止伪共享现象的发生，可以采用上面的宏定义使得变量在 Cache Line 里是对齐的。</p><p>举个例子，有下面这个结构体：</p><pre><code class="c">struct test &#123;    int a;    int b;&#125;</code></pre><p>结构体里的两个成员变量 a 和 b 在物理内存地址上是连续的，于是它们可能会位于同一个 Cache Line 中</p><p>所以，为了防止前面提到的 Cache 伪共享问题，我们可以使用上面介绍的宏定义，将 b 的地址设置为 Cache Line 对齐地址，如下：</p><pre><code class="c">struct test &#123;    int a;    int b __cacheline_aligned_in_smp;&#125;</code></pre><p>这样 a 和 b 变量就不会在同一个 Cache Line 中了，所以，<strong>避免 Cache 伪共享实际上是用空间换时间的思想</strong>，浪费一部分 Cache 空间，从而换来性能的提升。</p><p>除此之外还可以在结构体中填充一些没有意义的变量，这些变量不会被读写，这样可以减少一个Cache Line中修改操作的数量，从而降低伪共享的概率。</p><h3 id="Linux是怎么进行进程调度的"><a href="#Linux是怎么进行进程调度的" class="headerlink" title="Linux是怎么进行进程调度的"></a>Linux是怎么进行进程调度的</h3><p>在 Linux 内核中，进程和线程都是用 <code>task_struct</code> 结构体表示的，区别在于线程的 task_struct 结构体里部分资源是共享了进程已创建的资源，比如内存地址空间、代码段、文件描述符等，所以 Linux 中的线程也被称为轻量级进程，因为线程的 task_struct 相比进程的 task_struct 承载的 资源比较少，因此以「轻」得名。</p><p>所以，Linux 内核里的调度器，调度的对象就是 <code>task_struct</code>，接下来我们就把这个数据结构统称为<strong>任务</strong>。</p><p>在 Linux 系统中，根据任务的优先级以及响应要求，主要分为两种，其中优先级的数值越小，优先级越高：</p><ul><li>实时任务，对系统的响应时间要求很高，也就是要尽可能快的执行实时任务，优先级在 <code>0~99</code> 范围内的就算实时任务；</li><li>普通任务，响应时间没有很高的要求，优先级在 <code>100~139</code> 范围内都是普通任务级别；</li></ul><h4 id="调度类"><a href="#调度类" class="headerlink" title="调度类"></a>调度类</h4><p>由于任务有优先级之分，Linux 系统为了保障高优先级的任务能够尽可能早的被执行，于是分为了这几种调度类，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/%E8%B0%83%E5%BA%A6%E7%B1%BB.png" alt="img"></p><p>Deadline 和 Realtime 这两个调度类，都是应用于实时任务的，这两个调度类的调度策略合起来共有这三种，它们的作用如下：</p><ul><li><em>SCHED_DEADLINE</em>：是按照 deadline 进行调度的，距离当前时间点最近的 deadline 的任务会被优先调度；</li><li><em>SCHED_FIFO</em>：对于相同优先级的任务，按先来先服务的原则，但是优先级更高的任务，可以抢占低优先级的任务，也就是优先级高的可以「插队」；</li><li><em>SCHED_RR</em>：对于相同优先级的任务，轮流着运行，每个任务都有一定的时间片，当用完时间片的任务会被放到队列尾部，以保证相同优先级任务的公平性，但是高优先级的任务依然可以抢占低优先级的任务；</li></ul><p>而 Fair 调度类是应用于普通任务，都是由 CFS 调度器管理的，分为两种调度策略：</p><ul><li><em>SCHED_NORMAL</em>：普通任务使用的调度策略；</li><li><em>SCHED_BATCH</em>：后台任务的调度策略，不和终端进行交互，因此在不影响其他需要交互的任务，可以适当降低它的优先级。</li></ul><h4 id="CPU-运行队列"><a href="#CPU-运行队列" class="headerlink" title="CPU 运行队列"></a>CPU 运行队列</h4><p>一个系统通常都会运行着很多任务，多任务的数量基本都是远超 CPU 核心数量，因此这时候就需要<strong>排队</strong>。</p><p>事实上，每个 CPU 都有自己的<strong>运行队列（Run Queue, rq）</strong>，用于描述在此 CPU 上所运行的所有进程，其队列包含三个运行队列，Deadline 运行队列 dl_rq、实时任务运行队列 rt_rq 和 CFS 运行队列 csf_rq，<strong>其中 csf_rq 是用红黑树来描述的</strong>，按 vruntime 大小来排序的，最左侧的叶子节点，就是下次会被调度的任务。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/CPU_queue.png" alt="CPU_queue"></p><p>这几种调度类是有优先级的，优先级如下：Deadline &gt; Realtime &gt; Fair，这意味着 Linux 选择下一个任务执行的时候，会按照此优先级顺序进行选择，也就是说先从 <code>dl_rq</code> 里选择任务，然后从 <code>rt_rq</code> 里选择任务，最后从 <code>csf_rq</code> 里选择任务。因此，<strong>实时任务总是会比普通任务优先被执行</strong>。</p><h4 id="完全公平调度"><a href="#完全公平调度" class="headerlink" title="完全公平调度"></a>完全公平调度</h4><p>我们平日里遇到的基本都是普通任务，对于普通任务来说，公平性最重要，在 Linux 里面，实现了一个基于 CFS 的调度算法，也就是<strong>完全公平调度（Completely Fair Scheduling）</strong>。</p><p>这个算法的理念是想让分配给每个任务的 CPU 时间是一样，于是它为每个任务安排一个虚拟运行时间 vruntime，如果一个任务在运行，其运行的越久，该任务的 vruntime 自然就会越大，而没有被运行的任务，vruntime 是不会变化的。</p><p>那么，<strong>在 CFS 算法调度的时候，会优先选择 vruntime 少的任务</strong>，以保证每个任务的公平性。</p><p>这就好比，让你把一桶的奶茶平均分到 10 杯奶茶杯里，你看着哪杯奶茶少，就多倒一些；哪个多了，就先不倒，这样经过多轮操作，虽然不能保证每杯奶茶完全一样多，但至少是公平的。</p><p>当然，上面提到的例子没有考虑到优先级的问题，虽然是普通任务，但是普通任务之间还是有优先级区分的，所以在计算虚拟运行时间 vruntime 还要考虑普通任务的<strong>权重值</strong>，注意权重值并不是优先级的值，内核中会有一个 nice 级别与权重值的转换表，nice 级别越低的权重值就越大，至于 nice 值是什么，我们后面会提到。 于是就有了以下这个公式：</p><p>在「同样的实际运行时间」里，高权重任务的 vruntime 比低权重任务的 vruntime <strong>少</strong>， CFS 调度会优先选择 vruntime 少的任务进行调度，所以高权重的任务就会被优先调度了，于是高权重的获得的实际运行时间自然就多了。</p><h4 id="调整优先级"><a href="#调整优先级" class="headerlink" title="调整优先级"></a>调整优先级</h4><p>如果我们启动任务的时候，没有特意去指定优先级的话，默认情况下都是普通任务，普通任务的调度类是 Fair，由 CFS 调度器来进行管理。CFS 调度器的目的是实现任务运行的公平性，也就是保障每个任务的运行的时间是差不多的。</p><p>如果你想让某个普通任务有更多的执行时间，可以调整任务的 <code>nice</code> 值，从而让优先级高一些的任务执行更多时间。nice 的值能设置的范围是 <code>-20～19</code>， 值越低，表明优先级越高，因此 -20 是最高优先级，19 则是最低优先级，默认优先级是 0。</p><p>是不是觉得 nice 值的范围很诡异？事实上，nice 值并不是表示优先级，而是表示优先级的修正数值，它与优先级（priority）的关系是这样的：priority(new) &#x3D; priority(old) + nice。内核中，priority 的范围是 0<del>139，值越低，优先级越高，其中前面的 0</del>99 范围是提供给实时任务使用的，而 nice 值是映射到 100~139，这个范围是提供给普通任务用的，因此 nice 值调整的是普通任务的优先级。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/priority.png" alt="priority"></p><p>我们可以在启动任务的时候，可以指定 nice 的值，比如将 mysqld 以 -3 优先级：</p><pre><code class="shell">$ nice -n -3 /usr/sbin/mysqld</code></pre><p>如果想修改已经运行中的任务的优先级，则可以使用 <code>renice</code> 来调整 nice 值：</p><pre><code class="shell">$ renice -10 -p &lt;进程pid&gt;</code></pre><p>nice 调整的是普通任务的优先级，所以不管怎么缩小 nice 值，任务永远都是普通任务，如果某些任务要求实时性比较高，那么你可以考虑改变任务的优先级以及调度策略，使得它变成实时任务，比如：</p><pre><code class="shell"># 修改调度策略为 SCHED_FIFO，并且优先级为1$ chrt -f 1 -p 1996</code></pre><h3 id="中断和软中断"><a href="#中断和软中断" class="headerlink" title="中断和软中断"></a>中断和软中断</h3><p>在计算机中，中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。</p><p>中断是一种异步的事件处理机制，可以提高系统的并发处理能力。</p><p>操作系统收到了中断请求，会打断其他进程的运行，所以<strong>中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度地影响。</strong></p><p>而且，中断处理程序在响应中断时，可能还会「临时关闭中断」，这意味着，如果当前中断处理程序没有执行完之前，系统中其他的中断请求都无法被响应，也就说<strong>中断有可能会丢失</strong>，所以<strong>中断处理程序要短且快</strong>。</p><h4 id="什么是软中断？"><a href="#什么是软中断？" class="headerlink" title="什么是软中断？"></a>什么是软中断？</h4><p>前面我们也提到了，中断请求的处理程序应该要短且快，这样才能减少对正常进程运行调度地影响，而且中断处理程序可能会暂时关闭中断，这时如果中断处理程序执行时间过长，可能在还未执行完中断处理程序前，会丢失当前其他设备的中断请求。</p><p>那 Linux 系统<strong>为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」</strong>。</p><ul><li><strong>上半部，对应硬中断，由硬件触发，用来快速处理中断</strong>，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。</li><li><strong>下半部，对应软中断，由内核触发，用来延迟处理上半部未完成的工作</strong>，一般以「内核线程」的方式运行。</li></ul><p>举一个计算机中的例子，常见的网卡接收网络包的例子。</p><p>网卡收到网络包后，会通过<strong>硬件中断</strong>通知内核有新的数据到了，于是内核就会调用对应的中断处理程序来响应该事件，这个事件的处理也是会分成上半部和下半部。</p><p>上部分要做到快速处理，所以只要把网卡的数据读到内存中，然后更新一下硬件寄存器的状态，比如把状态更新为表示数据已经读到内存中的状态值。</p><p>接着，内核会触发一个<strong>软中断</strong>，把一些处理比较耗时且复杂的事情，交给「软中断处理程序」去做，也就是中断的下半部，其主要是需要从内存中找到网络数据，再按照网络协议栈，对网络数据进行逐层解析和处理，最后把数据送给应用程序。</p><p>所以，中断处理程序的上部分和下半部可以理解为：</p><ul><li><strong>上半部直接处理硬件请求，也就是硬中断</strong>，主要是负责耗时短的工作，特点是快速执行；</li><li><strong>下半部是由内核触发，也就说软中断</strong>，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行；</li></ul><p>还有一个区别，硬中断（上半部）是会打断 CPU 正在执行的任务，然后立即执行中断处理程序，而软中断（下半部）是以内核线程的方式执行，并且每一个 CPU 都对应一个软中断内核线程，名字通常为「ksoftirqd&#x2F;CPU 编号」，比如 0 号 CPU 对应的软中断内核线程的名字是 <code>ksoftirqd/0</code></p><p>不过，软中断不只是包括硬件设备中断处理程序的下半部，一些内核自定义事件也属于软中断，比如内核调度等、RCU 锁（内核里常用的一种锁）等</p><p>Linux 中的软中断包括网络收发、定时、调度、RCU 锁等各种类型，可以通过查看 &#x2F;proc&#x2F;softirqs 来观察软中断的累计中断次数情况，如果要实时查看中断次数的变化率，可以使用 watch -d cat &#x2F;proc&#x2F;softirqs 命令。</p><p>每一个 CPU 都有各自的软中断内核线程，我们还可以用 ps 命令来查看内核线程，一般名字在中括号里面到，都认为是内核线程。</p><p>如果在 top 命令发现，CPU 在软中断上的使用率比较高，而且 CPU 使用率最高的进程也是软中断 ksoftirqd 的时候，这种一般可以认为系统的开销被软中断占据了。</p><p>这时我们就可以分析是哪种软中断类型导致的，一般来说都是因为网络接收软中断导致的，如果是的话，可以用 sar 命令查看是哪个网卡的有大量的网络包接收，再用 tcpdump 抓网络包，做进一步分析该网络包的源头是不是非法地址，如果是就需要考虑防火墙增加规则，如果不是，则考虑硬件升级等。</p><h2 id="操作系统结构"><a href="#操作系统结构" class="headerlink" title="操作系统结构"></a>操作系统结构</h2><h3 id="Linux内核和Windows内核的区别"><a href="#Linux内核和Windows内核的区别" class="headerlink" title="Linux内核和Windows内核的区别"></a>Linux内核和Windows内核的区别</h3><p>什么是内核呢？</p><p>计算机是由各种外部硬件设备组成的，比如内存、cpu、硬盘等，如果每个应用都要和这些硬件设备对接通信协议，那这样太累了，所以这个中间人就由内核来负责，<strong>让内核作为应用连接硬件设备的桥梁</strong>，应用程序只需关心与内核交互，不用关心硬件的细节。</p><p>现代操作系统，内核一般会提供 4 个基本能力：</p><ul><li>管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力；</li><li>管理内存，决定内存的分配和回收，也就是内存管理的能力；</li><li>管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力；</li><li>提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。</li></ul><p>内核是怎么工作的？</p><p>内核具有很高的权限，可以控制 cpu、内存、硬盘等硬件，而应用程序具有的权限很小，因此大多数操作系统，把内存分成了两个区域：</p><ul><li>内核空间，这个内存空间只有内核程序可以访问；</li><li>用户空间，这个内存空间专门给应用程序使用；</li></ul><p>用户空间的代码只能访问一个局部的内存空间，而内核空间的代码可以访问所有内存空间。因此，当程序使用用户空间时，我们常说该程序在<strong>用户态</strong>执行，而当程序使内核空间时，程序则在<strong>内核态</strong>执行。</p><p>应用程序如果需要进入内核空间，就需要通过系统调用，下面来看看系统调用的过程：</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/systemcall.png"></p><p>内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。</p><h4 id="Linux的设计"><a href="#Linux的设计" class="headerlink" title="Linux的设计"></a>Linux的设计</h4><p>Linux 内核设计的理念主要有这几个点：</p><ul><li><em>MultiTask</em>，多任务</li><li><em>SMP</em>，对称多处理</li><li><em>ELF</em>，可执行文件链接格式</li><li><em>Monolithic Kernel</em>，宏内核</li></ul><p><strong>ultiTask</strong></p><p>MultiTask 的意思是<strong>多任务</strong>，代表着 Linux 是一个多任务的操作系统。</p><p>多任务意味着可以有多个任务同时执行，这里的「同时」可以是并发或并行：</p><ul><li>对于单核 CPU 时，可以让每个任务执行一小段时间，时间到就切换另外一个任务，从宏观角度看，一段时间内执行了多个任务，这被称为并发。</li><li>对于多核 CPU 时，多个任务可以同时被不同核心的 CPU 同时执行，这被称为并行。</li></ul><p><strong>SMP</strong></p><p>SMP 的意思是<strong>对称多处理</strong>，代表着每个 CPU 的地位是相等的，对资源的使用权限也是相同的，多个 CPU 共享同一个内存，每个 CPU 都可以访问完整的内存和硬件资源。</p><p>这个特点决定了 Linux 操作系统不会有某个 CPU 单独服务应用程序或内核程序，而是每个程序都可以被分配到任意一个 CPU 上被执行。</p><p><strong>ELF</strong></p><p>ELF 的意思是<strong>可执行文件链接格式</strong>，它是 Linux 操作系统中可执行文件的存储格式，你可以从下图看到它的结构：</p><h5 id="为什么栈地址从高到低，堆从低到高"><a href="#为什么栈地址从高到低，堆从低到高" class="headerlink" title="为什么栈地址从高到低，堆从低到高"></a><strong>为什么栈地址从高到低，堆从低到高</strong></h5><p><strong>这样设计可以使得堆和栈能够充分利用空闲的地址空间。</strong>如果栈向上涨的话，我们就必须得指定栈和堆的一个严格分界线，但这个分界线怎么确定呢？平均分？但是有的程序使用的堆空间比较多，而有的程序使用的栈空间比较多。所以就可能出现这种情况：一个程序因为栈溢出而崩溃的时候，其实它还有大量闲置的堆空间，但是我们却无法使用这些闲置的堆空间。所以呢，最好的办法就是让堆和栈一个向上涨，一个向下涨，这样它们就可以最大程度地共用这块剩余的地址空间，达到利用率的最大化。</p><p><strong>Monolithic Kernel</strong></p><p>Monolithic Kernel 的意思是<strong>宏内核</strong>，Linux 内核架构就是宏内核，意味着 <strong>Linux 的内核是一个完整的可执行程序，</strong>且拥有最高的权限。</p><p>宏内核的特征是系统内核的所有模块，比如进程调度、内存管理、文件系统、设备驱动等，都运行在内核态。</p><p>不过，Linux 也实现了动态加载内核模块的功能，例如大部分设备驱动是以可加载模块的形式存在的，与内核其他模块解藕，让驱动开发和驱动加载更为方便、灵活。</p><p>与宏内核相反的是<strong>微内核</strong>，微内核架构的内核只保留最基本的能力，比如进程调度、虚拟机内存、中断等，把一些应用放到了用户空间，比如驱动程序、文件系统等。这样服务与服务之间是隔离的，单个服务出现故障或者完全攻击，也不会导致整个操作系统挂掉，提高了操作系统的稳定性和可靠性。</p><p>微内核内核功能少，可移植性高，相比宏内核有一点不好的地方在于，由于驱动程序不在内核中，而且驱动程序一般会频繁调用底层能力的，于是驱动和硬件设备交互就需要频繁切换到内核态，这样会带来性能损耗。华为的鸿蒙操作系统的内核架构就是微内核。</p><p>还有一种内核叫<strong>混合类型内核</strong>，它的架构有点像微内核，内核里面会有一个最小版本的内核，然后其他模块会在这个基础上搭建，然后实现的时候会跟宏内核类似，也就是把整个内核做成一个完整的程序，大部分服务都在内核中，这就像是宏内核的方式包裹着一个微内核。</p><p><img src="https://pic3.zhimg.com/80/v2-9988d404585168775f779194ec3a53a6_720w.jpg" alt="img"></p><h4 id="Windows的设计"><a href="#Windows的设计" class="headerlink" title="Windows的设计"></a>Windows的设计</h4><p>当今 Windows 7、Windows 10 使用的内核叫 Windows NT，NT 全称叫 New Technology。</p><p>下图是 Windows NT 的结构图片：</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/windowNT.png" alt="Windows NT 的结构"></p><p>Windows 和 Linux 一样，同样支持 MultiTask 和 SMP，但不同的是，<strong>Window 的内核设计是混合型内核</strong>，在上图你可以看到内核中有一个 <em>MicroKernel</em> 模块，这个就是最小版本的内核，而整个内核实现是一个完整的程序，含有非常多模块。</p><p>Windows 的可执行文件的格式与 Linux 也不同，所以这两个系统的可执行文件是不可以在对方上运行的。</p><p>Windows 的可执行文件格式叫 PE，称为<strong>可移植执行文件</strong>，扩展名通常是<code>.exe</code>、<code>.dll</code>、<code>.sys</code>等。</p><h3 id="操作系统概念"><a href="#操作系统概念" class="headerlink" title="操作系统概念"></a>操作系统概念</h3><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/image-20220512235848305.png" alt="image-20220512235848305"></p><p>操作系统定义：给应用程序提供服务的程序。现代操作系统主要是因为<strong>更好的管理和支持多任务执行</strong>的需求而诞生的。</p><p>如果计算机没有操作系统，那么它将不支持多任务的执行。如单片机基本没有操作系统，所以单片机只支持执行单个程序。</p><p>程序并没有直接访问cpu，内存，I&#x2F;O这些硬件设备，真正访问硬件设备的是操作系统。所有程序对硬件的操作都必须通过操作系统来完成。它可以看成是应用程序和硬件之间的一层软件，给程序员提供硬件的抽象。</p><p>这样设计的目的有两个：</p><ol><li>防止硬件被失控的应用程序滥用，提高系统安全性</li><li>提供统一对硬件操作的接口，简化硬件操作</li></ol><p>为了实现这些功能操作系统引入了几个抽象的概念，<strong>抽象就是对外提供统一接口而隐藏内部复杂的细节</strong>，操作系统对于程序来说就是硬件的抽象。</p><p>操作系统将cpu，内存，I&#x2F;O设备抽象为进程；将内存和磁盘I&#x2F;O抽象为虚拟内存；将I&#x2F;O设备抽象为文件的形式。让程序员能够直接通过这层软件很好地调用硬件，避免了过多的硬件细节。</p><h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><h3 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h3><h4 id="什么是虚拟内存"><a href="#什么是虚拟内存" class="headerlink" title="什么是虚拟内存"></a>什么是虚拟内存</h4><p>操作系统为每个进程分配独立的一套「<strong>虚拟地址</strong>」，人人都有，互不干涉。每个进程都不能访问物理地址，虚拟地址最终怎么落到物理内存里对进程来说是透明的，操作系统已经把这些都安排的明明白白了。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/image-20220513215415380.png" alt="image-20220513215415380"></p><p><strong>操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。</strong></p><p>如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。</p><p>于是，这里就引出了两种地址的概念：</p><ul><li>我们程序所使用的内存地址叫做<strong>虚拟内存地址</strong>（<em>Virtual Memory Address</em>）</li><li>实际存在硬件里面的空间地址叫<strong>物理内存地址</strong>（<em>Physical Memory Address</em>）。</li></ul><p>操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存。</p><h4 id="为什么需要虚拟内存"><a href="#为什么需要虚拟内存" class="headerlink" title="为什么需要虚拟内存"></a>为什么需要虚拟内存</h4><p>解决多程序系统中内存分配和管理问题。主要为了隔离地址空间，如果程序可以直接操作物理地址(如单片机)，那么计算机无法同时运行多个程序，因为程序A可能会擦掉程序B的数据，这会导致程序B崩溃。</p><ol><li><strong>解决地址空间不隔离问题</strong>：若所有程序都直接访问物理地址，程序所使用的内存空间不是相互隔离的。程序可以很容易改写其他程序的内存数据，以达到破坏的目的，这对于需要安全稳定的计算环境的用户来说是不能容忍的。用户希望他在使用计算机的时候，其中一个任务失败了，至少不会影响其他任务。</li><li><strong>解决内存使用效率低问题：</strong>如果没有有效的内存管理机制，通常需要一个程序执行时，监控程序就将整个程序装入内存中然后开始执行。而当内存没有程序所需的连续空间时，就不得不将其他程序换出到磁盘，效率十分低下。</li><li><strong>解决程序运行地址不确定问题：</strong>程序每次运行时都要给它在内存中分配一块空闲空间，这个空间位置不确定。这会导致程序编写十分困难，因为程序中访问数据和指令跳转的目标地址很多都是固定的。</li><li><strong>虚拟内存可以使得进程对运行内存超过物理内存大小</strong>，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。</li><li>页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。</li></ol><p>虚拟内存屏蔽了虚拟地址到物理地址的转换过程，让程序看起来就像是在独占地使用内存。</p><h3 id="管理虚拟地址和物理地址的映射"><a href="#管理虚拟地址和物理地址的映射" class="headerlink" title="管理虚拟地址和物理地址的映射"></a>管理虚拟地址和物理地址的映射</h3><h4 id="内存分段"><a href="#内存分段" class="headerlink" title="内存分段"></a>内存分段</h4><h5 id="映射机制"><a href="#映射机制" class="headerlink" title="映射机制"></a>映射机制</h5><p>程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。<strong>不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。</strong></p><p>分段机制下的虚拟地址由两部分组成，<strong>段选择因子</strong>和<strong>段内偏移量</strong>。</p><p><img src="https://img-blog.csdnimg.cn/a9ed979e2ed8414f9828767592aadc21.png" alt="img"></p><p>段选择因子和段内偏移量：</p><ul><li><strong>段选择因子</strong>就保存在段寄存器里面。段选择因子里面最重要的是<strong>段号</strong>，用作段表的索引。<strong>段表</strong>里面保存的是这个<strong>段的基地址、段的界限和特权等级</strong>等。</li><li>虚拟地址中的<strong>段内偏移量</strong>应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。</li></ul><p>在上面，知道了虚拟地址是通过<strong>段表</strong>与物理地址进行映射的，分段机制会把程序的虚拟地址分成多个段(<strong>分段的数量跟段寄存器相关，跟虚拟空间的段无关，图片仅为假设</strong>)，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：</p><p><img src="https://img-blog.csdnimg.cn/c5e2ab63e6ee4c8db575f3c7c9c85962.png" alt="img"></p><h5 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h5><p>分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：</p><ul><li>第一个就是<strong>内存碎片</strong>的问题。</li><li>第二个就是<strong>内存交换的效率低</strong>的问题。</li></ul><p><strong>内存碎片</strong></p><p>内存碎片主要分为，内部内存碎片和外部内存碎片。</p><p>内存分段管理可以做到段根据实际需求分配内存(<strong>除了堆区，需要分配的空间大小在编译时已经确定</strong>)，所以有多少需求就分配多大的段，可以减少内部内存碎片(堆区无法避免内部碎片)。</p><p>但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以<strong>会出现外部内存碎片</strong>的问题。</p><p>解决「外部内存碎片」的问题就是<strong>内存交换</strong>。</p><p>可以把内存碎片写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着连续的空间。这样就能将碎片拼接起来，从而空出大片的连续空间，于是新的程序就可以装载进来。</p><p>这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。</p><p><strong>内存交换的效率低</strong></p><p>对于多进程的系统来说，用分段的方式，外部内存碎片是很容易产生的，产生了外部内存碎片，那不得不重新 <code>Swap</code> 内存区域，这个过程会产生性能瓶颈。</p><p>因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。</p><p>所以，<strong>如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。</strong></p><p>为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页。</p><h4 id="内存分页"><a href="#内存分页" class="headerlink" title="内存分页"></a>内存分页</h4><h5 id="映射机制-1"><a href="#映射机制-1" class="headerlink" title="映射机制"></a>映射机制</h5><p>分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。</p><p>要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是<strong>内存分页</strong>（<em>Paging</em>）。</p><p><strong>分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小</strong>。这样一个连续并且尺寸固定的内存空间，我们叫<strong>页</strong>（<em>Page</em>）。在 Linux 下，每一页的大小为 <code>4KB</code>。</p><p>虚拟地址与物理地址之间通过<strong>页表</strong>来映射，页表是存储在内存里的，<strong>内存管理单元</strong> （<em>MMU</em>）就做将虚拟内存地址转换成物理地址的工作。而当进程访问的虚拟地址没有装入物理内存时，系统会产生一个<strong>缺页异常</strong>，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。</p><p><strong>页表是一个有序数组，占据连续的内存空间</strong>，页表的空间必须预先分配并且按顺序初始化（也就是<strong>页表必须覆盖全部的虚拟内存地址空间</strong>），这主要是利用数组可以随机访问的特性，使得可以在O(1)时间内找到虚拟地址对应的页表项。如果使用其他的映射方法，比如链表之类的数据结构，遍历链表查找页表位置会耗费巨大性能。</p><p>虚拟地址分为两部分，<strong>页号</strong>和<strong>页内偏移</strong>。页号作为页表的索引，<strong>页表</strong>包含物理页每页所在<strong>物理内存的基地址</strong>，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。</p><p><img src="https://img-blog.csdnimg.cn/7884f4d8db4949f7a5bb4bbd0f452609.png" alt="img"></p><p>总结一下，对于一个内存地址转换，其实就是这样三个步骤：</p><ul><li>把虚拟内存地址，切分成页号和偏移量；</li><li>根据页号，从页表里面，查询对应的物理页号；</li><li>直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。</li></ul><p>下面举个例子，虚拟内存中的页通过页表映射为了物理内存中的页，如下图：</p><p><img src="https://img-blog.csdnimg.cn/8f187878c809414ca2486b0b71e8880e.png" alt="img"></p><h5 id="跟分段相比区别"><a href="#跟分段相比区别" class="headerlink" title="跟分段相比区别"></a>跟分段相比区别</h5><p>内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而<strong>采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。</strong></p><p>但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对<strong>内存分页机制会有内部内存碎片</strong>的现象。</p><p>如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为<strong>换出</strong>（<em>Swap Out</em>）。一旦需要的时候，再加载进来，称为<strong>换入</strong>（<em>Swap In</em>）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，<strong>内存交换的效率就相对比较高。</strong></p><p>更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是<strong>只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。</strong></p><h5 id="缺陷-1"><a href="#缺陷-1" class="headerlink" title="缺陷"></a>缺陷</h5><p>有空间上的缺陷。</p><p>因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。</p><p>在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 <code>4MB</code> 的内存来存储页表。</p><p>这 4MB 大小的页表，看起来也不是很大。但是<strong>页表需要连续空间</strong>，连续的4MB就不是一个小数字了。同时每个进程都有自己的虚拟地址空间的，也就说都有自己的页表。</p><p>那么，<code>100</code> 个进程的话，就需要 <code>400MB</code> 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。</p><h5 id="多级页表"><a href="#多级页表" class="headerlink" title="多级页表"></a>多级页表</h5><p>要解决上面的问题，就需要采用一种叫作<strong>多级页表</strong>（<em>Multi-Level Page Table</em>）的解决方案。</p><p>在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 <code>4KB</code> 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。</p><p>我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 <code>1024</code> 个页表（二级页表），每个表（二级页表）中包含 <code>1024</code> 个「页表项」，形成<strong>二级分页</strong>。如下图所示：</p><p><img src="https://img-blog.csdnimg.cn/19296e249b2240c29f9c52be70f611d5.png" alt="img"></p><blockquote><p>你可能会问，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？</p></blockquote><p>当然如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。</p><p>其实我们应该换个角度来看问题，还记得计算机组成原理里面无处不在的<strong>局部性原理</strong>么？</p><p>每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。</p><p>如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但<strong>如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表</strong>。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）&#x3D; <code>0.804MB</code>，这对比单级页表的 <code>4MB</code> 是不是一个巨大的节约？</p><p>那么为什么不分级的页表就做不到这样节约内存呢？</p><p><strong>页表是一个有序数组，占据连续的内存空间</strong>，页表的空间必须预先分配并且按顺序初始化。所以<strong>页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项</strong>（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。</p><p>我们把二级分页再推广到多级页表，就会发现页表占用的内存空间更少了，这一切都要归功于对局部性原理的充分应用。</p><p>对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是：</p><ul><li>全局页目录项 PGD（<em>Page Global Directory</em>）；</li><li>上层页目录项 PUD（<em>Page Upper Directory</em>）；</li><li>中间页目录项 PMD（<em>Page Middle Directory</em>）；</li><li>页表项 PTE（<em>Page Table Entry</em>）；</li></ul><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E5%9B%9B%E7%BA%A7%E5%88%86%E9%A1%B5.png" alt="img"></p><h5 id="TLB"><a href="#TLB" class="headerlink" title="TLB"></a>TLB</h5><p>多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。</p><p>程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。</p><p>我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（<em>Translation Lookaside Buffer</em>） ，通常称为页表缓存、转址旁路缓存、快表等。</p><p>在 CPU 芯片里面，封装了内存管理单元（<em>Memory Management Unit</em>）芯片，它用来完成地址转换和 TLB 的访问与交互。</p><p>有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。</p><p>TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。</p><h4 id="段页式内存管理"><a href="#段页式内存管理" class="headerlink" title="段页式内存管理"></a>段页式内存管理</h4><p>内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为<strong>段页式内存管理</strong>。</p><p>段页式内存管理实现的方式：</p><ul><li>先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；</li><li>接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；</li></ul><p>这样，地址结构就由<strong>段号、段内页号和页内位移</strong>三部分组成。</p><p>用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：</p><p><img src="https://img-blog.csdnimg.cn/8904fb89ae0c49c4b0f2f7b5a0a7b099.png" alt="img"></p><p>段页式地址变换中要得到物理地址须经过三次内存访问：</p><ul><li>第一次访问段表，得到页表起始地址；</li><li>第二次访问页表，得到物理页号；</li><li>第三次将物理页号与页内位移组合，得到物理地址。</li></ul><p>可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。</p><h4 id="Linux内存管理机制"><a href="#Linux内存管理机制" class="headerlink" title="Linux内存管理机制"></a>Linux内存管理机制</h4><p>早期 Intel 的处理器从 80286 开始使用的是段式内存管理。但是很快发现，光有段式内存管理而没有页式内存管理是不够的，这会使它的 X86 系列会失去市场的竞争力。因此，在不久以后的 80386 中就实现了页式内存管理。也就是说，80386 除了完成并完善从 80286 开始的段式内存管理的同时还实现了页式内存管理。</p><p>但是这个 80386 的页式内存管理设计时，没有绕开段式内存管理，而是建立在段式内存管理的基础上，这就意味着，<strong>页式内存管理的作用是在由段式内存管理所映射而成的地址上再加上一层地址映射。</strong></p><p>由于此时由段式内存管理映射而成的地址不再是“物理地址”了，Intel 就称之为“线性地址”（也称虚拟地址）。于是，段式内存管理先将逻辑地址映射成线性地址，然后再由页式内存管理将线性地址映射成物理地址。</p><p><img src="https://img-blog.csdnimg.cn/bc0aaaf379fc4bc8882efd94b9052b64.png" alt="img"></p><p><strong>Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理</strong>。于是 Linux 就把所有段的基地址设为 <code>0</code>，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。</p><p>另外，Linux 系统中虚拟空间分布可分为<strong>用户态</strong>和<strong>内核态</strong>两部分，其中用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区。</p><ul><li>进程在用户态时，只能访问用户空间内存；</li><li>只有进入内核态后，才可以访问内核空间的内存；</li></ul><p>虽然每个进程都各自有独立的虚拟内存，但是<strong>每个虚拟内存中的内核地址，其实关联的都是相同的物理内存</strong>。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。</p><h3 id="malloc是怎么分配内存的"><a href="#malloc是怎么分配内存的" class="headerlink" title="malloc是怎么分配内存的"></a>malloc是怎么分配内存的</h3><p>实际上，malloc() 并不是系统调用，而是 C 库里的函数，用于动态分配内存。</p><p>malloc 申请内存的时候，会有两种方式向操作系统申请堆内存。</p><ul><li>方式一：通过 brk() 系统调用从堆分配内存；</li><li>方式二：通过 mmap() 系统调用在文件映射区域分配内存；</li></ul><p>方式一实现的方式很简单，就是通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间。如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/brk%E7%94%B3%E8%AF%B7.png" alt="img"></p><p>方式二通过 mmap() 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存。如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/mmap%E7%94%B3%E8%AF%B7.png" alt="img"></p><blockquote><p>什么场景下 malloc() 会通过 brk() 分配内存？又是什么场景下通过 mmap() 分配内存？</p></blockquote><p>malloc() 源码里默认定义了一个阈值：</p><ul><li>如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；</li><li>如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；</li></ul><p>注意，不同的 glibc 版本定义的阈值也是不同的。</p><h4 id="malloc-分配的是物理内存吗？"><a href="#malloc-分配的是物理内存吗？" class="headerlink" title="malloc() 分配的是物理内存吗？"></a>malloc() 分配的是物理内存吗？</h4><p>不是的，<strong>malloc() 分配的是虚拟内存</strong>。</p><p>如果分配后的虚拟内存没有被访问的话，是不会将虚拟内存不会映射到物理内存，这样就不会占用物理内存了。</p><p>只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系。</p><h4 id="malloc-1-分配多少内存"><a href="#malloc-1-分配多少内存" class="headerlink" title="malloc(1)分配多少内存"></a>malloc(1)分配多少内存</h4><p>malloc() 在分配内存的时候，并不是老老实实按用户预期申请的字节数来分配内存空间大小，而是<strong>会预分配更大的空间作为内存池</strong>。</p><p>具体会预分配多大的空间，跟 malloc 使用的内存管理器有关系。</p><h4 id="free-释放内存，会归还给操作系统吗？"><a href="#free-释放内存，会归还给操作系统吗？" class="headerlink" title="free 释放内存，会归还给操作系统吗？"></a>free 释放内存，会归还给操作系统吗？</h4><ul><li>malloc 通过 <strong>brk()</strong> 方式申请的内存，free 释放内存的时候，<strong>并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用</strong>；</li><li>malloc 通过 <strong>mmap()</strong> 方式申请的内存，free 释放内存的时候，<strong>会把内存归还给操作系统，内存得到真正的释放</strong>。</li></ul><h4 id="为什么不全部使用-mmap-来分配内存？"><a href="#为什么不全部使用-mmap-来分配内存？" class="headerlink" title="为什么不全部使用 mmap 来分配内存？"></a>为什么不全部使用 mmap 来分配内存？</h4><p>因为向操作系统申请内存，是要通过系统调用的，执行系统调用是要进入内核态的，然后在回到用户态，运行态的切换会耗费不少时间。</p><p>所以，申请内存的操作应该避免频繁的系统调用，如果都用 mmap 来分配内存，等于每次都要执行系统调用。</p><p>另外，因为 mmap 分配的内存每次释放的时候，都会归还给操作系统，于是每次 mmap 分配的虚拟地址都是缺页状态的，然后在第一次访问该虚拟地址的时候，就会触发缺页中断。</p><p>也就是说，<strong>频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大</strong>。</p><p>为了改进这两个问题，malloc 通过 brk() 系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中。</p><p><strong>等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗</strong>。</p><h4 id="为什么不全部使用-brk-来分配？"><a href="#为什么不全部使用-brk-来分配？" class="headerlink" title="为什么不全部使用 brk 来分配？"></a>为什么不全部使用 brk 来分配？</h4><p>前面我们提到通过 brk 从堆空间分配的内存，并不会归还给操作系统，那么我们那考虑这样一个场景。</p><p>如果我们连续申请了 10k，20k，30k 这三片内存，如果 10k 和 20k 这两片释放了，变为了空闲内存空间，如果下次申请的内存小于 30k，那么就可以重用这个空闲内存空间。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/75edee0cb75450e7987a8a482b975bda.png" alt="图片"></p><p>但是如果下次申请的内存大于 30k，没有可用的空闲内存空间，必须向 OS 申请，实际使用内存继续增大。</p><p>因此，随着系统频繁地 malloc 和 free ，尤其对于小块内存，堆内将产生越来越多不可用的碎片。</p><p>所以，malloc 实现中，充分考虑了 brk 和 mmap 行为上的差异及优缺点，默认分配大块内存 (128KB) 才使用 mmap 分配内存空间。</p><h4 id="free-函数只传入一个内存地址，为什么能知道要释放多大的内存？"><a href="#free-函数只传入一个内存地址，为什么能知道要释放多大的内存？" class="headerlink" title="free() 函数只传入一个内存地址，为什么能知道要释放多大的内存？"></a>free() 函数只传入一个内存地址，为什么能知道要释放多大的内存？</h4><p>malloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节。</p><p>这个多出来的 16 字节就是保存了该内存块的元数据，比如有该内存块的大小。这样当执行 free() 函数时，free 会对传入进来的内存地址向左偏移 16 字节，然后从这个 16 字节的分析出当前的内存块的大小，自然就知道要释放多大的内存了。</p><h4 id="ptmalloc、tcmalloc与jemalloc对比分析"><a href="#ptmalloc、tcmalloc与jemalloc对比分析" class="headerlink" title="ptmalloc、tcmalloc与jemalloc对比分析"></a>ptmalloc、tcmalloc与jemalloc对比分析</h4><p>malloc其实就是一个通用的大众货，什么场景下都可以用，<strong>但是什么场景下都可以用就意味着什么场景下都不会有很高的性能</strong>。</p><ol><li><p>现代计算机内存都很大，你是不是可以牺牲内存利用率为代价换取更高的内存归还&#x2F;重用的效率？同时换取更快的分配速度？或许你会发现，你可以比 libc 的  malloc 平均浪费 30%内存的代价换来两倍以上的性能提升，在一些内存分配成为瓶颈的应用中起到积极的作用。</p></li><li><p>比如你可以调整大小内存的比值，libc如果认为 8K以下是小内存，那么你可以不那么认为。</p></li><li><p>比如如果你的系统就是一个单线程的东西，那么你是否能提供开关，完全以单线程的模式进行运作，完全绕过各种锁和针对多核进行的各种冗余操作呢？</p></li><li><p>比如你的机器内存有限，你应用需要耗费大量的内存，那么你可以引入其他机制，以牺牲少量性能为代价，换取更好的内存回收效果和内存利用率。</p></li><li><p>最近分配的对象尽量在线性地址上集中在一起，这样缓存命中高，也不易发生缺页。</p></li><li><p>比如你程序里面某些对象需要被跟踪，你能否直接在分配器上实现对象跟踪机制，跟踪各种泄漏，越界问题？</p></li><li><p>每个内存分配都在寻求最佳的公平，你在乎的公平是什么？</p></li></ol><p><a href="https://www.cyningsun.com/07-07-2018/memory-allocator-contrasts.html">ptmalloc、tcmalloc与jemalloc对比分析 (cyningsun.com)</a></p><h3 id="内存满了会发生什么"><a href="#内存满了会发生什么" class="headerlink" title="内存满了会发生什么"></a>内存满了会发生什么</h3><h4 id="内存分配过程"><a href="#内存分配过程" class="headerlink" title="内存分配过程"></a>内存分配过程</h4><p>应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。</p><p>当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生<strong>缺页中断</strong>，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。</p><p>缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。</p><p>如果没有空闲的物理内存，那么内核就会开始进行<strong>回收内存</strong>的工作，回收的方式主要是两种：直接内存回收和后台内存回收。</p><ul><li><strong>后台内存回收</strong>（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程<strong>异步</strong>的，不会阻塞进程的执行。</li><li><strong>直接内存回收</strong>（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是<strong>同步</strong>的，会阻塞进程的执行。</li></ul><p>如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——<strong>触发 OOM （Out of Memory）机制</strong>。</p><p>OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。</p><h4 id="哪些内存可以回收"><a href="#哪些内存可以回收" class="headerlink" title="哪些内存可以回收"></a>哪些内存可以回收</h4><p>系统内存紧张的时候，就会进行回收内测的工作，那具体哪些内存是可以被回收的呢？</p><p>主要有两类内存可以被回收，而且它们的回收方式也不同。</p><ul><li><strong>文件页</strong>（File-backed Page）：<strong>文件页指用作缓存的数据</strong>。内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，<strong>回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存</strong>。</li><li><strong>匿名页</strong>（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们<strong>回收的方式是通过 Linux 的 Swap 机制</strong>，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。</li></ul><p>文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中：</p><ul><li><strong>active_list</strong> 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；</li><li><strong>inactive_list</strong> 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；</li></ul><p>越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。</p><p>活跃和非活跃的内存页，按照类型的不同，又分别分为文件页和匿名页。可以从 &#x2F;proc&#x2F;meminfo 中，查询它们的大小。</p><h4 id="如何保护一个进程不被-OOM-杀掉"><a href="#如何保护一个进程不被-OOM-杀掉" class="headerlink" title="如何保护一个进程不被 OOM 杀掉"></a>如何保护一个进程不被 OOM 杀掉</h4><p>在系统空闲内存不足的情况，进程申请了一个很大的内存，如果直接内存回收都无法回收出足够大的空闲内存，那么就会触发 OOM 机制，内核就会根据算法选择一个进程杀掉。</p><p>Linux 到底是根据什么标准来选择被杀的进程呢？这就要提到一个在 Linux 内核里有一个 <code>oom_badness()</code> 函数，它会把系统中可以被杀掉的进程扫描一遍，并对每个进程打分，得分最高的进程就会被首先杀掉。</p><pre><code class="c">points = process_pages + oom_score_adj*totalpages/1000</code></pre><p>进程得分的结果受下面这两个方面影响：</p><ul><li>第一，进程已经使用的物理内存页面数。</li><li>第二，每个进程的 OOM 校准值 oom_score_adj。它是可以通过 <code>/proc/[pid]/oom_score_adj</code> 来配置的。我们可以在设置 -1000 到 1000 之间的任意一个数值，调整进程被 OOM Kill 的几率。</li></ul><p><strong>用「系统总的可用页面数」乘以 「OOM 校准值 oom_score_adj」再除以 1000，最后再加上进程已经使用的物理页面数，计算出来的值越大，那么这个进程被 OOM Kill 的几率也就越大</strong>。</p><p>每个进程的 oom_score_adj 默认值都为 0，所以最终得分跟进程自身消耗的内存有关，消耗的内存越大越容易被杀掉。我们可以通过调整 oom_score_adj 的数值，来改成进程的得分结果：</p><ul><li>如果你不想某个进程被首先杀掉，那你可以调整该进程的 oom_score_adj，从而改变这个进程的得分结果，降低该进程被 OOM 杀死的概率。</li><li>如果你想某个进程无论如何都不能被杀掉，那你可以将 oom_score_adj 配置为 -1000。</li></ul><p>我们最好将一些很重要的系统服务的 oom_score_adj 配置为 -1000，比如 sshd，因为这些系统服务一旦被杀掉，我们就很难再登陆进系统了。</p><p>但是，不建议将我们自己的业务程序的 oom_score_adj 设置为 -1000，因为业务程序一旦发生了内存泄漏，而它又不能被杀掉，这就会导致随着它的内存开销变大，OOM killer 不停地被唤醒，从而把其他进程一个个给杀掉。</p><h4 id="在-4GB-物理内存的机器上，申请-8G-内存会怎么样"><a href="#在-4GB-物理内存的机器上，申请-8G-内存会怎么样" class="headerlink" title="在 4GB 物理内存的机器上，申请 8G 内存会怎么样"></a>在 4GB 物理内存的机器上，申请 8G 内存会怎么样</h4><p>32 位操作系统和 64 位操作系统的虚拟地址空间大小是不同的，在 Linux 操作系统中，虚拟地址空间的内部又被分为<strong>内核空间和用户空间</strong>两部分，如下所示：</p><p><img src="https://img-blog.csdnimg.cn/3a6cb4e3f27241d3b09b4766bb0b1124.png" alt="img"></p><p>通过这里可以看出：</p><ul><li><code>32</code> 位系统的内核空间占用 <code>1G</code>，位于最高处，剩下的 <code>3G</code> 是用户空间；</li><li><code>64</code> 位系统的内核空间和用户空间都是 <code>128T</code>，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。</li></ul><p>因为malloc分配的是虚拟内存，跟实际物理内存无关，经过实验得出结论</p><ul><li>在 32 位操作系统，因为进程最大只能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。</li><li>在 64位 位操作系统，因为进程最大只能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。</li></ul><p>在实际使用过程中，如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：</p><ul><li>如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；</li><li>如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；</li></ul><h2 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h2><h3 id="进程"><a href="#进程" class="headerlink" title="进程"></a><strong>进程</strong></h3><p>我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个<strong>运行中的程序，就被称为「进程」（Process）</strong>。</p><p>现在我们考虑有一个会读取硬盘文件数据的程序被执行了，那么当运行到读取文件的指令时，就会去从硬盘读取数据，但是硬盘的读写速度是非常慢的，那么在这个时候，如果 CPU 傻傻的等硬盘返回数据的话，那 CPU 的利用率是非常低的。</p><p>所以，当进程要从硬盘读取数据时，CPU 不需要阻塞等待数据的返回，而是去执行另外的进程。当硬盘数据返回时，CPU 会收到个<strong>中断</strong>，于是 CPU 再继续运行这个进程。</p><p>这种<strong>多个程序、交替执行</strong>的思想，就有 CPU 管理多个进程的初步想法。虽然单核的 CPU 在某一个瞬间，只能运行一个进程。但在 1 秒钟期间，它可能会运行多个进程，这样就产生<strong>并行的错觉</strong>，实际上这是<strong>并发</strong>。</p><p><strong>为什么引入进程：</strong>为了支持和管理多任务并发执行</p><p>一开始操作系统是单道批处理系统，一个作业单独进入内存并独占系统资源，直到运行结束后下一个作业才能进入内存，当作业进行I&#x2F;O操作时，CPU只能处于等待状态，因此，CPU利用率较低。为此需要引入多道程序并发执行。</p><p>进程看起来在独占地使用硬件(而实际在和其他进程分时共享资源)，为程序员屏蔽了多道程序并发执行时进程调度和进程切换的细节。这样程序员就无需考虑程序之间切换所需操作的硬件，这些由操作系统的内核进行管理。</p><h4 id="进程的状态"><a href="#进程的状态" class="headerlink" title="进程的状态"></a>进程的状态</h4><p>在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。</p><ul><li>运行状态（<em>Running</em>）：该时刻进程占用 CPU；</li><li>就绪状态（<em>Ready</em>）：可运行，由于其他进程处于运行状态而暂时停止运行；</li><li>阻塞状态（<em>Blocked</em>）：该进程正在等待某一事件发生（如等待输入&#x2F;输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；</li></ul><p>当然，进程还有另外两个基本状态：</p><ul><li>创建状态（<em>new</em>）：进程正在被创建时的状态；</li><li>结束状态（<em>Exit</em>）：进程正在从系统中消失时的状态；</li></ul><p>如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占用着物理内存就一种浪费物理内存的行为。</p><p>所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。</p><p>那么，就需要一个新的状态，来<strong>描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态</strong>。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。</p><p>另外，挂起状态可以分为两种：</p><ul><li>阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；</li><li>就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；</li></ul><p><strong>导致进程挂起的原因</strong>不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：</p><ul><li>通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。</li><li>用户希望挂起一个程序的执行，比如在 Linux 中用 <code>Ctrl+Z</code> 挂起进程；</li></ul><p>这两种挂起状态加上前面的五种状态，就变成了七种状态变迁，见如下图：</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/process-state.jpg" alt="process-state"></p><h4 id="进程的控制结构"><a href="#进程的控制结构" class="headerlink" title="进程的控制结构"></a>进程的控制结构</h4><p>在操作系统中，是用<strong>进程控制块</strong>（<em>process control block，PCB</em>）数据结构来描述进程的。</p><p><strong>PCB 是进程存在的唯一标识</strong>，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。</p><blockquote><p>PCB 具体包含什么信息呢？</p></blockquote><p><strong>进程描述信息：</strong></p><ul><li>进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；</li><li>用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；</li></ul><p><strong>进程控制和管理信息：</strong></p><ul><li>进程当前状态，如 new、ready、running、waiting 或 blocked 等；</li><li>进程优先级：进程抢占 CPU 时的优先级；</li></ul><p><strong>资源分配清单：</strong></p><ul><li>有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I&#x2F;O 设备信息。</li></ul><p><strong>CPU 相关信息：</strong></p><ul><li>CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。</li></ul><blockquote><p>每个 PCB 是如何组织的呢？</p></blockquote><p>通常是通过<strong>链表</strong>的方式进行组织，把具有<strong>相同状态的进程链在一起，组成各种队列</strong>。比如：</p><ul><li>将所有处于就绪状态的进程链在一起，称为<strong>就绪队列</strong>；</li><li>把所有因等待某事件而处于等待状态的进程链在一起就组成各种<strong>阻塞队列</strong>；</li><li>另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。</li></ul><p>那么，就绪队列和阻塞队列链表的组织形式如下图：</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/PCB-queue.jpg" alt="PCB-queue"></p><p><strong>除了链表的组织方式，还有索引方式</strong>，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。</p><p>一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。</p><h4 id="进程控制"><a href="#进程控制" class="headerlink" title="进程控制"></a>进程控制</h4><p>进程的<strong>创建、终止、阻塞、唤醒</strong>的过程就是进程的控制。</p><p><strong>01 创建进程</strong></p><p>操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。</p><p>创建进程的过程如下：</p><ul><li>申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；</li><li>为该进程分配运行时所必需的资源，比如内存资源；</li><li>将 PCB 插入到就绪队列，等待被调度运行；</li></ul><p><strong>02 终止进程</strong></p><p>进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 <code>kill</code> 掉）。</p><p>当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。</p><p>终止进程的过程如下：</p><ul><li>查找需要终止的进程的 PCB；</li><li>如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；</li><li>如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；</li><li>将该进程所拥有的全部资源都归还给操作系统；</li><li>将其从 PCB 所在队列中删除；</li></ul><p><strong>03 阻塞进程</strong></p><p>当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。</p><p>阻塞进程的过程如下：</p><ul><li>找到将要被阻塞进程标识号对应的 PCB；</li><li>如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；</li><li>将该 PCB 插入到阻塞队列中去；</li></ul><p><strong>04 唤醒进程</strong></p><p>进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。</p><p>如果某进程正在等待 I&#x2F;O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。</p><p>唤醒进程的过程如下：</p><ul><li>在该事件的阻塞队列中找到相应进程的 PCB；</li><li>将其从阻塞队列中移出，并置其状态为就绪状态；</li><li>把该 PCB 插入到就绪队列中，等待调度程序调度；</li></ul><p>进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。</p><h4 id="进程的上下文切换"><a href="#进程的上下文切换" class="headerlink" title="进程的上下文切换"></a>进程的上下文切换</h4><p>CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 <strong>CPU 上下文</strong>。</p><p>CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。</p><p>根据任务的不同，把 CPU 上下文切换分成：<strong>进程上下文切换、线程上下文切换和中断上下文切换</strong>。</p><blockquote><p>进程的上下文切换到底是切换什么呢？</p></blockquote><p>进程是由内核管理和调度的，所以进程的切换只能发生在内核态。</p><p>所以，<strong>进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。</strong></p><p>通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行。</p><blockquote><p>发生进程上下文切换有哪些场景？</p></blockquote><ul><li>为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；</li><li>进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；</li><li>当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；</li><li>当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；</li><li>发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；</li></ul><p>以上，就是发生进程上下文切换的常见场景了。</p><h3 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h3><p><strong>线程是进程当中的一条执行流程。</strong></p><p>同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。</p><p><strong>为什么引入线程：</strong>为了进一步提高并发度，减少多进程的开销(多核CPU可以并行运行程序，多线程可以提高CPU利用率)</p><p>举个例子，假设你要编写一个视频播放器软件，那么该软件功能的核心模块有三个：</p><ul><li>从视频文件当中读取数据；</li><li>对读取的数据进行解压缩；</li><li>把解压缩后的视频数据播放出来；</li></ul><p>对于单进程的实现方式，我想大家都会是以下这个方式：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/14-%E5%8D%95%E7%BA%BF%E7%A8%8Bmp4%E4%BB%A3%E7%A0%81%E5%AE%9E%E4%BE%8B.jpg" alt="单进程实现方式"></p><p>对于单进程的这种方式，存在以下问题：</p><ul><li>播放出来的画面和声音会不连贯，因为当 CPU 能力不够强的时候，<code>Read</code> 的时候可能进程就等在这了，这样就会导致等半天才进行数据解压和播放；</li><li>各个函数之间不是并发执行，影响资源的使用效率；</li></ul><p>那改进成多进程的方式：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/15-%E5%A4%9A%E8%BF%9B%E7%A8%8Bmp4-%E4%BB%A3%E7%A0%81%E5%AE%9E%E4%BE%8B.jpg" alt="多进程实现方式"></p><p>对于多进程的这种方式，依然会存在问题：</p><ul><li>进程之间如何通信，共享数据？</li><li>维护进程的系统开销较大，如创建进程时，分配资源、建立 PCB；终止进程时，回收资源、撤销 PCB；进程切换时，保存当前进程的状态信息；</li></ul><p>那到底如何解决呢？需要有一种新的实体，满足以下特性：</p><ul><li>实体之间可以并发运行；</li><li>实体之间共享相同的地址空间；</li></ul><p>这个新的实体，就是**线程( Thread )**，线程之间可以并发运行且共享相同的地址空间。</p><p>对于，线程相比进程能减少开销，体现在：</p><ul><li>线程的<strong>创建</strong>时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；</li><li>线程的<strong>终止</strong>时间比进程快，因为线程释放的资源相比进程少很多；</li><li>同一个进程内的线程<strong>切换</strong>比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；</li><li>由于同一进程的各线程间共享内存和文件资源，那么在线程之间<strong>通信</strong>的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；</li></ul><p>所以，线程比进程不管是时间效率，还是空间效率都要高。</p><h4 id="线程的上下文切换"><a href="#线程的上下文切换" class="headerlink" title="线程的上下文切换"></a>线程的上下文切换</h4><p>线程与进程最大的区别在于：<strong>线程是调度的基本单位，而进程则是资源拥有的基本单位</strong>。</p><p>所以，所谓操作系统的任务调度，实际上的调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源。</p><p>对于线程和进程，我们可以这么理解：</p><ul><li>当进程只有一个线程时，可以认为进程就等于线程；</li><li>当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；</li></ul><p>另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。</p><blockquote><p>线程上下文切换的是什么？</p></blockquote><p>这还得看线程是不是属于同一个进程：</p><ul><li>当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；</li><li><strong>当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据</strong>；</li></ul><p>所以，线程的上下文切换相比进程，开销要小很多。</p><h4 id="线程的实现"><a href="#线程的实现" class="headerlink" title="线程的实现"></a>线程的实现</h4><p>主要有三种线程的实现方式：</p><ul><li><strong>用户线程（User Thread）</strong>：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；</li><li><strong>内核线程（Kernel Thread）</strong>：在内核中实现的线程，是由内核管理的线程；</li><li><strong>轻量级进程（LightWeight Process）</strong>：在内核中来支持用户线程；</li></ul><p><em>用户线程</em></p><p>用户线程是基于用户态的线程管理库来实现的，那么<strong>线程控制块（Thread Control Block, TCB）</strong> 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。</p><p>所以，<strong>用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。</strong></p><p>用户线程和内核线程存在多对一，一对一，多对多的对应关系</p><p><strong>多对一线程模型</strong>            </p><p>多对一线程模型中，线程的创建、调度、同步的所有细节全部由进程的用户空间线程库来处理。用户态线程的很多操作对内核来说都是透明的，因为不需要内核来接管，这意味不需要内核态和用户态频繁切换。线程的创建、调度、同步处理速度非常快。当然线程的一些其他操作还是要经过内核，如IO读写。这样导致了一个问题：当多线程并发执行时，如果其中一个线程执行IO操作时，内核接管这个操作，如果IO阻塞，用户态的其他线程都会被阻塞，因为这些线程都对应同一个内核调度实体。在多处理器机器上，内核不知道用户态有这些线程，无法把它们调度到其他处理器，也无法通过优先级来调度。这对线程的使用是没有意义的！</p><p><strong>一对一线程模型</strong>            </p><p>一对一模型中，每个用户线程都对应各自的内核调度实体。内核会对每个线程进行调度，可以调度到其他处理器上面。当然由内核来调度的结果就是：线程的每次操作会在用户态和内核态切换。另外，内核为每个线程都映射调度实体，如果系统出现大量线程，会对系统性能有影响。但该模型的实用性还是高于多对一的线程模型。</p><p><strong>多对多线程模型</strong>              </p><p>多对多模型中，结合了1：1和M：1的优点，避免了它们的缺点。每个线程可以拥有多个调度实体，也可以多个线程对应一个调度实体。听起来好像非常完美，但线程的调度需要由内核态和用户态一起来实现。可想而知，多个对象操作一个东西时，肯定要一些其他的同步机制。用户态和内核态的分工合作导致实现该模型非常复杂。NPTL曾经也想使用该模型，但它太复杂，要对内核进行大范围改动，所以还是采用了一对一的模型！！！</p><p>用户线程的<strong>优点</strong>：</p><ul><li>每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；</li><li>用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；</li></ul><p>用户线程的<strong>缺点</strong>：</p><ul><li>由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。</li><li>当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。</li><li>由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢；</li></ul><p><em>内核线程</em></p><p><strong>内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。</strong></p><p>内核线程的<strong>优点</strong>：</p><ul><li>在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；</li><li>分配给线程，多线程的进程获得更多的 CPU 运行时间；</li></ul><p>内核线程的<strong>缺点</strong>：</p><ul><li>在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；</li><li>线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大；</li></ul><p><em>轻量级进程</em></p><p><strong>轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度</strong>。</p><p>在大多数系统中，<strong>LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息</strong>。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。</p><h4 id="Linux线程模型"><a href="#Linux线程模型" class="headerlink" title="Linux线程模型"></a>Linux线程模型</h4><p>Linux刚诞生那时候，还没有“线程”的概念(Linux 2.4及以前的版本)，当然也没办法在操作系统上创建线程。所以，<strong>Linux 2.4内核中不知道什么是“线程”</strong>，只有一个<code>task_struct</code>的数据结构，就是进程。</p><p>后来随着科学技术的发展，大家提出线程的概念，于是，我们希望Linux能加入多线程编程。要修改一个操作系统，是很复杂的事情，特别是当操作系统越来越庞大的时候。怎么才能让Linux支持多线程呢？</p><p>最简单的，就是不去动操作系统的内核，而是写一个函数库来模拟线程。也就是说，我用C写一个函数，比如 create_thread，这个函数最终在Linux的内核里还是去调用了创建进程的函数去创建了一个进程，好了，这个线程，就是用库函数创建的线程，就是所谓的用户级线程了。这是最初始的<code>LinuxThreads</code>。</p><p><code>LinuxThreads</code>与真正的POSIX标准有一些不相容的地方，尤其是在信号处理、进程调度和进程间同步原语方面。<code>LinuxThreads</code>使用信号进行线程之间的通信，必须经过内核，效率较低。</p><p>要提高<code>LinuxThreads</code>的效率很明显需要提供内核支持以及必须重写线程函式库。为了解决这个问题出现了两个互相竞争的项目：一个IBM的组的项目叫做NGPT（Next Generation POSIX Threads，下一代POSIX线程），另一个组是由Red Hat程序员组成的叫做NPTL。2003年中NGPT被放弃。</p><p>NPTL从Linux内核2.6开始它被纳入内核。目前它完全被结合入GNU C 函式库。NPTL的解决方法与LinuxThreads类似，内核看到的首要抽象依然是一个进程，新线程是通过clone()系统调用产生的。但是NPTL需要特殊的内核支持来解决同步的原始类型之间互相竞争的状况。在这种情况下线程必须能够入眠和再复苏。用来完成这个任务的原始类型叫做futex。有了futex后，可在用户态进行线程同步，提高了效率。</p><p>总结：Linux采用的是1:1的线程模型，即一个用户线程对应一个内核线程。同时在Linux看来线程和进程是一样的，在内核中有着同样的数据结构<code>task_struct</code>，只是线程相比进程共享资源更多。</p><h4 id="多线程还是多进程"><a href="#多线程还是多进程" class="headerlink" title="多线程还是多进程"></a><strong>多线程还是多进程</strong></h4><p>多进程模式最大的优点就是稳定性高，因为一个进程崩溃了，不会影响其他进程。著名的Apache最早就是采用多进程模式。</p><p>多进程模式的缺点是创建进程的代价大，在Unix&#x2F;Linux系统下，用<code>fork</code>调用还行，在Windows下创建进程开销巨大；另外，操作系统能同时运行的进程数也是有限的，在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题；进程之间通信的性能也很差。</p><table><thead><tr><th><strong>对比维度</strong></th><th><strong>多进程</strong></th><th><strong>多线程</strong></th><th><strong>总结</strong></th></tr></thead><tbody><tr><td>数据共享、同步</td><td>数据共享复杂，需要用IPC；数据是分开的，同步简单</td><td>因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂</td><td>各有优势</td></tr><tr><td>内存、CPU</td><td>占用内存多，切换复杂，CPU利用率低</td><td>占用内存少，切换简单，CPU利用率高</td><td>线程占优</td></tr><tr><td>创建销毁、切换</td><td>创建销毁、切换复杂，速度慢</td><td>创建销毁、切换简单，速度很快</td><td>线程占优</td></tr><tr><td>编程、调试</td><td>编程简单，调试简单</td><td>编程复杂，调试复杂</td><td>进程占优</td></tr><tr><td>可靠性</td><td>进程间不会互相影响</td><td>一个线程挂掉将导致整个进程挂掉</td><td>进程占优</td></tr><tr><td>分布式</td><td>适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单</td><td>适应于多核分布式</td><td>进程占优</td></tr></tbody></table><p><strong>需要频繁创建销毁的优先用线程</strong></p><p>这种原则最常见的应用就是Web服务器了，来一个连接建立一个线程，断了就销毁线程，要是用进程，创建和销毁的代价是很难承受的</p><p><strong>需要进行大量计算的优先使用线程</strong></p><p>所谓大量计算，当然就是要耗费很多CPU，切换频繁了，这种情况下线程是最合适的。</p><p>这种原则最常见的是图像处理、算法处理。</p><p><strong>强相关的处理用线程，弱相关的处理用进程</strong></p><p>一般的Server需要完成如下任务：消息收发、消息处理。“消息收发”和“消息处理”就是弱相关的任务，而“消息处理”里面可能又分为“消息解码”、“业务处理”，这两个任务相对来说相关性就要强多了。因此“消息收发”和“消息处理”可以分进程设计，“消息解码”、“业务处理”可以分线程设计。</p><p><strong>可能要扩展到多机分布的用进程，多核分布的用线程</strong></p><p>原因请看上面对比。</p><h3 id="进程调度"><a href="#进程调度" class="headerlink" title="进程调度"></a>进程调度</h3><p>在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。</p><p>比如，以下状态的变化都会触发操作系统的调度：</p><ul><li><em>从就绪态 -&gt; 运行态</em>：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行；</li><li><em>从运行态 -&gt; 阻塞态</em>：当进程发生 I&#x2F;O 事件而阻塞时，操作系统必须选择另外一个进程运行；</li><li><em>从运行态 -&gt; 结束态</em>：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；</li></ul><p>另外，如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：</p><ul><li><strong>非抢占式调度算法</strong>挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。</li><li><strong>抢占式调度算法</strong>挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生<strong>时钟中断</strong>，以便把 CPU 控制返回给调度程序进行调度，也就是常说的<strong>时间片机制</strong>。</li></ul><p><strong>调度原则</strong></p><ul><li><strong>CPU 利用率</strong>：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；</li><li><strong>系统吞吐量</strong>：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；</li><li><strong>周转时间</strong>：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；</li><li><strong>等待时间</strong>：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；</li><li><strong>响应时间</strong>：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。</li></ul><h4 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h4><p><strong>先来先服务调度算法</strong></p><p>最简单的一个调度算法，就是非抢占式的<strong>先来先服务（First Come First Serve, FCFS）算法</strong>了。</p><p>顾名思义，先来后到，<strong>每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。</strong></p><p>这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。</p><p><strong>FCFS 对长作业有利，对CPU 繁忙型作业有利，而不适用于 I&#x2F;O 繁忙型作业(I&#x2F;O繁忙需要经常放弃CPU，并重新排队)。</strong></p><p><strong>最短作业优先调度算法</strong></p><p><strong>最短作业优先（Shortest Job First, SJF）调度算法</strong>同样也是顾名思义，它会<strong>优先选择运行时间最短的进程来运行</strong>，这有助于提高系统的吞吐量。</p><p>这显然对长作业不利，很容易造成一种极端现象。</p><p>比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。</p><p><strong>高响应比优先调度算法</strong></p><p>前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。</p><p>那么，<strong>高响应比优先 （Highest Response Ratio Next, HRRN）调度算法</strong>主要是权衡了短作业和长作业。</p><p><strong>每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行</strong>，「响应比优先级」的计算公式：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/26-%E5%93%8D%E5%BA%94%E6%AF%94%E5%85%AC%E5%BC%8F.jpg" alt="img"></p><p>从上面的公式，可以发现：</p><ul><li>如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；</li><li>如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；</li></ul><p><strong>因为进程要求服务时间不可预估，所以高响应比优先调度算法是「理想型」的调度算法，现实中是实现不了的。</strong></p><p><strong>时间片轮转调度算法</strong></p><p>最古老、最简单、最公平且使用最广的算法就是<strong>时间片轮转（Round Robin, RR）调度算法</strong>。</p><p><strong>每个进程被分配一个时间段，称为时间片（*Quantum*），即允许该进程在该时间段中运行。</strong></p><ul><li>如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；</li><li>如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；</li></ul><p>另外，时间片的长度就是一个很关键的点：</p><ul><li>如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；</li><li>如果设得太长又可能引起对短作业进程的响应时间变长。将</li></ul><p>一般来说，时间片设为 <code>20ms~50ms</code> 通常是一个比较合理的折中值。</p><p><strong>最高优先级调度算法</strong></p><p>前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。</p><p>但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能<strong>从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法</strong>。</p><p>进程的优先级可以分为，静态优先级和动态优先级：</p><ul><li>静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；</li><li>动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是<strong>随着时间的推移增加等待进程的优先级</strong>。</li></ul><p>该算法也有两种处理优先级高的方法，非抢占式和抢占式：</p><ul><li>非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。</li><li>抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。</li></ul><p>但是依然有缺点，可能会导致低优先级的进程永远不会运行。</p><p><strong>多级反馈队列调度算法</strong></p><p><strong>多级反馈队列（Multilevel Feedback Queue）调度算法</strong>是「时间片轮转算法」和「最高优先级算法」的综合和发展。</p><p>顾名思义：</p><ul><li>「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。</li><li>「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；</li></ul><p>来看看，它是如何工作的：</p><ul><li>设置了多个队列，赋予每个队列不同的优先级，每个<strong>队列优先级从高到低</strong>，同时<strong>优先级越高时间片越短</strong>；</li><li>新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；</li><li>当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行</li></ul><p>可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的<strong>兼顾了长短作业，同时有较好的响应时间。</strong></p><h3 id="进程通信"><a href="#进程通信" class="headerlink" title="进程通信"></a>进程通信</h3><p>每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。</p><h4 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h4><p>如果你学过 Linux 命令，那你肯定很熟悉「<code>|</code>」这个竖线。</p><pre><code class="bash">$ ps auxf | grep mysql</code></pre><p>上面命令行里的「<code>|</code>」竖线就是一个<strong>管道</strong>，它的功能是将前一个命令（<code>ps auxf</code>）的输出，作为后一个命令（<code>grep mysql</code>）的输入，从这功能描述，可以看出<strong>管道传输数据是单向的</strong>，如果想相互通信，我们需要创建两个管道才行。</p><p>同时，我们得知上面这种管道是没有名字，所以「<code>|</code>」表示的管道称为<strong>匿名管道</strong>，用完了就销毁。</p><p>管道还有另外一个类型是<strong>命名管道</strong>，也被叫做 <code>FIFO</code>，因为数据是先进先出的传输方式。</p><p>在使用命名管道前，先需要通过 <code>mkfifo</code> 命令来创建，并且指定管道名字：</p><pre><code class="bash">$ mkfifo myPipe</code></pre><p>基于 Linux 一切皆文件的理念，所以管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思。</p><p>接下来，我们往 myPipe 这个管道写入数据：</p><pre><code class="bash">$ echo &quot;hello&quot; &gt; myPipe  // 将数据写进管道                         // 停住了 ...</code></pre><p>你操作了后，你会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。</p><p>于是，我们执行另外一个命令来读取这个管道里的数据：</p><pre><code class="bash">$ cat &lt; myPipe  // 读取管道里的数据hello</code></pre><p>可以看到，管道里的内容被读取出来了，并打印在了终端上，另外一方面，echo 那个命令也正常退出了。</p><p>我们可以看出，<strong>管道这种通信方式效率低，不适合进程间频繁地交换数据</strong>。当然，它的好处，自然就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了。</p><h5 id="匿名管道创建原理"><a href="#匿名管道创建原理" class="headerlink" title="匿名管道创建原理"></a>匿名管道创建原理</h5><p>匿名管道的创建，需要通过下面这个系统调用：</p><pre><code class="c">int pipe(int fd[2])</code></pre><p>这里表示创建一个匿名管道，并返回了两个描述符，一个是管道的读取端描述符 <code>fd[0]</code>，另一个是管道的写入端描述符 <code>fd[1]</code>。注意，这个匿名管道是特殊的文件，只存在于内存，不存于文件系统中。</p><p>其实，<strong>所谓的管道，就是内核里面的一串缓存</strong>。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，<strong>管道传输的数据是无格式的流且大小受限</strong>。</p><p>看到这，你可能会有疑问了，这两个描述符都是在一个进程里面，并没有起到进程间通信的作用，怎么样才能使得管道是跨过两个进程的呢？</p><p>我们可以使用 <code>fork</code> 创建子进程，<strong>创建的子进程会复制父进程的文件描述符</strong>，这样就做到了两个进程各有两个「 <code>fd[0]</code> 与 <code>fd[1]</code>」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了。</p><p>管道只能一端写入，另一端读出，所以上面这种模式容易造成混乱，因为父进程和子进程都可以同时写入，也都可以读出。那么，<strong>为了避免这种情况，通常的做法是：</strong></p><ul><li>父进程关闭读取的 fd[0]，只保留写入的 fd[1]；</li><li>子进程关闭写入的 fd[1]，只保留读取的 fd[0]；</li></ul><p>所以说如果需要双向通信，则应该创建两个管道。</p><p>到这里，我们仅仅解析了使用管道进行父进程与子进程之间的通信，但是在我们 shell 里面并不是这样的。在 shell 里面执行 <code>A | B</code>命令的时候，A 进程和 B 进程都是 shell 创建出来的子进程，A 和 B 之间不存在父子关系，它俩的父进程都是 shell。</p><p>所以说，在 shell 里通过「<code>|</code>」匿名管道将多个命令连接在一起，实际上也就是创建了多个子进程，那么在我们编写 shell 脚本时，能使用一个管道搞定的事情，就不要多用一个管道，这样可以减少创建子进程的系统开销。</p><p>我们可以得知，<strong>对于匿名管道，它的通信范围是存在父子关系的进程</strong>。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。</p><p>另外，<strong>对于命名管道，它可以在不相关的进程间也能相互通信</strong>。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。</p><p>不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循<strong>先进先出</strong>原则，不支持 lseek 之类的文件定位操作。</p><h4 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h4><p>前面说到管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。</p><p>对于这个问题，<strong>消息队列</strong>的通信模式就可以解决。比如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。</p><p>再来，<strong>消息队列是保存在内核中的消息链表</strong>，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。<strong>消息队列</strong>克服了管道通信的数据是无格式的字节流的问题</p><p><strong>消息队列生命周期随内核</strong>，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的<strong>匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。</strong></p><p>消息这种模型，两个进程之间的通信就像平时发邮件一样，你来一封，我回一封，可以频繁沟通了。</p><p>但邮件的通信方式存在不足的地方有两点，<strong>一是通信不及时，二是附件也有大小限制</strong>，这同样也是消息队列通信不足的点。</p><p><strong>消息队列不适合比较大数据的传输</strong>，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 <code>MSGMAX</code> 和 <code>MSGMNB</code>，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。</p><p><strong>消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销</strong>，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。</p><h4 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h4><p>消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那<strong>共享内存</strong>的方式，就很好的解决了这一问题。</p><p>现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。</p><p><strong>共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中</strong>。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。</p><h4 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h4><p>用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。</p><p>为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，<strong>信号量</strong>就实现了这一保护机制。</p><p><strong>信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据</strong>。</p><p>信号量表示资源的数量，控制信号量的方式有两种原子操作：</p><ul><li>一个是 <strong>P 操作</strong>，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;&#x3D; 0，则表明还有资源可使用，进程可正常继续执行。</li><li>另一个是 <strong>V 操作</strong>，这个操作会把信号量加上 1，相加后如果信号量 &lt;&#x3D; 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程；</li></ul><p>P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。</p><p>信号初始化为 <code>1</code>，就代表着是<strong>互斥信号量</strong>，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。</p><p>信号初始化为 <code>0</code>，就代表着是<strong>同步信号量</strong>，它可以保证进程 A 应在进程 B 之前执行。</p><h4 id="信号"><a href="#信号" class="headerlink" title="信号"></a>信号</h4><p>上面说的进程间通信，都是常规状态下的工作模式。<strong>对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。</strong></p><p>信号跟信号量虽然名字相似度 66.66%，但两者用途完全不一样，就好像 Java 和 JavaScript 的区别。</p><p>在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 <code>kill -l</code> 命令，查看所有的信号。</p><p>运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如</p><ul><li>Ctrl+C 产生 <code>SIGINT</code> 信号，表示终止该进程；</li><li>Ctrl+Z 产生 <code>SIGTSTP</code> 信号，表示停止该进程，但还未结束；</li></ul><p>如果进程在后台运行，可以通过 <code>kill</code> 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如：</p><ul><li>kill -9 1050 ，表示给 PID 为 1050 的进程发送 <code>SIGKILL</code> 信号，用来立即结束该进程；</li></ul><p>所以，<strong>信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）</strong>。</p><p>信号是进程间通信机制中<strong>唯一的异步通信机制</strong>，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。</p><p><strong>1.执行默认操作</strong>。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。</p><p><strong>2.捕捉信号</strong>。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。</p><p><strong>3.忽略信号</strong>。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 <code>SIGKILL</code> 和 <code>SEGSTOP</code>，它们用于在任何时候中断或结束某一进程。</p><h4 id="socket"><a href="#socket" class="headerlink" title="socket"></a>socket</h4><p>前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想<strong>跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。</strong></p><p>实际上，Socket 通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。</p><h3 id="多线程冲突"><a href="#多线程冲突" class="headerlink" title="多线程冲突"></a>多线程冲突</h3><p>在进程&#x2F;线程并发执行的过程中，进程&#x2F;线程之间存在协作的关系，例如有互斥、同步的关系。</p><p>为了实现进程&#x2F;线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：</p><ul><li><em>锁</em>：加锁、解锁操作；</li><li><em>信号量</em>：P、V 操作；</li></ul><p>这两个都可以方便地实现进程&#x2F;线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程&#x2F;线程同步。</p><h4 id="锁"><a href="#锁" class="headerlink" title="锁"></a><strong>锁</strong></h4><p>使用加锁操作和解锁操作可以解决并发线程&#x2F;进程的互斥问题。</p><p>任何想进入临界区的线程，必须先执行加锁操作。若加锁操作顺利通过，则线程可进入临界区；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。</p><p>根据锁的实现不同，可以分为「忙等待锁」和「无忙等待锁」。</p><h5 id="忙等待锁"><a href="#忙等待锁" class="headerlink" title="忙等待锁"></a>忙等待锁</h5><p>在说明「忙等待锁」的实现之前，先介绍现代 CPU 体系结构提供的特殊<strong>原子操作指令 —— 测试和置位（Test-and-Set）指令</strong>。</p><p>如果用 C 代码表示 Test-and-Set 指令，形式如下：</p><pre><code class="c">int TestAndSet(int *old_ptr, int new)&#123;    int old = *old_ptr;    *old_ptr = new;    return old;&#125;</code></pre><p>测试并设置指令做了下述事情:</p><ul><li>把 <code>old_ptr</code> 更新为 <code>new</code> 的新值</li><li>返回 <code>old_ptr</code> 的旧值；</li></ul><p>当然，<strong>关键是这些代码是原子执行</strong>。因为既可以测试旧值，又可以设置新值，所以我们把这条指令叫作「测试并设置」。</p><p>我们可以运用 Test-and-Set 指令来实现「忙等待锁」，代码如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/14-%E8%87%AA%E6%97%8B%E9%94%81.jpg" alt="img"></p><p>我们来确保理解为什么这个锁能工作：</p><ul><li>第一个场景是，首先假设一个线程在运行，调用 <code>lock()</code>，没有其他线程持有锁，所以 <code>flag</code> 是 0。当调用 <code>TestAndSet(flag, 1)</code> 方法，返回 0，线程会跳出 while 循环，获取锁。同时也会原子的设置 flag 为1，标志锁已经被持有。当线程离开临界区，调用 <code>unlock()</code> 将 <code>flag</code> 清理为 0。</li><li>第二种场景是，当某一个线程已经持有锁（即 <code>flag</code> 为1）。本线程调用 <code>lock()</code>，然后调用 <code>TestAndSet(flag, 1)</code>，这一次返回 1。只要另一个线程一直持有锁，<code>TestAndSet()</code> 会重复返回 1，本线程会一直<strong>忙等</strong>。当 <code>flag</code> 终于被改为 0，本线程会调用 <code>TestAndSet()</code>，返回 0 并且原子地设置为 1，从而获得锁，进入临界区。</li></ul><p>很明显，当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为<strong>自旋锁（spin lock）</strong>。</p><p>这是最简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。在单处理器上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。</p><h5 id="无等待锁"><a href="#无等待锁" class="headerlink" title="无等待锁"></a>无等待锁</h5><p>无等待锁顾名思义就是获取不到锁的时候，不用自旋。<br>既然不想自旋，那当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/15-%E6%97%A0%E7%AD%89%E5%BE%85%E9%94%81.jpg" alt="img"></p><h5 id="常见的锁"><a href="#常见的锁" class="headerlink" title="常见的锁"></a>常见的锁</h5><p>接下来，针对不同的应用场景，谈一谈「<strong>互斥锁、自旋锁、读写锁、乐观锁、悲观锁</strong>」的选择和使用。</p><p><strong>互斥锁与自旋锁</strong></p><p>最底层的两种就是会「互斥锁和自旋锁」，有很多高级的锁都是基于它们实现的，你可以认为它们是各种锁的地基，所以我们必须清楚它俩之间的区别和应用。</p><p>加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。</p><p>当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：</p><ul><li><strong>互斥锁</strong>加锁失败后，线程会<strong>释放 CPU</strong> ，给其他线程；</li><li><strong>自旋锁</strong>加锁失败后，线程会<strong>忙等待</strong>，直到它拿到锁；</li></ul><p>互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，<strong>既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞</strong>。</p><p><strong>对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的</strong>。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。</p><p>所以，互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。</p><p>那这个开销成本是什么呢？会有<strong>两次线程上下文切换的成本</strong>：</p><ul><li>当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行；</li><li>接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。</li></ul><p>所以，<strong>如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。</strong></p><p>自旋锁是通过 CPU 提供的 <code>CAS</code> 函数（<em>Compare And Swap</em>），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。</p><p>一般加锁的过程，包含两个步骤：</p><ul><li>第一步，查看锁的状态，如果锁是空闲的，则执行第二步；</li><li>第二步，将锁设置为当前线程持有；</li></ul><p>CAS 函数就把这两个步骤合并成一条硬件级指令，形成<strong>原子指令</strong>，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。</p><p>自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。<strong>需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。</strong></p><p>自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系，我们需要清楚的知道这一点。</p><p>自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：<strong>当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对</strong>。</p><p>它俩是锁的最基本处理方式，<strong>更高级的锁都会选择其中一个来实现，比如读写锁既可以选择互斥锁实现，也可以基于自旋锁实现</strong>。</p><p><strong>读写锁</strong></p><p>读写锁从字面意思我们也可以知道，它由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。</p><p>所以，<strong>读写锁适用于能明确区分读操作和写操作的场景</strong>。</p><p>读写锁的工作原理是：</p><ul><li>当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。</li><li>但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。</li></ul><p>所以说，写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有。</p><p>知道了读写锁的工作原理后，我们可以发现，<strong>读写锁在读多写少的场景，能发挥出优势</strong>。</p><p>另外，根据实现的不同，读写锁可以分为「读优先锁」和「写优先锁」。</p><p>读优先锁期望的是，读锁能被更多的线程持有，以便提高读线程的并发性，它的工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取写锁。</p><p>而「写优先锁」是优先服务写线程，其工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，这样只要读线程 A 释放读锁后，写线程 B 就可以成功获取写锁。</p><p>读优先锁对于读线程并发性更好，但也不是没有问题。我们试想一下，如果一直有读线程获取读锁，那么写线程将永远获取不到写锁，这就造成了写线程「饥饿」的现象。</p><p>写优先锁可以保证写线程不会饿死，但是如果一直有写线程获取写锁，读线程也会被「饿死」。</p><p>既然不管优先读锁还是写锁，对方可能会出现饿死问题，那么我们就不偏袒任何一方，搞个「公平读写锁」。</p><p><strong>公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。</strong></p><p>互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。</p><p><strong>乐观锁与悲观锁</strong></p><p>前面提到的互斥锁、自旋锁、读写锁，都是属于悲观锁。</p><p>悲观锁做事比较悲观，它认为<strong>多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁</strong>。</p><p>那相反的，如果多线程同时修改共享资源的概率比较低，就可以采用乐观锁。</p><p>乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：<strong>先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作</strong>。</p><p>可见，乐观锁的心态是，不管三七二十一，先改了资源再说。另外，你会发现<strong>乐观锁全程并没有加锁，所以它也叫无锁编程</strong>。</p><p>这里举一个场景例子：在线文档。</p><p>我们都知道在线文档可以同时多人编辑的，如果使用了悲观锁，那么只要有一个用户正在编辑文档，此时其他用户就无法打开相同的文档了，这用户体验当然不好了。</p><p>那实现多人同时编辑，实际上是用了乐观锁，它允许多个用户打开同一个文档进行编辑，编辑完提交之后才验证修改的内容是否有冲突。</p><p>服务端要怎么验证是否冲突了呢？通常方案如下：</p><ul><li>由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号；</li><li>当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号一致则修改成功，否则提交失败。</li></ul><p>实际上，我们常见的 SVN 和 Git 也是用了乐观锁的思想，先让用户编辑代码，然后提交的时候，通过版本号来判断是否产生了冲突，发生了冲突的地方，需要我们自己修改后，再重新提交。</p><p>乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以<strong>只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。</strong></p><h4 id="信号量-1"><a href="#信号量-1" class="headerlink" title="信号量"></a>信号量</h4><p>信号量是操作系统提供的一种协调共享资源访问的方法。</p><p>通常<strong>信号量表示资源的数量</strong>，对应的变量是一个整型（<code>sem</code>）变量。</p><p>另外，还有<strong>两个原子操作的系统调用函数来控制信号量的</strong>，分别是：</p><ul><li><em>P 操作</em>：将 <code>sem</code> 减 <code>1</code>，相减后，如果 <code>sem &lt; 0</code>，则进程&#x2F;线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；</li><li><em>V 操作</em>：将 <code>sem</code> 加 <code>1</code>，相加后，如果 <code>sem &lt;= 0</code>，唤醒一个等待中的进程&#x2F;线程，表明 V 操作不会阻塞；</li></ul><p>P 操作是用在进入临界区之前，V 操作是用在离开临界区之后，这两个操作是必须成对出现的。</p><blockquote><p>操作系统是如何实现 PV 操作的呢？</p></blockquote><p>信号量数据结构与 PV 操作的算法描述如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/17-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9FPV%E7%AE%97%E6%B3%95%E6%8F%8F%E8%BF%B0.jpg" alt="PV 操作的算法描述"></p><p>PV 操作的函数是由操作系统管理和实现的，所以操作系统已经使得执行 PV 函数时是具有原子性的。</p><h4 id="生产者消费者问题"><a href="#生产者消费者问题" class="headerlink" title="生产者消费者问题"></a>生产者消费者问题</h4><p>生产者-消费者问题描述：</p><ul><li><strong>生产者</strong>在生成数据后，放在一个缓冲区中；</li><li><strong>消费者</strong>从缓冲区取出数据处理；</li><li>任何时刻，<strong>只能有一个</strong>生产者或消费者可以访问缓冲区；</li></ul><p>我们对问题分析可以得出：</p><ul><li>任何时刻只能有一个线程操作缓冲区，说明操作缓冲区是临界代码，<strong>需要互斥</strong>；</li><li>缓冲区空时，消费者必须等待生产者生成数据；缓冲区满时，生产者必须等待消费者取出数据。说明生产者和消费者<strong>需要同步</strong>。</li></ul><p>那么我们需要三个信号量，分别是：</p><ul><li>互斥信号量 <code>mutex</code>：用于互斥访问缓冲区，初始化值为 1；</li><li>资源信号量 <code>fullBuffers</code>：用于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0（表明缓冲区一开始为空）；</li><li>资源信号量 <code>emptyBuffers</code>：用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为 n （缓冲区大小）；</li></ul><h4 id="哲学家就餐问题"><a href="#哲学家就餐问题" class="headerlink" title="哲学家就餐问题"></a>哲学家就餐问题</h4><p>先来看看哲学家就餐的问题描述：</p><ul><li><code>5</code> 个老大哥哲学家，闲着没事做，围绕着一张圆桌吃面；</li><li>巧就巧在，这个桌子只有 <code>5</code> 支叉子，每两个哲学家之间放一支叉子；</li><li>哲学家围在一起先思考，思考中途饿了就会想进餐；</li><li><strong>奇葩的是，这些哲学家要两支叉子才愿意吃面，也就是需要拿到左右两边的叉子才进餐</strong>；</li><li><strong>吃完后，会把两支叉子放回原处，继续思考</strong>；</li></ul><p>那么问题来了，如何保证哲 学家们的动作有序进行，而不会出现有人永远拿不到叉子呢？</p><blockquote><p>方案一</p></blockquote><p>我们用信号量的方式，也就是 PV 操作来尝试解决它，哲学家先拿左边叉子，再拿右边叉子，拿完两个叉子后进餐，吃完之后放回叉子。</p><p>不过，这种解法存在一个极端的问题：<strong>假设五位哲学家同时拿起左边的叉子，桌面上就没有叉子了， 这样就没有人能够拿到他们右边的叉子，也就说每一位哲学家都会在 <code>P(fork[(i + 1) % N ])</code> 这条语句阻塞了，很明显这发生了死锁的现象</strong>。</p><blockquote><p>方案二</p></blockquote><p>既然「方案一」会发生同时竞争左边叉子导致死锁的现象，那么我们就在拿叉子前，加个互斥信号量，代码如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/26-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90-%E6%96%B9%E6%A1%88%E4%BA%8C%E7%A4%BA%E4%BE%8B.jpg" alt="img"></p><p>上面程序中的互斥信号量的作用就在于，<strong>只要有一个哲学家进入了「临界区」，也就是准备要拿叉子时，其他哲学家都不能动，只有这位哲学家用完叉子了，才能轮到下一个哲学家进餐。</strong></p><p>方案二虽然能让哲学家们按顺序吃饭，但是每次进餐只能有一位哲学家，而桌面上是有 5 把叉子，按道理是能可以有两个哲学家同时进餐的，所以从效率角度上，这不是最好的解决方案。</p><blockquote><p>方案三</p></blockquote><p>那既然方案二使用互斥信号量，会导致只能允许一个哲学家就餐，那么我们就不用它。</p><p>另外，方案一的问题在于，会出现所有哲学家同时拿左边刀叉的可能性，那我们就避免哲学家可以同时拿左边的刀叉，采用分支结构，根据哲学家的编号的不同，而采取不同的动作。</p><p><strong>即让偶数编号的哲学家「先拿左边的叉子后拿右边的叉子」，奇数编号的哲学家「先拿右边的叉子后拿左边的叉子」。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/28-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90-%E6%96%B9%E6%A1%88%E4%B8%89%E7%A4%BA%E4%BE%8B.jpg" alt="img"></p><p>上面的程序，在 P 操作时，根据哲学家的编号不同，拿起左右两边叉子的顺序不同。另外，V 操作是不需要分支的，因为 V 操作是不会阻塞的。</p><p>方案三即不会出现死锁，也可以两人同时进餐。</p><blockquote><p>方案四</p></blockquote><p>在这里再提出另外一种可行的解决方案，我们<strong>用一个数组 state 来记录每一位哲学家的三个状态，分别是在进餐状态、思考状态、饥饿状态（正在试图拿叉子）。</strong></p><p>那么，<strong>一个哲学家只有在两个邻居都没有进餐时，才可以进入进餐状态。</strong></p><p>第 <code>i</code> 个哲学家的左邻右舍，则由宏 <code>LEFT</code> 和 <code>RIGHT</code> 定义：</p><ul><li><em>LEFT</em> : ( i + 5 - 1 ) % 5</li><li><em>RIGHT</em> : ( i + 1 ) % 5</li></ul><p>比如 i 为 2，则 <code>LEFT</code> 为 1，<code>RIGHT</code> 为 3。</p><p>具体代码实现如下：<br><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/30-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90-%E6%96%B9%E6%A1%88%E5%9B%9B%E7%A4%BA%E4%BE%8B.jpg" alt="img"></p><p>上面的程序使用了一个信号量数组，每个信号量对应一位哲学家，这样在所需的叉子被占用时，想进餐的哲学家就被阻塞。</p><p>注意，每个进程&#x2F;线程将 <code>smart_person</code> 函数作为主代码运行，而其他 <code>take_forks</code>、<code>put_forks</code> 和 <code>test</code> 只是普通的函数，而非单独的进程&#x2F;线程。</p><p>方案四同样不会出现死锁，也可以两人同时进餐。</p><h4 id="读者-写者问题"><a href="#读者-写者问题" class="headerlink" title="读者-写者问题"></a>读者-写者问题</h4><p>前面的「哲学家进餐问题」对于互斥访问有限的竞争问题（如 I&#x2F;O 设备）一类的建模过程十分有用。</p><p>另外，还有个著名的问题是「读者-写者」，它为数据库访问建立了一个模型。</p><p>读者只会读取数据，不会修改数据，而写者即可以读也可以修改数据。</p><p>读者-写者的问题描述：</p><ul><li>「读-读」允许：同一时刻，允许多个读者同时读</li><li>「读-写」互斥：没有写者时读者才能读，没有读者时写者才能写</li><li>「写-写」互斥：没有其他写者时，写者才能写</li></ul><p>接下来，提出几个解决方案来分析分析。</p><blockquote><p>方案一</p></blockquote><p>使用信号量的方式来尝试解决：</p><ul><li>信号量 <code>wMutex</code>：控制写操作的互斥信号量，初始值为 1 ；</li><li>读者计数 <code>rCount</code>：正在进行读操作的读者个数，初始化为 0；</li><li>信号量 <code>rCountMutex</code>：控制对 rCount 读者计数器的互斥修改，初始值为 1；</li></ul><p>接下来看看代码的实现：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/32-%E8%AF%BB%E8%80%85%E5%86%99%E8%80%85-%E6%96%B9%E6%A1%88%E4%B8%80%E7%A4%BA%E4%BE%8B.jpg" alt="img"></p><p>上面的这种实现，是读者优先的策略，因为只要有读者正在读的状态，后来的读者都可以直接进入，如果读者持续不断进入，则写者会处于饥饿状态。</p><blockquote><p>方案二</p></blockquote><p>那既然有读者优先策略，自然也有写者优先策略：</p><ul><li>只要有写者准备要写入，写者应尽快执行写操作，后来的读者就必须阻塞；</li><li>如果有写者持续不断写入，则读者就处于饥饿；</li></ul><p>在方案一的基础上新增如下变量：</p><ul><li>信号量 <code>rMutex</code>：控制读者进入的互斥信号量，初始值为 1；</li><li>信号量 <code>wDataMutex</code>：控制写者写操作的互斥信号量，初始值为 1；</li><li>写者计数 <code>wCount</code>：记录写者数量，初始值为 0；</li><li>信号量 <code>wCountMutex</code>：控制 wCount 互斥修改，初始值为 1；</li></ul><p>具体实现如下代码：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/33-%E8%AF%BB%E8%80%85%E5%86%99%E8%80%85-%E6%96%B9%E6%A1%88%E4%BA%8C%E7%A4%BA%E4%BE%8B.jpg" alt="img"></p><p>注意，这里 <code>rMutex</code> 的作用，开始有多个读者读数据，它们全部进入读者队列，此时来了一个写者，执行了 <code>P(rMutex)</code> 之后，后续的读者由于阻塞在 <code>rMutex</code> 上，都不能再进入读者队列，而写者到来，则可以全部进入写者队列，因此保证了写者优先。</p><p>同时，第一个写者执行了 <code>P(rMutex)</code> 之后，也不能马上开始写，必须等到所有进入读者队列的读者都执行完读操作，通过 <code>V(wDataMutex)</code> 唤醒写者的写操作。</p><blockquote><p>方案三</p></blockquote><p>既然读者优先策略和写者优先策略都会造成饥饿的现象，那么我们就来实现一下公平策略。</p><p>公平策略：</p><ul><li>优先级相同；</li><li>写者、读者互斥访问；</li><li>只能一个写者访问临界区；</li><li>可以有多个读者同时访问临界资源；</li></ul><p>具体代码实现：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/34-%E8%AF%BB%E8%80%85%E5%86%99%E8%80%85-%E6%96%B9%E6%A1%88%E4%B8%89%E7%A4%BA%E4%BE%8B.jpg" alt="img"></p><p>看完代码不知你是否有这样的疑问，为什么加了一个信号量 <code>flag</code>，就实现了公平竞争？</p><p>对比方案一的读者优先策略，可以发现，读者优先中只要后续有读者到达，读者就可以进入读者队列， 而写者必须等待，直到没有读者到达。</p><p>没有读者到达会导致读者队列为空，即 <code>rCount==0</code>，此时写者才可以进入临界区执行写操作。</p><p>而这里 <code>flag</code> 的作用就是阻止读者的这种特殊权限（特殊权限是只要读者到达，就可以进入读者队列）。</p><p>比如：开始来了一些读者读数据，它们全部进入读者队列，此时来了一个写者，执行 <code>P(flag)</code> 操作，使得后续到来的读者都阻塞在 <code>flag</code> 上，不能进入读者队列，这会使得读者队列逐渐为空，即 <code>rCount</code> 减为 0。</p><p>这个写者也不能立马开始写（因为此时读者队列不为空），会阻塞在信号量 <code>wDataMutex</code> 上，读者队列中的读者全部读取结束后，最后一个读者进程执行 <code>V(wDataMutex)</code>，唤醒刚才的写者，写者则继续开始进行写操作。</p><h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><p><strong>死锁（Deadlock）：</strong>死锁问题的产生是由两个或者以上线程并行执行的时候，争夺资源而互相等待造成的。若无外力作用，它们都将无法推进下去。称此时系统处于死锁状态或系统产生了死锁。</p><p>死锁只有<strong>同时满足</strong>以下四个条件才会发生：</p><ul><li>互斥条件：<strong>多个线程不能同时使用同一个资源</strong>。</li><li>持有并等待条件：当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 B 持有了，所以线程 A 就会处于等待状态，但是<strong>线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1</strong>。</li><li>不可剥夺条件：当线程已经持有了资源 ，<strong>在自己使用完之前不能被其他线程获取</strong>，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。</li><li>环路等待条件：在死锁发生的时候，<strong>多个线程获取资源的顺序构成了环形链</strong>。</li></ul><h5 id="排查死锁"><a href="#排查死锁" class="headerlink" title="排查死锁"></a>排查死锁</h5><p>在 Linux 下，我们可以使用 <code>pstack</code> + <code>gdb</code> 工具来定位死锁问题。</p><p>pstack 命令可以显示每个线程的栈跟踪信息（函数调用过程），它的使用方式也很简单，只需要 <code>pstack &lt;pid&gt;</code> 就可以了。</p><p>那么，在定位死锁问题时，我们可以多次执行 pstack 命令查看线程的函数调用过程，多次对比结果，确认哪几个线程一直没有变化，且是因为在等待锁，那么大概率是由于死锁问题导致的。</p><p>但是，还不能够确认这两个线程是在互相等待对方的锁的释放，因为我们看不到它们是等在哪个锁对象，于是我们可以使用 gdb 工具进一步确认。gdb可以查看函数栈帧的信息，以及查看对象的信息。</p><h5 id="避免死锁"><a href="#避免死锁" class="headerlink" title="避免死锁"></a>避免死锁</h5><p>前面我们提到，产生死锁的四个必要条件是：互斥条件、持有并等待条件、不可剥夺条件、环路等待条件。</p><p>那么避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是<strong>使用资源有序分配法，来破环环路等待条件</strong>。</p><p>那什么是资源有序分配法呢？</p><p>线程 A 和 线程 B 获取资源的顺序要一样，当线程 A 是先尝试获取资源 A，然后尝试获取资源 B 的时候，线程 B 同样也是先尝试获取资源 A，然后尝试获取资源 B。也就是说，线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。</p><h3 id="一个进程最多可以创建多少个线程"><a href="#一个进程最多可以创建多少个线程" class="headerlink" title="一个进程最多可以创建多少个线程"></a>一个进程最多可以创建多少个线程</h3><p>这个问题跟两个东西有关系：</p><ul><li><strong>进程的虚拟内存空间上限</strong>，因为创建一个线程，操作系统需要为其分配一个栈空间，如果线程数量越多，所需的栈空间就要越大，那么虚拟内存就会占用的越多。</li><li><strong>系统参数限制</strong>，虽然 Linux 并没有内核参数来控制单个进程创建的最大线程个数，但是有系统级别的参数来控制整个系统的最大线程个数。</li></ul><p>我们可以执行 ulimit -a 这条命令，查看进程创建线程时默认分配的栈空间大小。</p><p>下面这三个内核参数的大小，都会影响创建线程的上限：</p><ul><li><em><strong>&#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;threads-max</strong></em>，表示系统支持的最大线程数，默认值是 <code>14553</code>；</li><li><em><strong>&#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;pid_max</strong></em>，表示系统全局的 PID 号数值的限制，每一个进程或线程都有 ID，ID 的值超过这个数，进程或线程就会创建失败，默认值是 <code>32768</code>；</li><li><em><strong>&#x2F;proc&#x2F;sys&#x2F;vm&#x2F;max_map_count</strong></em>，表示限制一个进程可以拥有的VMA(虚拟内存区域)的数量，具体什么意思我也没搞清楚，反正如果它的值很小，也会导致创建线程失败，默认值是 <code>65530</code>。</li></ul><p>除此之外创建线程还受到cpu的限制，如果更改内核参数到极大值，创建线程过多时会导致cpu被占满，服务器被卡死无法创建新的线程。</p><p><strong>总结：</strong></p><ul><li>32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。</li><li>64 位系统，用户态的虚拟空间大到有 128T，如果按创建一个线程需占用 10M 栈空间的情况来算，那么理论上可以创建 128T&#x2F;10M 个线程，也就是 1000多万个线程，理论上不会受虚拟内存大小的限制，而是会受系统参数和cpu性能限制。</li></ul><h3 id="线程崩溃了，进程也会崩溃吗？"><a href="#线程崩溃了，进程也会崩溃吗？" class="headerlink" title="线程崩溃了，进程也会崩溃吗？"></a>线程崩溃了，进程也会崩溃吗？</h3><p>一般来说如果线程是因为非法访问内存引起的崩溃，那么进程肯定会崩溃，为什么系统要让进程崩溃呢，这主要是因为在进程中，<strong>各个线程的地址空间是共享的</strong>，既然是共享，那么某个线程对地址的非法访问就会导致内存的不确定性，进而可能会影响到其他线程，这种操作是危险的，操作系统会认为这很可能导致一系列严重的后果，于是干脆让整个进程崩溃。</p><p>线程共享代码段，数据段，地址空间，文件非法访问内存有以下几种情况，我们以 C 语言举例来看看。</p><p>1.、针对只读内存写入数据</p><pre><code class="c">   #include &lt;stdio.h&gt;   #include &lt;stdlib.h&gt;      int main() &#123;      char *s = &quot;hello world&quot;;      // 向只读内存写入数据，崩溃      s[1] = &#39;H&#39;;    &#125;</code></pre><p>2、访问了进程没有权限访问的地址空间（比如内核空间）</p><pre><code class="c">   #include &lt;stdio.h&gt;   #include &lt;stdlib.h&gt;   int main() &#123;      int *p = (int *)0xC0000fff;      // 针对进程的内核空间写入数据，崩溃      *p = 10;    &#125;</code></pre><p>在 32 位虚拟地址空间中，p 指向的是内核空间，显然不具有写入权限，所以上述赋值操作会导致崩溃</p><p>3、访问了不存在的内存，比如：</p><pre><code class="c">   #include &lt;stdio.h&gt;   #include &lt;stdlib.h&gt;      int main() &#123;      int *a = NULL;      *a = 1;        &#125;</code></pre><p>以上错误都是访问内存时的错误，所以统一会报 Segment Fault 错误（即段错误），这些都会导致进程崩溃</p><h4 id="进程是如何崩溃的-信号机制简介"><a href="#进程是如何崩溃的-信号机制简介" class="headerlink" title="进程是如何崩溃的-信号机制简介"></a>进程是如何崩溃的-信号机制简介</h4><p>那么线程崩溃后，进程是如何崩溃的呢，这背后的机制到底是怎样的，答案是<strong>信号</strong>。</p><p>大家想想要干掉一个正在运行的进程是不是经常用 kill -9 pid 这样的命令，这里的 kill 其实就是给指定 pid 发送终止信号的意思，其中的 9 就是信号。</p><p>其实信号有很多类型的，在 Linux 中可以通过 <code>kill -l</code>查看所有可用的信号：</p><p>当然了发 kill 信号必须具有一定的权限，否则任意进程都可以通过发信号来终止其他进程，那显然是不合理的，实际上 kill 执行的是系统调用，将控制权转移给了内核（操作系统），由内核来给指定的进程发送信号</p><p>那么发个信号进程怎么就崩溃了呢，这背后的原理到底是怎样的？</p><p>其背后的机制如下</p><ol><li>CPU 执行正常的进程指令</li><li>调用 kill 系统调用向进程发送信号</li><li>进程收到操作系统发的信号，CPU 暂停当前程序运行，并将控制权转交给操作系统</li><li>调用 kill 系统调用向进程发送信号（假设为 11，即 SIGSEGV，一般非法访问内存报的都是这个错误）</li><li><strong>操作系统根据情况执行相应的信号处理程序（函数），一般执行完信号处理程序逻辑后会让进程退出</strong></li></ol><p>注意上面的第五步，如果进程没有注册自己的信号处理函数，那么操作系统会执行默认的信号处理程序（一般最后会让进程退出），但如果注册了，则会执行自己的信号处理函数，这样的话就给了进程一个垂死挣扎的机会，它收到 kill 信号后，可以调用 exit() 来退出，<strong>但也可以使用 sigsetjmp，siglongjmp 这两个函数来恢复进程的执行</strong></p><pre><code class="c">// 自定义信号处理函数示例#include &lt;stdio.h&gt;#include &lt;signal.h&gt;#include &lt;stdlib.h&gt;// 自定义信号处理函数，处理自定义逻辑后再调用 exit 退出void sigHandler(int sig) &#123;  printf(&quot;Signal %d catched!\n&quot;, sig);  exit(sig);&#125;int main(void) &#123;  signal(SIGSEGV, sigHandler);  int *p = (int *)0xC0000fff;  *p = 10; // 针对不属于进程的内核空间写入数据，崩溃&#125;// 以上结果输出: Signal 11 catched!</code></pre><p><strong>如代码所示</strong>：注册信号处理函数后，当收到 SIGSEGV 信号后，先执行相关的逻辑再退出</p><p>另外当进程接收信号之后也可以不定义自己的信号处理函数，而是选择忽略信号，如下</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;signal.h&gt;#include &lt;stdlib.h&gt;int main(void) &#123;  // 忽略信号  signal(SIGSEGV, SIG_IGN);  // 产生一个 SIGSEGV 信号  raise(SIGSEGV);  printf(&quot;正常结束&quot;);&#125;</code></pre><p>也就是说虽然给进程发送了 kill 信号，但如果进程自己定义了信号处理函数或者无视信号就有机会逃出生天，当然了 kill -9 命令例外，不管进程是否定义了信号处理函数，都会马上被干掉。</p><h4 id="为什么线程崩溃不会导致-JVM-进程崩溃"><a href="#为什么线程崩溃不会导致-JVM-进程崩溃" class="headerlink" title="为什么线程崩溃不会导致 JVM 进程崩溃"></a>为什么线程崩溃不会导致 JVM 进程崩溃</h4><p>现在我们再来看看开头这个问题，相信你多少会心中有数，想想看在 Java 中有哪些是常见的由于非法访问内存而产生的 Exception 或 error 呢，常见的是大家熟悉的 StackoverflowError 或者 NPE（NullPointerException）,NPE 我们都了解，属于是访问了不存在的内存。</p><p>那么 stackoverflow 是怎么发生的呢？</p><p>进程每调用一个函数，都会分配一个栈桢，然后在栈桢里会分配函数里定义的各种局部变量。</p><p>假设现在调用了一个无限递归的函数，那就会持续分配栈帧，但 stack 的大小是有限的（Linux 中默认为 8 M，可以通过 ulimit -a 查看），如果无限递归很快栈就会分配完了，此时再调用函数试图分配超出栈的大小内存，就会发生段错误，也就是 stackoverflowError。</p><p>那问题来了，既然 StackoverflowError 或者 NPE 都属于非法访问内存， JVM 为什么不会崩溃呢？</p><p>有了上一节的铺垫，相信你不难回答，其实就是<strong>因为 JVM 自定义了自己的信号处理函数，拦截了 SIGSEGV 信号，针对这两者不让它们崩溃，而是自己内部作了额外的处理，其实是恢复了线程的执行，并抛出 StackoverflowError 和 NPE，这就是为什么 JVM 不会崩溃且我们能捕获这两个错误&#x2F;异常的原因</strong>。</p><p><strong>如果 JVM 不对信号做额外的处理，最后会自己退出并产生 crash 文件 hs_err_pid_xxx.log（可以通过 -XX:ErrorFile&#x3D;&#x2F;var&#x2F;*log*&#x2F;hs_err.log 这样的方式指定），这个文件记录了虚拟机崩溃的重要原因</strong>。</p><p>所以也可以说，虚拟机是否崩溃只要看它是否会产生此崩溃日志文件</p><h3 id="调度算法-1"><a href="#调度算法-1" class="headerlink" title="调度算法"></a>调度算法</h3><h4 id="内存页面置换算法"><a href="#内存页面置换算法" class="headerlink" title="内存页面置换算法"></a>内存页面置换算法</h4><p>在了解内存页面置换算法前，我们得先谈一下<strong>缺页异常（缺页中断）</strong>。</p><p>当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于：</p><ul><li>缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。</li><li>缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。</li></ul><p>缺页中断的处理流程：</p><ol><li>在 CPU 里访问一条 Load M 指令，然后 CPU 会去找 M 所对应的页表项。</li><li>如果该页表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「无效的」，则 CPU 则会发送缺页中断请求。</li><li>操作系统收到了缺页中断，则会执行缺页中断处理函数，先会查找该页面在磁盘中的页面的位置。</li><li>找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。</li><li>页面从磁盘换入到物理内存完成后，则把页表项中的状态位修改为「有效的」。</li><li>最后，CPU 重新执行导致缺页异常的指令。</li></ol><p>上面所说的过程，第 4 步是能在物理内存找到空闲页的情况，那如果找不到呢？</p><p>找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。</p><p>这里提一下，页表项通常有如下图的字段：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E9%A1%B5%E8%A1%A8%E9%A1%B9%E5%AD%97%E6%AE%B5.png" alt="img"></p><p>那其中：</p><ul><li><em>状态位</em>：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。</li><li><em>访问字段</em>：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。</li><li><em>修改位</em>：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。</li><li><em>硬盘地址</em>：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。</li></ul><p>所以，页面置换算法的功能是，<strong>当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面</strong>，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。</p><h5 id="最佳页面置换算法"><a href="#最佳页面置换算法" class="headerlink" title="最佳页面置换算法"></a>最佳页面置换算法</h5><p>最佳页面置换算法基本思路是，<strong>置换在「未来」最长时间不访问的页面</strong>。</p><p>所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。</p><p>这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。</p><p>所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。</p><h5 id="先进先出置换算法"><a href="#先进先出置换算法" class="headerlink" title="先进先出置换算法"></a>先进先出置换算法</h5><p>既然我们无法预知页面在下一次访问前所需的等待时间，那我们可以<strong>选择在内存驻留时间最长的页面进行中置换</strong>，这个就是「先进先出置换」算法的思想。</p><p>因为最早的页面并不一定是缺少访问的页面，所以先进先出效率很低。</p><h5 id="最近最久未使用的置换算法"><a href="#最近最久未使用的置换算法" class="headerlink" title="最近最久未使用的置换算法"></a>最近最久未使用的置换算法</h5><p>最近最久未使用（<em>LRU</em>）的置换算法的基本思路是，发生缺页时，<strong>选择最长时间没有被访问的页面进行置换</strong>，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。</p><p>这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。</p><p>虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。</p><p>困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。</p><p>所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。</p><h5 id="时钟页面置换算法"><a href="#时钟页面置换算法" class="headerlink" title="时钟页面置换算法"></a>时钟页面置换算法</h5><p>那有没有一种即能优化置换的次数，也能方便实现的算法呢？</p><p>时钟页面置换算法就可以两者兼得，它跟 LRU 近似，又是对 FIFO 的一种改进。</p><p>该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。</p><p>当发生缺页中断时，算法顺时针遍历环形链表：</p><ul><li>如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；</li><li>如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；</li></ul><p>时钟算法会淘汰掉过去一段时间没有访问过的页面，跟LRU类似。区别在于时钟算法不需要把最近访问过的页面移动到表头，开销小了一些。</p><h5 id="最不常用算法"><a href="#最不常用算法" class="headerlink" title="最不常用算法"></a>最不常用算法</h5><p>最不常用（<em>LFU</em>）算法，这名字听起来很调皮，但是它的意思不是指这个算法不常用，而是<strong>当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰</strong>。</p><p>它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。</p><p>看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。</p><p>要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。</p><p>但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。</p><p>那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。</p><h4 id="磁盘调度算法"><a href="#磁盘调度算法" class="headerlink" title="磁盘调度算法"></a>磁盘调度算法</h4><p>磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。</p><p>寻道的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间，从而提高磁盘的访问性能。</p><h5 id="先来先服务"><a href="#先来先服务" class="headerlink" title="先来先服务"></a>先来先服务</h5><p>先来先服务（<em>First-Come，First-Served，FCFS</em>），顾名思义，先到来的请求，先被服务，按照请求序列的顺序依次移动磁头到磁道。</p><p>这种算法，比较简单粗暴，如果大量进程竞争使用磁盘，请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过长。</p><h5 id="最短寻道时间优先"><a href="#最短寻道时间优先" class="headerlink" title="最短寻道时间优先"></a>最短寻道时间优先</h5><p>最短寻道时间优先（<em>Shortest Seek First，SSF</em>）算法的工作方式是，优先选择从当前磁头位置所需寻道时间最短的请求。</p><p>相比先来先服务性能提高了不少，但这个算法可能存在某些请求的<strong>饥饿</strong>，假设是一个动态的请求，如果后续来的请求都比之前的请求更近，那么之前的请求可能永远不会被响应，于是就产生了饥饿现象，这里<strong>产生饥饿的原因是磁头在一小块区域来回移动</strong>。</p><h5 id="扫描算法"><a href="#扫描算法" class="headerlink" title="扫描算法"></a>扫描算法</h5><p>最短寻道时间优先算法会产生饥饿的原因在于：磁头有可能再一个小区域内来回得移动。</p><p>为了防止这个问题，可以规定：<strong>磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向，这就是扫描（Scan）算法</strong>。</p><p><strong>这种算法也叫做电梯算法</strong>，比如电梯保持按一个方向移动，直到在那个方向上没有请求为止，然后改变方向。</p><p>磁头先响应一边的请求(比如左边)，直到到达最左端（ 0 磁道）后，才开始反向移动，响应右边的请求。</p><p>扫描调度算法性能较好，不会产生饥饿现象，但是存在这样的问题，中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。</p><h5 id="循环扫描算法"><a href="#循环扫描算法" class="headerlink" title="循环扫描算法"></a>循环扫描算法</h5><p>扫描算法使得每个磁道响应的频率存在差异，那么要优化这个问题的话，可以总是按相同的方向进行扫描，使得每个磁道的响应频率基本一致。</p><p>循环扫描（<em>Circular Scan, CSCAN</em> ）规定：只有磁头朝某个特定方向移动时(如向右)，才处理磁道访问请求，移动到最右端后需要复位磁头，也就是直接快速移动至最靠左的磁道，这个过程是很快的，并且<strong>复位中途不处理任何请求</strong>，该算法的特点，就是<strong>磁道只响应一个方向上的请求</strong>。</p><p>以这个序列为例子，磁头的初始位置是 53：</p><p>98，183，37，122，14，124，65，67</p><p>那么，假设循环扫描调度算先朝磁道增加的方向移动，具体请求会是下列从左到右的顺序：</p><p>65，67，98，122，124，183，<code>199</code>，<code>0</code>，14，37</p><p>循环扫描算法相比于扫描算法，对于各个位置磁道响应频率相对比较平均。</p><h5 id="LOOK-与-C-LOOK算法"><a href="#LOOK-与-C-LOOK算法" class="headerlink" title="LOOK 与 C-LOOK算法"></a>LOOK 与 C-LOOK算法</h5><p>我们前面说到的扫描算法和循环扫描算法，都是磁头移动到磁盘「最始端或最末端」才开始调换方向。</p><p>那这其实是可以优化的，优化的思路就是<strong>磁头在移动到「最远的请求」位置，然后立即反向移动。</strong></p><p>那针对扫描算法的优化则叫 LOOK 算法，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，<strong>反向移动的途中会响应请求</strong>。</p><p>而针对循环扫描算法的优化则叫 C-LOOK，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，<strong>反向移动的途中不会响应请求</strong>。</p><h2 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h2><p>文件系统是管理磁盘的软件系统，它简化了用户对磁盘空间的使用方法，并降低了磁盘空间的使用难度，通过更加形象的方式将磁盘中的数据展示给用户。</p><p>文件系统实现对磁盘空间的统一管理，<strong>一方面文件系统对磁盘空间进行统一规划，另外一方面文件系统提供给普通用户人性化的接口</strong>。就好比仓库中的货架，将空间进行规划和编排，这样根据编号可以方便的找到具体的货物。而文件系统也是类似，将磁盘空间进行规划和编号处理，<strong>这样通过文件名就可以找到具体的数据</strong>，而不用关心数据到底是怎么存储的。如果没有文件系统，数据被毫无规律的放到磁盘上，最后查找的时候会非常费劲，甚至可能找不到需要的数据。</p><p>没有文件系统的磁盘就像一个空仓库，数据被杂乱的堆放；有了文件系统相当于给仓库加了货架，将空间统一规划和编排。</p><p>Linux 最经典的一句话是：「<strong>一切皆文件</strong>」，不仅普通的文件和目录，就连块设备、管道、socket 等，也都是统一交给文件系统管理的。</p><p>Linux 文件系统会为每个文件分配两个数据结构：<strong>索引节点（index node）和目录项（directory entry）</strong>，它们主要用来记录文件的元信息和目录层次结构。</p><ul><li>索引节点，也就是 <em>inode</em>，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、<strong>数据在磁盘的位置</strong>等等。索引节点是文件的<strong>唯一</strong>标识，它们之间一一对应，也同样都会被存储在硬盘中，所以<strong>索引节点同样占用磁盘空间</strong>。</li><li>目录项，也就是 <em>dentry</em>，用来记录文件的名字、<strong>索引节点指针</strong>以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，<strong>目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存</strong>。</li></ul><p>由于索引节点唯一标识一个文件，而目录项记录着文件的名字，所以目录项和索引节点的关系是多对一，也就是说，<strong>一个文件可以有多个别名。</strong>比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。</p><p>注意，目录也是文件，也是用索引节点唯一标识，持久化存储在磁盘。和普通文件不同的是，普通文件在磁盘里面保存的是文件数据，而目录文件在磁盘里面保存子目录或文件；目录项是内核一个数据结构，缓存在内存。</p><p>如果查询目录频繁从磁盘读，效率会很低，所以内核会把已经读过的目录用目录项这个数据结构缓存在内存，下次再次读到相同的目录时，只需从内存读就可以，大大提高了文件系统的效率。</p><p>注意，目录项这个数据结构不只是表示目录，也是可以表示文件的。</p><blockquote><p>那文件数据是如何存储在磁盘的呢？</p></blockquote><p>磁盘读写的最小单位是<strong>扇区</strong>，扇区的大小只有 <code>512B</code> 大小，很明显，如果每次读写都以这么小为单位，那这读写的效率会非常低。</p><p>所以，文件系统把多个扇区组成了一个<strong>逻辑块</strong>，每次读写的最小单位就是逻辑块（数据块），Linux 中的逻辑块大小为 <code>4KB</code>，也就是一次性读写 8 个扇区，这将大大提高了磁盘的读写的效率。</p><p>以上就是索引节点、目录项以及文件数据的关系，下面这个图就很好的展示了它们之间的关系：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%9B%AE%E5%BD%95%E9%A1%B9%E5%92%8C%E7%B4%A2%E5%BC%95%E5%85%B3%E7%B3%BB%E5%9B%BE.png" alt="img"></p><p>索引节点是存储在硬盘上的数据，那么为了加速文件的访问，通常会把索引节点加载到内存中。</p><p>另外，磁盘进行格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。</p><ul><li><em>超级块</em>，用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。</li><li><em>索引节点区</em>，用来存储索引节点；</li><li><em>数据块区</em>，用来存储文件或目录数据；</li></ul><p>我们不可能把超级块和索引节点区全部加载到内存，这样内存肯定撑不住，所以只有当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的：</p><ul><li>超级块：当文件系统挂载时进入内存；</li><li>索引节点区：当文件被访问时进入内存；</li></ul><h3 id="虚拟文件系统"><a href="#虚拟文件系统" class="headerlink" title="虚拟文件系统"></a>虚拟文件系统</h3><p>文件系统的种类众多，而操作系统希望<strong>对用户提供一个统一的接口</strong>，于是在用户层与文件系统层引入了中间层，这个中间层就称为<strong>虚拟文件系统（Virtual File System，VFS）。</strong></p><p>VFS 定义了一组所有文件系统都支持的数据结构和标准接口，这样程序员不需要了解文件系统的工作原理，只需要了解 VFS 提供的统一接口即可。</p><p>在 Linux 文件系统中，用户空间、系统调用、虚拟文件系统、缓存、文件系统以及存储之间的关系如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F.png" alt="img"></p><p>Linux 支持的文件系统也不少，根据存储位置的不同，可以把文件系统分为三类：</p><ul><li><em>磁盘的文件系统</em>，它是直接把数据存储在磁盘中，比如 Ext 2&#x2F;3&#x2F;4、XFS 等都是这类文件系统。</li><li><em>内存的文件系统</em>，这类文件系统的数据不是存储在硬盘的，而是占用内存空间，我们经常用到的 <code>/proc</code> 和 <code>/sys</code> 文件系统都属于这一类，读写这类文件，实际上是读写内核中相关的数据。</li><li><em>网络的文件系统</em>，用来访问其他计算机主机数据的文件系统，比如 NFS、SMB 等等。</li></ul><p>文件系统首先要先挂载到某个目录才可以正常使用，比如 Linux 系统在启动时，会把文件系统挂载到根目录。</p><h3 id="文件的使用"><a href="#文件的使用" class="headerlink" title="文件的使用"></a>文件的使用</h3><p>我们从用户角度来看文件的话，就是我们要怎么使用文件？首先，我们得通过系统调用来打开一个文件。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%86%99%E5%88%B0%E7%A3%81%E7%9B%98%E8%BF%87%E7%A8%8B.png" alt="write 的过程"></p><pre><code class="c">fd = open(name, flag); # 打开文件...write(fd,...);         # 写数据...close(fd);             # 关闭文件</code></pre><p>上面简单的代码是读取一个文件的过程：</p><ul><li>首先用 <code>open</code> 系统调用打开文件，<code>open</code> 的参数中包含文件的路径名和文件名。</li><li>使用 <code>write</code> 写数据，其中 <code>write</code> 使用 <code>open</code> 所返回的<strong>文件描述符</strong>，并不使用文件名作为参数。</li><li>使用完文件后，要用 <code>close</code> 系统调用关闭文件，避免资源的泄露。</li></ul><p>我们打开了一个文件后，操作系统会跟踪进程打开的所有文件，所谓的跟踪呢，就是操作系统为每个进程维护一个打开文件表，文件表里的每一项代表「<strong>文件描述符</strong>」，所以说文件描述符是打开文件的标识。</p><p>操作系统在打开文件表中维护着打开文件的状态和信息：</p><ul><li>文件指针：系统跟踪上次读写位置作为当前文件位置指针，这种指针对打开文件的某个进程来说是唯一的；</li><li>文件打开计数器：文件关闭时，操作系统必须重用其打开文件表条目，否则表内空间不够用。因为多个进程可能打开同一个文件，所以系统在删除打开文件条目之前，必须等待最后一个进程关闭文件，该计数器跟踪打开和关闭的数量，当该计数为 0 时，系统关闭文件，删除该条目；</li><li>文件磁盘位置：绝大多数文件操作都要求系统修改文件数据，该信息保存在内存中，以免每个操作都从磁盘中读取；</li><li>访问权限：每个进程打开文件都需要有一个访问模式（创建、只读、读写、添加等），该信息保存在进程的打开文件表中，以便操作系统能允许或拒绝之后的 I&#x2F;O 请求；</li></ul><p>用户和操作系统对文件的读写操作是有差异的，用户习惯以字节的方式读写文件，而操作系统则是以数据块来读写文件，那屏蔽掉这种差异的工作就是文件系统了。</p><p>我们来分别看一下，读文件和写文件的过程：</p><ul><li>当用户进程从文件读取 1 个字节大小的数据时，文件系统则需要获取字节所在的数据块，再返回数据块对应的用户进程所需的数据部分。</li><li>当用户进程把 1 个字节大小的数据写进文件时，文件系统则找到需要写入数据的数据块的位置，然后修改数据块中对应的部分，最后再把数据块写回磁盘。</li></ul><p>所以说，<strong>文件系统的基本操作单位是数据块</strong>。</p><h3 id="文件的存储"><a href="#文件的存储" class="headerlink" title="文件的存储"></a>文件的存储</h3><p>文件的数据是要存储在硬盘上面的，数据在磁盘上的存放方式，就像程序在内存中存放的方式那样，有以下两种：</p><ul><li>连续空间存放方式</li><li>非连续空间存放方式</li></ul><p>其中，非连续空间存放方式又可以分为「链表方式」和「索引方式」。</p><h4 id="连续空间存放方式"><a href="#连续空间存放方式" class="headerlink" title="连续空间存放方式"></a>连续空间存放方式</h4><p>连续空间存放方式顾名思义，<strong>文件存放在磁盘「连续的」物理空间中</strong>。这种模式下，文件的数据都是紧密相连，<strong>读写效率很高</strong>，因为一次磁盘寻道就可以读出整个文件。</p><p>使用连续存放的方式有一个前提，必须先知道一个文件的大小，这样文件系统才会根据文件的大小在磁盘上找到一块连续的空间分配给文件。</p><p>所以，<strong>文件头里需要指定「起始块的位置」和「长度」</strong>，有了这两个信息就可以很好的表示文件存放方式是一块连续的磁盘空间。</p><p>注意，此处说的文件头，就类似于 Linux 的 inode。</p><p>连续空间存放的方式虽然读写效率高，<strong>但是有「外部碎片」和「文件长度不易扩展」的缺陷。</strong>使用非连续空间存放方式可以解决这些缺陷。</p><h4 id="非连续空间存放方式"><a href="#非连续空间存放方式" class="headerlink" title="非连续空间存放方式"></a>非连续空间存放方式</h4><p>非连续空间存放方式分为「链表方式」和「索引方式」。</p><blockquote><p>我们先来看看链表的方式。</p></blockquote><p>链表的方式存放是<strong>离散的，不用连续的</strong>，于是就可以<strong>消除磁盘碎片</strong>，可大大提高磁盘空间的利用率，同时<strong>文件的长度可以动态扩展</strong>。根据实现的方式的不同，链表可分为「<strong>隐式链表</strong>」和「<strong>显式链接</strong>」两种形式。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%9D%9E%E8%BF%9E%E7%BB%AD%E7%A9%BA%E9%97%B4%E5%AD%98%E6%94%BE%E6%96%B9%E5%BC%8F-%E9%93%BE%E8%A1%A8%E6%96%B9%E5%BC%8F.png" alt="隐式链表"></p><p>文件要以「<strong>隐式链表</strong>」的方式存放的话，<strong>实现的方式是文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置</strong>，这样一个数据块连着一个数据块，从链头开始就可以顺着指针找到所有的数据块，所以存放的方式可以是不连续的。</p><p>隐式链表的存放方式的<strong>缺点在于无法直接访问数据块，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间</strong>。隐式链接分配的<strong>稳定性较差</strong>，系统在运行过程中由于软件或者硬件错误<strong>导致链表中的指针丢失或损坏，会导致文件数据的丢失。</strong></p><p>如果取出每个磁盘块的指针，把它放在内存的一个表中，就可以解决上述隐式链表的两个不足。那么，这种实现方式是「<strong>显式链接</strong>」，它指<strong>把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中</strong>，该表在整个磁盘仅设置一张，<strong>每个表项中存放链接指针，指向下一个数据块号</strong>。</p><p>对于显式链接的工作方式，我们举个例子，文件 A 依次使用了磁盘块 4、7、2、10 和 12 ，文件 B 依次使用了磁盘块 6、3、11 和 14 。利用下图中的表，可以从第 4 块开始，顺着链走到最后，找到文件 A 的全部磁盘块。同样，从第 6 块开始，顺着链走到最后，也能够找出文件 B 的全部磁盘块。最后，这两个链都以一个不属于有效磁盘编号的特殊标记（如 -1 ）结束。内存中的这样一个表格称为<strong>文件分配表（File Allocation Table，FAT）</strong>。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E5%88%86%E9%85%8D%E8%A1%A8.png" alt="显式链接"></p><p>由于查找记录的过程是在内存中进行的，因而不仅显著地<strong>提高了检索速度</strong>，而且<strong>大大减少了访问磁盘的次数</strong>。但也正是整个表都存放在内存中的关系，它的主要的缺点是<strong>不适用于大磁盘</strong>。</p><p>比如，对于 200GB 的磁盘和 1KB 大小的块，这张表需要有 2 亿项，每一项对应于这 2 亿个磁盘块中的一个块，每项如果需要 4 个字节，那这张表要占用 800MB 内存，很显然 FAT 方案对于大磁盘而言不太合适。</p><blockquote><p>接下来，我们来看看索引的方式。</p></blockquote><p>链表的方式解决了连续分配的磁盘碎片和文件动态扩展的问题，但是不能有效支持直接访问（FAT除外），索引的方式可以解决这个问题。</p><p>索引的实现是为每个文件创建一个「<strong>索引数据块</strong>」，里面存放的是<strong>指向文件数据块的指针列表</strong>，说白了就像书的目录一样，要找哪个章节的内容，看目录查就可以。</p><p>另外，<strong>文件头需要包含指向「索引数据块」的指针</strong>，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块。</p><p>创建文件时，索引块的所有指针都设为空。当首次写入第 i 块时，先从空闲空间中取得一个块，再将其地址写到索引块的第 i 个条目。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%9D%9E%E8%BF%9E%E7%BB%AD%E7%A9%BA%E9%97%B4%E5%AD%98%E6%94%BE%E6%96%B9%E5%BC%8F-%E7%B4%A2%E5%BC%95%E6%96%B9%E5%BC%8F.png" alt="索引的方式"></p><p>索引的方式优点在于：</p><ul><li>文件的创建、增大、缩小很方便；</li><li>不会有碎片的问题；</li><li>支持顺序读写和随机读写；</li></ul><p>由于索引数据也是存放在磁盘块的，如果文件很小，明明只需一块就可以存放的下，但还是需要额外分配一块来存放索引数据，所以缺陷之一就是存储索引带来的开销。</p><p>如果文件很大，大到一个索引数据块放不下索引信息，这时又要如何处理大文件的存放呢？我们可以通过组合的方式，来处理大文件的存。</p><p>先来看看链表 + 索引的组合，这种组合称为「<strong>链式索引块</strong>」，它的实现方式是<strong>在索引数据块留出一个存放下一个索引数据块的指针</strong>，于是当一个索引数据块的索引信息用完了，就可以通过指针的方式，找到下一个索引数据块的信息。那这种方式也会出现前面提到的链表方式的问题，万一某个指针损坏了，后面的数据也就会无法读取了。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%93%BE%E5%BC%8F%E7%B4%A2%E5%BC%95%E5%9D%97.png" alt="链式索引块"></p><p>还有另外一种组合方式是索引 + 索引的方式，这种组合称为「<strong>多级索引块</strong>」，实现方式是<strong>通过一个索引块来存放多个索引数据块</strong>，一层套一层索引，像极了俄罗斯套娃是吧。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%A4%9A%E7%BA%A7%E7%B4%A2%E5%BC%95%E5%9D%97.png" alt="多级索引块"></p><h4 id="Unix-文件的实现方式"><a href="#Unix-文件的实现方式" class="headerlink" title="Unix 文件的实现方式"></a>Unix 文件的实现方式</h4><p>我们先把前面提到的文件实现方式，做个比较：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F%E6%AF%94%E8%BE%83.png" alt="img"></p><p>那早期 Unix 文件系统是组合了前面的文件存放方式的优点，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/Unix%20%E5%A4%9A%E7%BA%A7%E7%B4%A2%E5%BC%95.png" alt="早期 Unix 文件系统"></p><p>它是根据文件的大小，存放的方式会有所变化：</p><ul><li>如果存放文件所需的数据块小于 10 块，则采用直接查找的方式；</li><li>如果存放文件所需的数据块超过 10 块，则采用一级间接索引方式；</li><li>如果前面两种方式都不够存放大文件，则采用二级间接索引方式；</li><li>如果二级间接索引也不够存放大文件，这采用三级间接索引方式；</li></ul><p>那么，文件头（<em>Inode</em>）就需要包含 13 个指针：</p><ul><li>10 个指向数据块的指针；</li><li>第 11 个指向索引块的指针；</li><li>第 12 个指向二级索引块的指针；</li><li>第 13 个指向三级索引块的指针；</li></ul><p>所以，这种方式能很灵活地支持小文件和大文件的存放：</p><ul><li>对于小文件使用直接查找的方式可减少索引数据块的开销；</li><li>对于大文件则以多级索引的方式来支持，所以大文件在访问数据块时需要大量查询；</li></ul><p>这个方案就用在了 Linux Ext 2&#x2F;3 文件系统里，虽然解决大文件的存储，但是对于大文件的访问，需要大量的查询，效率比较低。</p><p>为了解决这个问题，Ext 4 做了一定的改变，具体怎么解决的，本文就不展开了。</p><h3 id="空闲空间管理"><a href="#空闲空间管理" class="headerlink" title="空闲空间管理"></a>空闲空间管理</h3><p>前面说到的文件的存储是针对已经被占用的数据块组织和管理，接下来的问题是，如果我要保存一个数据块，我应该放在硬盘上的哪个位置呢？难道需要将所有的块扫描一遍，找个空的地方随便放吗？</p><p>那这种方式效率就太低了，所以针对磁盘的空闲空间也是要引入管理的机制，接下来介绍几种常见的方法：</p><ul><li>空闲表法</li><li>空闲链表法</li><li>位图法</li></ul><h4 id="空闲表法"><a href="#空闲表法" class="headerlink" title="空闲表法"></a>空闲表法</h4><p>空闲表法就是为所有空闲空间建立一张表，表内容包括空闲区的第一个块号和该空闲区的块个数，注意，这个方式是连续分配的。如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%A9%BA%E9%97%B2%E8%A1%A8%E6%B3%95.png" alt="空闲表法"></p><p>当请求分配磁盘空间时，系统依次扫描空闲表里的内容，直到找到一个合适的空闲区域为止。当用户撤销一个文件时，系统回收文件空间。这时，也需顺序扫描空闲表，寻找一个空闲表条目并将释放空间的第一个物理块号及它占用的块数填到这个条目中。</p><p>这种方法仅当有少量的空闲区时才有较好的效果。因为，如果存储空间中有着大量的小的空闲区，则空闲表变得很大，这样查询效率会很低。另外，这种分配技术适用于建立连续文件。</p><h4 id="空闲链表法"><a href="#空闲链表法" class="headerlink" title="空闲链表法"></a>空闲链表法</h4><p>我们也可以使用「链表」的方式来管理空闲空间，每一个空闲块里有一个指针指向下一个空闲块，这样也能很方便的找到空闲块并管理起来。如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%A9%BA%E9%97%B2%E5%9D%97%E9%93%BE%E8%A1%A8.png" alt="空闲链表法"></p><p>当创建文件需要一块或几块时，就从链头上依次取下一块或几块。反之，当回收空间时，把这些空闲块依次接到链头上。</p><p>这种技术只要在主存中保存一个指针，令它指向第一个空闲块。其特点是简单，但不能随机访问，工作效率低，因为每当在链上增加或移动空闲块时需要做很多 I&#x2F;O 操作，同时数据块的指针消耗了一定的存储空间。</p><p>空闲表法和空闲链表法都不适合用于大型文件系统，因为这会使空闲表或空闲链表太大。</p><h4 id="位图法"><a href="#位图法" class="headerlink" title="位图法"></a>位图法</h4><p>位图是利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。</p><p>当值为 0 时，表示对应的盘块空闲，值为 1 时，表示对应的盘块已分配。它形式如下：</p><pre><code class="text">1111110011111110001110110111111100111 ...</code></pre><p>在 Linux 文件系统就采用了位图的方式来管理空闲空间，不仅用于数据空闲块的管理，还用于 inode 空闲块的管理，因为 inode 也是存储在磁盘的，自然也要有对其管理。</p><h3 id="文件系统的结构"><a href="#文件系统的结构" class="headerlink" title="文件系统的结构"></a>文件系统的结构</h3><p>前面提到 Linux 是用位图的方式管理空闲空间，用户在创建一个新文件时，Linux 内核会通过 inode 的位图找到空闲可用的 inode，并进行分配。要存储数据时，会通过块的位图找到空闲的块，并分配，但仔细计算一下还是有问题的。</p><p>数据块的位图是放在磁盘块里的，假设是放在一个块里，一个块 4K，每位表示一个数据块，共可以表示 <code>4 * 1024 * 8 = 2^15</code> 个空闲块，由于 1 个数据块是 4K 大小，那么最大可以表示的空间为 <code>2^15 * 4 * 1024 = 2^27</code> 个 byte，也就是 128M。</p><p>也就是说按照上面的结构，如果采用「一个块的位图 + 一系列的块」，外加「一个块的 inode 的位图 + 一系列的 inode 的结构」能表示的最大空间也就 128M，这太少了，现在很多文件都比这个大。</p><p>在 Linux 文件系统，把这个结构称为一个<strong>块组</strong>，那么有 N 多的块组，就能够表示 N 大的文件。</p><p>下图给出了 Linux Ext2 整个文件系统的结构和块组的内容，文件系统都由大量块组组成，在硬盘上相继排布：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%9D%97%E7%BB%84.png" alt="img"></p><p>最前面的第一个块是引导块，在系统启动时用于启用引导，接着后面就是一个一个连续的块组了，块组的内容如下：</p><ul><li><em>超级块</em>，包含的是文件系统的重要信息，比如 inode 总个数、块总个数、每个块组的 inode 个数、每个块组的块个数等等。</li><li><em>块组描述符</em>，包含文件系统中各个块组的状态，比如块组中空闲块和 inode 的数目等，每个块组都包含了文件系统中「所有块组的组描述符信息」。</li><li><em>数据位图和 inode 位图</em>， 用于表示对应的数据块或 inode 是空闲的，还是被使用中。</li><li><em>inode 列表</em>，包含了块组中所有的 inode，inode 用于保存文件系统中与各个文件和目录相关的所有元数据。</li><li><em>数据块</em>，包含文件的有用数据。</li></ul><p>你可以会发现每个块组里有很多重复的信息，比如<strong>超级块和块组描述符表，这两个都是全局信息，而且非常的重要</strong>，这么做是有两个原因：</p><ul><li>如果系统崩溃破坏了超级块或块组描述符，有关文件系统结构和内容的所有信息都会丢失。如果有冗余的副本，该信息是可能恢复的。</li><li>通过使文件和管理数据尽可能接近，减少了磁头寻道和旋转，这可以提高文件系统的性能。</li></ul><p>不过，Ext2 的后续版本采用了稀疏技术。该做法是，超级块和块组描述符表不再存储到文件系统的每个块组中，而是只写入到块组 0、块组 1 和其他 ID 可以表示为 3、 5、7 的幂的块组中。</p><h3 id="目录的存储"><a href="#目录的存储" class="headerlink" title="目录的存储"></a>目录的存储</h3><p>在前面，我们知道了一个普通文件是如何存储的，但还有一个特殊的文件，经常用到的目录，它是如何保存的呢？</p><p>基于 Linux 一切皆文件的设计思想，目录其实也是个文件，你甚至可以通过 <code>vim</code> 打开它，它也有 inode，inode 里面也是指向一些块。</p><p>和普通文件不同的是，<strong>普通文件的块里面保存的是文件数据，而目录文件的块里面保存的是目录里面一项一项的文件信息。</strong></p><p>在目录文件的块中，最简单的保存格式就是<strong>列表</strong>，就是一项一项地将目录下的文件信息（如文件名、文件 inode、文件类型等）列在表里。</p><p>列表中每一项就代表该目录下的文件的文件名和对应的 inode，通过这个 inode，就可以找到真正的文件。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%9B%AE%E5%BD%95%E5%93%88%E5%B8%8C%E8%A1%A8.png" alt="目录格式哈希表"></p><p>通常，第一项是「<code>.</code>」，表示当前目录，第二项是「<code>..</code>」，表示上一级目录，接下来就是一项一项的文件名和 inode。</p><p>如果一个目录有超级多的文件，我们要想在这个目录下找文件，按照列表一项一项的找，效率就不高了。</p><p>于是，保存目录的格式改成<strong>哈希表</strong>，对文件名进行哈希计算，把哈希值保存起来，如果我们要查找一个目录下面的文件名，可以通过名称取哈希。如果哈希能够匹配上，就说明这个文件的信息在相应的块里面。</p><p>Linux 系统的 ext 文件系统就是采用了哈希表，来保存目录的内容，这种方法的优点是查找非常迅速，插入和删除也较简单，不过需要一些预备措施来避免哈希冲突。</p><p>目录查询是通过在磁盘上反复搜索完成，需要不断地进行 I&#x2F;O 操作，开销较大。所以，为了减少 I&#x2F;O 操作，把当前使用的文件目录缓存在内存，以后要使用该文件时只要在内存中操作，从而降低了磁盘操作次数，提高了文件系统的访问速度。</p><h3 id="软链接和硬链接"><a href="#软链接和硬链接" class="headerlink" title="软链接和硬链接"></a>软链接和硬链接</h3><p>有时候我们希望给某个文件取个别名，那么在 Linux 中可以通过<strong>硬链接（Hard Link）</strong> 和<strong>软链接（Symbolic Link）</strong> 的方式来实现，它们都是比较特殊的文件，但是实现方式也是不相同的。</p><p>硬链接是<strong>多个目录项中的「索引节点」指向一个文件</strong>，也就是指向同一个 inode，但是 inode 是不可能跨越文件系统的，每个文件系统都有各自的 inode 数据结构和列表，所以<strong>硬链接是不可用于跨文件系统的</strong>。由于多个目录项都是指向一个 inode，那么<strong>只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%A1%AC%E9%93%BE%E6%8E%A5-2.png" alt="硬链接"></p><p>软链接相当于重新创建一个文件，这个文件有<strong>独立的 inode</strong>，但是这个<strong>文件的内容是另外一个文件的路径</strong>，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以<strong>软链接是可以跨文件系统的</strong>，甚至<strong>目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E8%BD%AF%E9%93%BE%E6%8E%A5.png" alt="软链接"></p><h3 id="文件-I-x2F-O"><a href="#文件-I-x2F-O" class="headerlink" title="文件 I&#x2F;O"></a>文件 I&#x2F;O</h3><p>文件的读写方式各有千秋，对于文件的 I&#x2F;O 分类也非常多，常见的有</p><ul><li>缓冲与非缓冲 I&#x2F;O</li><li>直接与非直接 I&#x2F;O</li><li>阻塞与非阻塞 I&#x2F;O VS 同步与异步 I&#x2F;O</li></ul><p>接下来，分别对这些分类讨论。</p><h4 id="缓冲与非缓冲-I-x2F-O"><a href="#缓冲与非缓冲-I-x2F-O" class="headerlink" title="缓冲与非缓冲 I&#x2F;O"></a>缓冲与非缓冲 I&#x2F;O</h4><p>文件操作的标准库是可以实现数据的缓存，那么<strong>根据「是否利用标准库缓冲」，可以把文件 I&#x2F;O 分为缓冲 I&#x2F;O 和非缓冲 I&#x2F;O</strong>：</p><ul><li>缓冲 I&#x2F;O，利用的是标准库的缓存实现文件的加速访问，而标准库再通过系统调用访问文件。</li><li>非缓冲 I&#x2F;O，直接通过系统调用访问文件，不经过标准库缓存。</li></ul><p>这里所说的「缓冲」特指标准库内部实现的缓冲。</p><p>比方说，很多程序遇到换行时才真正输出，而换行前的内容，其实就是被标准库暂时缓存了起来，这样做的目的是，减少系统调用的次数，毕竟系统调用是有 CPU 上下文切换的开销的。</p><h4 id="直接与非直接-I-x2F-O"><a href="#直接与非直接-I-x2F-O" class="headerlink" title="直接与非直接 I&#x2F;O"></a>直接与非直接 I&#x2F;O</h4><p>我们都知道磁盘 I&#x2F;O 是非常慢的，所以 Linux 内核为了减少磁盘 I&#x2F;O 次数，在系统调用后，会把用户数据拷贝到内核中缓存起来，这个内核缓存空间也就是「页缓存」，只有当缓存满足某些条件的时候，才发起磁盘 I&#x2F;O 的请求。</p><p>那么，<strong>根据是「否利用操作系统的缓存」，可以把文件 I&#x2F;O 分为直接 I&#x2F;O 与非直接 I&#x2F;O</strong>：</p><ul><li>直接 I&#x2F;O，不会发生内核缓存和用户程序之间数据复制，而是直接经过文件系统访问磁盘。</li><li>非直接 I&#x2F;O，读操作时，数据从内核缓存中拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写入数据到磁盘。</li></ul><p>如果你在使用文件操作类的系统调用函数时，指定了 <code>O_DIRECT</code> 标志，则表示使用直接 I&#x2F;O。如果没有设置过，默认使用的是非直接 I&#x2F;O。</p><blockquote><p>如果用了非直接 I&#x2F;O 进行写数据操作，内核什么情况下才会把缓存数据写入到磁盘？</p></blockquote><p>以下几种场景会触发内核缓存的数据写入磁盘：</p><ul><li>在调用 <code>write</code> 的最后，当发现内核缓存的数据太多的时候，内核会把数据写到磁盘上；</li><li>用户主动调用 <code>sync</code>，内核缓存会刷到磁盘上；</li><li>当内存十分紧张，无法再分配页面时，也会把内核缓存的数据刷到磁盘上；</li><li>内核缓存的数据的缓存时间超过某个时间时，也会把数据刷到磁盘上；</li></ul><h4 id="阻塞与非阻塞-I-x2F-O-VS-同步与异步-I-x2F-O"><a href="#阻塞与非阻塞-I-x2F-O-VS-同步与异步-I-x2F-O" class="headerlink" title="阻塞与非阻塞 I&#x2F;O VS 同步与异步 I&#x2F;O"></a>阻塞与非阻塞 I&#x2F;O VS 同步与异步 I&#x2F;O</h4><p>为什么把阻塞 &#x2F; 非阻塞与同步与异步放一起说的呢？因为它们确实非常相似，也非常容易混淆，不过它们之间的关系还是有点微妙的。</p><p>先来看看<strong>阻塞 I&#x2F;O</strong>，当用户程序执行 <code>read</code> ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，<code>read</code> 才会返回。</p><p>注意，<strong>阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程</strong>。过程如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%98%BB%E5%A1%9E%20I_O.png" alt="阻塞 I/O"></p><p>知道了阻塞 I&#x2F;O ，来看看<strong>非阻塞 I&#x2F;O</strong>，非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，<code>read</code> 调用才可以获取到结果。过程如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E9%9D%9E%E9%98%BB%E5%A1%9E%20I_O%20.png" alt="非阻塞 I/O"></p><p>注意，<strong>这里最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。</strong></p><p>举个例子，访问管道或 socket 时，如果设置了 <code>O_NONBLOCK</code> 标志，那么就表示使用的是非阻塞 I&#x2F;O 的方式访问，而不做任何设置的话，默认是阻塞 I&#x2F;O。</p><p>应用程序每次轮询内核的 I&#x2F;O 是否准备好，感觉有点傻乎乎，因为轮询的过程中，应用程序啥也做不了，只是在循环。</p><p>为了解决这种傻乎乎轮询方式，于是 <strong>I&#x2F;O 多路复用</strong>技术就出来了，如 select、poll，它是通过 I&#x2F;O 事件分发，当内核数据准备好时，再以事件通知应用程序进行操作。</p><p>这个做法大大改善了 CPU 的利用率，因为当调用了 I&#x2F;O 多路复用接口，如果没有事件发生，那么当前线程就会发生阻塞，这时 CPU 会切换其他线程执行任务，等内核发现有事件到来的时候，会唤醒阻塞在 I&#x2F;O 多路复用接口的线程，然后用户可以进行后续的事件处理。</p><p>整个流程要比阻塞 IO 要复杂，似乎也更浪费性能。但 <strong>I&#x2F;O 多路复用接口最大的优势在于，用户可以在一个线程内同时处理多个 socket 的 IO 请求</strong>。用户可以注册多个 socket，然后不断地调用 I&#x2F;O 多路复用接口读取被激活的 socket，即可达到在同一个线程内同时处理多个 IO 请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。</p><p>下图是使用 select I&#x2F;O 多路复用过程。注意，<code>read</code> 获取数据的过程（数据从内核态拷贝到用户态的过程），也是一个<strong>同步的过程</strong>，需要等待：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%9F%BA%E4%BA%8E%E9%9D%9E%E9%98%BB%E5%A1%9E%20I_O%20%E7%9A%84%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png" alt="I/O 多路复用"></p><p>实际上，无论是阻塞 I&#x2F;O、非阻塞 I&#x2F;O，还是基于非阻塞 I&#x2F;O 的多路复用<strong>都是同步调用。因为它们在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。</strong></p><p>而真正的<strong>异步 I&#x2F;O</strong> 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。</p><p>当我们发起 <code>aio_read</code> 之后，就立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作。过程如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%BC%82%E6%AD%A5%20I_O.png" alt="异步 I/O"></p><p>下面这张图，总结了以上几种 I&#x2F;O 模型：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%90%8C%E6%AD%A5VS%E5%BC%82%E6%AD%A5IO.png" alt="img"></p><p>在前面我们知道了，I&#x2F;O 是分为两个过程的：</p><ol><li>数据准备的过程</li><li>数据从内核空间拷贝到用户进程缓冲区的过程</li></ol><p>阻塞 I&#x2F;O 会阻塞在「过程 1 」和「过程 2」，而非阻塞 I&#x2F;O 和基于非阻塞 I&#x2F;O 的多路复用只会阻塞在「过程 2」，所以这三个都可以认为是同步 I&#x2F;O。</p><p>异步 I&#x2F;O 则不同，「过程 1 」和「过程 2 」都不会阻塞。</p><h4 id="五大IO模型"><a href="#五大IO模型" class="headerlink" title="五大IO模型"></a>五大IO模型</h4><p>1.阻塞IO</p><p>2.非阻塞IO</p><p>3.IO多路复用</p><p>4.信号驱动IO:信号驱动IO不是像select用循环请求询问的方式去监控数据就绪状态，而是在调用sigaction时候建立一个SIGIO的信号联系，当内核数据准备好之后再通过SIGIO信号通知线程数据准备好后的可读状态，当线程收到可读状态的信号后，此时再向内核发起recvfrom读取数据的请求，因为信号驱动IO的模型下应用线程在发出信号监控后即可返回，不会阻塞，所以这样的方式下，一个应用线程也可以同时监控多个fd。</p><p>5.异步IO</p><h2 id="设备管理"><a href="#设备管理" class="headerlink" title="设备管理"></a>设备管理</h2><h3 id="I-x2F-O控制器"><a href="#I-x2F-O控制器" class="headerlink" title="I&#x2F;O控制器"></a>I&#x2F;O控制器</h3><p>我们的电脑设备可以接非常多的输入输出设备，比如键盘、鼠标、显示器、网卡、硬盘、打印机、音响等等，每个设备的用法和功能都不同，那操作系统是如何把这些输入输出设备统一管理的呢?</p><p>为了屏蔽设备之间的差异，每个设备都有一个叫<strong>设备控制器（Device Control）</strong> 的组件，比如硬盘有硬盘控制器、显示器有视频控制器等。</p><p>因为这些控制器都很清楚的知道对应设备的用法和功能，所以 CPU 是通过设备控制器来和设备打交道的。</p><p>设备控制器里有芯片，它可执行自己的逻辑，也有自己的寄存器，用来与 CPU 进行通信，比如：</p><ul><li>通过写入这些寄存器，操作系统可以命令设备发送数据、接收数据、开启或关闭，或者执行某些其他操作。</li><li>通过读取这些寄存器，操作系统可以了解设备的状态，是否准备好接收一个新的命令等。</li></ul><p>实际上，控制器是有三类寄存器，它们分别是<strong>状态寄存器（Status Register）</strong>、 <strong>命令寄存器（Command Register）<em>以及</em>数据寄存器（Data Register）</strong>，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6%E5%99%A8.png" alt="img"></p><p>这三个寄存器的作用：</p><ul><li><em>数据寄存器</em>，CPU 向 I&#x2F;O 设备写入需要传输的数据，比如要打印的内容是「Hello」，CPU 就要先发送一个 H 字符给到对应的 I&#x2F;O 设备。</li><li><em>命令寄存器</em>，CPU 发送一个命令，告诉 I&#x2F;O 设备，要进行输入&#x2F;输出操作，于是就会交给 I&#x2F;O 设备去工作，任务完成后，会把状态寄存器里面的状态标记为完成。</li><li><em>状态寄存器</em>，目的是告诉 CPU ，现在已经在工作或工作已经完成，如果已经在工作状态，CPU 再发送数据或者命令过来，都是没有用的，直到前面的工作已经完成，状态寄存标记成已完成，CPU 才能发送下一个字符和命令。</li></ul><p>CPU 通过读写设备控制器中的寄存器控制设备，这可比 CPU 直接控制输入输出设备，要方便和标准很多。</p><p>另外， 输入输出设备可分为两大类 ：<strong>块设备（Block Device）<em>和</em>字符设备（Character Device）</strong>。</p><ul><li><em>块设备</em>，把数据存储在固定大小的块中，每个块有自己的地址，硬盘、USB 是常见的块设备。</li><li><em>字符设备</em>，以字符为单位发送或接收一个字符流，字符设备是不可寻址的，也没有任何寻道操作，鼠标是常见的字符设备。</li></ul><p>块设备通常传输的数据量会非常大，于是控制器设立了一个可读写的<strong>数据缓冲区</strong>。</p><ul><li>CPU 写入数据到控制器的缓冲区时，当缓冲区的数据囤够了一部分，才会发给设备。</li><li>CPU 从控制器的缓冲区读取数据时，也需要缓冲区囤够了一部分，才拷贝到内存。</li></ul><p>这样做是为了，减少对设备的频繁操作。</p><p>那 CPU 是如何与设备的控制寄存器和数据缓冲区进行通信的？存在两个方法：</p><ul><li><em>端口 I&#x2F;O</em>，每个控制寄存器被分配一个 I&#x2F;O 端口，可以通过特殊的汇编指令操作这些寄存器，比如 <code>in/out</code> 类似的指令。</li><li><em>内存映射 I&#x2F;O</em>，将所有控制寄存器映射到内存空间中，这样就可以像读写内存一样读写数据缓冲区。</li></ul><h3 id="I-x2F-O-控制方式"><a href="#I-x2F-O-控制方式" class="headerlink" title="I&#x2F;O 控制方式"></a>I&#x2F;O 控制方式</h3><p>在前面我知道，每种设备都有一个设备控制器，控制器相当于一个小 CPU，它可以自己处理一些事情，但有个问题是，当 CPU 给设备发送了一个指令，让设备控制器去读设备的数据，它读完的时候，要怎么通知 CPU 呢？</p><p>控制器的寄存器一般会有状态标记位，用来标识输入或输出操作是否完成。于是，我们想到第一种<strong>轮询等待</strong>的方法，让 CPU 一直查寄存器的状态，直到状态标记为完成，很明显，这种方式非常的傻瓜，它会占用 CPU 的全部时间。</p><p>那我们就想到第二种方法 —— <strong>中断</strong>，通知操作系统数据已经准备好了。我们一般会有一个硬件的<strong>中断控制器</strong>，当设备完成任务后触发中断到中断控制器，中断控制器就通知 CPU，一个中断产生了，CPU 需要停下当前手里的事情来处理中断。</p><p>另外，中断有两种，一种<strong>软中断</strong>，例如代码调用 <code>INT</code> 指令触发，一种是<strong>硬件中断</strong>，就是硬件通过中断控制器触发的。</p><p>但中断的方式对于频繁读写数据的磁盘，并不友好，这样 CPU 容易经常被打断，会占用 CPU 大量的时间。对于这一类设备的问题的解决方法是使用 <strong>DMA（Direct Memory Access）</strong> 功能，它可以使得设备在 CPU 不参与的情况下，能够自行完成把设备 I&#x2F;O 数据放入到内存。那要实现 DMA 功能要有 「DMA 控制器」硬件的支持。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/DMA%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png" alt="img"></p><p>DMA 的工作方式如下：</p><ul><li>CPU 需对 DMA 控制器下发指令，告诉它想读取多少数据，读完的数据放在内存的某个地方就可以了；</li><li>接下来，DMA 控制器会向磁盘控制器发出指令，通知它从磁盘读数据到其内部的缓冲区中，接着磁盘控制器将缓冲区的数据传输到内存；</li><li>当磁盘控制器把数据传输到内存的操作完成后，磁盘控制器在总线上发出一个确认成功的信号到 DMA 控制器；</li><li>DMA 控制器收到信号后，DMA 控制器发中断通知 CPU 指令完成，CPU 就可以直接用内存里面现成的数据了；</li></ul><p>可以看到， CPU 当要读取磁盘数据的时候，只需给 DMA 控制器发送指令，然后返回去做其他事情，当磁盘数据拷贝到内存后，DMA 控制机器通过中断的方式，告诉 CPU 数据已经准备好了，可以从内存读数据了。仅仅在传送开始和结束时需要 CPU 干预。</p><h3 id="设备驱动程序"><a href="#设备驱动程序" class="headerlink" title="设备驱动程序"></a>设备驱动程序</h3><p>虽然设备控制器屏蔽了设备的众多细节，但每种设备的控制器的寄存器、缓冲区等使用模式都是不同的，所以为了屏蔽「设备控制器」的差异，引入了<strong>设备驱动程序</strong>。<br><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F.png" alt="img"></p><p>设备控制器不属于操作系统范畴，它是属于硬件，而设备驱动程序属于操作系统的一部分，操作系统的内核代码可以像本地调用代码一样使用设备驱动程序的接口，而设备驱动程序是面向设备控制器的代码，它发出操控设备控制器的指令后，才可以操作设备控制器。</p><p>不同的设备控制器虽然功能不同，但是<strong>设备驱动程序会提供统一的接口给操作系统</strong>，这样不同的设备驱动程序，就可以以相同的方式接入操作系统。</p><p>前面提到了不少关于中断的事情，设备完成了事情，则会发送中断来通知操作系统。那操作系统就需要有一个地方来处理这个中断，这个地方也就是在设备驱动程序里，它会及时响应控制器发来的中断请求，并根据这个中断的类型调用响应的<strong>中断处理程序</strong>进行处理。</p><p>通常，设备驱动程序初始化的时候，要先注册一个该设备的中断处理函数。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/%E4%B8%AD%E6%96%AD%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B.png" alt="img"></p><p>我们来看看，中断处理程序的处理流程：</p><ol><li>在 I&#x2F;O 时，设备控制器如果已经准备好数据，则会通过中断控制器向 CPU 发送中断请求；</li><li>保护被中断进程的 CPU 上下文；</li><li>转入相应的设备中断处理函数；</li><li>进行中断处理；</li><li>恢复被中断进程的上下文；</li></ol><h3 id="通用块层"><a href="#通用块层" class="headerlink" title="通用块层"></a>通用块层</h3><p>对于块设备，为了减少不同块设备的差异带来的影响，Linux 通过一个统一的<strong>通用块层</strong>，来管理不同的块设备。</p><p>通用块层是处于文件系统和磁盘驱动中间的一个块设备抽象层，它主要有两个功能：</p><ul><li>第一个功能，向上为文件系统和应用程序，提供访问块设备的标准接口，向下把各种不同的磁盘设备抽象为统一的块设备，并在内核层面，提供一个框架来管理这些设备的驱动程序；</li><li>第二功能，通用层还会给文件系统和应用程序发来的 I&#x2F;O 请求排队，接着会对队列重新排序、请求合并等方式，也就是 I&#x2F;O 调度，主要目的是为了提高磁盘读写的效率。</li></ul><p>Linux 内存支持 5 种 I&#x2F;O 调度算法，分别是：</p><ul><li>没有调度算法</li><li>先入先出调度算法</li><li>完全公平调度算法</li><li>优先级调度</li><li>最终期限调度算法</li></ul><p>第一种，没有调度算法，是的，你没听错，它不对文件系统和应用程序的 I&#x2F;O 做任何处理，这种算法常用在虚拟机 I&#x2F;O 中，此时磁盘 I&#x2F;O 调度算法交由物理机系统负责。</p><p>第二种，先入先出调度算法，这是最简单的 I&#x2F;O 调度算法，先进入 I&#x2F;O 调度队列的 I&#x2F;O 请求先发生。</p><p>第三种，完全公平调度算法，大部分系统都把这个算法作为默认的 I&#x2F;O 调度器，它为每个进程维护了一个 I&#x2F;O 调度队列，并按照时间片来均匀分布每个进程的 I&#x2F;O 请求。</p><p>第四种，优先级调度算法，顾名思义，优先级高的 I&#x2F;O 请求先发生， 它适用于运行大量进程的系统，像是桌面环境、多媒体应用等。</p><p>第五种，最终期限调度算法，分别为读、写请求创建了不同的 I&#x2F;O 队列，这样可以提高机械磁盘的吞吐量，并确保达到最终期限的请求被优先处理，适用于在 I&#x2F;O 压力比较大的场景，比如数据库等。</p><h3 id="存储系统-I-x2F-O-软件分层"><a href="#存储系统-I-x2F-O-软件分层" class="headerlink" title="存储系统 I&#x2F;O 软件分层"></a>存储系统 I&#x2F;O 软件分层</h3><p>前面说到了不少东西，设备、设备控制器、驱动程序、通用块层，现在再结合文件系统原理，我们来看看 Linux 存储系统的 I&#x2F;O 软件分层。</p><p>可以把 Linux 存储系统的 I&#x2F;O 由上到下可以分为三个层次，分别是文件系统层、通用块层、设备层。他们整个的层次关系如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/I_O%E8%BD%AF%E4%BB%B6%E5%88%86%E5%B1%82.png" alt="img"></p><p>这三个层次的作用是：</p><ul><li>文件系统层，包括虚拟文件系统和其他文件系统的具体实现，它向上为应用程序统一提供了标准的文件访问接口，向下会通过通用块层来存储和管理磁盘数据。</li><li>通用块层，包括块设备的 I&#x2F;O 队列和 I&#x2F;O 调度器，它会对文件系统的 I&#x2F;O 请求进行排队，再通过 I&#x2F;O 调度器，选择一个 I&#x2F;O 发给下一层的设备层。</li><li>设备层，包括硬件设备、设备控制器和驱动程序，负责最终物理设备的 I&#x2F;O 操作。</li></ul><p>有了文件系统接口之后，不但可以通过文件系统的命令行操作设备，也可以通过应用程序，调用 <code>read</code>、<code>write</code> 函数，就像读写文件一样操作设备，所以说设备在 Linux 下，也只是一个特殊的文件。</p><p>但是，除了读写操作，还需要有检查特定于设备的功能和属性。于是，需要 <code>ioctl</code> 接口，它表示输入输出控制接口，是用于配置和修改特定设备属性的通用接口。</p><p>另外，存储系统的 I&#x2F;O 是整个系统最慢的一个环节，所以 Linux 提供了不少缓存机制来提高 I&#x2F;O 的效率。</p><ul><li>为了提高文件访问的效率，会使用<strong>页缓存、索引节点缓存、目录项缓存</strong>等多种缓存机制，目的是为了减少对块设备的直接调用。</li><li>为了提高块设备的访问效率， 会使用<strong>缓冲区</strong>，来缓存块设备的数据。</li></ul><h3 id="键盘敲入字母时，期间发生了什么？"><a href="#键盘敲入字母时，期间发生了什么？" class="headerlink" title="键盘敲入字母时，期间发生了什么？"></a>键盘敲入字母时，期间发生了什么？</h3><p>看完前面的内容，相信你对输入输出设备的管理有了一定的认识，那接下来就从操作系统的角度回答「键盘敲入字母时，操作系统期间发生了什么？」</p><p>我们先来看看 CPU 的硬件架构图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/CPU%20%E7%A1%AC%E4%BB%B6%E6%80%BB%E7%BA%BF%E5%9B%BE.png" alt="CPU 的硬件架构图"></p><p>CPU 里面的内存接口，直接和系统总线通信，然后系统总线再接入一个 I&#x2F;O 桥接器，这个 I&#x2F;O 桥接器，另一边接入了内存总线，使得 CPU 和内存通信。再另一边，又接入了一个 I&#x2F;O 总线，用来连接 I&#x2F;O 设备，比如键盘、显示器等。</p><p>那当用户输入了键盘字符，<strong>键盘控制器</strong>就会产生扫描码数据，并将其缓冲在键盘控制器的寄存器中，紧接着键盘控制器通过总线给 CPU 发送<strong>中断请求</strong>。</p><p>CPU 收到中断请求后，操作系统会<strong>保存被中断进程的 CPU 上下文</strong>，然后调用键盘的<strong>中断处理程序</strong>。</p><p>键盘的中断处理程序是在<strong>键盘驱动程序</strong>初始化时注册的，那键盘<strong>中断处理函数</strong>的功能就是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到用户在键盘输入的字符，如果输入的字符是显示字符，那就会把扫描码翻译成对应显示字符的 ASCII 码，比如用户在键盘输入的是字母 A，是显示字符，于是就会把扫描码翻译成 A 字符的 ASCII 码。</p><p>得到了显示字符的 ASCII 码后，就会把 ASCII 码放到「读缓冲区队列」，接下来就是要把显示字符显示屏幕了，显示设备的驱动程序会定时从「读缓冲区队列」读取数据放到「写缓冲区队列」，最后把「写缓冲区队列」的数据一个一个写入到显示设备的控制器的寄存器中的数据缓冲区，最后将这些数据显示在屏幕里。</p><p>显示出结果后，<strong>恢复被中断进程的上下文</strong>。</p><h2 id="文件传输优化"><a href="#文件传输优化" class="headerlink" title="文件传输优化"></a>文件传输优化</h2><h3 id="DMA"><a href="#DMA" class="headerlink" title="DMA"></a>DMA</h3><p>在没有 DMA 技术前，I&#x2F;O 的过程是这样的：</p><ul><li>CPU 发出对应的指令给磁盘控制器，然后返回；</li><li>磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个<strong>中断</strong>；</li><li>CPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。</li></ul><p>为了方便你理解，我画了一副图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/I_O%20%E4%B8%AD%E6%96%AD.png" alt="img"></p><p>可以看到，整个数据的传输过程，都要需要 CPU 亲自参与搬运数据的过程，而且这个过程，CPU 是不能做其他事情的。</p><p>简单的搬运几个字符数据那没问题，但是如果我们用千兆网卡或者硬盘传输大量数据的时候，都用 CPU 来搬运的话，肯定忙不过来。</p><p>计算机科学家们发现了事情的严重性后，于是就发明了 DMA 技术，也就是<strong>直接内存访问（Direct Memory Access）</strong> 技术。</p><p>什么是 DMA 技术？简单理解就是，<strong>在进行 I&#x2F;O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务</strong>。</p><p>那使用 DMA 控制器进行数据传输的过程究竟是什么样的呢？下面我们来具体看看。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/DRM%20I_O%20%E8%BF%87%E7%A8%8B.png" alt="img"></p><p>具体过程：</p><ul><li>用户进程调用 read 方法，向操作系统发出 I&#x2F;O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；</li><li>操作系统收到请求后，进一步将 I&#x2F;O 请求发送 DMA，然后让 CPU 执行其他任务；</li><li>DMA 进一步将 I&#x2F;O 请求发送给磁盘；</li><li>磁盘收到 DMA 的 I&#x2F;O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；</li><li><strong>DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务</strong>；</li><li>当 DMA 读取了足够多的数据，就会发送中断信号给 CPU；</li><li>CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；</li></ul><p>可以看到， 整个数据传输的过程，CPU 不再参与数据搬运的工作，而是全程由 DMA 完成，但是 CPU 在这个过程中也是必不可少的，因为传输什么数据，从哪里传输到哪里，都需要 CPU 来告诉 DMA 控制器。</p><p>早期 DMA 只存在在主板上，如今由于 I&#x2F;O 设备越来越多，数据传输的需求也不尽相同，所以<strong>每个 I&#x2F;O 设备里面都有自己的 DMA 控制器。</strong></p><h3 id="传统的文件传输有多糟糕？"><a href="#传统的文件传输有多糟糕？" class="headerlink" title="传统的文件传输有多糟糕？"></a>传统的文件传输有多糟糕？</h3><p>如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。</p><p>传统 I&#x2F;O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I&#x2F;O 接口从磁盘读取或写入。</p><p>代码通常如下，一般会需要两个系统调用：</p><pre><code class="c">read(file, tmp_buf, len);write(socket, tmp_buf, len);</code></pre><p>代码很简单，虽然就两行代码，但是这里面发生了不少的事情。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/%E4%BC%A0%E7%BB%9F%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93.png" alt="img"></p><p>首先，期间共<strong>发生了 4 次用户态与内核态的上下文切换</strong>，因为发生了两次系统调用，一次是 <code>read()</code> ，一次是 <code>write()</code>，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。</p><p>上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。</p><p>其次，还<strong>发生了 4 次数据拷贝</strong>，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程：</p><ul><li><em>第一次拷贝</em>，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。</li><li><em>第二次拷贝</em>，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。</li><li><em>第三次拷贝</em>，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。</li><li><em>第四次拷贝</em>，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。</li></ul><p>我们回过头看这个文件传输的过程，我们只是搬运一份数据，结果却搬运了 4 次，过多的数据拷贝无疑会消耗 CPU 资源，大大降低了系统性能。</p><p>这种简单又传统的文件传输方式，存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。</p><p>所以，<strong>要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数</strong>。</p><h3 id="如何优化文件传输的性能？"><a href="#如何优化文件传输的性能？" class="headerlink" title="如何优化文件传输的性能？"></a>如何优化文件传输的性能？</h3><blockquote><p>先来看看，如何减少「用户态与内核态的上下文切换」的次数呢？</p></blockquote><p>读取磁盘数据的时候，之所以要发生上下文切换，这是因为用户空间没有权限操作磁盘或网卡，内核的权限最高，这些操作设备的过程都需要交由操作系统内核来完成，所以一般要通过内核去完成某些任务的时候，就需要使用操作系统提供的系统调用函数。</p><p>而一次系统调用必然会发生 2 次上下文切换：首先从用户态切换到内核态，当内核执行完任务后，再切换回用户态交由进程代码执行。</p><p>所以，<strong>要想减少上下文切换到次数，就要减少系统调用的次数</strong>。</p><blockquote><p>再来看看，如何减少「数据拷贝」的次数？</p></blockquote><p>在前面我们知道了，传统的文件传输方式会历经 4 次数据拷贝，而且这里面，「从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里」，这个过程是没有必要的。</p><p>因为文件传输的应用场景中，在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此<strong>用户的缓冲区是没有必要存在的</strong>。</p><h3 id="如何实现零拷贝？"><a href="#如何实现零拷贝？" class="headerlink" title="如何实现零拷贝？"></a>如何实现零拷贝？</h3><p>零拷贝技术实现的方式通常有 2 种：</p><ul><li>mmap + write</li><li>sendfile</li></ul><p>下面就谈一谈，它们是如何减少「上下文切换」和「数据拷贝」的次数。</p><h4 id="mmap-write"><a href="#mmap-write" class="headerlink" title="mmap + write"></a>mmap + write</h4><p>在前面我们知道，<code>read()</code> 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 <code>mmap()</code> 替换 <code>read()</code> 系统调用函数。</p><pre><code class="c">buf = mmap(file, len);write(sockfd, buf, len);</code></pre><p><code>mmap()</code> 系统调用函数会直接把内核缓冲区里的数据「<strong>映射</strong>」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/mmap%20%2B%20write%20%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt="img"></p><p>具体过程如下：</p><ul><li>应用进程调用了 <code>mmap()</code> 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；</li><li>应用进程再调用 <code>write()</code>，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；</li><li>最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。</li></ul><p>我们可以得知，通过使用 <code>mmap()</code> 来代替 <code>read()</code>， 可以减少一次数据拷贝的过程。</p><p>但这还不是最理想的零拷贝，因为仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。</p><h4 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h4><p>在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 <code>sendfile()</code>，函数形式如下：</p><pre><code class="c">#include &lt;sys/socket.h&gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);</code></pre><p>它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。</p><p>首先，它可以替代前面的 <code>read()</code> 和 <code>write()</code> 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。</p><p>其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-3%E6%AC%A1%E6%8B%B7%E8%B4%9D.png" alt="img"></p><p>但是这还不是真正的零拷贝技术，如果网卡支持 SG-DMA（<em>The Scatter-Gather Direct Memory Access</em>）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。</p><p>你可以在你的 Linux 系统通过下面这个命令，查看网卡是否支持 scatter-gather 特性：</p><pre><code class="bash">$ ethtool -k eth0 | grep scatter-gatherscatter-gather: on</code></pre><p>于是，从 Linux 内核 <code>2.4</code> 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， <code>sendfile()</code> 系统调用的过程发生了点变化，具体过程如下：</p><ul><li>第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；</li><li>第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；</li></ul><p>所以，这个过程之中，只进行了 2 次数据拷贝，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt="img"></p><p>这就是所谓的<strong>零拷贝（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。</strong>。</p><p>零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，<strong>只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。</strong></p><p>所以，总体来看，<strong>零拷贝技术可以把文件传输的性能提高至少一倍以上</strong>。</p><p>kafka和nginx都使用了零拷贝技术。</p><h3 id="PageCache-有什么作用？"><a href="#PageCache-有什么作用？" class="headerlink" title="PageCache 有什么作用？"></a>PageCache 有什么作用？</h3><p>回顾前面说道文件传输过程，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是<strong>磁盘高速缓存（PageCache）</strong>。</p><p>由于零拷贝使用了 PageCache 技术，可以使得零拷贝进一步提升了性能，我们接下来看看 PageCache 是如何做到这一点的。</p><p>读写磁盘相比读写内存的速度慢太多了，所以我们应该想办法把「读写磁盘」替换成「读写内存」。于是，我们会通过 DMA 把磁盘里的数据搬运到内存里，这样就可以用读内存替换读磁盘。</p><p>但是，内存空间远比磁盘要小，内存注定只能拷贝磁盘里的一小部分数据。</p><p>那问题来了，选择哪些磁盘数据拷贝到内存呢？</p><p>我们都知道程序运行的时候，具有「局部性」，所以通常，刚被访问的数据在短时间内再次被访问的概率很高，于是我们可以用 <strong>PageCache 来缓存最近被访问的数据</strong>，当空间不足时淘汰最久未被访问的缓存。</p><p>所以，读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中。</p><p>还有一点，读取磁盘数据的时候，需要找到数据所在的位置，但是对于机械磁盘来说，就是通过磁头旋转到数据所在的扇区，再开始「顺序」读取数据，但是旋转磁头这个物理动作是非常耗时的，为了降低它的影响，<strong>PageCache 使用了「预读功能」</strong>。</p><p>比如，假设 read 方法每次只会读 <code>32 KB</code> 的字节，虽然 read 刚开始只会读 0 ～ 32 KB 的字节，但内核会把其后面的 32～64 KB 也读取到 PageCache，这样后面读取 32～64 KB 的成本就很低，如果在 32～64 KB 淘汰出 PageCache 前，进程读取到它了，收益就非常大。</p><p>所以，PageCache 的优点主要是两个：</p><ul><li>缓存最近被访问的数据；</li><li>预读功能；</li></ul><p>这两个做法，将大大提高读写磁盘的性能。</p><p><strong>但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能</strong></p><p>这是因为如果你有很多 GB 级别文件需要传输，每当用户访问这些大文件的时候，内核就会把它们载入 PageCache 中，于是 PageCache 空间很快被这些大文件占满。</p><p>另外，由于文件太大，可能某些部分的文件数据被再次访问的概率比较低，这样就会带来 2 个问题：</p><ul><li>PageCache 由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 PageCache，于是这样磁盘读写的性能就会下降了；</li><li>PageCache 中的大文件数据，由于没有享受到缓存带来的好处，但却耗费 DMA 多拷贝到 PageCache 一次；</li></ul><p>所以，针对大文件的传输，不应该使用 PageCache，也就是说不应该使用零拷贝技术，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，这样在高并发的环境下，会带来严重的性能问题。</p><h3 id="大文件传输用什么方式实现？"><a href="#大文件传输用什么方式实现？" class="headerlink" title="大文件传输用什么方式实现？"></a>大文件传输用什么方式实现？</h3><p>那针对大文件的传输，我们应该使用什么方式呢？</p><p>我们先来看看最初的例子，当调用 read 方法读取文件时，进程实际上会阻塞在 read 方法调用，因为要等待磁盘数据的返回，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/%E9%98%BB%E5%A1%9E%20IO%20%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="img"></p><p>具体过程：</p><ul><li>当调用 read 方法时，会阻塞着，此时内核会向磁盘发起 I&#x2F;O 请求，磁盘收到请求后，便会寻址，当磁盘数据准备好后，就会向内核发起 I&#x2F;O 中断，告知内核磁盘数据已经准备好；</li><li>内核收到 I&#x2F;O 中断后，就将数据从磁盘控制器缓冲区拷贝到 PageCache 里；</li><li>最后，内核再把 PageCache 中的数据拷贝到用户缓冲区，于是 read 调用就正常返回了。</li></ul><p>对于阻塞的问题，可以用异步 I&#x2F;O 来解决，它工作方式如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/%E5%BC%82%E6%AD%A5%20IO%20%E7%9A%84%E8%BF%87%E7%A8%8B.png" alt="img"></p><p>它把读操作分为两部分：</p><ul><li>前半部分，内核向磁盘发起读请求，但是可以<strong>不等待数据就位就可以返回</strong>，于是进程此时可以处理其他任务；</li><li>后半部分，当内核将磁盘中的数据拷贝到进程缓冲区后，进程将接收到内核的<strong>通知</strong>，再去处理数据；</li></ul><p>而且，我们可以发现，异步 I&#x2F;O 并没有涉及到 PageCache，所以使用异步 I&#x2F;O 就意味着要绕开 PageCache。</p><p>绕开 PageCache 的 I&#x2F;O 叫直接 I&#x2F;O，使用 PageCache 的 I&#x2F;O 则叫缓存 I&#x2F;O。<strong>通常，对于磁盘，异步 I&#x2F;O 只支持直接 I&#x2F;O。</strong></p><p>前面也提到，大文件的传输不应该使用 PageCache，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache。</p><p>于是，<strong>在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I&#x2F;O + 直接 I&#x2F;O」来替代零拷贝技术</strong>。</p><p>直接 I&#x2F;O 应用场景常见的两种：</p><ul><li>应用程序已经实现了磁盘数据的缓存，那么可以不需要 PageCache 再次缓存，减少额外的性能损耗。在 MySQL 数据库中，可以通过参数设置开启直接 I&#x2F;O，默认是不开启；</li><li>传输大文件的时候，由于大文件难以命中 PageCache 缓存，而且会占满 PageCache 导致「热点」文件无法充分利用缓存，从而增大了性能开销，因此，这时应该使用直接 I&#x2F;O。</li></ul><p>另外，由于直接 I&#x2F;O 绕过了 PageCache，就无法享受内核的这两点的优化：</p><ul><li>内核的 I&#x2F;O 调度算法会缓存尽可能多的 I&#x2F;O 请求在 PageCache 中，最后「<strong>合并</strong>」成一个更大的 I&#x2F;O 请求再发给磁盘，这样做是为了减少磁盘的寻址操作；</li><li>内核也会「<strong>预读</strong>」后续的 I&#x2F;O 请求放在 PageCache 中，一样是为了减少对磁盘的操作；</li></ul><p>于是，传输大文件的时候，使用「异步 I&#x2F;O + 直接 I&#x2F;O」了，就可以无阻塞地读取文件了。</p><p>所以，传输文件的时候，我们要根据文件的大小来使用不同的方式：</p><ul><li>传输大文件的时候，使用「异步 I&#x2F;O + 直接 I&#x2F;O」；</li><li>传输小文件的时候，则使用「零拷贝技术」；</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E7%BC%96%E8%AF%91%E6%9C%9F%E5%B8%B8%E9%87%8F%E5%92%8Cconstexpr/"/>
      <url>/2023/01/22/%E7%BC%96%E8%AF%91%E6%9C%9F%E5%B8%B8%E9%87%8F%E5%92%8Cconstexpr/</url>
      
        <content type="html"><![CDATA[<h1 id="编译期常量和constexpr"><a href="#编译期常量和constexpr" class="headerlink" title="编译期常量和constexpr"></a>编译期常量和constexpr</h1><h2 id="编译期常量类型"><a href="#编译期常量类型" class="headerlink" title="编译期常量类型"></a>编译期常量类型</h2><p>总有些东西是编译器要求编译期间就要确定的，除了变量的类型外，最频繁出现的地方就是数组、switch的case标签和模板了。</p><p><strong>数组中的编译期常量</strong></p><p>如果我们想要创建一个不是动态分配内存的数组，那么我们就必须给他设定一个size，这个size必须在编译期间就知道，因此静态数组的大小是编译期常量。</p><pre><code class="cpp"> int someArray[520];</code></pre><p>因为函数栈分配的内存大小是要在编译期确定的，所以数组大小也必须在编译期确定。</p><p>有些时候我们不用显示得指明数组的大小，我们用字符串或花括号来初始化数组的时候，编译器会实现帮我们数好这个数组的大小。</p><pre><code class="cpp"> int someArray[] = &#123;5, 2, 0&#125;; char charArray[] = &quot;Ich liebe dich.&quot;;</code></pre><p><strong>模板中的编译期常量</strong></p><p>除了类型以外，数字也可以作为模板的参数。这些数值变量包括int，long，short，bool，char和弱枚举enum等。</p><p>编译器在初始化模板的时候必须知道模板的类型，那么这些模板的参数也必须是编译期常量。</p><pre><code class="cpp"> enum Color &#123;RED, GREEN, BLUE&#125;;  template&lt;unsigned long N, char ID, Color C&gt; struct someStruct &#123;&#125;;  someStruct&lt;42ul, &#39;e&#39;, GREEN&gt; theStruct;</code></pre><p><strong>Case 表达式</strong></p><p>switch语句中case后接的表达式也必须是编译期常量，和上边模板的情况非常类似。</p><pre><code class="cpp"> void comment(int phrase) &#123;   switch(phrase) &#123;   case 42:   std::cout &lt;&lt; &quot;You are right!&quot; &lt;&lt; std::endl;   break;   case BLUE:   std::cout &lt;&lt; &quot;Don&#39;t be upset!&quot; &lt;&lt; std::endl;   break;   case &#39;z&#39;:   std::cout &lt;&lt; &quot;You are the last one!&quot; &lt;&lt; std::endl;   break;   default:   std::cout &lt;&lt; &quot;This is beyond what I can handle...&quot; &lt;&lt; std::endl;   &#125; &#125;</code></pre><h2 id="使用编译期常量有什么好处"><a href="#使用编译期常量有什么好处" class="headerlink" title="使用编译期常量有什么好处"></a><strong>使用编译期常量有什么好处</strong></h2><h3 id="更安全的程序"><a href="#更安全的程序" class="headerlink" title="更安全的程序"></a><strong>更安全的程序</strong></h3><p>编译期常量能让我们写出更有逻辑的代码——在编译期就体现出逻辑。比如矩阵相乘：</p><pre><code class="cpp"> class Matrix&#123;   unsigned rowCount;   unsigned columnCount;   //... &#125;;</code></pre><p>我们都知道，两个矩阵相乘，当且仅当左矩阵的列数等于右矩阵的行数，如果不满足这个规则的话，那就完蛋了，所以针对上边矩阵的乘法，我们在函数中要做一些判断：</p><pre><code class="cpp"> Matrix operator*(Matrix const&amp; lhs, Matrix const&amp; rhs) &#123;   if(lhs.getColumnCount() != rhs.getRowCount()) &#123;     throw OhWeHaveAProblem();    &#125;      //... &#125;</code></pre><p>但是如果我们在编译期就知道了矩阵的size，那么我们就可以把上边的判断放在模板中完成——这样的话不同size的矩阵一下子就成了不同类型的变量了。这样我们的矩阵乘法也相应变得简单了一些：</p><pre><code class="cpp"> template &lt;unsigned Rows, unsigned Columns&gt; class Matrix &#123;   /* ... */ &#125;;  template &lt;unsigned N, unsigned M, unsigned P&gt; Matrix&lt;N, P&gt; operator*(Matrix&lt;N, M&gt; const&amp; lhs, Matrix&lt;M, P&gt; const&amp; rhs) &#123;   /* ... */ &#125;  Matrix&lt;1, 2&gt; m12 = /* ... */; Matrix&lt;2, 3&gt; m23 = /* ... */; auto m13 = m12 * m23; // OK auto mX = m23 * m13;  // Compile Error!</code></pre><p>在这个例子中，编译器本身就阻止了错误的发生，还有很多其他的例子——更复杂的例子在编译期间使用模板。从C++11后有一堆这样的模板都定义在了标准库STL中，这个之后再说。所以大家不要觉得上边这种做法是脱裤子放屁，相当于我们把运行时的条件判断交给了编译期来做，前提就是矩阵的类型必须是编译期常量。你可能会问，除了像上边直接用常数来实例化矩阵，有没有其他方法来告诉编译器这是个编译期常量呢？请往下看。</p><h3 id="编译优化"><a href="#编译优化" class="headerlink" title="编译优化"></a><strong>编译优化</strong></h3><p>编译器能根据编译期常量来实现各种不同的优化。比如，如果在一个if判断语句中，其中一个条件是编译期常量，编译器知道在这个判断句中一定会走某一条路，那么编译器就会把这个if语句优化掉，留下只会走的那一条路。</p><pre><code class="cpp"> if (sizeof(void*) == 4) &#123;   std::cout &lt;&lt; &quot;This is a 32-bit system!&quot; &lt;&lt; std::endl; &#125; else &#123;   std::cout &lt;&lt; &quot;This is a 64-bit system!&quot; &lt;&lt; std::endl; &#125;</code></pre><p>在上例中，编译器就会直接利用其中某一个cout语句来替换掉整个if代码块——反正运行代码的机器是32还是64位的又不会变。 另一个可以优化的地方在空间优化。总体来说，如果我们的对象利用编译期常数来存储数值，那么我们就不用在这个对象中再占用内存存储这些数。就拿本文之前的例子来举例：</p><ul><li>someStruct结构中包含一个‘unsigned long’，一个‘char’，和一个‘color’，尽管如此他的实例对象却只占用一个byte左右的空间。</li><li>矩阵相乘的时候，我们在矩阵中也没必要花费空间去存储矩阵的行数和列数了。</li></ul><h2 id="编译期常量都从哪里来？"><a href="#编译期常量都从哪里来？" class="headerlink" title="编译期常量都从哪里来？"></a><strong>编译期常量都从哪里来？</strong></h2><p>在我们的经验中，大部分编译期常量的来源还是字面常量（literals）以及枚举量（enumerations）。如<code>someStruct&lt;42ul, &#39;e&#39;, GREEN&gt; theStruct;</code>中<code>someStruct</code>的三个模板参数都是常量——分别是整形字面量、char型字面量和枚举常量。</p><p>比较典型的编译期常量的来源就是内置的<code>sizeof</code>操作符。编译器必须在编译期就知道一个变量占据了多少内存，所以它的值也可以被用作编译期常量。</p><pre><code class="cpp"> class SomeClass &#123;   //... &#125;; int const count = 10;  //作为数组的size，编译期常量 SomeClass theMovie[count] = &#123; /* ... */&#125;; //常量表达式，在编译期计算 int const otherConst = 26; //只是常量，但不是编译期常量  int i = 419; unsigned char buffer[sizeof(i)] = &#123;&#125;;   //常量表达式，在编译期计算</code></pre><p>另一个经常出现编译期常量最常出现的地方就是<strong>静态类成员变量</strong>（static class member variables），而枚举常量常常作为它的替换也出现在类中。</p><pre><code class="cpp"> struct SomeStruct&#123;   static unsigned const size1 = 44;  //编译期常量   enum &#123; size2 = 45 &#125;;  //编译期常量   int someIntegers[size1];  //常量表达式，在编译期计算   double someDoubles[size2]; //常量表达式，在编译期计算 &#125;;</code></pre><p>与编译期常量对应的概念<strong>编译期常量表达式（compile-time constant expression）</strong>指的是，值不会改变且在编译期就可以计算出来的表达式。其实更好理解的说法是，<strong>任何不是用户自己定义的——而必须通过编译期计算出来的字面量都属于编译期常量表达式</strong>。需要注意的是，并不是所有的常量表达式都是编译期常量表达式，只有我们<strong>要求编译器计算出来时</strong>，才是编译期常量表达式。希望下边这个例子可以做很好的说明：我们通过把<code>p</code>安排在合适的位置——数组的size，强制编译器去计算<code>p</code>的值，即<code>p</code>此时变成了编译期常量表达式。</p><pre><code class="cpp">const int i = 100;        const int j = i * 200;    //常量表达式，但不是编译期常量表达式const int k = 100;        const int p = k * 200;    //是编译期常量表达式，由下边数组确定unsigned char helper[p] = &#123;&#125;; //要求p是编译期常量表达式，在编译期就需确定</code></pre><h2 id="编译期运算"><a href="#编译期运算" class="headerlink" title="编译期运算"></a><strong>编译期运算</strong></h2><p>从上边的例子可以看出，有时我们可以<strong>通过某些手段去“胁迫”编译器，把运算任务从运行时提前到编译期</strong>，这就是编译期运算的原理。正如“常量表达式”这个名字，我们可以做各种各样的编译期运算，实现在编译期就确定一个常量表达式的目的。事实上，由最简单的运算表达式出发，我们可以做到各种各样的编译期运算。比如非常简单：</p><pre><code class="cpp"> int const doubleCount = 10; unsigned char doubleBuffer[doubleCount * sizeof(double)] = &#123;&#125;;</code></pre><p>除此之外，我们也可以用许多其他的操作，比如考虑下边并没有什么意义的代码：</p><pre><code class="cpp"> std::string nonsense(char input) &#123;   switch(input) &#123;   case &quot;some&quot;[(sizeof(void*) == 4) ? 0 : 1]:     return &quot;Aachen&quot;;   default:     return &quot;Wuhan&quot;;   &#125; &#125;</code></pre><p>上边的代码并没有什么实际的意义，<code>switch</code>语句的每一个case label必须是编译期常量，表达式<code>sizeof(void*) == 4</code>的意思是当前系统是不是一个32位系统，这个表达式由于<code>sizeof</code>的原因是常量表达式，判断结果作为三元运算符的第一个参数，最后的case label由当前系统的位数分别是”some”的”s”（是32位系统）或”o”（不是32位系统）。返回的两个字符串分别是两个城市。</p><p>尽管上边的例子是无意义的，我们仍然可以看出由这种方法写出的常量表达式很难读。我们可以改进可读性，将上边例子改写成：</p><pre><code class="cpp"> std::string nonsense(char input) &#123;   auto const index = (sizeof(void*) == 4) ? 0 : 1;   auto const someLabel = &quot;some&quot;[index];   switch(input) &#123;   case someLabel:     return &quot;Aachen&quot;;   default:     return &quot;Wuhan&quot;;   &#125; &#125;</code></pre><h3 id="使用模板进行编译期运算"><a href="#使用模板进行编译期运算" class="headerlink" title="使用模板进行编译期运算"></a><strong>使用模板进行编译期运算</strong></h3><p>实例化模板的参数必须为编译期常数——换句话说编译器会在编译期计算<strong>作为实例化模板参数的常量表达式</strong>。回忆一下我们可以利用静态成员常量作为编译期常量，我们就可以利用以上特性去把函数模板当成函数来计算，其实这就是模板元编程（template meta programming）方法的雏形。</p><pre><code class="cpp"> template &lt;unsigned N&gt;  struct Fibonacci;  template &lt;&gt; struct Fibonacci&lt;0&gt; &#123;   static unsigned const value = 0;    &#125;;  template &lt;&gt; struct Fibonacci&lt;1&gt; &#123;   static unsigned const value = 1;    &#125;;  template &lt;unsigned N&gt;  struct Fibonacci &#123;   static unsigned const value = Fibonacci&lt;N-1&gt;::value + Fibonacci&lt;N-2&gt;::value; &#125;;</code></pre><p>最后一个模板比较有意思，仔细看代码就会发现，它<strong>递归式地</strong>去实例化参数为N的的模板，递归终止在模板参数为<code>0</code>和<code>1</code>时，就是我们的第二和第三个模板所直接返回的编译期常量。</p><p>这种模板元函数看起来啰啰嗦嗦的，但是在C++11出现前，它是<strong>唯一</strong>可以在编译期进行复杂编译期运算的方法。虽然它已经被证实为图灵完备的，但是往往编译器在递归的时候还是会设置一个模板最大初始化深度来避免无穷编译期递归。</p><h2 id="constexpr"><a href="#constexpr" class="headerlink" title="constexpr"></a>constexpr</h2><p>C++03版编译期运算最大的问题恐怕就在于，我们写出来的代码<strong>只能够给编译期使用</strong>。如果我们想实现一个函数，使得他在编译期和运行时都能够被使用，我们就必须复制一份代码，一份给编译期，一份适配run-time，这也无形中给代码维护和迭代带来没有必要的压力。</p><p>所以能不能写一种函数，它既能够在编译期运行也能够在运行期运行——上边的选择仅仅取决于当前的调用语境呢？在C++11中我们引入了<code>constexpr</code>关键字来很好地解决这个问题。</p><p><code>constexpr</code>关键字出现在函数的声明中，保证函数返回一个编译期常量的<strong>可能性</strong>（但这个函数不是只能在编译期使用），即如果穿进去的参数是编译期常量，那么这个函数就能够也返回一个编译期常量。</p><p>有了<code>constexpr</code>，模板元编程版本的斐波那契函数的计算就可以被简化成：</p><pre><code class="cpp"> constexpr unsigned fibonacci(unsigned i) &#123;   return (i &lt;= 1u) ? i : (fibonacci(i - 1) + fibonacci(i - 2)); &#125;</code></pre><p>只是多了一个<code>constexpr</code>，这个函数就可以在编译期和运行期同时起作用。如果带有<code>constexpr</code>的函数的参数被编译器检测到为编译期常量，那么这个函数就可以自动地在编译期运行。请看下边的例子：</p><pre><code class="cpp"> int main(int argc, char** argv) &#123;   char int_values[fibonacci(6)] = &#123;&#125;;           //正确，数组大小在编译期被强制计算   std::cout &lt;&lt; sizeof(int_values) &lt;&lt; std::endl; //正确，sizeof函数参数在编译期被计算      std::cout &lt;&lt; fibonacci(argc) &lt;&lt; std::endl;    //在运行时计算，因为argc只有在运行时才能确定   std::cout &lt;&lt; sizeof(std::array&lt;char, fibonacci(argc)&gt;) &lt;&lt; std::endl;  //ERROR，模板参数要求在编译期确定fibonacci的值，但是argc是运行时参数。 &#125;</code></pre><p>最后一行编译时会报错，因为模板参数和<code>sizeof()</code>函数都要求在编译期确定<code>fibonacci(argc)</code>的值，但是<code>argc</code>只能在运行时确定。</p><h3 id="constexptr修饰的变量"><a href="#constexptr修饰的变量" class="headerlink" title="constexptr修饰的变量"></a><strong>constexptr修饰的变量</strong></h3><p>声明时带有<code>constexpr</code>关键字的变量是常量表达式，因而可以被用做编译期计算。不像在C++03标准中，只有内置类型的字面量才能被视作编译期常量，这个标准在C++11和C++14中被放宽了许多。</p><p>由此衍生出了一个新概念literal type：声明时可以加<code>constexpr</code>修饰的类我们成为literal type。</p><blockquote><p>Specifies that a type is a literal type. Literal types are the types of constexpr variables and they can be constructed, manipulated, and returned from constexpr functions.  <a href="http://link.zhihu.com/?target=http://-cppreference.com">http://-cppreference.com</a></p></blockquote><p>需要注意的是，所有拥有<code>constexpr</code>修饰的构造函数的类也都是literal type，因为拥有此类构造函数的类的对象可以被<code>constexpr</code>函数初始化。考虑下边的Point类，它就是一个literal type：</p><pre><code class="cpp"> class Point &#123;   int x;   int y; public:   constexpr Point(int ix, int iy) : x&#123;ix&#125;, y&#123;iy&#125; &#123;&#125;   constexpr int getX() const &#123; return x; &#125;   constexpr int getY() const &#123; return y; &#125; &#125;;</code></pre><p>我们可以使用<code>constexpr</code>构造函数来创造它的编译期常量对象，鉴于它也有<code>x</code>的<code>constepxr</code>类型的getter函数，我们也可以在编译期使用这些函数来获取它的成员值。</p><pre><code class="cpp"> constexpr Point p&#123;1, 2&#125;;      //OK, 因为有constexpr构造函数 constexpr int py = p.getY();  //OK, 因为y的getter是constexpr的。 double darry[py] &#123;&#125;;</code></pre><h3 id="constexpr修饰的函数"><a href="#constexpr修饰的函数" class="headerlink" title="constexpr修饰的函数"></a><strong>constexpr修饰的函数</strong></h3><p>那么是不是所有的函数都可以被这么定义为编译期运算函数呢？其实不然。在C++11中，我们对<code>constexpr</code>函数的内容有非常严格的规定，在C++14中这些标准被放宽松了许多，但是保留的最严格的规定莫过于函数体内不能有<code>try</code>块，以及任何<code>static</code>和局部线程变量。并且，在函数中只能调用其他<code>constexpr</code>函数，该函数也不能有任何运行时才会有的行为，比如抛出异常、使用<code>new</code>或<code>delete</code>操作等等。所以在C++14中，如果把斐波那契函数写成下边这样，它的可读性会大大提升。：</p><pre><code class="cpp"> constexpr unsigned fibonacci(unsigned i) &#123;   switch (i) &#123;     case 0: return 0;     case 1: return 1;     default: return fibonacci(i - 1) + fibonacci(i - 2);   &#125; &#125;</code></pre><p>如果我们给一个函数加上一个<code>constexpr</code>关键字，<strong>不是说我们就把这个函数绑死在编译期上了</strong>——在文章一开始就说过，这个函数也应该能在运行期被复用。如果一次调用被认为是runtime的，那么这个函数返回的值也不再是编译期常量了——它就被当作一个正常的函数来对待。需要注意的是，在编译期调用<code>constexpr</code>函数，所有运行时所做的检查，在编译期均不会处理。最常见的问题就是<code>int</code>溢出的问题，此时我们还应该在代码中手动加上相应的检查：</p><pre><code class="cpp"> constexpr unsigned fibonacci(unsigned i) &#123;   switch (i) &#123;     case 0: return 0;     case 1: return 1;     default: &#123;       auto f1 = fibonacci(i - 1);       auto f1 = fibonacci(i - 2);       //手动进行越界检查，如果compile-time发现越界，引导函数进入throw语句，throw语句是典型的run-time语句       if(f1 &gt; std::numeric_limits&lt;unsigned&gt;::max() - f2) &#123;         throw std::invalid_argument&#123;&quot;Overflow detected!&quot;&#125;;       &#125;     &#125;   &#125; &#125;</code></pre><p>上边的检查会始终起作用，如果我们在编译期传入一个过大的参数从而产生了整型溢出，那么函数语句就会走到抛出<code>std::invalid_argument</code>的分支语句中，又因为抛出异常这种行为是编译期所不允许的，所以编译时就会报错——<strong>这个函数调用并不是一个编译期运算表达式</strong>；如果没有上边的检查，那么编译器就会默许这种错误，导致错误更难发现。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a><strong>结论</strong></h2><p>尽管编译期运算会延长我们的编译时间，但是我们有些时候会用它来加快程序的运行速度。但是在使用时我们仍应该抱着谨慎的态度。有些人说，反正<code>constexpr</code>函数在运行时和编译期都可以执行，那我们可不可以给每一个函数都加上<code>constexpr</code>呢？我对此观点持保留意见，因为它会让我们的代码中充斥着不必要的关键字，影响阅读不说，它到底给我们编译期带来的好处能不能把坏的影响抵消掉还是要好好权衡的。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/vscode%20c++%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
      <url>/2023/01/22/vscode%20c++%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="vscode-c-运行环境配置"><a href="#vscode-c-运行环境配置" class="headerlink" title="vscode c++运行环境配置"></a>vscode c++运行环境配置</h1><p>VSCode打开文件夹（称作工作目录）之后，如果进行一定的配置之后，会在该文件夹下产生一个叫”.vscode”的文件夹，该文件夹中存放的是一些.json的配置文件，这些配置文件是对工作目录中的代码文件产生作用的。所以以后需要相同开发环境的时候，不用每次都去创建配置文件并进行相关配置，直接拷贝.vscode文件夹即可，但是第一次还是需要手动配置出自己所需的环境。</p><p>1.下载vscode</p><p>2.下载minGW并将minGW的bin文件夹路径添加到环境变量中</p><p>3.安装c&#x2F;c++ extension pack扩展包</p><p>4.用vscode打开文件夹，ctrl+shift+p调出命令面板，输入c&#x2F;c++</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220308200821131.png" alt="image-20220308200821131"></p><p>点击c&#x2F;c++:编辑配置（UI），修改编译器路径为minGW的bin文件夹路径，其中有gcc.exe，g++.exe，c++.exe。一般来说c程序选择gcc，c++选择g++。</p><p>5.新建cpp文件并运行，<img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220308215000782.png" alt="image-20220308215000782"></p><p>选择第一项”C++ (GDB&#x2F;LLDB)”（Windows那个是给MSVC编译器用的，MingGW需要使用GDB）</p><p>6.VS Code自动创建好tasks.json和launch.json文件,并运行（linux下的vscode不会自动创建，需要自行添加）</p><h3 id="gcc和g-区别如下："><a href="#gcc和g-区别如下：" class="headerlink" title="gcc和g++区别如下："></a>gcc和g++区别如下：</h3><p>gcc和g++并不是编译器，也不是编译器的集合，它们只是一种驱动器，根据参数中要编译的文件的类型，调用对应的GNU编译器而已，比如，用gcc编译一个c文件的话，会有以下几个步骤：</p><p>Step1：Call a preprocessor, like cpp.</p><p>Step2：Call an actual compiler, like cc or cc1.</p><p>Step3：Call an assembler, like as.</p><p>Step4：Call a linker, like ld</p><p>所以，更准确的说法是：<strong>gcc调用了C compiler，而g++调用了C++ compiler</strong></p><p>gcc和g++的主要区别</p><ol><li><p>对于 <em>.c和</em>.cpp文件，gcc分别当做c和cpp文件编译（c和cpp的语法强度是不一样的）</p></li><li><p>对于 <em>.c和</em>.cpp文件，g++则统一当做cpp文件编译</p></li><li><p>使用g++编译文件时，<strong>g++会自动链接标准库STL，而gcc不会自动链接STL，需要手动指明</strong></p></li><li><p>gcc在编译C文件时，可使用的预定义宏是比较少的</p></li><li><p>gcc在编译cpp文件时&#x2F;g++在编译c文件和cpp文件时（这时候gcc和g++调用的都是cpp文件的编译器），会加入一些额外的宏，这些宏如下：</p></li></ol><p>#define <strong>GXX_WEAK</strong> 1<br>#define __cplusplus 1<br>#define __DEPRECATED 1<br>#define <strong>GNUG</strong> 4<br>#define __EXCEPTIONS 1<br>#define <strong>private_extern</strong> extern</p><ol start="6"><li>在用gcc编译c++文件时，为了能够使用STL，需要加参数 –lstdc++ ，但这并不代表 gcc –lstdc++ 和 g++等价。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/stdref/"/>
      <url>/2023/01/22/stdref/</url>
      
        <content type="html"><![CDATA[<h1 id="std-ref"><a href="#std-ref" class="headerlink" title="std::ref"></a>std::ref</h1><p>作用：<br><code>std::ref</code> 用于取某个变量的引用，引入其是为了解决函数式编程（如std::bind）的一些传参问题。</p><p>总结：</p><ul><li>std::bind使用的是参数的拷贝而不是引用，当可调用对象期待入参为引用时，必须显示利用std::ref来进行引用绑定。</li><li>多线程std::thread的可调用对象期望入参为引用时，也必须显式通过std::ref来绑定引用进行传参。</li></ul><p>我们知道 C++ 中本来就有引用的存在，为何 C++11 中还要引入一个 <code>std::ref</code> 了？主要是考虑函数式编程（如 <code>std::bind</code>）在使用时，是对参数直接拷贝，而不是引用。下面通过例子说明</p><p>示例1：</p><pre><code class="c++">#include &lt;functional&gt;#include &lt;iostream&gt;void f(int&amp; n1, int&amp; n2, const int&amp; n3)&#123;    std::cout &lt;&lt; &quot;In function: &quot; &lt;&lt; n1 &lt;&lt; &#39; &#39; &lt;&lt; n2 &lt;&lt; &#39; &#39; &lt;&lt; n3 &lt;&lt; &#39;\n&#39;;    ++n1; // increments the copy of n1 stored in the function object    ++n2; // increments the main()&#39;s n2    // ++n3; // compile error&#125;int main()&#123;    int n1 = 1, n2 = 2, n3 = 3;    std::function&lt;void()&gt; bound_f = std::bind(f, n1, std::ref(n2), std::cref(n3));    n1 = 10;    n2 = 11;    n3 = 12;    std::cout &lt;&lt; &quot;Before function: &quot; &lt;&lt; n1 &lt;&lt; &#39; &#39; &lt;&lt; n2 &lt;&lt; &#39; &#39; &lt;&lt; n3 &lt;&lt; &#39;\n&#39;;    bound_f();    std::cout &lt;&lt; &quot;After function: &quot; &lt;&lt; n1 &lt;&lt; &#39; &#39; &lt;&lt; n2 &lt;&lt; &#39; &#39; &lt;&lt; n3 &lt;&lt; &#39;\n&#39;;&#125;</code></pre><p>输出：</p><pre><code>Before function: 10 11 12In function: 1 11 12After function: 10 12 12</code></pre><p>上述代码在执行 <code>std::bind</code> 后，在函数 <code>f()</code> 中 <code>n1</code> 的值仍然是 1，<code>n2</code> 和 <code>n3</code> 改成了修改的值，<strong>说明 <code>std::bind</code> 使用的是参数的拷贝而不是引用，因此必须显示利用 <code>std::ref</code> 来进行引用绑定</strong>。具体为什么 <code>std::bind</code> 不使用引用，可能确实有一些需求，使得 C++11 的设计者认为默认应该采用拷贝，如果使用者有需求，加上 <code>std::ref</code> 即可。</p><p>示例2：</p><pre><code class="c++">#include&lt;thread&gt;#include&lt;iostream&gt;#include&lt;string&gt;void threadFunc(std::string &amp;str, int a)&#123;    str = &quot;change by threadFunc&quot;;    a = 13;&#125;int main()&#123;    std::string str(&quot;main&quot;);    int a = 9;    std::thread th(threadFunc, std::ref(str), a);    th.join();    std::cout&lt;&lt;&quot;str = &quot; &lt;&lt; str &lt;&lt; std::endl;    std::cout&lt;&lt;&quot;a = &quot; &lt;&lt; a &lt;&lt; std::endl;    return 0;&#125;</code></pre><p>输出：</p><pre><code>str = change by threadFunca = 9</code></pre><p>可以看到，和 <code>std::bind</code> 类似，多线程的 <code>std::thread</code> 也是必须显式通过 <code>std::ref</code> 来绑定引用进行传参，否则，形参的引用声明是无效的。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/stdaccumulate%E5%92%8Cstdtransform/"/>
      <url>/2023/01/22/stdaccumulate%E5%92%8Cstdtransform/</url>
      
        <content type="html"><![CDATA[<h1 id="std-accumulate和std-transform"><a href="#std-accumulate和std-transform" class="headerlink" title="std::accumulate和std::transform"></a>std::accumulate和std::transform</h1><h2 id="accumulate"><a href="#accumulate" class="headerlink" title="accumulate"></a>accumulate</h2><p><code>std::accumulate</code> 用于对容器[first,last)内的元素和初始值init进行累积运算。头文件#include <numeric></p><p>函数签名如下：</p><pre><code class="cpp">template&lt; class InputIt, class T &gt;T accumulate( InputIt first, InputIt last, T init );</code></pre><p>前2个参数指定容器的范围，第3个参数指定初始值。返回值为累加的结果，其返回类型就是其第三个实参的类型。</p><p>默认的运算是第三个参数的加法运算，如果第三个参数是int，运算就是数值加法运算；如果第三个参数是string，运算就是字符串的拼接。</p><p>可以自定义运算，自定义的运算作为第四个参数，函数签名如下：</p><pre><code class="cpp">template&lt; class InputIt, class T, class BinaryOperation &gt;T accumulate( InputIt first, InputIt last, T init,              BinaryOperation op );</code></pre><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p><strong>累加</strong></p><pre><code class="cpp">#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;numeric&gt;int main()&#123;    std::vector&lt;int&gt; v&#123; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 &#125;;    int sum = std::accumulate(v.begin(), v.end(), 0);    std::cout &lt;&lt; &quot;sum: &quot; &lt;&lt; sum &lt;&lt; std::endl;    return 0;&#125;</code></pre><p><strong>累乘</strong></p><pre><code class="cpp">#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;numeric&gt;int main()&#123;    std::vector&lt;int&gt; v&#123; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 &#125;;    int product = std::accumulate(v.begin(), v.end(), 1, std::multiplies&lt;int&gt;());    std::cout &lt;&lt; &quot;product: &quot; &lt;&lt; product &lt;&lt; std::endl;    return 0;&#125;</code></pre><h2 id="transform"><a href="#transform" class="headerlink" title="transform"></a>transform</h2><p><strong>头文件：</strong><algorithm></p><p>作用：std::transform在指定的范围内应用于给定的操作，并将结果存储在指定的另一个范围内</p><p>操作有两种：一元和二元。</p><p>一元是对容器给定范围内的每个元素做某种一元运算后放在另一个容器里。有4个参数，前2个指定要进行操作的容器的起止范围，第3个参数是结果存放容器的起始位置，第4个参数是一元运算。函数签名是：</p><pre><code class="cpp">template&lt; class InputIt, class OutputIt, class UnaryOperation &gt;OutputIt transform( InputIt first1, InputIt last1, OutputIt d_first,                    UnaryOperation unary_op );</code></pre><p>二元是对两个容器给定范围内的每个元素做二元运算后放在另一个容器里。涉及两个参与运算的容器。有5个参数，前2个指定参与转换的第1个容器的起止范围，第3个参数是转换的第2个容器的起始位置，第4个参数是结果存放容器的起始位置，第5个参数是二元运算。函数签名是：</p><pre><code class="cpp">template&lt; class InputIt1, class InputIt2, class OutputIt, class BinaryOperation &gt;OutputIt transform( InputIt1 first1, InputIt1 last1, InputIt2 first2,                     OutputIt d_first, BinaryOperation binary_op );</code></pre><h3 id="例子-1"><a href="#例子-1" class="headerlink" title="例子"></a>例子</h3><p><strong>对字符串进行大小写转换</strong></p><pre><code class="cpp">#include &lt;iostream&gt;#include &lt;cctype&gt;#include &lt;string&gt;#include &lt;algorithm&gt;using namespace std;int main()&#123;    std::string str = &quot;Hello, World!&quot;;    cout &lt;&lt; str &lt;&lt; endl;    // toupper    std::string strUpper(str.length(), &#39; &#39;);    std::transform(str.begin(), str.end(), strUpper.begin(), std::toupper);    cout &lt;&lt; strUpper &lt;&lt; endl;    // tolower    std::transform(str.begin(), str.end(), str.begin(), std::tolower);    cout &lt;&lt; str &lt;&lt; endl;    system(&quot;pause&quot;);    return 0;&#125;</code></pre><p>结果：</p><pre><code class="cpp">Hello, World!HELLO, WORLD!hello, world!</code></pre><p><strong>两个数组元素分别相加</strong></p><pre><code class="cpp">#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;iterator&gt;int main()&#123;    std::vector&lt;int&gt; v1 = &#123;10, 20, 30, 40, 50&#125;;    std::vector&lt;int&gt; v2 = &#123; 1, 2, 3, 4, 5 &#125;;    std::vector&lt;int&gt; result(5);    std::transform(v1.begin(), v1.end(), v2.begin(), result.begin(), std::plus&lt;int&gt;());    for (int i : result) &#123;        std::cout &lt;&lt; i &lt;&lt; &quot;\t&quot;;    &#125;    std::cout &lt;&lt; std::endl;    return 0;&#125;</code></pre><p>结果：</p><pre><code class="cpp">11      22      33      44      55</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/socket%20api/"/>
      <url>/2023/01/22/socket%20api/</url>
      
        <content type="html"><![CDATA[<h1 id="socket-api"><a href="#socket-api" class="headerlink" title="socket api"></a>socket api</h1><h2 id="socket"><a href="#socket" class="headerlink" title="socket"></a>socket</h2><pre><code class="cpp">//1.创建监听socket文件描述符int listenfd = socket(PF_INET, SOCK_STREAM, 0);/*1、指明通信域，如PF_UNIX(unix域,用于进程通信)，PF_INET(IPv4)，PF_INET6(IPv6)等2、指明通信类型，最常用的如SOCK_STREAM(面向连接可靠方式,比如TCP）、SOCK_DGRAM(非面向连接的非可靠方式，比如udp）SOCK_RAW(原始套接字,不在传输层使用协议，直接转给ip层)3、指定需要使用的协议。对于TCP参数可指定为IPPROTO_TCP,对于UDP可以用IPPROTO_UDP。使用0则根据前两个参数使用默认的协议。*///2.创建地址//地址数据结构如下struct   sockaddr_in &#123;short int sin_family;            //Address familyunsigned short int sin_port;    // Port numberstruct in_addr sin_addr;       // Internet addressunsigned char sin_zero[8];    //为了让sockaddr与sockaddr_in两个数据结构保持大小相同而保留的空字节。&#125;;struct sockaddr_in address;memset(&amp;address,0,sizeof(address));//初始化addressaddress.sin_family = AF_INET;/*指定通信域，如AF_UNIX(unix域)，AF_INET(IPv4)，AF_INET6(IPv6)等。设计时以为同一个  协议可能有多种地址，所以做了区分，而不都是PF                             */address.sin_addr.s_addr = htonl(INADDR_ANY); //INADDR_ANY：监听机器所有的ip，客户端无论连接哪个ip都可以连上。address.sin_port = htons(port);/*htonl的功能：将一个无符号长整型数值转换为网络字节序，即大端模式(big-endian)                                 htons的功能：将一个无符号短整型数值转换为网络字节序，即大端模式(big-endian)                                 因为sockaddr_in的地址和端口需要网络字节序                               *///3.设置socketbool flag=true;setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;flag, sizeof(flag));//用法较多，使用时谷歌查询//4.绑定socket和地址//大多数socket接口中，内核不关心地址结构，当它复制或传递地址给驱动的时候，它需要一个参数来确定需要复制多少数据。ret = bind(listenfd, (struct sockaddr*)&amp;address, sizeof(address));//成功返回0，失败返回-1//5.监听socketret = listen(listenfd, 5);//listen状态下可以监听多个client。这个代表可以有5个client处于连接等待状态,超过的就忽略//6.建立和客户端的连接int connfd=accept(int sockfd,struct sockaddr *addr,socklen_t *addrlen);/*参数addr和addrlen用来返回已连接的对端进程（客户端）的协议地址。如果我们对客户端的协议地址不感兴趣，可以把arrd和addrlen均置为空指针若成功返回一个新的socket描述符用于跟客户端通信，若出错则为-1*///客户端连接服务器int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);</code></pre><h2 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h2><pre><code class="cpp">//1.创建一个指示epoll内核事件表的文件描述符，该描述符将用作其他epoll系统调用的第一个参数，传入的5无意义。int epollfd = epoll_create(5);//2.注册epoll事件int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);/*op：表示动作，EPOLL_CTL_ADD (注册新的fd到epfd)，EPOLL_CTL_MOD (修改已经注册的fd的监听事件)，EPOLL_CTL_DEL (从epfd删除一个fd)event：告诉内核需要监听的事件*///event数据结构epoll_event表示内核所监听的事件，具体定义如下：     struct epoll_event &#123;         __uint32_t events;      /* epoll event */         epoll_data_t data;      /* User data variable */     &#125;;events描述事件类型，其中epoll事件类型有以下几种EPOLLIN：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）EPOLLOUT：表示对应的文件描述符可以写EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）EPOLLERR：表示对应的文件描述符发生错误EPOLLHUP：表示对应的文件描述符被挂断；EPOLLET：将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)而言的EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里可以监听多种，每种事件只占一个bit位，用|运算符来相加，如event.events = EPOLLIN | EPOLLET//3.创建用于存储epoll事件表中就绪事件的event数组epoll_event events[MAX_EVENT_NUMBER]; //4.等待事件就绪，并把就绪事件存入数组int number = epoll_wait(epollfd, events, MAX_EVENT_NUMBER, -1);/*成功返回有多少文件描述符就绪，时间到时返回0，出错返回-1events：用来存内核得到事件的集合,即上面的events数组MAX_EVENT_NUMBER：events大小，这个值不能超过数组大小-1是等待超时时间：-1时阻塞直到事件就绪，0表示立即返回，&gt;0：等待指定的毫秒*/</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/mysql/"/>
      <url>/2023/01/22/mysql/</url>
      
        <content type="html"><![CDATA[<h1 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h1><h2 id="mysql体系结构"><a href="#mysql体系结构" class="headerlink" title="mysql体系结构"></a>mysql体系结构</h2><p><strong>连接层</strong>：最上层是一些客户端和连接服务。<strong>主要完成一些类似于连接处理、授权认证、及相关的安全方案</strong>。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证操作权限。</p><p><strong>服务层</strong>：第二层服务层，主要完成大部分的<strong>核心服务功能</strong>， 包括查询解析、分析、优化、缓存、以及所有的内置函数，所有跨存储引擎的功能也都在这一层实现，包括触发器、存储过程、视图等。</p><p><strong>引擎层</strong>：第三层存储引擎层，存储引擎就是存储数据、建立索引、更新&#x2F;查询数据等技术的实现方式。<strong>存储引擎真正的负责了MySQL中数据的存储和提取</strong>。存储引擎是基于表的，而不是基于库的，<strong>不同的表可以有不同的存储引擎</strong>。服务器通过API与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取。</p><p><strong>存储层</strong>：第四层为数据存储层，主要是将<strong>数据存储在运行于该设备的文件系统</strong>之上，并完成与存储引擎的交互。</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\mysqlarchitecture.png" alt="img"></p><h2 id="InnoDB存储结构"><a href="#InnoDB存储结构" class="headerlink" title="InnoDB存储结构"></a>InnoDB存储结构</h2><p>InnoDB 的数据是按「数据页」为单位来读写的，默认数据页大小为 16 KB。每个数据页之间通过双向链表的形式组织起来，物理上不连续，但是逻辑上连续。</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220603121225077.png" alt="image-20220603121225077"></p><p>数据页内包含用户记录，每个记录之间用单向有序链表的方式组织起来，为了加快在数据页内高效查询记录，设计了一个页目录，页目录存储各个槽（分组），且主键值是有序的，于是可以通过二分查找法的方式进行检索从而提高效率。</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220603121302165.png" alt="image-20220603121302165"></p><p>为了高效查询记录所在的数据页，InnoDB 采用 b+ 树作为索引，每个节点都是一个数据页。</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220603121415375.png" alt="image-20220603121415375"></p><h2 id="DML-DDL-DCL"><a href="#DML-DDL-DCL" class="headerlink" title="DML,DDL,DCL"></a>DML,DDL,DCL</h2><p> DML（Data Manipulation Language，数据操作语言）：用于<strong>检索或者修改数据</strong>。<br> DML包括： </p><p>​SELECT：用于检索数据；<br>​    INSERT：用于增加数据到数据库；<br>​    UPDATE：用于从数据库中修改现存的数据<br>​    DELETE：用于从数据库中删除数据。</p><p> DDL（Data Definition Language，数据定义语言）： 用于<strong>定义数据的结构</strong>，比如创建、修改或者删除数据库对象。<br> DDL包括：DDL语句可以用于创建用户和重建数据库对象。下面是DDL命令：<br>    CREATE TABLE：创建表<br>    ALTER TABLE<br>    DROP TABLE：删除表<br>    CREATE INDEX<br>    DROP INDEX</p><p> DCL（Data Control Language，数据控制语言）：用于<strong>定义数据库用户的权限</strong>。<br> DCL包括：<br>    ALTER PASSWORD<br>    GRANT<br>    REVOKE<br>    CREATE SYNONYM</p><h2 id="sql语句"><a href="#sql语句" class="headerlink" title="sql语句"></a>sql语句</h2><h3 id="sql语句执行过程"><a href="#sql语句执行过程" class="headerlink" title="sql语句执行过程"></a>sql语句执行过程</h3><h4 id="一条查询语句执行过程"><a href="#一条查询语句执行过程" class="headerlink" title="一条查询语句执行过程"></a>一条查询语句执行过程</h4><p>1.<strong>客户端发出请求</strong></p><p>2.<strong>mysql连接器连接客户端</strong>（验证用户身份，给予权限）。</p><p>​连接有长连接和短连接。长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。<strong>尽量使用长连接</strong>。</p><p>3.<strong>查询缓存</strong>。</p><p>​之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。<strong>MySQL 8.0版本之后已经没有此功能</strong>。</p><p>4.<strong>分析器（对SQL语句进行语法分析和词法分析操作）</strong></p><p>​MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。<br>​<strong>词法分析：</strong>你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。检查查询的表或者列是否存在。</p><p>​<strong>语法分析：</strong>语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。比如 select 少打了开头的字母“s”</p><p>5.<strong>优化器（主要对执行的SQL优化，执行最优的方案）</strong><br>     在开始执行之前，还要先经过优化器的处理。同一条sql语句可以有多个执行方案，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。</p><p>6.<strong>执行器（先检查用户是否有执行权限，有才会使用这个引擎提供的接口）</strong><br>    开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。</p><p>​执行器循环调用引擎接口获取每行数据，这些接口都是引擎中已经定义好的。最后将所有满足条件的行组成的记录集作为结果集返回给客户端</p><p><strong>一条简单的查询语句</strong>。<code>select * from name = &quot;花一个无所&quot;</code></p><ol><li>判断 <code>buffer pool</code> 中是否存在这条数据</li><li>如果不存在则查磁盘。如果存在则读入<code>buffer pool</code> </li><li>判断 <code>change buffer</code> 中是否有这条数据。如果存在则 merge并写入<code>buffer pool</code> </li><li>返回 merge 之后的数据</li></ol><h4 id="更新语句执行过程"><a href="#更新语句执行过程" class="headerlink" title="更新语句执行过程"></a>更新语句执行过程</h4><p>前五个步骤与查询语句相同，关键在于执行器不同。InnoDB更新语句操作如下，以update T set c&#x3D;c+1 where ID&#x3D;2为例</p><ol><li>执行器先找引擎取ID&#x3D;2这一行。</li><li>执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</li><li>引擎将这行新数据<strong>更新到内存中</strong>，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。</li><li>执行器生成这个操作的binlog，并把binlog写入磁盘。</li><li>执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。</li></ol><p><strong>一条根据普通索引简单的更新语句</strong>。<code>where name =  &quot;花一个无所&quot;</code></p><ol><li>判断 <code>buffer pool</code> 中是否存在这条数据</li><li>若存在则直接更新 <code>buffer pool</code></li><li>否则将改动写入 <code>change buffer</code></li><li>写 <code>redo log</code></li></ol><p><strong>一条根据唯一索引更新的语句</strong>。<code>where uniqId = 7</code></p><ol><li>判断 <code>buffer pool</code>  中是否存在这条数据</li><li>若存在则直接更新 <code>buffer pool</code></li><li>否则查磁盘，存在则读入 <code>buffer pool</code></li><li>更新 <code>buffer pool</code></li><li>写 <code>redo log</code></li></ol><h5 id="先更新内存数据，不直接更新磁盘数据的原因"><a href="#先更新内存数据，不直接更新磁盘数据的原因" class="headerlink" title="先更新内存数据，不直接更新磁盘数据的原因"></a>先更新内存数据，不直接更新磁盘数据的原因</h5><p>MySQL里如果在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中，这整个过程IO成本、查找成本都很高。</p><ol><li>Innodb 是以页为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！</li><li>一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差</li><li>磁盘IO缓慢</li></ol><p>对于mysql来说，所有的变更都必须先更新缓冲池中的数据，然后缓冲池中的脏页会以一定的频率被刷入磁盘（<strong>checkPoint</strong>机制），通过缓冲池来优化CPU和磁盘之间的鸿沟，这样就可以保证整体的性能不会下降太快。</p><h5 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h5><p><strong>作用</strong>：保证事务的持久性</p><p>缓冲池可以帮助我们消除CPU和磁盘之间的鸿沟，checkpoint机制可以保证数据的最终落盘，然而由于checkpoint并不是每次变更的时候就触发的，而是master线程隔一段时间去处理的。所以最坏的情况就是刚写完缓冲池，数据库宕机了，那么这段数据就是丢失的，无法恢复。这样的话就不满足ACID中的D，为了解决这种情况下的持久化问题，InnoDB引擎的事务采用了WAL技术（Write-Ahead Logging），这种技术的思想就是先写日志，再写磁盘，只有日志写入成功，才算事务提交成功，这里的日志就是redo log。当发生宕机且数据未刷到磁盘的时候，可以通过redo log来恢复，保证ACID中的D，这就是redo log的作用。</p><p> 与从缓冲区写入磁盘相比，写redo log性能更高。redo log <strong>只记录事务对数据页做了哪些修改</strong>，这样就能完美地解决性能问题了(相对而言文件更小并且是顺序IO)。redo log是对页的物理修改，第x页的第x位置修改成xx，比如：</p><pre><code>page(2,4),offset 64,value 2</code></pre><p><strong>redo log 包括两部分</strong>：一个是内存中的日志缓冲( redo log buffer )，另一个是磁盘上的日志文件( redo log file )。 mysql 每执行一条 DML 语句，先将记录写入 redo log buffer ，后续某个时间点再一次性将多个操作记录写到 redo log file 。</p><p>具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，如系统比较空闲或者redo log写满的时候。</p><p>redo log采用循环写，会发生覆盖。文件中有write pos和checkpoint。write pos是当前记录的位置，一边写一边后移，写到文件末尾后回到文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。</p><p>如果write pos追上checkpoint，表示log满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。</p><p>有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为<strong>crash-safe</strong>。</p><h5 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a><strong>两阶段提交</strong></h5><p>两阶段、三阶段都是为了解决分布式事务中的数据一致性问题</p><p>所谓两阶段提交，其实就是把 redo log 的写入拆分成了两个步骤：prepare 和 commit。这是为了解决bin log 与 redo log 的一致性问题，从而使从库用bin log同步时数据跟主库保持一致。</p><p>首先，存储引擎将执行更新好的新数据存到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务</p><p>然后执行器生成这个操作的 bin log，并把 bin log 写入磁盘</p><p>最后执行器调用存储引擎的提交事务接口，存储引擎把刚刚写入的 redo log 状态改成提交(commit)状态，更新完成</p><p>如果数据库在写入 redo log(prepare) 阶段之后、写入 binlog 之前，发生了崩溃：</p><p>此时 redo log 里面的事务处于 prepare 状态，binlog 还没写，之后从库进行同步的时候，无法执行这个操作，但是实际上主库已经完成了这个操作，所以为了主备一致，MySQL 崩溃时会在主库上回滚这个事务</p><p> 而如果数据库在写入 binlog 之后，redo log 状态修改为 commit 前发生崩溃，此时 redo log 里面的事务仍然是 prepare 状态，binlog 存在并完整，这样之后就会被从库同步过去，但是实际上主库并没有完成这个操作，所以为了主备一致，即使在这个时刻数据库崩溃了，恢复后仍会重新提交事务。</p><h5 id="bin-log"><a href="#bin-log" class="headerlink" title="bin log"></a>bin log</h5><p>binlog 用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。 binlog 是 mysql的逻辑日志，并且由 Server 层进行记录，使用任何存储引擎的 mysql 数据库都会记录 binlog 日志。</p><ul><li><strong>逻辑日志</strong>： 可以简单理解为记录的就是sql语句 。</li><li><strong>物理日志</strong>： mysql 数据最终是保存在数据页中的，物理日志记录的就是数据页变更 。</li></ul><p>binlog 是通过追加的方式进行写入的，可以通过 max_binlog_size 参数设置每个 binlog文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。</p><p>在实际应用中， binlog 的主要使用场景有两个，分别是 <strong>主从复制</strong> 和 <strong>数据恢复</strong> 。</p><ol><li><strong>主从复制</strong> ：在 Master 端开启 binlog ，然后将 binlog 发送到各个 Slave 端， Slave 端重放 binlog 从而达到主从数据一致。</li><li><strong>数据恢复</strong> ：通过使用 mysqlbinlog 工具来恢复数据。</li></ol><p><strong>bin log和redo log不同之处</strong></p><p>bin log和redo log有以下不同。</p><ol><li>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。</li><li>redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑。</li><li>redo log是循环写的，文件大小固定会用完；binlog是可以追加写入的，可以设置每个文件大小，binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li><li>redo log 适用于崩溃恢复(crash-safe)；binlog 适用于主从复制和数据从备份恢复</li></ol><h5 id="崩溃恢复"><a href="#崩溃恢复" class="headerlink" title="崩溃恢复"></a>崩溃恢复</h5><p><strong>redo log能用于崩溃恢复的原因</strong></p><p>redo log <strong>只会记录未刷入磁盘的日志</strong>，已经刷入磁盘的数据都会从 redo log 这个有限大小的日志文件里删除。</p><p>而 bin log 是追加日志，<strong>保存的是全量的日志</strong>。这就会导致一个问题，那就是没有标志能让 InnoDB 从 bin log 中判断哪些数据已经刷入磁盘了，哪些数据还没有。</p><p>因此数据库重启后，直接把 redo log 中的数据都恢复至内存就可以了。这就是为什么说 redo log 具有崩溃恢复的能力，而 bin log 不具备。</p><p>但是如果不小心整个数据库的数据被删除了，能使用redo log文件恢复数据吗？此时不可以使用redo log文件恢复，只能使用binlog文件从备份恢复。因为redo log文件不会存储历史所有的数据的变更，当内存数据刷新到磁盘中，redo log的数据就失效了，也就是redo log文件内容是会被覆盖的。</p><p><strong>恢复步骤</strong></p><p>根据两阶段提交，崩溃恢复时的判断规则是这样的：</p><p>如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交</p><p>如果 redo log 里面的事务处于 prepare 状态，则判断对应的事务 binlog 是否存在并完整（一个事务的 binlog 有完整格式，mysql可以判断）</p><ul><li>a. 如果 binlog 存在并完整，则提交事务;</li><li>b. 否则，回滚事务。</li></ul><h5 id="change-buffer"><a href="#change-buffer" class="headerlink" title="change buffer"></a>change buffer</h5><p>change buffer是 <code>buffer pool</code>中的一块缓冲区，存储的是<strong>普通二级索引页</strong>的数据变更。它主要解决的是<strong>随机读磁盘IO</strong>消耗大的问题。</p><p>当有一条更新语句进来对某条数据进行修改时，需要找到这条数据，优先从 <code>buffer pool</code> 中找，不存在则从磁盘获取。将数据页从磁盘读入 <code>buffer pool</code> 涉及随机 IO 访问，这是数据库中成本最高的操作之一。所以有了这么一块缓冲区之后，针对某些写入或修改操作，直接把改动缓存在 <code>change buffer</code> 中，省去将数据从磁盘读入的过程。当下次查询的时候再从磁盘读出原始数据，将原始数据和 <code>change buffer</code> 中的改动做 merge 之后返回。</p><p><code>change buffer</code> 虽然是缓冲区。但其实它是可以持久化的，它持久化的地方默认是 <code>ibdata1</code>  共享空间表中(change buffer的写盘策略跟数据一样，内存放不下会触发落盘，还有checkpoint推进的时候也可能会触发)。因为为了保证数据的一致性。同时， <code>change buffer</code> 也是需要写 <code>redo log</code> 的。所以 <code>redo log</code> 里不仅有针对普通数据页的改动记录，也有 <code>change buffer</code> 的记录。</p><p>change buffer适合<strong>写多读少</strong>的业务场景，这种业务模型常见的就是账单类、日志类的系统。反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。所以，对于这种业务模式来说，change buffer反而起到了副作用。</p><p><strong>唯一索引无法使用change buffer</strong>，因为唯一索引更新时需要进行唯一性检查，这必须要将数据从磁盘读入才能判断。</p><h3 id="buffer-pool"><a href="#buffer-pool" class="headerlink" title="buffer pool"></a>buffer pool</h3><p> MySQL 的数据是存储在磁盘里的，每次都从磁盘里面读取数据性能是极差的。</p><p>为此，Innodb 存储引擎设计了一个<strong>缓冲池(Buffer Pool）</strong>，来提高数据库的读写性能。</p><p>有了缓冲池后：</p><ul><li>当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。</li><li>当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。</li></ul><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220603140803847.png" alt="image-20220603140803847"></p><p>为了更好的管理这些在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个<strong>控制块</strong>，控制块信息包括「缓存页的表空间、页号、缓存页地址、链表节点」等等。</p><p>当我们查询一条记录时，InnoDB 会把整个页的数据加载到 Buffer Pool 中，因为，通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。</p><p><strong>如何管理空闲页</strong></p><p>为了能够快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为 <strong>Free 链表</strong>（空闲链表）。</p><p>有了 Free 链表后，每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。</p><p><strong>如何管理脏页</strong></p><p>更新数据的时候，不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为<strong>脏页</strong>，然后再由后台线程将脏页写入到磁盘。</p><p>那为了能快速知道哪些缓存页是脏的，于是就设计出 <strong>Flush 链表</strong>，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。</p><p><strong>如何管理脏页+干净页</strong></p><p>干净页，表示此页已被使用，但是页面未发生修改。使用<strong>LRU 链表（Least recently used）</strong>管理脏页+干净页，也就是说<strong>脏页同时存在于 LRU 链表和 Flush 链表</strong>。</p><p>简单的 LRU 算法并没有被 MySQL 使用，因为简单的 LRU 算法无法避免下面这两个问题：</p><ul><li>预读失效；</li><li>Buffer Pool 污染；</li></ul><p>程序有空间局部性的，靠近当前被访问数据的数据，在未来很大概率会被访问到。因此MySQL 在加载数据页时，会提前把它相邻的数据页一并加载进来，这就是预读。但是可能这些被提前加载进来的数据页，并没有被访问，相当于这个预读是白做了，这个就是<strong>预读失效</strong>。如果这些预读页如果一直不会被访问到，就会出现一个很奇怪的问题，<strong>不会被访问的预读页却占用了 LRU 链表前排的位置</strong>，而末尾淘汰的页，可能是频繁访问的页，这样就大大降低了缓存命中率。</p><p><strong>如何解决预读失效</strong></p><p>MySQL 是这样做的，它改进了 LRU 算法，将 LRU 划分了 2 个区域：<strong>old 区域 和 young 区域</strong>。young 区域在 LRU 链表的前半部分，old 区域则是在后半部分，如下图：</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220605025934160.png" alt="image-20220605025934160"></p><p>old 区域占整个 LRU 链表长度的比例可以通过 <code>innodb_old_blocks_pc</code> 参数来设置，默认是 37，代表整个 LRU 链表中 young 区域与 old 区域比例是 63:37。</p><p><strong>划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部</strong>。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。</p><p><strong>如何解决Buffer Pool 污染</strong></p><p>当某一个 SQL 语句<strong>扫描了大量的数据</strong>时，在 Buffer Pool 空间比较有限的情况下，可能会将 <strong>Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了</strong>，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 <strong>Buffer Pool 污染</strong>。</p><p>像前面这种全表扫描的查询，很多缓冲页其实只会被访问一次，但是它却只因为被访问了一次而进入到 young 区域，从而导致热点数据被替换了。LRU 链表中 young 区域就是热点数据，只要我们<strong>提高进入到 young 区域的门槛</strong>，就能有效地保证 young 区域里的热点数据不会被替换掉。</p><p>MySQL 是这样做的，进入到 young 区域条件增加了一个<strong>停留在 old 区域的时间判断</strong>。</p><p>具体是这样做的，在对某个处在 old 区域的缓存页进行第一次访问时，就在它对应的控制块中记录下来这个访问时间：</p><ul><li>如果后续的访问时间与第一次访问的时间<strong>在某个时间间隔内</strong>，那么<strong>该缓存页就不会被从 old 区域移动到 young 区域的头部</strong>；</li><li>如果后续的访问时间与第一次访问的时间<strong>不在某个时间间隔内</strong>，那么<strong>该缓存页移动到 young 区域的头部</strong>；</li></ul><p>这个间隔时间是由 <code>innodb_old_blocks_time</code> 控制的，默认是 1000 ms。</p><p>也就说，<strong>只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部</strong>，这样就解决了 Buffer Pool 污染的问题 。</p><p>另外，MySQL 针对 young 区域其实做了一个优化，为了防止 young 区域节点频繁移动到头部。young 区域前面 1&#x2F;4 被访问不会移动到链表头部，只有后面的 3&#x2F;4被访问了才会。</p><p><strong>脏页什么时候会被刷入磁盘</strong></p><p>下面几种情况会触发脏页的刷新：</p><ul><li>当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘；</li><li>Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘；</li><li>MySQL 认为空闲时，后台线程回定期将适量的脏页刷入到磁盘；</li><li>MySQL 正常关闭之前，会把所有的脏页刷入到磁盘；</li></ul><h3 id="sql流程控制函数"><a href="#sql流程控制函数" class="headerlink" title="sql流程控制函数"></a>sql流程控制函数</h3><table><thead><tr><th>函数</th><th>功能</th></tr></thead><tbody><tr><td>IF(expr1,expr2,expr3)</td><td>如果expr1是真, 返回expr2, 否则返回expr3</td></tr><tr><td>IFNULL(expr1,expr2)</td><td>如果expr1不是NULL,返回expr1,否则返回expr2</td></tr><tr><td>CASE WHEN [value1] THEN[result1]… ELSE[default] END</td><td>如果value是真, 返回result1,否则返回default</td></tr><tr><td>CASE [expr] WHEN [value1] THEN[result1]… ELSE[default] END</td><td>如果expr等于value1, 返回result1,否则返回default</td></tr></tbody></table><p><strong>case when 相当于if…else if…</strong></p><p>查询员工的信息，<br>如果薪资高于20000，显示该员工是“高富帅”，<br>如果薪资在15000-20000之间，显示“潜力股”<br>如果薪资在10000-15000之间，显示“有为青年”<br>如果薪资在10000以下，显示“屌丝”</p><p>SELECT ename, salary,<br>CASE<br>WHEN salary&gt;&#x3D;20000 THEN “高富帅”<br>WHEN salary&gt;&#x3D;15000 THEN “潜力股”<br>WHEN salary&gt;&#x3D;10000 THEN “有为青年”<br>ELSE “屌丝”<br>END AS “标签”<br>FROM t_employee;</p><p><strong>case [expr] when相当于switch…case</strong></p><p>#查询订单表，显示订单编号，和订单状态，如果订单状态是0，显示新订单，是1，显示已付款…</p><p>SELECT oid ,price,<br>CASE state<br>WHEN 0 THEN “新建订单”<br>WHEN 1 THEN “已付款”<br>WHEN 2 THEN “已发货”<br>WHEN 3 THEN “已收货”<br>END<br>FROM t_order</p><h3 id="sql语句执行顺序"><a href="#sql语句执行顺序" class="headerlink" title="sql语句执行顺序"></a>sql语句执行顺序</h3><ol><li>from </li><li>join </li><li>on </li><li>where </li><li>group by(开始使用select中的别名，后面的语句中都可以使用)</li><li>avg,sum…. </li><li>having </li><li>select </li><li>distinct </li><li>order by</li><li>limit</li></ol><p>第一步：首先对from子句中的前两个表执行一个笛卡尔乘积，此时生成虚拟表 vt1（选择相对小的表做基础表）。<br>第二步：接下来便是应用on筛选器，on 中的逻辑表达式将应用到 vt1 中的各个行，筛选出满足on逻辑表达式的行，生成虚拟表 vt2 。<br>第三步：如果是outer join 那么这一步就将添加外部行，left outer jion 就把左表在第二步中过滤的添加进来，如果是right outer join 那么就将右表在第二步中过滤掉的行添加进来，这样生成虚拟表 vt3 。</p><p>第四步：如果 from 子句中的表数目多余两个表，那么就将vt3和第三个表连接从而计算笛卡尔乘积，生成虚拟表，该过程就是一个重复1-3的步骤，最终得到一个新的虚拟表 vt3。 </p><p>第五步：应用where筛选器，对上一步生产的虚拟表引用where筛选器，生成虚拟表vt4，在这有个比较重要的细节不得不说一下，对于包含outer join子句的查询，就有一个让人感到困惑的问题，到底在on筛选器还是用where筛选器指定逻辑表达式呢？on和where的最大区别在于，如果在on应用逻辑表达式那么在第三步outer join中还可以把移除的行再次添加回来，而where的移除的最终的。举个简单的例子，有一个学生表（班级,姓名）和一个成绩表(姓名,成绩)，我现在需要返回一个x班级的全体同学的成绩，但是这个班级有几个学生缺考，也就是说在成绩表中没有记录。为了得到我们预期的结果我们就需要在on子句指定学生和成绩表的关系（学生.姓名&#x3D;成绩.姓名）那么我们是否发现在执行第二步的时候，对于没有参加考试的学生记录就不会出现在vt2中，因为他们被on的逻辑表达式过滤掉了,但是我们用left outer join就可以把左表（学生）中没有参加考试的学生找回来，因为我们想返回的是x班级的所有学生，如果在on中应用学生.班级&#x3D;’x’的话，left outer join会把x班级的所有学生记录找回，所以只能在where筛选器中应用学生.班级&#x3D;’x’ 因为它的过滤是最终的。 </p><p>第六步：group by 子句将中的唯一的值组合成为一组，得到虚拟表vt5。如果应用了group by，那么后面的所有步骤都只能得到的vt5的列或者是聚合函数（count、sum、avg等）。原因在于最终的结果集中只为每个组包含一行。这一点请牢记。 </p><p>第七步：应用cube或者rollup选项，为vt5生成超组，生成vt6.<br>第八步：应用having筛选器，生成vt7。having筛选器是第一个也是为唯一一个应用到已分组数据的筛选器。<br>第九步：处理select子句。将vt7中的在select中出现的列筛选出来。生成vt8. </p><p>第十步：应用distinct子句，vt8中移除相同的行，生成vt9。事实上如果应用了group by子句那么distinct是多余的，原因同样在于，分组的时候是将列中唯一的值分成一组，同时只为每一组返回一行记录，那么所以的记录都将是不相同的。 </p><p>第十一步：应用order by子句。按照order_by_condition排序vt9，此时返回的一个游标，而不是虚拟表。sql是基于集合的理论的，集合不会预先对他的行排序，它只是成员的逻辑集合，成员的顺序是无关紧要的。对表进行排序的查询可以返回一个对象，这个对象包含特定的物理顺序的逻辑组织。这个对象就叫游标。正因为返回值是游标，那么使用order by 子句查询不能应用于表表达式。排序是很需要成本的，除非你必须要排序，否则最好不要指定order by，最后，在这一步中是第一个也是唯一一个可以使用select列表中别名的步骤。 </p><p>第十二步：应用top选项。此时才返回结果给请求者即用户。 </p><h3 id="约束"><a href="#约束" class="headerlink" title="约束"></a>约束</h3><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220311014136188.png" alt="image-20220311014136188"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220311013953804.png" alt="image-20220311013953804"></p><p>外键：</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220311014811937.png" alt="image-20220311014811937"></p><h3 id="多表关系"><a href="#多表关系" class="headerlink" title="多表关系"></a>多表关系</h3><p>表与表之间的三种关系<br>一对多关系：最常见的关系：学生对班级 ， 员工对部门<br>多对多关系：学生与课程 ， 用户与角色<br>一对一关系：使用较少，因为一对一关系可以合成为一张表</p><p>一对多关系 （常见）</p><p>　　　　例如： 班级和学生， 部门和员工， 客户和订单， 分类和商品</p><p>　　　　建表原则： 在从表（多方）创建一个字段， 字段作为外键指向主表（一方）的主键</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220314204301248.png" alt="image-20220314204301248"></p><p>多对多关系 （常见）</p><p>　　　　例如：老师和学生， 学生和课程， 用户和角色</p><p>　　　　建表原则： 需要创建第三行表，中间表中至少有两个字段，这两个字段分别作为外键，指向各自一方的主键</p><p>　　　　</p><p> <img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220314204333533.png" alt="image-20220314204333533"></p><p>  一对一关系（了解）</p><p>　　　　在实际开发中应用不多，因为一对一可以创建成一张表</p><p>　　　　建表原则： 外键唯一， 主表的主键和从表的唯一外键，形成主外键关系， 外键唯一用UNIQUE修饰</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220314204340789.png" alt="image-20220314204340789"></p><h3 id="多表查询"><a href="#多表查询" class="headerlink" title="多表查询"></a>多表查询</h3><p>等值连接是从关系R与S的广义笛卡儿积中选取A、B属性值相等的元组。</p><p>给出教师信息表A如下：</p><table><thead><tr><th><strong>教师号</strong></th><th><strong>教师名</strong></th></tr></thead><tbody><tr><td>2017</td><td>司小东</td></tr><tr><td>2018</td><td>魏大勇</td></tr></tbody></table><p>课程表B如下：</p><table><thead><tr><th>教师名</th><th>课程名</th></tr></thead><tbody><tr><td>司小东</td><td>数学模型</td></tr><tr><td>魏大勇</td><td>数据库原理</td></tr></tbody></table><p>如果我想通过教师号获得课程名，那就需要把两个表连接起来了，按照教师名这个属性来连接，<br>结果如下：</p><table><thead><tr><th>教师号</th><th>A.教师名</th><th>B.教师名</th><th>课程名</th></tr></thead><tbody><tr><td>2017</td><td>司小东</td><td>司小东</td><td>数学模型</td></tr><tr><td>2018</td><td>魏大勇</td><td>魏大勇</td><td>数据库原理</td></tr></tbody></table><p><strong>自然连接是一种特殊的等值连接，它会把重复列消除。</strong></p><p>所以对于自然连接后的结果应该是：</p><table><thead><tr><th>教师号</th><th>教师名</th><th>课程名</th></tr></thead><tbody><tr><td>2017</td><td>司小东</td><td>数学模型</td></tr><tr><td>2018</td><td>魏大勇</td><td>数据库原理</td></tr></tbody></table><p><strong>等值连接要求相等的分量,不一定是公共属性;而自然连接要求相等的分量必须是公共属性。</strong></p><p><strong>单表可以进行自连接</strong></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220315233135576.png" alt="image-20220315233135576"></p><h4 id="联合查询"><a href="#联合查询" class="headerlink" title="联合查询"></a>联合查询</h4><p>联合查询可以把多次查询结果集合并，形成一个新的结果集</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220315233531404.png" alt="image-20220315233531404"></p><h4 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a>子查询</h4><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220315233744692.png" alt="image-20220315233744692"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220315234206480.png" alt="image-20220315234206480"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220315234836449.png" alt="image-20220315234836449"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220315235257760.png" alt="image-20220315235257760"></p><h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><h3 id="锁的分类"><a href="#锁的分类" class="headerlink" title="锁的分类"></a>锁的分类</h3><h4 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h4><p>要使用全局锁，则要执行这条命令：flush tables with read lock</p><p>执行后，<strong>整个数据库就处于只读状态了</strong>，这时其他线程执行以下操作，都会被阻塞：</p><ul><li>对数据的增删查改操作，比如 select、insert、delete、update等语句；</li><li>对表结构的更改操作，比如 alter table、drop table 等语句。</li></ul><p>如果要释放全局锁，则要执行这条命令：unlock tables。当然，当会话断开了，全局锁会被自动释放。</p><p><strong>应用场景</strong></p><p>全局锁主要应用于做<strong>全库逻辑备份</strong>，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。</p><p>在全库逻辑备份期间，假设不加全局锁的场景，看看会出现什么意外的情况。</p><p>如果在全库逻辑备份期间，有用户购买了一件商品，一般购买商品的业务逻辑是会涉及到多张数据库表的更细，比如在用户表更新该用户的余额，然后在商品表更新被购买的商品的库存。</p><p>那么，有可能出现这样的顺序：</p><ol><li>先备份了用户表的数据；</li><li>然后有用户发起了购买商品的操作；</li><li>接着再备份商品表的数据。</li></ol><p>也就是在备份用户表和商品表之间，有用户购买了商品。</p><p>这种情况下，备份的结果是用户表中该用户的余额并没有扣除，反而商品表中该商品的库存被减少了，如果后面用这个备份文件恢复数据库数据的话，用户钱没少，而库存少了，等于用户白嫖了一件商品。</p><p><strong>缺点</strong></p><p>加上全局锁，意味着整个数据库都是只读状态。</p><p>那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。</p><p><strong>解决方法</strong></p><p>在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这样备份期间备份的数据一直是在开启事务时的数据。</p><p>备份数据库的工具是 mysqldump，在使用 mysqldump 时加上 <code>–single-transaction</code> 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎，如InnoDB</p><p>但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法。</p><h4 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h4><p>MySQL 里面表级别的锁有这几种：</p><ul><li>表锁；</li><li>元数据锁（MDL）;</li><li>意向锁；</li><li>AUTO-INC 锁；</li></ul><h5 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h5><p>如果我们想对学生表（t_student）加表锁，可以使用下面的命令：</p><pre><code class="sql">//表级别的共享锁，也就是读锁；lock tables t_student read;//表级别的独占锁，也就是写锁；lock tables t_stuent wirte;</code></pre><p>需要注意的是，表锁除了会限制别的线程的读写外，<strong>也会限制本线程接下来的读写操作</strong>。</p><p>也就是说如果本线程对学生表加了共享表锁，那么本线程接下来如果要对学生表执行写操作的语句，是会被阻塞的，当然其他线程对学生表进行写操作时也会被阻塞，直到锁被释放。</p><p>要释放表锁，可以使用下面这条命令，会释放当前会话的所有表锁：</p><pre><code class="sql">unlock tables</code></pre><p>另外，当会话退出后，也会释放所有表锁。</p><h5 id="元数据锁（metadata-lock）"><a href="#元数据锁（metadata-lock）" class="headerlink" title="元数据锁（metadata lock）"></a><strong>元数据锁（metadata lock）</strong></h5><p>我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：</p><ul><li>对一张表进行 CRUD 操作时，加的是 <strong>MDL 读锁</strong>；</li><li>对一张表做结构变更操作的时候，加的是 <strong>MDL 写锁</strong>；</li></ul><p><strong>作用</strong></p><p>在MySQL5.5.3之前，有一个著名的bug#989，大致如下:</p><p>session1:<br>BEGIN;<br>INSERT INTO t … ;<br>COMMIT;</p><p>session2:<br>DROP TABLE t;</p><p>然而上面的操作流程在binlog记录的顺序是：<br>DROP TABLE t;</p><p>BEGIN;<br>INSERT INTO t … ;<br>COMMIT;</p><p>很显然备库执行binlog恢复数据时会先删除表t，然后执行insert 会报error，导致复制中断。为了解决该bug,MySQL 在5.5.3引入了MDL锁（metadata lock），来保护表的元数据信息，用于解决或者<strong>保证DDL操作与DML操作之间的一致性</strong>。</p><p>简单的例子，如果你在查询一个表的过程中，另外一个session对该表删除了一个列，那前面的查询到底该显示什么呢？事物中再次执行相同的语句还会和之前结果一致吗？为了防止这种情况，表查询开始MySQL会在表上加一个锁，来防止被别的session修改了表定义，这个锁就叫MDL</p><p><strong>与行锁的区别</strong></p><p>mdl是表级锁，是在server层加的，适用于所有存储引擎。<strong>mdl为了解决ddl和dml之间的冲突，而行锁则是解决dml内的冲突</strong>。所有的dml操作都会在表上加一个metadata读锁；所有的ddl操作都会在表上加一个metadata写锁。读锁和写锁的阻塞关系如下：</p><ul><li>读锁和写锁之间相互阻塞，即同一个表上的dml和ddl之间互相阻塞。</li><li>写锁和写锁之间互相阻塞，即两个session不能对表同时做表定义变更，需要串行操作。</li><li>读锁和读锁之间不会产生阻塞。也就是<strong>增删改查不会因为mdl产生阻塞</strong>，可以并发执行，日常工作中大家看到的dml之间的锁等待是innodb行锁引起的，和mdl无关。</li></ul><p><strong>MDL为什么会造成系统崩溃</strong></p><p>MDL申请锁是串行队列排队申请，若队列前有事务阻塞，则后面的事务则可能无法申请到锁。</p><p>如事务1对表t1执行一个简单的查询；事务2对t1加一个字段；事务3来对t1做一个查询；</p><p>若事务1没有提交，则会导致事务2的ddl操作被阻塞，事务3本身不会被事务1阻塞，但由于在锁队列中，事务2排队更早，它准备加的是MDL写锁，阻塞了事务3的读锁。如果t1是一个执行频繁的表，show processlist会发现大量waiting for table metadata lock的线程，数据库连接很快就会消耗完，导致业务系统无法正常响应。</p><p>最新版本的mysql已经解决了这个问题，事务2不会再阻塞事务3。</p><p><strong>MDL生命周期</strong></p><p>MDL 在语句执行前申请，事务提交后才会释放，这意味着<strong>事务执行期间，MDL 是一直持有的</strong>。若执行完语句就释放，可能会导致事务中途其他事务删除或改变表，无法保证一致性。</p><p><strong>注意事项</strong></p><ul><li>生产环境的任何大表或频繁操作的小表，ddl都要非常慎重，最好在业务低峰期执行。同时ddl前需要检测是否存在长事务，若有长事务最好先kill掉，不能会导致阻塞。</li><li>设计上要尽可能避免长事务，长事务不仅仅会带来各种锁问题，还好引起复制延迟&#x2F;回滚空间爆满等各类问题。</li><li>要及时提交事务，经常发现客户端设置了事务手工提交，但sql执行后忘记点击提交按钮，导致事务长时间无法提交。建议监控实例中的长事务，避免由于各种原因导致事务没有及时提交。</li></ul><h5 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h5><p>意向锁是一种<strong>快速判断表锁与之前可能存在的行锁冲突的机制</strong>，在添加行锁之前必须先申请意向锁。在添加表锁时会先查有没有意向锁，有则阻塞。</p><p><strong>表锁和行锁冲突</strong></p><p>事务A锁住了表中的<strong>一行</strong>，让这一行只能读，不能写。</p><p>之后，事务B申请<strong>整个表</strong>的写锁。</p><p>如果事务B申请成功，那么理论上它就能修改表中的任意一行，这与A持有的行锁是冲突的。</p><p>因此表锁在申请时除了判断表是否已被其他事务用表锁锁表，还需要遍历每行判断表中是否有某行已被行锁锁住，效率低。</p><p>那么有了意向锁，由于在对记录加行锁前，先会加上表级别的意向锁，那么在加表锁时，直接查该表是否有意向锁，如果有就意味着表里已经有记录被加了行锁，这样就不用去遍历表里的记录。</p><h5 id="AUTO-INC-锁"><a href="#AUTO-INC-锁" class="headerlink" title="AUTO-INC 锁"></a>AUTO-INC 锁</h5><p> AUTO-INC 锁是为了在插入数据时，保证声明 <code>AUTO_INCREMENT</code> 属性的字段可以连续递增。</p><p>AUTO-INC 锁是特殊的表锁机制，锁不是再一个事务提交后才释放，而是<strong>在执行完插入语句后就会立即释放。</strong></p><p><strong>在插入数据时，会加一个表级别的 AUTO-INC 锁</strong>，然后为被 <code>AUTO_INCREMENT</code> 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。</p><p>那么，一个事务在持有 AUTO-INC 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 <code>AUTO_INCREMENT</code> 修饰的字段的值是连续递增的。</p><p>但是， AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。</p><p>因此， 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种<strong>轻量级的锁</strong>来实现自增。</p><p>一样也是在插入数据的时候，会为被 <code>AUTO_INCREMENT</code> 修饰的字段加上轻量级锁，<strong>然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁</strong>。</p><p>InnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。</p><ul><li>当 innodb_autoinc_lock_mode &#x3D; 0，就采用 AUTO-INC 锁；</li><li>当 innodb_autoinc_lock_mode &#x3D; 2，就采用轻量级锁；</li><li>当 innodb_autoinc_lock_mode &#x3D; 1，这个是默认值，两种锁混着用，如果能够确定插入记录的数量就采用轻量级锁，不确定时就采用 AUTO-INC 锁。</li></ul><p>不过，当 innodb_autoinc_lock_mode &#x3D; 2 是性能最高的方式，但是会带来一定的问题。因为并发插入的存在，在每次插入时，自增长的值可能不是连续的，<strong>这在有主从复制的场景中是不安全的</strong>。</p><h4 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h4><p>InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。</p><p><strong>InnoDB有三种行锁：</strong></p><p>1，Record Lock：单个行记录上的锁。包括共享锁和独占锁（不包括其他行，所以会出现幻读）</p><p>2，Gap Lock：间隙锁，锁定一个范围，但不包括记录本身。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。</p><p>3，Next-Key Lock：1+2，锁定记录本身和记录左边的间隙，即一个左开右闭区间。主要目的是解决幻读。</p><p>在查询时主动对记录加行锁，可以使用下面这两个方式：</p><pre><code class="sql">//对读取的记录加共享锁select ... lock in share mode;//对读取的记录加独占锁select ... for update;</code></pre><p>存储引擎还会在读写时会自动加锁，详情看InnoDB的事务隔离级别的实现。</p><p><strong>提高锁的性能</strong></p><p><strong>修改事务中操作的顺序可以提高性能</strong>。</p><p>在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。</p><p>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p><p>假设你负责实现一个电影票在线交易业务，顾客A要在影院B购买电影票。我们简化一点，这个业务需要涉及到以下操作：</p><ol><li>从顾客A账户余额中扣除电影票价；</li><li>给影院B的账户余额增加这张电影票价；</li><li>记录一条交易日志。</li></ol><p>也就是说，要完成这个交易，我们需要update两条记录，并insert一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？</p><p>试想如果同时有另外一个顾客C要在影院B买票，那么这两个事务冲突的部分就是语句2了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。</p><p>根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句2安排在最后，比如按照3、1、2这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。</p><h4 id="死锁和死锁检测"><a href="#死锁和死锁检测" class="headerlink" title="死锁和死锁检测"></a>死锁和死锁检测</h4><p>当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。</p><p>以行锁为例：</p><table><thead><tr><th>事务A</th><th>事务B</th></tr></thead><tbody><tr><td>update t set k&#x3D;k+1 where id&#x3D;2</td><td></td></tr><tr><td></td><td>update t set k&#x3D;k+1 where id&#x3D;1</td></tr><tr><td>update t set k&#x3D;k+1 where id&#x3D;1</td><td></td></tr><tr><td></td><td>update t set k&#x3D;k+1 where id&#x3D;2</td></tr></tbody></table><p>这时候，事务A在等待事务B释放id&#x3D;1的行锁，而事务B在等待事务A释放id&#x3D;2的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：</p><ul><li>一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。</li><li>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。</li></ul><p>在InnoDB中，innodb_lock_wait_timeout的默认值是50s，当出现死锁以后，第一个被锁住的线程要过50s才会超时退出，然后其他线程才有可能继续执行。时间过长。</p><p>若时间很短，比如1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。</p><p>正常情况下我们还是要采用第二种策略，即：<strong>主动死锁检测</strong>，而且innodb_deadlock_detect的默认值本身就是on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。</p><p>如果所有事务都要更新同一行的场景，每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的。这期间要消耗大量的CPU资源。</p><p><strong>死锁检测优化办法</strong></p><p>1.<strong>如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。</strong>但是这种操作本身带有一定的风险</p><p>2.<strong>控制并发度。</strong>比如同一行同时最多只有10个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是因为客户端很多，即使每个客户端控制到只有5个并发线程，汇总到数据库服务端以后，峰值并发数也可能会很高。因此，这个<strong>并发控制要做在数据库服务端</strong>。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改MySQL源码的人，也可以做在MySQL里面。基本思路就是，<strong>对于相同行的更新，在进入引擎之前排队</strong>。这样在InnoDB内部就不会有大量的死锁检测工作了。</p><p>3.<strong>从设计上优化</strong>。可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的1&#x2F;10，可以减少锁等待个数，也就减少了死锁检测的CPU消耗。</p><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p><strong>一条sql语句默认为一个事务</strong></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220316000331849.png" alt="image-20220316000331849"></p><h3 id="事务的四大特性"><a href="#事务的四大特性" class="headerlink" title="事务的四大特性"></a>事务的四大特性</h3><ol><li>原子性：原子性是指事务是一个不可分割的工作单位，事务中的操作要么全部成功，要么全部失败。部分操作失败时会进行回滚，从而保证原子性</li><li>一致性：事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。也就是说数据库应该只包含成功事务提交的结果时</li><li>隔离性：一个事务的执行不能其它事务干扰。多个并发事务之间要相互隔离</li><li>持久性：持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，不能回滚。并且接下来即使数据库发生故障也不应该对其有任何影响。</li></ol><h3 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h3><p>事务隔离级别要实际解决的三大问题</p><ol><li><p>脏读：脏读指的是读到了其他事务未提交的数据，未提交意味着这些数据可能会回滚，也就是可能最终不会存到数据库中的数据。</p></li><li><p>不可重复读：不可重复读针对其他事务的update和delete操作。指的是在同一事务内，不同的时刻读到的同一批数据可能是不一样的，可能会受到其他事务的影响，比如其他事务改了这批数据并提交了。</p></li><li><p>幻读：针对的是其他事务的insert操作。在事务A中同样的查询在不同的时间产生了不同的结果，这就是幻读。原因是事务B中在两次查询间隔中间插入了新的数据。</p></li></ol><p>SQL 标准定义了四种隔离级别，MySQL 全都支持。这四种隔离级别分别是：</p><ol><li>读未提交（READ UNCOMMITTED）</li><li>读提交 （READ COMMITTED）</li><li>可重复读 （REPEATABLE READ）</li><li>串行化 （SERIALIZABLE）</li></ol><p>从上往下，隔离强度逐渐增强，性能逐渐变差。采用哪种隔离级别要根据系统需求权衡决定，其中，<strong>可重复读</strong>是 MySQL 的默认级别。</p><p>事务隔离其实就是为了解决上面提到的脏读、不可重复读、幻读这几个问题，下面展示了 4 种隔离级别对这三个问题的解决程度。</p><table><thead><tr><th>隔离级别</th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>读未提交</td><td>未解决</td><td>未解决</td><td>未解决</td></tr><tr><td>读提交</td><td>解决</td><td>未解决</td><td>未解决</td></tr><tr><td>可重复读</td><td>解决</td><td>解决</td><td>未解决</td></tr><tr><td>串行化</td><td>解决</td><td>解决</td><td>解决</td></tr></tbody></table><p>MySQL <strong>事务隔离其实是依靠锁来实现的</strong>，锁是通过索引来锁住记录的(每个表都至少有一个聚集索引)。加锁自然会带来性能的损失，因此隔离级别越高性能越差。</p><p>加行锁的过程要<strong>分有索引和无索引两种情况</strong>，有索引的情况，MySQL 直接就在索引数中找到了这行数据，然后干净利落的加上行锁就可以了。</p><p>无索引时MySQL 无法直接定位到这行数据。MySQL 会为这张表中所有行加行锁，在加上行锁后，MySQL 会进行一遍过滤，发现不满足的行就释放锁，最终只留下符合条件的行，因此更新无索引的数据非常影响性能。</p><h3 id="锁和事务详解"><a href="#锁和事务详解" class="headerlink" title="锁和事务详解"></a>锁和事务详解</h3><p>几个概念：</p><p><strong>锁定读</strong>：在一个事务中，主动给读加锁，如SELECT … LOCK IN SHARE MODE 和 SELECT … FOR UPDATE。分别加上了行共享锁和行排他锁。共享锁可以和共享锁共存，所以可以多事务同时读。排他锁独占，所以加了排他锁之后其他事务不可以读和写。</p><p><strong>一致性非锁定读</strong>：InnoDB在读提交和可重复读隔离级别处理SELECT语句的默认模式。一致性非锁定读不会对其访问的表设置任何锁，因此，在对表执行一致性非锁定读的同时，其它事务可以同时并发的读取或者修改它们。</p><p><strong>当前读</strong>：读取的是最新版本，像<strong>UPDATE、DELETE、INSERT、SELECT … LOCK IN SHARE MODE、SELECT … FOR UPDATE</strong>这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。</p><p><strong>快照读</strong>：读取的是快照版本，也就是历史版本，像不加锁的<strong>SELECT</strong>操作就是快照读，即不加锁的非阻塞读；</p><p><strong>隐式锁定</strong>：InnoDB在事务执行过程中，使用两阶段锁协议（不主动进行显示锁定的情况）：</p><ul><li>随时都可以执行锁定，InnoDB会根据隔离级别在需要的时候自动加锁；</li><li>锁只有在执行commit或者rollback的时候才会释放，并且所有的锁都是在同一时刻被释放。</li></ul><p><strong>显式锁定</strong>：如SELECT … LOCK IN SHARE MODE 和 SELECT … FOR UPDATE（存储引擎层）；lock table和unlock table（server层）</p><p><strong>InnoDB有三种行锁的算法：</strong></p><p>1，Record Lock：单个行记录上的锁。（不包括其他行，所以会出现幻读）</p><p>2，Gap Lock：间隙锁，锁定一个范围，但不包括记录本身。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。</p><p>3，Next-Key Lock：1+2，锁定记录本身和记录左边的间隙，即一个左开右闭区间。主要目的是解决幻读。</p><p><strong>InnoDB的事务具体实现</strong></p><table><thead><tr><th>事务隔离级别</th><th>实现方式</th></tr></thead><tbody><tr><td>未提交读（RU）</td><td>事务对当前被读取的数据不加锁，都是<strong>当前读</strong>；  事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加<strong>行级共享锁</strong>，直到事务结束才释放。</td></tr><tr><td>提交读（RC）</td><td>事务对当前被读取的数据不加锁，且是<strong>快照读</strong>；  事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加<strong>行级排他锁（Record）</strong>，直到事务结束才释放。</td></tr><tr><td>可重复读（RR）</td><td>事务对当前被读取的数据不加锁，且是<strong>快照读</strong>；  事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加<strong>行级排他锁（Record，GAP，Next-Key）</strong>，直到事务结束才释放。  <strong>通过间隙锁，在这个级别MySQL就解决了幻读的问题</strong>  <strong>通过快照，在这个级别MySQL就解决了不可重复读的问题</strong></td></tr><tr><td>序列化读（S）</td><td>事务在读取数据时，必须先对其加<strong>表级共享锁</strong> ，直到事务结束才释放，都是<strong>当前读</strong>；  事务在更新数据时，必须先对其加<strong>表级排他锁</strong> ，直到事务结束才释放。</td></tr></tbody></table><p><strong>RR级别的锁都是next-key锁，可以解决幻读的问题，但是需要主动加锁</strong>。</p><pre><code class="sql">begin;#假设users表为空，下面查出来的数据为空select * from users lock in share mode; #加上共享锁#此时另一个事务B想提交且插入了一条id=1的数据，由于有间隙锁，所以要等待select * from users; #读快照，查出来的数据为空update users set name=&#39;mysql&#39; where id=1;#update是当前读，由于不存在数据，不进行更新select * from users; #读快照，查出来的数据为空commit;#事务B提交成功并插入数据</code></pre><h3 id="mvcc（多版本并发控制）"><a href="#mvcc（多版本并发控制）" class="headerlink" title="mvcc（多版本并发控制）"></a>mvcc（多版本并发控制）</h3><p>需要mvcc的原因：锁住一个资源后会禁止其他任何线程访问同一个资源。但是很多应用的一个特点都是读多写少的场景——&gt;使用了一种读写锁的方法，读锁和读锁之间不互斥，而写锁和写锁、读锁都互斥——&gt;让读写之间也不冲突的方法，就是读取数据时通过一种类似快照的方式将数据保存下来，这样读锁就和写锁不冲突了，不同的事务session会看到自己特定版本的数据。</p><p>mvcc：对于Mysql中的每一个数据行都有可能存在多个版本，在每次事务更新数据的时候都会同时记录undo log（未提交的也会记录undo log），并且把自己的事务id赋值给当前版本的row trx_id。记录上的最新值，通过回滚操作，都可以得到前一个版本的值。这就是mvcc</p><p>假如三个事务更新了同一行数据，那么就会有对应的三个数据版本。</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220317221606939.png" alt="image-20220317221606939"></p><p>系统会判断，<strong>当没有事务再需要用到这些回滚日志时，回滚日志会被删除。</strong>就是当系统里没有比这个回滚日志更早的视图的时候。</p><p>因此最好避免使用长事务，长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。</p><p>不同时刻启动的事务会有不同的快照，记录数据的值。</p><p>在实现可重复读的隔离级别，只需要在<strong>事务开始的时候创建快照</strong>，之后的查询里都共用这个快照，后续的事务对数据的更改是对当前事务是不可见的，这样就实现了可重复读。</p><p>而读提交，每一个<strong>语句执行前都会重新计算</strong>出一个新的快照。</p><h3 id="快照原理"><a href="#快照原理" class="headerlink" title="快照原理"></a>快照原理</h3><p>快照并非为每个事务存储真正的行数据，而是而是每次需要的时候根据当前版本和undo log计算出来的。</p><p>InnoDB为每个事务构造了一个活跃事务数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。</p><p>譬如数组为[47,49,52]，事务id为60，那么小于47的事务都已经提交，对事务60来说是可见的；id大于60的事务还未创建，是不可见的。</p><p>对于<strong>可重复读，这个数组不会变</strong>；而<strong>读提交则会在每次读取时更新活跃数组</strong>；</p><p>可重复读事务创建时，就要顺着undo log往前找，直到找到某个版本的事务id小于60并且不在活跃数组中，这个版本的数据就是事务的快照。</p><p>而读提交事务每次读取数据时，先会更新活跃数组，然后顺着undo log往前找，直到找到某个版本的事务不在活跃数组中即可。</p><p>需要注意快照不适用于并发写的情况，因为写的时候(如update k&#x3D;k+1)需要读取最新版本的数据，并且会给版本加排他锁（不影响读其他版本的数据），等到事务结束才释放。</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\b7bd3c773392176bba242235f4da000f.webp" alt="b7bd3c773392176bba242235f4da000f"></p><p>如B读到的数据是3而不是2。</p><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="索引结构优劣分析"><a href="#索引结构优劣分析" class="headerlink" title="索引结构优劣分析"></a>索引结构优劣分析</h3><p>设计一个适合 MySQL 索引的数据结构，至少满足以下要求：</p><ul><li>能在尽可能少的磁盘的 I&#x2F;O 操作中完成查询工作；</li><li>要能高效地查询某一个记录，也要能高效地执行范围查找；</li></ul><p><strong>数组</strong></p><p>优点：查询最快，可用二分查找</p><p>缺点：维护困难，插入删除效率低。适合存储静态数据，比如你要保存的是2017年某个城市的所有人口信息，这类不会再修改的数据。</p><p><strong>红黑树，avl树</strong></p><p>优点：相比数组维护简单，插入删除效率高</p><p>缺点：一个节点只能有两个子节点，树过高，需要的I&#x2F;O操作多</p><p><strong>哈希表</strong></p><p>优点：查询速度快</p><p>缺点：只支持精确匹配，不支持范围查询；不支持根据索引排序</p><p><strong>B树</strong></p><p>优点：多叉树，树的高度低，磁盘I&#x2F;O次数少</p><p>缺点： B 树的每个节点都包含数据（索引+记录），而用户的记录数据的大小很有可能远远超过了索引数据，这就需要花费更多的磁盘 I&#x2F;O 操作次数来读到有用的索引数据。因此B树的查询速度不平均，有可能很快，有可能很慢； B 树做范围查询，需要使用中序遍历，这会涉及多个节点的磁盘 I&#x2F;O 问题，从而导致整体速度下降；B树插入和删除可能发生树变形，效率低</p><p><strong>B+树</strong></p><p>优点：记录都保存在叶子节点，相比B树，每个节点索引更多，树更矮，磁盘I&#x2F;O次数少，查询速度平均；记录用双向链表相连，支持范围查询和排序；存在冗余节点，插入和删除不会发生严重的树变形，相比B树效率更高</p><p>缺点：单记录查询平均I&#x2F;O次数相比B树更多(因此mongodb使用B树。不使用哈希表是因为哈希表范围查询太慢，做了综合考虑)</p><h3 id="自增主键的好处"><a href="#自增主键的好处" class="headerlink" title="自增主键的好处"></a>自增主键的好处</h3><p>自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。</p><p>而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。</p><p>除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？</p><p>由于每个二级索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约20个字节，而如果用整型做主键，则只要4个字节，如果是长整型（bigint）则是8个字节。</p><p><strong>显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。</strong></p><p>所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。</p><p>有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：</p><ol><li>只有一个索引；</li><li>该索引必须是唯一索引。</li></ol><p>你一定看出来了，这就是典型的KV场景。</p><p>由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。</p><p>索引结构：</p><table><thead><tr><th>索引结构</th><th>描述</th></tr></thead><tbody><tr><td>b+树</td><td>最常见的索引类型，大部分引擎支持</td></tr><tr><td>hash索引</td><td>用哈希表实现，只支持精确匹配，不支持范围查询</td></tr><tr><td>R-tree(空间索引)</td><td>MyISAM引擎的一个特殊索引，主要用于地理空间数据类型，使用少</td></tr><tr><td>Full-text(全文索引)</td><td>是一种通过建立倒排索引，快速匹配文档的方式</td></tr></tbody></table><p>各引擎支持索引：</p><table><thead><tr><th>索引</th><th>InnoDB</th><th>MyISAM</th><th>Memory</th></tr></thead><tbody><tr><td>B+tree索引</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>Hash索引</td><td>不支持(在指定条件下会自动构建)</td><td>不支持</td><td>支持</td></tr><tr><td>R-tree</td><td>不支持</td><td>支持</td><td>不支持</td></tr><tr><td>Full-text</td><td>5.6版本后支持</td><td>支持</td><td>不支持</td></tr></tbody></table><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220318232645585.png" alt="image-20220318232645585"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220318232725678.png" alt="image-20220318232725678"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220318232828330.png" alt="image-20220318232828330"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220318232941993.png" alt="image-20220318232941993"></p><h3 id="索引分类"><a href="#索引分类" class="headerlink" title="索引分类"></a>索引分类</h3><table><thead><tr><th>分类</th><th>含义</th><th>特点</th><th>关键字</th></tr></thead><tbody><tr><td>主键索引</td><td>针对表中主键创建的索引</td><td>默认自动创建，只能有一个</td><td>PRIMARY</td></tr><tr><td>唯一索引</td><td>针对UNIQUE列创建的索引</td><td>可以有多个</td><td>UNIQUE</td></tr><tr><td>常规索引</td><td>快速定位数据</td><td>可以有多个</td><td></td></tr><tr><td>全文索引</td><td>查找文本关键词，而不是比较值</td><td>可以有多个</td><td>FULLTEXT</td></tr></tbody></table><p>在InnoDB引擎中，根据索引存储形式又可以分为聚集索引和二级索引</p><p><strong>聚集索引</strong>：索引的叶子节点保存的是行数据，必须有且只能有一个聚集索引。有主键时主键索引就是聚集索引，没有时第一个唯一索引就是聚集索引，二者都无时自动创建自增主键作为聚集索引。</p><p><strong>二级索引</strong>：普通索引，索引的叶子节点存储的是聚集索引的值。可以有多个。</p><p>注意，二级索引存放的是聚集索引的索引值（一般也就是行数据对应主键的值），因此得到主键值之后还需要用主键值去聚集索引中再查询一次得到行数据。在这个过程中，<strong>回到主键索引树搜索的过程，我们称为回表</strong>。</p><h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h3><p>若在查询中避免了回表的过程，就是覆盖索引。如执行的语句是select ID from T where k between 3 and 5，id是主键，已经存放在了二级索引树上，因此只需要查询一次二级索引就可以得到结果。</p><p>由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以<strong>使用覆盖索引是一个常用的性能优化手段</strong>。</p><p><strong>除了查询主键的情况还有什么办法可以使用到覆盖索引呢？</strong></p><p>如在一个市民表上需要查询市民的身份证号和名字，那么我们可以将身份证号和名字建立一个联合索引，那么二级索引的叶子节点上就包括了身份证号和名字，无需再回表查询了。</p><p>当然增加索引会造成额外的维护代价，需要综合考虑。</p><h3 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h3><p>多个普通字段组合在一起创建的索引就叫做联合索引</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\index.png" alt="image-20220319032542383"></p><p>索引会先根据第一个索引列排序，如果相同，再根据后面的索引列进行排序。</p><h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h3><p>在通过联合索引检索数据时，从索引中最左边的列开始，一直向右匹配，并且不跳过索引中的列。</p><p>比如，如果创建了一个 <code>(a, b, c)</code> 联合索引，如果查询条件是以下这几种，就可以匹配上联合索引：</p><ul><li>where a&#x3D;1；</li><li>where a&#x3D;1 and b&#x3D;2 and c&#x3D;3；</li><li>where a&#x3D;1 and b&#x3D;2；</li></ul><p>需要注意的是，因为<strong>有查询优化器</strong>，所以 <strong>a 字段在 where 子句的顺序并不重要</strong>。</p><p>但是，如果查询条件是以下这几种，因为不符合最左匹配原则，所以就无法匹配上联合索引，联合索引就会失效:</p><ul><li>where b&#x3D;2；</li><li>where c&#x3D;3；</li><li>where b&#x3D;2 and c&#x3D;3；</li></ul><h3 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h3><p>索引下推功能，可以在索引遍历过程中，在存储引擎层对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p><p>假设我们想从一开始创建的表中，查询 name 以 ‘L’ 开头，并且 age 为 17 的人员信息。</p><pre><code class="sql">select * from t_user where name like &#39;L%&#39; and age = 17;</code></pre><p>在不用索引下推的情况下，根据前边”最左匹配原则”描述的那样，该查询在联合索引中只有 name 列可以使用到索引，age 列是用不到索引的。在扫描 (‘name’, age) 索引树时，根据 name like ‘L%’ 这个条件，可以查找到 LiLei、Lili、Lisa、Lucy 四条索引数据，接下来，再根据这四条索引数据中的 id 值，逐一进行回表扫描，从聚簇索引中找到相应的行数据，将找到的行数据返回给 server 层。server 层中，再根据 age &#x3D; 17 这个条件进行筛选，最终只留下 Lucy 用户的数据信息。</p><p>在使用索引下推的情况下，存储引擎层还是先根据 name like ‘L%’ 这个条件，查找到 LiLei、Lili、Lisa、Lucy 四条索引数据，不过接下来不是直接进行回表操作，而是根据 age &#x3D; 17 这个条件，对四条索引数据进行判断筛选，将符合条件的索引对应的 id 进行回表扫描，最终将找到的行数据返回给 server 层。（也就是我们把本应该在 server 层进行筛选的条件，下推到存储引擎层来进行筛选判断了。这个下推的前提是索引中有 age 列信息，如果是其它条件，如 gender &#x3D; 0，这个即使下推下来也没用）</p><p>使用索引下推优化，可以有效减少回表次数，也可以减少 server 层从存储引擎层接收数据的次数，从而大大提升查询效率。</p><h3 id="唯一索引和普通索引的选择"><a href="#唯一索引和普通索引的选择" class="headerlink" title="唯一索引和普通索引的选择"></a>唯一索引和普通索引的选择</h3><p>假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号。如果市民系统需要按照身份证号查姓名，就会执行类似这样的SQL语句：</p><pre><code>select name from CUser where id_card = &#39;xxxxxxxyyyyyyzzzzz&#39;;</code></pre><p>此时选择普通索引还是唯一索引</p><p><strong>查询性能分析</strong></p><p>查询时两种索引性能差距很小。</p><p>假设，执行查询的语句是 select id from T where k&#x3D;5。这个查询语句在索引树上查找的过程，先是通过B+树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为<strong>数据页内部通过二分法来定位记录</strong>（所以不同的索引节点不能放在同一页）。</p><ul><li>对于普通索引来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足k&#x3D;5条件的记录。</li><li>对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。</li></ul><p>那么，这个不同带来的性能差距会有多少呢？<strong>答案是，微乎其微。</strong></p><p>你知道的，InnoDB的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在InnoDB中，每个数据页的大小默认是16KB。</p><p>因为引擎是按页读写的，所以说，当找到k&#x3D;5的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。</p><p>当然，如果k&#x3D;5这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。</p><p>但是，我们之前计算过，对于整型字段，一个数据页可以放近千个key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的CPU来说可以忽略不计。</p><p><strong>更新性能分析</strong></p><p>更新时由于change buffer的存在，在写多读少的业务场景下最好选择普通索引</p><h3 id="索引失效"><a href="#索引失效" class="headerlink" title="索引失效"></a>索引失效</h3><p>1.<strong>对索引列使用函数</strong></p><p>当我们在查询条件中对索引列使用函数，就会导致索引失效。</p><p>因为索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了。</p><p>不过，从 MySQL 8.0 开始，索引特性增加了函数索引，即可以针对函数计算后的值建立一个索引，也就是说该索引的值是函数计算后的值，所以就可以通过扫描索引来查询数据。</p><p>举个例子，我通过下面这条语句，对 length(name) 的计算结果建立一个名为 idx_name_length 的索引。</p><pre><code class="sql">alter table t_user add key idx_name_length ((length(name)));</code></pre><p>2.<strong>对索引列进行表达式计算</strong></p><p>在查询条件中对索引进行表达式计算，也是无法走索引的。</p><p>比如，下面这条查询语句</p><pre><code class="sql">select * from t_user where id + 1 = 10;</code></pre><p>但是，如果把查询语句的条件<strong>改成 where id &#x3D; 10 - 1</strong>，这样就不是在索引字段进行表达式计算了，于是就可以走索引查询了。</p><p>原因在索引保存的是索引字段的原始值，而不是 id + 1 表达式计算后的值，所以无法走索引</p><p>当然mysql可以进行特殊处理求出索引字段原始值，但是表达式计算的情况多种多样，每种都要考虑的话，代码可能会很臃肿，所以mysql没有这样做。</p><p>3.<strong>对索引使用头部模糊匹配</strong></p><p>当我们使用头部模糊匹配的时候，也就是 <code>like %xx</code> 或者 <code>like %xx%</code> 这两种方式都会造成索引失效。</p><p>如name like ‘林%’有效，name like ‘%林’则会失效</p><p>因为索引 B+ 树是按照索引值有序排列存储的，只能根据前缀进行比较。</p><p>4.<strong>字符串不加引号</strong></p><p>MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。</p><p>如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。</p><p>失效例子：</p><pre><code class="sql">select * from t_user where phone = 1300000001;//phone是字符串</code></pre><p>phone 字段为字符串，所以 MySQL 要会自动把字符串转为数字，所以这条语句相当于：</p><pre><code class="sql">select * from t_user where CAST(phone AS signed int) = 1300000001;</code></pre><p>可以看到，CAST 函数是作用在了 phone 字段，而 phone 字段是索引，也就是<strong>对索引使用了函数</strong>！而前面我们也说了，对索引使用函数是会导致索引失效的。</p><p>不失效例子：</p><pre><code class="sql">select * from t_user where id = &quot;1&quot;;//id是数字</code></pre><p>这时因为字符串部分是输入参数，也就需要将字符串转为数字，所以这条语句相当于：</p><pre><code class="sql">select * from t_user where id = CAST(&quot;1&quot; AS signed int);</code></pre><p>可以看到，索引字段并没有用任何函数，CAST 函数是用在了输入参数，因此是可以走索引扫描的。</p><p>5.<strong>WHERE 子句中 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列</strong></p><p>举个例子，比如下面的查询语句，id 是主键，age 是普通列，从执行计划的结果看，是走了全表扫描。</p><pre><code class="sql">select * from t_user where id = 1 or age = 18;</code></pre><p>这是因为 OR 的含义就是两个只要满足一个即可，因此两个条件的记录都要查询，然后进行合并。只要有条件列不是索引列，就会进行全表扫描。</p><p>6.<strong>联合索引不遵守最左前缀法则</strong></p><p>7.<strong>联合索引范围查询(&gt;、&lt;、between、like等)</strong></p><pre><code class="sql">select * from testTable where a&gt;1 and b=2</code></pre><p>首先a字段在B+树上是有序的，所以可以用二分查找法定位到1，然后将所有大于1的数据取出来，a可以用到索引。</p><p>b有序的前提是a是确定的值，那么现在a的值是取大于1的，可能有10个大于1的a，也可能有一百个a。</p><p>大于1的a那部分的B+树里，b字段是无序的，所以<strong>b不能用二分查找来查询</strong>，b用不到索引。（索引失效关键在于能不能使用二分查找）</p><p>8.<strong>优化器导致索引失效</strong></p><p>因为回表的原因，走索引效率不一定更高。优化器会判断走索引和全表扫描谁的效率高，若全表扫描更高时不会走索引</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220319034349465.png" alt="image-20220319034349465"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220319035020522.png" alt="image-20220319035020522"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220319035416073.png" alt="image-20220319035416073"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220319035556705.png" alt="image-20220319035556705"></p><h3 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h3><p><code>show global status like &#39;Com______&#39;</code>&#x2F;&#x2F;查询数据库增删改查各自的访问频次</p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220319030133337.png" alt="image-20220319030133337"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220319030637629.png" alt="image-20220319030637629"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220319031045669.png" alt="image-20220319031045669"></p><h3 id="sql优化"><a href="#sql优化" class="headerlink" title="sql优化"></a>sql优化</h3><h4 id="插入优化"><a href="#插入优化" class="headerlink" title="插入优化"></a>插入优化</h4><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220320212637861.png" alt="image-20220320212637861"></p><p>插入大批量数据使用load</p><h4 id="主键优化"><a href="#主键优化" class="headerlink" title="主键优化"></a>主键优化</h4><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220320213439189.png" alt="image-20220320213439189"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220320213503174.png" alt="image-20220320213503174"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220320213613180.png" alt="image-20220320213613180"></p><h4 id="排序优化"><a href="#排序优化" class="headerlink" title="排序优化"></a>排序优化</h4><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220320214021525.png" alt="image-20220320214021525"></p><h4 id="分组优化"><a href="#分组优化" class="headerlink" title="分组优化"></a>分组优化</h4><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220320214238071.png" alt="image-20220320214238071"></p><h4 id="limit优化"><a href="#limit优化" class="headerlink" title="limit优化"></a>limit优化</h4><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220320214906293.png" alt="image-20220320214906293"></p><h4 id="count优化"><a href="#count优化" class="headerlink" title="count优化"></a>count优化</h4><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220320215359582.png" alt="image-20220320215359582"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220320215330621.png" alt="image-20220320215330621"></p><h4 id="update优化"><a href="#update优化" class="headerlink" title="update优化"></a>update优化</h4><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220320220409456.png" alt="image-20220320220409456"></p><h3 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h3><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220320221846951.png" alt="image-20220320221846951"></p><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220320221528463.png" alt="image-20220320221528463"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/muduo%E7%BD%91%E7%BB%9C%E6%BA%90%E7%A0%81/"/>
      <url>/2023/01/22/muduo%E7%BD%91%E7%BB%9C%E6%BA%90%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<h1 id="muduo网络源码"><a href="#muduo网络源码" class="headerlink" title="muduo网络源码"></a>muduo网络源码</h1><p>学到的东西：tie延长生命周期；vector的首指针可以直接代替数组首指针；</p><h2 id="各个类详解"><a href="#各个类详解" class="headerlink" title="各个类详解"></a>各个类详解</h2><h3 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h3><p>Channel类封装了poll&#x2F;epoll中的 <code>I/O</code> 事件(epoll_event)和事件对应的回调函数，不拥有 <code>fd</code>，可以代表多种实体：<code>listening fd</code>、<code>timer fd</code>、<code>event fd</code> 等。</p><p>每个Channel对象自始至终只属于一个EventLoop，因此每个Channel对象都只属于某一个IO线程。</p><p>每个Channel对象自始至终只负责一个文件描述符（fd）的IO事件分发，但它并不拥有这个fd，也不会在析构的时候关闭这个fd。</p><p>Muduo用户一般不直接使用Channel，而会使用更上层的封装，如TcpConnection。</p><pre><code class="c++">class Channel : noncopyable&#123; public:  typedef std::function&lt;void()&gt; EventCallback;  typedef std::function&lt;void(Timestamp)&gt; ReadEventCallback;  Channel(EventLoop* loop, int fd);  ~Channel();  void handleEvent(Timestamp receiveTime); private:  static const int kNoneEvent;  static const int kReadEvent;  static const int kWriteEvent;  EventLoop* loop_;  const int  fd_;  int        events_;  int        revents_; // it&#39;s the received event types of epoll or poll  int        index_; // used by Poller.  ReadEventCallback readCallback_;  EventCallback writeCallback_;  EventCallback closeCallback_;  EventCallback errorCallback_;&#125;;</code></pre><p><code>events_</code> 是 <code>Channel</code> 关心的事件，<code>Poller</code> 根据这个来设置。<code>revents_</code> 是 <code>Poller</code> 返回的已就绪的事件，<code>handleEvent()</code> 会调用相应的 <code>callback</code> 来处理。</p><p>所有需要由 <code>EventLoop</code> 处理的如 <code>Acceptor</code>、<code>TcpConnection</code> 都有 <code>Channel</code> 成员并设置 <code>callback</code> 注册到 <code>EventLoop</code> 中。<code>Muduo</code> 的 <code>callback</code> 基本都是 <code>member function</code>， 用 <code>std::bind()</code> 绑定 <code>this</code> 指针来注册，一些网络库会采用继承接口类来实现回调的注册。</p><p><strong>源码分析</strong></p><p>Channel.h源码</p><pre><code class="c++">#ifndef MUDUO_NET_CHANNEL_H#define MUDUO_NET_CHANNEL_H#include &lt;boost/function.hpp&gt;#include &lt;boost/noncopyable.hpp&gt;#include &lt;boost/shared_ptr.hpp&gt;#include &lt;boost/weak_ptr.hpp&gt;#include &lt;muduo/base/Timestamp.h&gt;/*个人理解：channel是一个具体来处理事件的类，它与eventloop关系紧密，主要是根据事件宏定义来调用对应的回调函数 *主要的事件有三种，读事件，写事件和结束事件 **/namespace muduo &#123;    namespace net &#123;        class EventLoop;////// A selectable I/O channel.////// This class doesn&#39;t own the file descriptor./// The file descriptor could be a socket,/// an eventfd, a timerfd, or a signalfd        class Channel : boost::noncopyable &#123;        public:            typedef boost::function&lt;void()&gt; EventCallback;            typedef boost::function&lt;void(Timestamp)&gt; ReadEventCallback;//读事件的回调函数中必须有参数Timestamp            Channel(EventLoop *loop, int fd);//一个channel要绑定一个EventLoop和一个文件描述符，但channel无权操作fd            ~Channel();            void handleEvent(Timestamp receiveTime);//处理事件                        //设置四种事件的回调函数            void setReadCallback(const ReadEventCallback &amp;cb) &#123; readCallback_ = cb; &#125;            void setWriteCallback(const EventCallback &amp;cb) &#123; writeCallback_ = cb; &#125;            void setCloseCallback(const EventCallback &amp;cb) &#123; closeCallback_ = cb; &#125;            void setErrorCallback(const EventCallback &amp;cb) &#123; errorCallback_ = cb; &#125;            /// Tie this channel to the owner object managed by shared_ptr,            /// prevent the owner object being destroyed in handleEvent.            //这个函数，用于延长某些对象的生命期，使其寿命长过Channel::handleEvent()函数。            void tie(const boost::shared_ptr&lt;void&gt; &amp;);//将一个shared_ptr指针的值赋给tie_            int fd() const &#123; return fd_; &#125;            int events() const &#123; return events_; &#125;            void set_revents(int revt) &#123; revents_ = revt; &#125; // used by pollers            // int revents() const &#123; return revents_; &#125;            bool isNoneEvent() const &#123; return events_ == kNoneEvent; &#125;//判断事件是否为0，也就是没有关注的事件            void enableReading() &#123;                events_ |= kReadEvent;                update();            &#125;//设置读事件，并将当前channel加入到poll队列当中            // void disableReading() &#123; events_ &amp;= ~kReadEvent; update(); &#125;            void enableWriting() &#123;                events_ |= kWriteEvent;                update();            &#125;//设置写事件，并将当前channel加入到poll队列当中            void disableWriting() &#123;                events_ &amp;= ~kWriteEvent;                update();            &#125;//关闭写事件，并将当前channel加入到poll队列当中            void disableAll() &#123;                events_ = kNoneEvent;                update();            &#125;//关闭所有事件，并暂时删除当前channel            bool isWriting() const &#123; return events_ &amp; kWriteEvent; &#125;//是否关注写事件            // for Poller            int index() &#123; return index_; &#125;//返回序号            void set_index(int idx) &#123; index_ = idx; &#125;//设置序号            // for debug            string reventsToString() const;            void doNotLogHup() &#123; logHup_ = false; &#125;//把挂起标志位置false            EventLoop *ownerLoop() &#123; return loop_; &#125;            void remove();        private:            void update();            void handleEventWithGuard(Timestamp receiveTime);            static const int kNoneEvent;            static const int kReadEvent;            static const int kWriteEvent;            EventLoop *loop_;            // 所属EventLoop            const int fd_;            // 文件描述符，但不负责关闭该文件描述符            int events_;        // 需要epoll关注的事件            int revents_;        // poll/epoll wait返回的需要处理的事件            int index_;        // used by Poller.表示在epoll队列中的状态：1.正在队列中2.曾经在队列中3.从来没在队列中            bool logHup_;        // for POLLHUP是否被挂起            boost::weak_ptr&lt;void&gt; tie_;//保证channel所在的类            bool tied_;            bool eventHandling_;        // 是否处于处理事件中            ReadEventCallback readCallback_;//当文件描述符产生读事件时，最后调用的读函数            EventCallback writeCallback_;//当文件描述符产生写事件时，最后调用的写函数            EventCallback closeCallback_;//当文件描述符产生关闭事件时，最后调用的关闭函数            EventCallback errorCallback_;//当文件描述符产生错误事件时，最后调用的错误函数        &#125;;    &#125;&#125;#endif  // MUDUO_NET_CHANNEL_H</code></pre><p>Channel.cc源码</p><pre><code class="c++">#include &lt;muduo/base/Logging.h&gt;#include &lt;muduo/net/Channel.h&gt;#include &lt;muduo/net/EventLoop.h&gt;#include &lt;sstream&gt;#include &lt;poll.h&gt;using namespace muduo;using namespace muduo::net;const int Channel::kNoneEvent = 0;const int Channel::kReadEvent = POLLIN | POLLPRI;const int Channel::kWriteEvent = POLLOUT;Channel::Channel(EventLoop *loop, int fd__)        : loop_(loop),          fd_(fd__),          events_(0),          revents_(0),          index_(-1),//就是kNew          logHup_(true),          tied_(false),          eventHandling_(false) &#123;&#125;Channel::~Channel() &#123;    assert(!eventHandling_);&#125;void Channel::tie(const boost::shared_ptr&lt;void&gt; &amp;obj)//给tie_指针赋值，tie_指针是一个weak_ptr指针&#123;    tie_ = obj;    tied_ = true;&#125;void Channel::update()//把当前的channel加入到poll队列当中&#123;    loop_-&gt;updateChannel(this);&#125;// 调用这个函数之前确保调用disableAll// 从EventLoop中移除这个channelvoid Channel::remove() &#123;    assert(isNoneEvent());    loop_-&gt;removeChannel(this);&#125;void Channel::handleEvent(Timestamp receiveTime)//Timestamp主要用于读事件的回调函数&#123;    //guard是一个shared_ptr，这样guard指向的对象在智能指针析构前就不会析构了，延长了生命周期    boost::shared_ptr&lt;void&gt; guard;    if (tied_) &#123;        guard = tie_.lock();//提升tie_为shared_ptr，如果提升成功，说明指向一个存在的对象        if (guard) &#123;            LOG_TRACE &lt;&lt; &quot;[6] usecount=&quot; &lt;&lt; guard.use_count();            handleEventWithGuard(receiveTime);            LOG_TRACE &lt;&lt; &quot;[12] usecount=&quot; &lt;&lt; guard.use_count();        &#125;    &#125; else &#123;        handleEventWithGuard(receiveTime);    &#125;&#125;void Channel::handleEventWithGuard(Timestamp receiveTime)//查看epoll/poll返回的具体是什么事件，并根据事件的类型进行相应的处理&#123;    eventHandling_ = true;    /*    if (revents_ &amp; POLLHUP)    &#123;        LOG_TRACE &lt;&lt; &quot;1111111111111111&quot;;    &#125;    if (revents_ &amp; POLLIN)    &#123;        LOG_TRACE &lt;&lt; &quot;2222222222222222&quot;;    &#125;    */    if ((revents_ &amp; POLLHUP) &amp;&amp; !(revents_ &amp; POLLIN))//当事件为挂起并没有可读事件时    &#123;        if (logHup_) &#123;            LOG_WARN &lt;&lt; &quot;Channel::handle_event() POLLHUP&quot;;        &#125;        if (closeCallback_) closeCallback_();    &#125;    if (revents_ &amp; POLLNVAL)//描述字不是一个打开的文件描述符    &#123;        LOG_WARN &lt;&lt; &quot;Channel::handle_event() POLLNVAL&quot;;    &#125;    if (revents_ &amp; (POLLERR | POLLNVAL))//发生错误或者描述符不可打开    &#123;        if (errorCallback_) errorCallback_();    &#125;    if (revents_ &amp; (POLLIN | POLLPRI | POLLRDHUP))//关于读的事件    &#123;        if (readCallback_) readCallback_(receiveTime);    &#125;    if (revents_ &amp; POLLOUT)//关于写的事件    &#123;        if (writeCallback_) writeCallback_();    &#125;    eventHandling_ = false;&#125;string Channel::reventsToString() const//把事件转成一个string，用于日志打印debug&#123;    std::ostringstream oss;    oss &lt;&lt; fd_ &lt;&lt; &quot;: &quot;;    if (revents_ &amp; POLLIN)        oss &lt;&lt; &quot;IN &quot;;    if (revents_ &amp; POLLPRI)        oss &lt;&lt; &quot;PRI &quot;;    if (revents_ &amp; POLLOUT)        oss &lt;&lt; &quot;OUT &quot;;    if (revents_ &amp; POLLHUP)        oss &lt;&lt; &quot;HUP &quot;;    if (revents_ &amp; POLLRDHUP)        oss &lt;&lt; &quot;RDHUP &quot;;    if (revents_ &amp; POLLERR)        oss &lt;&lt; &quot;ERR &quot;;    if (revents_ &amp; POLLNVAL)        oss &lt;&lt; &quot;NVAL &quot;;    return oss.str().c_str();&#125;</code></pre><p><strong>Channel::tie()详解</strong></p><p>这里是一个智能指针使用的特定场景之一，用于特定时刻延长对象的生命周期。我们知道持有对象的shared_ptr可以延长对象的生命周期，但是如果我们只想在特定时刻延长对象的生命周期怎么办(比如执行对象的成员函数时)。解决方法就是持有对象的weak_ptr，并在函数内升级为shared_ptr。</p><pre><code class="c++">//给tie_指针赋值，tie_指针是一个weak_ptr指针void Channel::tie(const boost::shared_ptr&lt;void&gt; &amp;obj)&#123;    tie_ = obj;    tied_ = true;&#125;void Channel::handleEvent(Timestamp receiveTime)//Timestamp主要用于读事件的回调函数&#123;    //guard是一个shared_ptr，这样guard指向的对象在handleEventWithGuard()函数执行期间就不会析构了，延长了生命周期    boost::shared_ptr&lt;void&gt; guard;    if (tied_) &#123;        guard = tie_.lock();//提升tie_为shared_ptr，如果提升成功，说明指向一个存在的对象        if (guard) &#123;            LOG_TRACE &lt;&lt; &quot;[6] usecount=&quot; &lt;&lt; guard.use_count();            handleEventWithGuard(receiveTime);            LOG_TRACE &lt;&lt; &quot;[12] usecount=&quot; &lt;&lt; guard.use_count();        &#125;    &#125; else &#123;        handleEventWithGuard(receiveTime);    &#125;&#125;</code></pre><p>结合例子分析，看下面的一个调用时序图</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/muduo_tie.png" alt="img"></p><p>当对方断开TCP连接，这个IO事件会触发Channel::handleEvent()调用，后者会调用用户提供的CloseCallback，而用户代码在onClose()中有可能析构Channel对象，这就造成了灾难。等于说Channel::handleEvent()执行到一半的时候，其所属的Channel对象本身被销毁了。这时程序无疑会出错或崩溃。</p><p>Muduo的解决办法是提供Channel::tie(const boost::shared_ptr<void>&amp;)这个函数，用于延长某些对象（可以是Channel对象，也可以是其owner对象）的生命周期，使之长过Channel::handleEvent()函数。</p><p>Muduo TcpConnection采用shared_ptr管理对象生命期的原因之一就是因为这个。</p><p>当有关闭事件时，调用流程如下：</p><p>Channel::handleEvent -&gt; TcpConnection::handleClose -&gt;TcpClient::removeConnection -&gt;TcpConnection::connectDestroyed-&gt;channel_-&gt;remove()。</p><p>1、为了在Channel::handleEvent处理期间，防止因其owner对象被修改，进而导致Channel被析构，最后出现不可预估错误。 Channel::tie()的作用就是将Channel的owner对象进行绑定保护起来。</p><p> 2、另外channel-&gt;remove的作用是删除channel在Poll中的地址拷贝，而不是销毁channel。channel的销毁由其owner对象决定。</p><h3 id="poller"><a href="#poller" class="headerlink" title="poller"></a>poller</h3><p>Poller class 是IO multiplexing的封装。在muduo中它是一个抽象类，因为muduo同时支持poll和epoll两种IO multiplexing机制。</p><p>Poller是EventLoop的间接成员，只供其owner EventLoop在IO线程中调用，因此无需加锁。其生命周期和EvenLoop相等。Poller并不拥有Channel，Channel在析构前必须自己unregister（EventLoop::removeChannel()）,避免悬空指针。</p><p><strong>Poller.h</strong></p><p>Poller.h只是一个简单的抽象类</p><pre><code class="c++">#ifndef MUDUO_NET_POLLER_H#define MUDUO_NET_POLLER_H#include &lt;vector&gt;#include &lt;boost/noncopyable.hpp&gt;#include &lt;muduo/base/Timestamp.h&gt;#include &lt;muduo/net/EventLoop.h&gt;namespace muduo &#123;    namespace net &#123;        class Channel;////// Base class for IO Multiplexing////// This class doesn&#39;t own the Channel objects.        // 这个Poller类只是一个抽象类主要实现在EpollPoller/PollPoller中        class Poller : boost::noncopyable &#123;        public:            typedef std::vector&lt;Channel *&gt; ChannelList;            Poller(EventLoop *loop);            virtual ~Poller();            /// Polls the I/O events.            /// Must be called in the loop thread.            virtual Timestamp poll(int timeoutMs, ChannelList *activeChannels) = 0; // poll函数            /// Changes the interested I/O events.            /// Must be called in the loop thread.            virtual void updateChannel(Channel *channel) = 0;// 更新Channel            /// Remove the channel, when it destructs.            /// Must be called in the loop thread.            virtual void removeChannel(Channel *channel) = 0;    // 移除Channel            static Poller *newDefaultPoller(EventLoop *loop);// 在这里会根据环境变量生成epoll或者poll            void assertInLoopThread() &#123;// 确保所有的操作都在eventloop的线程中                ownerLoop_-&gt;assertInLoopThread();            &#125;        private:            EventLoop *ownerLoop_;    // Poller所属EventLoop        &#125;;    &#125;&#125;#endif  // MUDUO_NET_POLLER_H</code></pre><p><strong>EPollPoller.h</strong></p><p>这个类主要利用epoll函数，封装了epoll三个函数，</p><p>其中epoll_event.data是一个指向channel类的指针，这里可以等价理解为channel就是epoll_event，用于在epoll队列中注册，删除，更改的结构体。因为文件描述符fd，Channel，以及epoll_event结构体（只有需要添加到epoll上时才有epoll_event结构体）三个都是一一对应的关系Channel.fd应该等于fd，epoll_event.data应该等于&amp;Channel。如果不添加到epoll队列中，Channel和fd一一对应，就没有epoll_event结构体了</p><p>从epoll队列中删除有两种删除方法，</p><p>第一种暂时删除，就是从epoll队列中删除，并且把标志位置为kDeleted，但是并不从ChannelMap channels_中删除</p><p>第二种是完全删除，从epoll队列中删除，并且从ChannelMap channels_中也删除，最后把标志位置kNew。</p><p>可以理解为ChannelMap channels_的作用就是：暂时不需要的，就从epoll队列中删除，但是在channels_中保留信息，类似与挂起，这样下次再使用这个channel时，只需要添加到epoll队列中即可。而完全删除，就把channels_中也删除。</p><p>下面的源码有详细的注释</p><pre><code class="c++">#ifndef MUDUO_NET_POLLER_EPOLLPOLLER_H#define MUDUO_NET_POLLER_EPOLLPOLLER_H#include &lt;muduo/net/Poller.h&gt;#include &lt;map&gt;#include &lt;vector&gt;struct epoll_event;namespace muduo &#123;    namespace net &#123;////// IO Multiplexing with epoll(4).///        class EPollPoller : public Poller &#123;        public:            EPollPoller(EventLoop *loop);            virtual ~EPollPoller();            virtual Timestamp poll(int timeoutMs, ChannelList *activeChannels);            virtual void updateChannel(Channel *channel);            virtual void removeChannel(Channel *channel);        private:            static const int kInitEventListSize = 16; //默认事件数组大小，是用来装epoll_wait()返回的可读或可写事件的            void fillActiveChannels(int numEvents, ChannelList *activeChannels) const;            void update(int operation, Channel *channel);            typedef std::vector&lt;struct epoll_event&gt; EventList;            typedef std::map&lt;int, Channel *&gt; ChannelMap;            int epollfd_;//epoll监视的文件描述符            EventList events_;//用来存储活跃文件描述符的epoll_event结构体数组            ChannelMap channels_;//记录标志符是kAdded或者kDeleted的channel和fd        &#125;;    &#125;&#125;#endif  // MUDUO_NET_POLLER_EPOLLPOLLER_H</code></pre><p><strong>EPollPoller.cc</strong></p><p>主要是一些EPollPoller类的具体实现，注释很详细。</p><pre><code class="c++">#include &lt;muduo/net/poller/EPollPoller.h&gt;#include &lt;muduo/base/Logging.h&gt;#include &lt;muduo/net/Channel.h&gt;#include &lt;boost/static_assert.hpp&gt;#include &lt;assert.h&gt;#include &lt;errno.h&gt;#include &lt;poll.h&gt;#include &lt;sys/epoll.h&gt;using namespace muduo;using namespace muduo::net;// On Linux, the constants of poll(2) and epoll(4)// are expected to be the same.BOOST_STATIC_ASSERT(EPOLLIN== POLLIN);BOOST_STATIC_ASSERT(EPOLLPRI== POLLPRI);BOOST_STATIC_ASSERT(EPOLLOUT== POLLOUT);BOOST_STATIC_ASSERT(EPOLLRDHUP== POLLRDHUP);BOOST_STATIC_ASSERT(EPOLLERR== POLLERR);BOOST_STATIC_ASSERT(EPOLLHUP== POLLHUP);namespace &#123;    const int kNew = -1;//代表不在epoll队列中，也不在ChannelMap channels_中    const int kAdded = 1;//代表正在epoll队列当中    const int kDeleted = 2;//代表曾经在epoll队列当中过，但是被删除了，现在不在了，但是还是在ChannelMap channels_中的&#125;EPollPoller::EPollPoller(EventLoop *loop)        : Poller(loop),//所属的EventLoop          epollfd_(::epoll_create1(EPOLL_CLOEXEC)),//创建一个epoll文件描述符，用来监听所有注册的事件          events_(kInitEventListSize) &#123;//初始化vector    if (epollfd_ &lt; 0) &#123;        LOG_SYSFATAL &lt;&lt; &quot;EPollPoller::EPollPoller&quot;;    &#125;&#125;EPollPoller::~EPollPoller()//关闭epoll文件描述符&#123;    ::close(epollfd_);&#125;Timestamp EPollPoller::poll(int timeoutMs, ChannelList *activeChannels)//封装epoll_wait&#123;    int numEvents = ::epoll_wait(epollfd_,                                 &amp;*events_.begin(),//等价于&amp;events[0],就是传入一个vecotr&lt;struct epoll_event&gt;的首指针进去,用vector首指针代替了数组首指针                                 static_cast&lt;int&gt;(events_.size()),                                 timeoutMs);    Timestamp now(Timestamp::now());    if (numEvents &gt; 0) &#123;        LOG_TRACE &lt;&lt; numEvents &lt;&lt; &quot; events happended&quot;;        fillActiveChannels(numEvents, activeChannels);        //如果返回的事件数目等于当前事件数组大小，就就扩充events_，分配2倍空间,        if (implicit_cast&lt;size_t&gt;(numEvents) == events_.size())        &#123;            events_.resize(events_.size() * 2);        &#125;    &#125; else if (numEvents == 0)//如果timeoutMs设置的是大于0的数，也就是超时时间有效的话，那么过了超时时间并且没有事件发生，就会出现这种情况    &#123;        LOG_TRACE &lt;&lt; &quot; nothing happended&quot;;    &#125; else &#123;        LOG_SYSERR &lt;&lt; &quot;EPollPoller::poll()&quot;;    &#125;    return now;//返回的是事件发生时的时间&#125;void EPollPoller::fillActiveChannels(int numEvents,                                     ChannelList *activeChannels) const //epoll_event转为channel&#123;    assert(implicit_cast&lt;size_t&gt;(numEvents) &lt;= events_.size());    for (int i = 0; i &lt; numEvents; ++i)//将返回的活跃epoll_event转成channel放到activeChannels列表中    &#123;        Channel *channel = static_cast&lt;Channel *&gt;(events_[i].data.ptr);//把产生事件的channel变量拿出来/*这是epoll模式epoll_event事件的数据结构，其中data不仅可以保存fd，也可以保存一个void*类型的指针。typedef union epoll_data &#123;               void    *ptr;               int      fd;               uint32_t u32;               uint64_t u64;           &#125; epoll_data_t;           struct epoll_event &#123;               uint32_t     events;    // Epoll events               epoll_data_t data;      //User data variable           &#125;;*/#ifndef NDEBUG//在调试时会执行下面的代码，否则就直接忽视        int fd = channel-&gt;fd();        ChannelMap::const_iterator it = channels_.find(fd);        assert(it != channels_.end());        assert(it-&gt;second == channel);//判断ChannelMap中key和value的对应关系是否准确#endif        channel-&gt;set_revents(events_[i].events);//把已经触发的事件写入channel中        activeChannels-&gt;push_back(channel);//把channel放入要处理的channel列表中    &#125;&#125;void EPollPoller::updateChannel(Channel *channel)//根据channel的序号在epoll队列中来删除，增加channel或者改变channel&#123;    Poller::assertInLoopThread();//负责epoll_wait的线程和创建eventloop的线程为同一个    LOG_TRACE &lt;&lt; &quot;fd = &quot; &lt;&lt; channel-&gt;fd() &lt;&lt; &quot; events = &quot; &lt;&lt; channel-&gt;events();    const int index = channel-&gt;index();    if (index == kNew || index == kDeleted)//如果是完全没在或者曾经在epoll队列中的，就添加到epoll队列中    &#123;        // a new one, add with EPOLL_CTL_ADD        int fd = channel-&gt;fd();        if (index == kNew) &#123;//完全没在epoll队列中            assert(channels_.find(fd) == channels_.end());//确保这个channel的文件描述符不在channels_中            channels_[fd] = channel;//将新添加的fd和channel添加到channels_中        &#125; else // index == kDeleted  曾经在epoll队列中        &#123;            assert(channels_.find(fd) != channels_.end());//确保这个channel的文件描述符在channels_中            assert(channels_[fd] == channel);//确保在epoll队列中channel和fd一致        &#125;        channel-&gt;set_index(kAdded);//修改index为已在队列中        update(EPOLL_CTL_ADD, channel);    &#125; else//如果是现在就在epoll队列中的，如果没有关注事件了，就暂时删除，如果有关注事件，就修改    &#123;        // update existing one with EPOLL_CTL_MOD/DEL        int fd = channel-&gt;fd();        (void) fd;        assert(channels_.find(fd) != channels_.end());//channels_中是否有这个文件描述符        assert(channels_[fd] == channel);//channels_中channel和fd是否一致        assert(index == kAdded);//标志位是否正在队列中        if (channel-&gt;isNoneEvent()) &#123;            update(EPOLL_CTL_DEL, channel);            channel-&gt;set_index(kDeleted);        &#125; else &#123;            update(EPOLL_CTL_MOD, channel);        &#125;    &#125;&#125;void EPollPoller::removeChannel(Channel *channel)//完全删除channel&#123;    Poller::assertInLoopThread();    int fd = channel-&gt;fd();    LOG_TRACE &lt;&lt; &quot;fd = &quot; &lt;&lt; fd;    assert(channels_.find(fd) != channels_.end());//channels_中是否有这个文件描述符    assert(channels_[fd] == channel);//channels_中channel和fd是否一致    assert(channel-&gt;isNoneEvent());//channel中要关注的事件是否为空    int index = channel-&gt;index();    assert(index == kAdded || index == kDeleted);//标志位必须是kAdded或者kDeleted    size_t n = channels_.erase(fd);    (void) n;    assert(n == 1);    if (index == kAdded) &#123;        update(EPOLL_CTL_DEL, channel);//从epoll队列中删除这个channel    &#125;    channel-&gt;set_index(kNew);//设置标志位是kNew，相当于完全删除&#125;void EPollPoller::update(int operation, Channel *channel)//主要执行epoll_ctl函数&#123;    struct epoll_event event;    bzero(&amp;event, sizeof event);    event.events = channel-&gt;events();    event.data.ptr = channel;//设置epoll_event结构体    int fd = channel-&gt;fd();    if (::epoll_ctl(epollfd_, operation, fd, &amp;event) &lt; 0) &#123;        if (operation == EPOLL_CTL_DEL) &#123;            LOG_SYSERR &lt;&lt; &quot;epoll_ctl op=&quot; &lt;&lt; operation &lt;&lt; &quot; fd=&quot; &lt;&lt; fd;        &#125; else &#123;            LOG_SYSFATAL &lt;&lt; &quot;epoll_ctl op=&quot; &lt;&lt; operation &lt;&lt; &quot; fd=&quot; &lt;&lt; fd;        &#125;    &#125;&#125;</code></pre><h3 id="acceptor"><a href="#acceptor" class="headerlink" title="acceptor"></a>acceptor</h3><p><code>Acceptor</code> 用于初始化socket，监听端口，接受连接并调用传入的 <code>callback</code> 创建连接：</p><p>Acceptor的数据成员包括Socket、Channel。</p><p>Acceptor的socket是listening socket（即server socket）。</p><p>Channel用于观察此socket的readable事件，并Acceptor::handleRead()，后者调用accept(2)来接受连接，并回调用户callback。</p><p>Acceptor类在上层应用程序中我们不直接使用，而是把它封装作为TcpServer的成员。</p><p>Acceptor.h源码分析</p><pre><code class="c++">/*就是用一个Acceptor类专门用一个channel来创建套接字，绑定，监听等操作*/#ifndef MUDUO_NET_ACCEPTOR_H#define MUDUO_NET_ACCEPTOR_H#include &lt;boost/function.hpp&gt;#include &lt;boost/noncopyable.hpp&gt;#include &lt;muduo/net/Channel.h&gt;#include &lt;muduo/net/Socket.h&gt;namespace muduo &#123;    namespace net &#123;        class EventLoop;        class InetAddress;////// Acceptor of incoming TCP connections.///        class Acceptor : boost::noncopyable &#123;        public:            typedef boost::function&lt;void(int sockfd,const InetAddress &amp;)&gt; NewConnectionCallback;            Acceptor(EventLoop *loop, const InetAddress &amp;listenAddr);            ~Acceptor();            //newConnectionCallback_是在Acceptor::handleRead里面执行的，也就是在acceptChannel_的读事件发生的时候会被调用            void setNewConnectionCallback(const NewConnectionCallback &amp;cb) &#123; newConnectionCallback_ = cb; &#125;            bool listenning() const &#123; return listenning_; &#125;            void listen();        private:            void handleRead();//可读回调函数，绑定在acceptChannel_的读函数上            EventLoop *loop_;//所属的EventLoop对象            Socket acceptSocket_;//监听套接字            Channel acceptChannel_;//和监听套接字绑定的通道 acceptChannel_和监听套接字acceptSocket_绑定            NewConnectionCallback newConnectionCallback_;//一旦有新连接发生，执行的回调函数            bool listenning_;//acceptChannel所处的eventloop是否处于监听状态            int idleFd_;//预留一个fd，用来解决文件描述符过多，引起电平触发不断触发的问题，详见handleRead函数的最后        &#125;;    &#125;&#125;#endif  // MUDUO_NET_ACCEPTOR_H</code></pre><p>Acceptor.cc源码分析</p><pre><code class="c++">#include &lt;muduo/net/Acceptor.h&gt;#include &lt;muduo/net/EventLoop.h&gt;#include &lt;muduo/net/InetAddress.h&gt;#include &lt;muduo/net/SocketsOps.h&gt;#include &lt;boost/bind.hpp&gt;#include &lt;errno.h&gt;#include &lt;fcntl.h&gt;//#include &lt;sys/types.h&gt;//#include &lt;sys/stat.h&gt;using namespace muduo;using namespace muduo::net;Acceptor::Acceptor(EventLoop *loop, const InetAddress &amp;listenAddr)        : loop_(loop),          acceptSocket_(sockets::createNonblockingOrDie()),//设置监听套接字          acceptChannel_(loop, acceptSocket_.fd()),          listenning_(false),          idleFd_(::open(&quot;/dev/null&quot;, O_RDONLY | O_CLOEXEC))//这个描述符打开一个linux系统的空文件，所有写入的内容都会被丢弃&#123;    assert(idleFd_ &gt;= 0);    acceptSocket_.setReuseAddr(true);    acceptSocket_.bindAddress(listenAddr);    acceptChannel_.setReadCallback(boost::bind(&amp;Acceptor::handleRead, this));&#125;Acceptor::~Acceptor() &#123;    acceptChannel_.disableAll();    acceptChannel_.remove();    ::close(idleFd_);&#125;void Acceptor::listen()//开启监听&#123;    loop_-&gt;assertInLoopThread();    listenning_ = true;    acceptSocket_.listen();    acceptChannel_.enableReading();//将socket套接字挂到eventloop的epoll上，并开启读监听&#125;void Acceptor::handleRead()//读的回调函数，一旦socket套接字监听到连接，epoll就会立刻调用回调函数&#123;    loop_-&gt;assertInLoopThread();    InetAddress peerAddr(0);//对端的    //FIXME loop until no more    int connfd = acceptSocket_.accept(&amp;peerAddr);    if (connfd &gt;= 0) &#123;        // string hostport = peerAddr.toIpPort();        // LOG_TRACE &lt;&lt; &quot;Accepts of &quot; &lt;&lt; hostport;        if (newConnectionCallback_) &#123;            newConnectionCallback_(connfd, peerAddr);        &#125; else &#123;            sockets::close(connfd);        &#125;    &#125; else &#123;        // Read the section named &quot;The special problem of        // accept()ing when you can&#39;t&quot; in libev&#39;s doc.        // By Marc Lehmann, author of livev.        //在监听套接字可读事件触发时，我们会调用accept接受连接。如果此时注册过回调函数，就执行它。如果没有就直接关闭！        //另一方面，如果已用文件描述符过多，accept会返回-1，我们构造函数中注册的idleFd_就派上用场了。        // 当前文件描述符过多，无法接收新的连接。但是由于我们采用LT模式，如果无法接收，可读事件会一直触发。        // 那么在这个地方的处理机制就是，关掉之前创建的idleFd_，然后去accept让这个事件不会一直触发，        // 然后再关掉该文件描述符，重新将它设置为空文件描述符。        //这种机制可以让网络库在处理连接过多，文件描述符不够用时，不至于因为LT模式一直触发而产生坏的影响。        if (errno == EMFILE)//当accept函数出错时，是因为文件描述符太多了        &#123;            ::close(idleFd_);//就关闭一个空闲描述符，相当于现在就有一个空的文件描述符位置了            idleFd_ = ::accept(acceptSocket_.fd(), NULL, NULL);//然后把刚才没有接受的描述符接受进来            ::close(idleFd_);//把这个描述符给关闭，相当于忽略这个请求连接了            idleFd_ = ::open(&quot;/dev/null&quot;, O_RDONLY | O_CLOEXEC);//重新开启这个空闲描述符        &#125;//之所以这样，是因为poll使用的是水平触发，如果没有这个if判断，就会一直触发    &#125;&#125;</code></pre><h3 id="tcp-server和tcp-connection"><a href="#tcp-server和tcp-connection" class="headerlink" title="tcp server和tcp connection"></a>tcp server和tcp connection</h3><p><strong>TcpServer</strong></p><p>TcpServer相当于主线程reactor， 此时主线程循环只负责TCP连接的建立，及任务的分配，需要让哪个线程干活， 就把timer或连接分配给那个线程即可；对实时性有要求的connection可以单独用一个线程； 数据量大的connection可以独占一个线程；并把数据处理任务分摊到另几个计算线程中（用线程池）；其他次要的辅助性connections共享一个线程。</p><p>分配连接主要通过EventLoopThreadPool 线程池实现，新建TcpConnection时从event loop pool里分配一个loop给TcpConnection。 TcpServer自己的EventLoop只用来接受新连接， 而新连接会用其他EventLoop来执行IO。</p><p><strong>EventLoopThreadPool</strong></p><p>TcpServer每次新建一条TcpConnection就会通过EventLoopThreadPool::getNextLoop()方法来取一个EventLoop， 目前的getNextLoop()只是循环的从池中取一条loop，如果提供给每条TcpConncetion的是均等的服务，那么这样就能很均匀的分配系统的资源了。</p><p> TcpServer的工作方式取决于EventLoopThreadPool中线程的创建数量。</p><p>0 意味着所有的I&#x2F;O 都在TcpServer的主事件循环中，不会创建新的线程。</p><p>1 意味着所有的 I&#x2F;O 在另一个线程中 ，TcpServer的主线程只负责建立连接。</p><p>N 意味着新的连接会被循环的分配到N条线程中工作。</p><p>TcpServer.h</p><pre><code class="c++">/* 这个类相当于把TcpConnection以及Accept类整合起来，完全能够实现Tcp通信，也就是socket函数都实现了 * 一个TcpServer类中，有Acceptor，EventLoopThreadPool各一个，以及多个TcpConnection类的指针， * 在TcpServer类的启动函数中，先开启EventLoopThreadPool线程池，然后将Acceptor监听函数放入eventloop中去执行 * 在TcpServer类的构造函数中，就已经把一个成功连接的回调函数绑定在Acceptor类的连接回调函数中，如果Acceptor监听 * 到有连接进来，先调监听socket描述符的回调函数，把这个连接accept进来，然后再调用newConnectionCallback_函数 * 来处理连接，每个连接都有一个对应的TcpConnection类来作为缓冲区 * */#ifndef MUDUO_NET_TCPSERVER_H#define MUDUO_NET_TCPSERVER_H#include &lt;muduo/base/Types.h&gt;#include &lt;muduo/net/TcpConnection.h&gt;#include &lt;map&gt;#include &lt;boost/noncopyable.hpp&gt;#include &lt;boost/scoped_ptr.hpp&gt;namespace muduo &#123;    namespace net &#123;        class Acceptor;        class EventLoop;        class EventLoopThreadPool;////// TCP server, supports single-threaded and thread-pool models.////// This is an interface class, so don&#39;t expose too much details.        class TcpServer : boost::noncopyable &#123;        public:            typedef boost::function&lt;void(EventLoop *)&gt; ThreadInitCallback;            //TcpServer(EventLoop* loop, const InetAddress&amp; listenAddr);            TcpServer(EventLoop *loop,                      const InetAddress &amp;listenAddr,                      const string &amp;nameArg);            ~TcpServer();  // force out-line dtor, for scoped_ptr members.            const string &amp;hostport() const &#123; return hostport_; &#125;            const string &amp;name() const &#123; return name_; &#125;            /// Set the number of threads for handling input.            ///            /// Always accepts new connection in loop&#39;s thread.            /// Must be called before @c start            /// @param numThreads            /// - 0 means all I/O in loop&#39;s thread, no thread will created.            ///   this is the default value.            /// - 1 means all I/O in another thread.            /// - N means a thread pool with N threads, new connections            ///   are assigned on a round-robin basis.            void setThreadNum(int numThreads);            void setThreadInitCallback(                    const ThreadInitCallback &amp;cb) &#123; threadInitCallback_ = cb; &#125;//这个函数会作为EventLoopThreadPool::start的入口参数            /// Starts the server if it&#39;s not listenning.            ///            /// It&#39;s harmless to call it multiple times.            /// Thread safe.            void start();            /// Set connection callback.            /// Not thread safe.            // 设置连接到来或者连接关闭回调函数,这个函数指针会赋值给TcpConnection::connectionCallback_函数，就是在连接建立之后，和连接断开之前会调用            void setConnectionCallback(const ConnectionCallback &amp;cb) &#123; connectionCallback_ = cb; &#125;            /// Set message callback.            /// Not thread safe.            //  设置消息到来回调函数，这个函数指针在TcpConnection::handleread函数中调用，也就是TcpConnection的Channel的读函数的一部分            void setMessageCallback(const MessageCallback &amp;cb) &#123; messageCallback_ = cb; &#125;            /// Set write complete callback.            /// Not thread safe.            /// 在发送完消息以后调用，这个函数指针会赋值给TcpConnection::writeCompleteCallback_函数            void setWriteCompleteCallback(const WriteCompleteCallback &amp;cb) &#123; writeCompleteCallback_ = cb; &#125;        private:            /// Not thread safe, but in loop            void newConnection(int sockfd, const InetAddress &amp;peerAddr);            //这个函数会赋值给Acceptor::newConnectionCallback_，在新连接建立以后调用            /// Thread safe.            /// 会赋值给TcpConnection::closeCallback_函数，也就是当连接描述符关闭以后调用这个            void removeConnection(const TcpConnectionPtr &amp;conn);            /// Not thread safe, but in loop，在上面这个函数removeConnection中调用            void removeConnectionInLoop(const TcpConnectionPtr &amp;conn);            typedef std::map &lt;string, TcpConnectionPtr&gt; ConnectionMap;            EventLoop *loop_;  // the acceptor loop            const string hostport_;        // 服务的ip:端口            const string name_;            // 服务名            boost::scoped_ptr &lt;Acceptor&gt; acceptor_; // avoid revealing Acceptor            boost::scoped_ptr &lt;EventLoopThreadPool&gt; threadPool_;            ConnectionCallback connectionCallback_;            MessageCallback messageCallback_;            WriteCompleteCallback writeCompleteCallback_;        // 数据发送完毕，会回调此函数            ThreadInitCallback threadInitCallback_;    // IO线程池中的线程在进入事件循环前，会回调用此函数            bool started_;            // always in loop thread            int nextConnId_;                // 下一个连接ID,每次增加一个就加1            ConnectionMap connections_;    // 连接列表        &#125;;    &#125;&#125;#endif  // MUDUO_NET_TCPSERVER_H</code></pre><p>TcpServer.cc</p><pre><code class="c++">#include &lt;muduo/net/TcpServer.h&gt;#include &lt;muduo/base/Logging.h&gt;#include &lt;muduo/net/Acceptor.h&gt;#include &lt;muduo/net/EventLoop.h&gt;#include &lt;muduo/net/EventLoopThreadPool.h&gt;#include &lt;muduo/net/SocketsOps.h&gt;#include &lt;boost/bind.hpp&gt;#include &lt;stdio.h&gt;  // snprintfusing namespace muduo;using namespace muduo::net;TcpServer::TcpServer(EventLoop *loop, const InetAddress &amp;listenAddr,                     const string &amp;nameArg)        : loop_(CHECK_NOTNULL(loop)),          hostport_(listenAddr.toIpPort()),          name_(nameArg),          acceptor_(new Acceptor(loop, listenAddr)),          threadPool_(new EventLoopThreadPool(loop)),          connectionCallback_(defaultConnectionCallback),          messageCallback_(defaultMessageCallback),          started_(false),          nextConnId_(1) &#123;    // Acceptor::handleRead函数中会回调用TcpServer::newConnection    // _1对应的是socket文件描述符，_2对应的是对等方的地址(InetAddress)    acceptor_-&gt;setNewConnectionCallback(            boost::bind(&amp;TcpServer::newConnection, this, _1, _2));&#125;TcpServer::~TcpServer() &#123;    loop_-&gt;assertInLoopThread();    LOG_TRACE &lt;&lt; &quot;TcpServer::~TcpServer [&quot; &lt;&lt; name_ &lt;&lt; &quot;] destructing&quot;;    for (ConnectionMap::iterator it(connections_.begin());         it != connections_.end(); ++it) &#123;        TcpConnectionPtr conn = it-&gt;second;        it-&gt;second.reset();        // 释放当前所控制的对象，引用计数减一        conn-&gt;getLoop()-&gt;runInLoop(                boost::bind(&amp;TcpConnection::connectDestroyed, conn));        conn.reset();            // 释放当前所控制的对象，引用计数减一    &#125;&#125;void TcpServer::setThreadNum(int numThreads) &#123;    assert(0 &lt;= numThreads);    threadPool_-&gt;setThreadNum(numThreads);&#125;// 该函数多次调用是无害的// 该函数可以跨线程调用void TcpServer::start() &#123;    if (!started_) &#123;        started_ = true;        threadPool_-&gt;start(threadInitCallback_);    &#125;    if (!acceptor_-&gt;listenning()) &#123;        // get_pointer返回原生指针        loop_-&gt;runInLoop(                boost::bind(&amp;Acceptor::listen, get_pointer(acceptor_)));    &#125;&#125;void TcpServer::newConnection(int sockfd, const InetAddress &amp;peerAddr)//建立新连接以后的回调函数&#123;    loop_-&gt;assertInLoopThread();    // 按照轮叫的方式选择一个EventLoop    EventLoop *ioLoop = threadPool_-&gt;getNextLoop();    char buf[32];    snprintf(buf, sizeof buf, &quot;:%s#%d&quot;, hostport_.c_str(), nextConnId_);//buf的内容是 ip:端口#nextConnId_    ++nextConnId_;    string connName = name_ + buf;    LOG_INFO &lt;&lt; &quot;TcpServer::newConnection [&quot; &lt;&lt; name_             &lt;&lt; &quot;] - new connection [&quot; &lt;&lt; connName             &lt;&lt; &quot;] from &quot; &lt;&lt; peerAddr.toIpPort();    InetAddress localAddr(sockets::getLocalAddr(sockfd));    // FIXME poll with zero timeout to double confirm the new connection    // FIXME use make_shared if necessary    /*TcpConnectionPtr conn(new TcpConnection(loop_,                                            connName,                                            sockfd,                                            localAddr,                                            peerAddr));*/    TcpConnectionPtr conn(new TcpConnection(ioLoop,                                            connName,                                            sockfd,                                            localAddr,                                            peerAddr));    LOG_TRACE &lt;&lt; &quot;[1] usecount=&quot; &lt;&lt; conn.use_count();    connections_[connName] = conn;//将连接名和TCPConnection的指针拷贝进连接列表中，这样就有两个shared_ptr指针指向conn了，    //如果没有这一句程序，这个conn在newConnection函数执行结束以后就会析构掉，所以真正要删除时，也要把这个列表中的对应元素也删除了。    LOG_TRACE &lt;&lt; &quot;[2] usecount=&quot; &lt;&lt; conn.use_count();    //设置回调函数    conn-&gt;setConnectionCallback(connectionCallback_);    conn-&gt;setMessageCallback(messageCallback_);    conn-&gt;setWriteCompleteCallback(writeCompleteCallback_);//无论是否非空，都可以先设置，在使用之前会有判断    conn-&gt;setCloseCallback(            boost::bind(&amp;TcpServer::removeConnection, this, _1));    // conn-&gt;connectEstablished();    ioLoop-&gt;runInLoop(boost::bind(&amp;TcpConnection::connectEstablished, conn));    //bind在绑定类成员函数时，后面跟的参数一定比输入参数多一个，就是一个类指针，表明这个函数属于那个类变量的，    //一般都使用this，而这里是用的TcpConnectionPtr    LOG_TRACE &lt;&lt; &quot;[5] usecount=&quot; &lt;&lt; conn.use_count();&#125;void TcpServer::removeConnection(const TcpConnectionPtr &amp;conn) &#123;    /*  loop_-&gt;assertInLoopThread();  LOG_INFO &lt;&lt; &quot;TcpServer::removeConnectionInLoop [&quot; &lt;&lt; name_           &lt;&lt; &quot;] - connection &quot; &lt;&lt; conn-&gt;name();  LOG_TRACE &lt;&lt; &quot;[8] usecount=&quot; &lt;&lt; conn.use_count();  size_t n = connections_.erase(conn-&gt;name());  LOG_TRACE &lt;&lt; &quot;[9] usecount=&quot; &lt;&lt; conn.use_count();  (void)n;  assert(n == 1);    loop_-&gt;queueInLoop(      boost::bind(&amp;TcpConnection::connectDestroyed, conn));  LOG_TRACE &lt;&lt; &quot;[10] usecount=&quot; &lt;&lt; conn.use_count();  */    loop_-&gt;runInLoop(boost::bind(&amp;TcpServer::removeConnectionInLoop, this, conn));&#125;void TcpServer::removeConnectionInLoop(const TcpConnectionPtr &amp;conn)//就是把TcpConnection从Eventloop中移除&#123;    loop_-&gt;assertInLoopThread();    LOG_INFO &lt;&lt; &quot;TcpServer::removeConnectionInLoop [&quot; &lt;&lt; name_             &lt;&lt; &quot;] - connection &quot; &lt;&lt; conn-&gt;name();    LOG_TRACE &lt;&lt; &quot;[8] usecount=&quot; &lt;&lt; conn.use_count();    size_t n = connections_.erase(conn-&gt;name());    LOG_TRACE &lt;&lt; &quot;[9] usecount=&quot; &lt;&lt; conn.use_count();    (void) n;    assert(n == 1);    EventLoop *ioLoop = conn-&gt;getLoop();    ioLoop-&gt;queueInLoop(            boost::bind(&amp;TcpConnection::connectDestroyed, conn));    //loop_-&gt;queueInLoop(    //    boost::bind(&amp;TcpConnection::connectDestroyed, conn));    LOG_TRACE &lt;&lt; &quot;[10] usecount=&quot; &lt;&lt; conn.use_count();&#125;</code></pre><p><strong>TcpConnection</strong></p><p>TcpConnection类主要负责封装一次TCP连接，向Channel类注册回调函数（可读、可写、可关闭、错误处理），将来当Channel类上的事件发生时，调用相应的回调函数进行数据收发或者错误处理。</p><p>TcpConnection是使用shared_ptr来管理的类，因为它的生命周期模糊。TcpConnection表示已经建立或正在建立的连接，建立连接后，用户只需要在上层类如TcpServer中设置连接到来和消息到来的处理函数，继而回调TcpConnection中的 setConnectionCallback和setMessageCallback函数，实现对事件的处理。用户需要关心的事件是有限的，其他都由网络库负责。</p><p>TcpConnection中封装了InputBuffer和OutputBuffer，用来表示应用层的缓冲区。在发送数据时，如果不能一次将Buffer中的数据发送完毕，它还会继续关注Channel中的可写事件，当sockfd可写时，会再次发送。</p><p>前面提到TcpConnection的生存期模糊，主要是因为我们不能在TcpServer中直接erase掉TcpConnection对象，因为此时有可能Channel中的handleEvent还在执行，如果析构TcpConnection对象，那么他的成员channel_也会被析构，会导致core dump。也就是说我们需要TcpConnection 对象生存期要长于handleEvent() 函数，直到执行完connectDestroyed() 后才会析构。</p><p><strong>断开连接：</strong></p><p>TcpConnection的断开是采用被动方式，即对方先关闭连接，本地read(2)返回0后，调用顺序如下：</p><p>handleClose()-&gt;TcpServer::removeConnection-&gt;TcpConnection::connectDestroyed()。</p><p>连接关闭时序图：</p><p>​    <img src="https://raw.githubusercontent.com/hufei96/Image/main/muduo_tcp_close.png" alt="img"></p><p>当连接到来，创建一个TcpConnection对象，立刻用shared_ptr来管理，引用计数为1，在Channel中维护一个weak_ptr（tie_），将这个shared_ptr对象赋值给_tie，引用计数仍然为1。当连接关闭时，在handleEvent中，将tie_提升，得到一个shard_ptr对象，引用计数就变成了2。当shared_ptr的计数不为0时，TcpConnection不会被销毁。</p><p>TcpConnection.h</p><pre><code class="c++">/*这个类主要用来和buffer类一起作为非阻塞IO的一个读取桥梁，其中主要封装的函数是从文件描述符中读取传输的数据到 *接受缓冲区中，或者把规定数据，或者触发写事件的输出缓冲区的数据写入对应的文件描述符中。 */#ifndef MUDUO_NET_TCPCONNECTION_H#define MUDUO_NET_TCPCONNECTION_H#include &lt;muduo/base/Mutex.h&gt;#include &lt;muduo/base/StringPiece.h&gt;#include &lt;muduo/base/Types.h&gt;#include &lt;muduo/net/Callbacks.h&gt;#include &lt;muduo/net/Buffer.h&gt;#include &lt;muduo/net/InetAddress.h&gt;#include &lt;boost/any.hpp&gt;#include &lt;boost/enable_shared_from_this.hpp&gt;#include &lt;boost/noncopyable.hpp&gt;#include &lt;boost/scoped_ptr.hpp&gt;#include &lt;boost/shared_ptr.hpp&gt;namespace muduo &#123;    namespace net &#123;        class Channel;        class EventLoop;        class Socket;////// TCP connection, for both client and server usage.////// This is an interface class, so don&#39;t expose too much details.        class TcpConnection : boost::noncopyable,public boost::enable_shared_from_this&lt;TcpConnection&gt; &#123;        public:            /// Constructs a TcpConnection with a connected sockfd            ///            /// User should not create this object.            TcpConnection(EventLoop *loop,const string &amp;name,int sockfd,                          const InetAddress &amp;localAddr,                          const InetAddress &amp;peerAddr);            ~TcpConnection();            EventLoop *getLoop() const &#123; return loop_; &#125;//获取当前TcpConnection所在的Eventloop            const string &amp;name() const &#123; return name_; &#125;//            const InetAddress &amp;localAddress() &#123; return localAddr_; &#125;            const InetAddress &amp;peerAddress() &#123; return peerAddr_; &#125;            bool connected() const &#123; return state_ == kConnected; &#125;            // void send(string&amp;&amp; message); // C++11            void send(const void *message, size_t len);            void send(const StringPiece &amp;message);            // void send(Buffer&amp;&amp; message); // C++11            void send(Buffer *message);  // this one will swap data            void shutdown(); // NOT thread safe, no simultaneous calling            void setTcpNoDelay(bool on);            void setContext(const boost::any &amp;context) &#123; context_ = context; &#125;            const boost::any &amp;getContext() const//得到常数值的context_            &#123; return context_; &#125;            boost::any *getMutableContext()//得到可以改变的context_            &#123; return &amp;context_; &#125;            void setConnectionCallback(const ConnectionCallback &amp;cb) &#123; connectionCallback_ = cb; &#125;            //在handleClose，connectEstablished，connectDestroyed中调用，个人理解这个连接回调函数主要起到            //显示作用，就是在和连接描述符建立连接或者关闭连接前，显示连接状态的，表明还在连接中            void setMessageCallback(const MessageCallback &amp;cb) &#123; messageCallback_ = cb; &#125;            //在handleRead函数当中调用了，也可以理解为channel_写函数的一部分            void setWriteCompleteCallback(const WriteCompleteCallback &amp;cb) &#123; writeCompleteCallback_ = cb; &#125;            //在handleWrite和sendInLoop写函数中，写完调用的            void setHighWaterMarkCallback(const HighWaterMarkCallback &amp;cb, size_t highWaterMark) &#123;                highWaterMarkCallback_ = cb;                highWaterMark_ = highWaterMark;            &#125;//都在sendInLoop中调用了            Buffer *inputBuffer() &#123; return &amp;inputBuffer_; &#125;            /// Internal use only.            void setCloseCallback(const CloseCallback &amp;cb) &#123; closeCallback_ = cb; &#125;//在handleClose函数中调用            // called when TcpServer accepts a new connection            void connectEstablished();   // should be called only once            // called when TcpServer has removed me from its map            void connectDestroyed();  // should be called only once        private:            enum StateE &#123;                kDisconnected, kConnecting, kConnected, kDisconnecting            &#125;;            void handleRead(Timestamp receiveTime);//绑定channel_的读函数            void handleWrite();//绑定channel_的写函数            void handleClose();//绑定channel_的关闭函数，同时也在handleRead中调用            void handleError();////绑定channel_的错误函数            void sendInLoop(const StringPiece &amp;message);            void sendInLoop(const void *message, size_t len);            void shutdownInLoop();            void setState(StateE s) &#123; state_ = s; &#125;//设置状态位            EventLoop *loop_;            // 所属EventLoop            string name_;                // 连接名            StateE state_;  // FIXME: use atomic variable            // we don&#39;t expose those classes to client.            //连接状态            boost::scoped_ptr &lt;Socket&gt; socket_;            boost::scoped_ptr &lt;Channel&gt; channel_;            //channel_在TCPServer中绑定了连接套接字，就是能够实现通信的那个connfd套接字，这个套接字是从Socket::accept函数得到的            //在Tcpclient绑定的是创建的套接字，因为客户端只需要一个套接字就可以了，这个套接字是从socket()函数中得到的            InetAddress localAddr_;//当前服务端的地址            InetAddress peerAddr_;//当前建立连接的客户端地址            ConnectionCallback connectionCallback_;            MessageCallback messageCallback_;            WriteCompleteCallback writeCompleteCallback_;        // 数据发送完毕回调函数，即所有的用户数据都已拷贝到内核缓冲区时回调该函数            // outputBuffer_被清空也会回调该函数，可以理解为低水位标回调函数            HighWaterMarkCallback highWaterMarkCallback_;        // 高水位标回调函数            CloseCallback closeCallback_;            size_t highWaterMark_;        // 高水位标            Buffer inputBuffer_;            // 应用层接收缓冲区            Buffer outputBuffer_;            // 应用层发送缓冲区            boost::any context_;            // 绑定一个未知类型的上下文对象，一般用来放HttpContext类的        &#125;;        typedef boost::shared_ptr &lt;TcpConnection&gt; TcpConnectionPtr;    &#125;&#125;#endif  // MUDUO_NET_TCPCONNECTION_H</code></pre><p>TcpConnection.cc</p><pre><code class="c++">#include &lt;muduo/net/TcpConnection.h&gt;#include &lt;muduo/base/Logging.h&gt;#include &lt;muduo/net/Channel.h&gt;#include &lt;muduo/net/EventLoop.h&gt;#include &lt;muduo/net/Socket.h&gt;#include &lt;muduo/net/SocketsOps.h&gt;#include &lt;boost/bind.hpp&gt;#include &lt;errno.h&gt;#include &lt;stdio.h&gt;using namespace muduo;using namespace muduo::net;void muduo::net::defaultConnectionCallback(const TcpConnectionPtr &amp;conn)//默认的连接回调函数，输出连接状态&#123;    LOG_TRACE &lt;&lt; conn-&gt;localAddress().toIpPort() &lt;&lt; &quot; -&gt; &quot;              &lt;&lt; conn-&gt;peerAddress().toIpPort() &lt;&lt; &quot; is &quot;              &lt;&lt; (conn-&gt;connected() ? &quot;UP&quot; : &quot;DOWN&quot;);&#125;void muduo::net::defaultMessageCallback(const TcpConnectionPtr &amp;, Buffer *buf, Timestamp)//默认的有消息时执行的回调函数，把缓冲区读指针和写指针回到初始化的位置//可以理解为将缓冲区清零&#123;    buf-&gt;retrieveAll();&#125;TcpConnection::TcpConnection(EventLoop *loop, const string &amp;nameArg, int sockfd,                             const InetAddress &amp;localAddr,                             const InetAddress &amp;peerAddr)        : loop_(CHECK_NOTNULL(loop)), // 所属EventLoop          name_(nameArg),// 连接名          state_(kConnecting),//连接状态          socket_(new Socket(sockfd)),//连接套接字          channel_(new Channel(loop, sockfd)),          //channel_在TCPServer中绑定了连接套接字，就是能够实现通信的那个connfd套接字，这个套接字是从Socket::accept函数得到的          //在Tcpclient绑定的是创建的套接字，因为客户端只需要一个套接字就可以了，这个套接字是从socket()函数中得到的          localAddr_(localAddr),//当前服务端的地址          peerAddr_(peerAddr),//当前建立连接的客户端地址          highWaterMark_(64 * 1024 * 1024) &#123;    // 通道可读事件到来的时候，回调TcpConnection::handleRead，_1是事件发生时间    channel_-&gt;setReadCallback(boost::bind(&amp;TcpConnection::handleRead, this, _1));    // 通道可写事件到来的时候，回调TcpConnection::handleWrite    channel_-&gt;setWriteCallback(boost::bind(&amp;TcpConnection::handleWrite, this));    // 连接关闭，回调TcpConnection::handleClose    channel_-&gt;setCloseCallback(boost::bind(&amp;TcpConnection::handleClose, this));    // 发生错误，回调TcpConnection::handleError    channel_-&gt;setErrorCallback(boost::bind(&amp;TcpConnection::handleError, this));    LOG_DEBUG &lt;&lt; &quot;TcpConnection::ctor[&quot; &lt;&lt; name_ &lt;&lt; &quot;] at &quot; &lt;&lt; this&lt;&lt; &quot; fd=&quot; &lt;&lt; sockfd;    socket_-&gt;setKeepAlive(true);//定期探测连接是否存在，类似于心跳包&#125;TcpConnection::~TcpConnection() &#123;    LOG_DEBUG &lt;&lt; &quot;TcpConnection::dtor[&quot; &lt;&lt; name_ &lt;&lt; &quot;] at &quot; &lt;&lt; this              &lt;&lt; &quot; fd=&quot; &lt;&lt; channel_-&gt;fd();&#125;// 线程安全，可以跨线程调用void TcpConnection::send(const void *data, size_t len) &#123;    if (state_ == kConnected) &#123;        if (loop_-&gt;isInLoopThread()) &#123;            sendInLoop(data, len);        &#125; else &#123;            string message(static_cast&lt;const char *&gt;(data), len);            loop_-&gt;runInLoop(boost::bind(&amp;TcpConnection::sendInLoop,this,message));        &#125;    &#125;&#125;// 线程安全，可以跨线程调用void TcpConnection::send(const StringPiece &amp;message) &#123;    if (state_ == kConnected) &#123;        if (loop_-&gt;isInLoopThread()) &#123;            sendInLoop(message);        &#125; else &#123;            loop_-&gt;runInLoop(boost::bind(&amp;TcpConnection::sendInLoop,this,message.as_string()));            //std::forward&lt;string&gt;(message)));        &#125;    &#125;&#125;// 线程安全，可以跨线程调用void TcpConnection::send(Buffer *buf) &#123;    if (state_ == kConnected) &#123;        if (loop_-&gt;isInLoopThread()) &#123;            sendInLoop(buf-&gt;peek(), buf-&gt;readableBytes());            buf-&gt;retrieveAll();        &#125; else &#123;            loop_-&gt;runInLoop(boost::bind(&amp;TcpConnection::sendInLoop,this,buf-&gt;retrieveAllAsString()));            //std::forward&lt;string&gt;(message)));        &#125;    &#125;&#125;void TcpConnection::sendInLoop(const StringPiece &amp;message) &#123;    sendInLoop(message.data(), message.size());&#125;void TcpConnection::sendInLoop(const void *data, size_t len) &#123;    /*    loop_-&gt;assertInLoopThread();    sockets::write(channel_-&gt;fd(), data, len);    */    loop_-&gt;assertInLoopThread();    ssize_t nwrote = 0;    size_t remaining = len;    bool error = false;    if (state_ == kDisconnected) &#123;        LOG_WARN &lt;&lt; &quot;disconnected, give up writing&quot;;        return;    &#125;    // if no thing in output queue, try writing directly    // 通道没有关注可写事件并且发送缓冲区没有数据，直接write    if (!channel_-&gt;isWriting() &amp;&amp; outputBuffer_.readableBytes() == 0) &#123;        nwrote = sockets::write(channel_-&gt;fd(), data, len);        if (nwrote &gt;= 0) &#123;            remaining = len - nwrote;            // 写完了，回调writeCompleteCallback_            if (remaining == 0 &amp;&amp; writeCompleteCallback_) &#123;                loop_-&gt;queueInLoop(boost::bind(writeCompleteCallback_, shared_from_this()));            &#125;        &#125; else // nwrote &lt; 0        &#123;            nwrote = 0;            if (errno != EWOULDBLOCK) &#123;                LOG_SYSERR &lt;&lt; &quot;TcpConnection::sendInLoop&quot;;                if (errno == EPIPE) // FIXME: any others?                &#123;                    error = true;                &#125;            &#125;        &#125;    &#125;    assert(remaining &lt;= len);    // 没有错误，并且还有未写完的数据（说明内核发送缓冲区满，要将未写完的数据添加到output buffer中）    if (!error &amp;&amp; remaining &gt; 0) &#123;        LOG_TRACE &lt;&lt; &quot;I am going to write more data&quot;;        size_t oldLen = outputBuffer_.readableBytes();        // 如果超过highWaterMark_（高水位标），回调highWaterMarkCallback_        if (oldLen + remaining &gt;= highWaterMark_            &amp;&amp; oldLen &lt; highWaterMark_            &amp;&amp; highWaterMarkCallback_) &#123;            loop_-&gt;queueInLoop(boost::bind(highWaterMarkCallback_, shared_from_this(), oldLen + remaining));        &#125;        outputBuffer_.append(static_cast&lt;const char *&gt;(data) + nwrote, remaining);//将剩余数据存入应用层发送缓冲区        if (!channel_-&gt;isWriting()) &#123;            channel_-&gt;enableWriting();        // 关注POLLOUT事件        &#125;    &#125;&#125;void TcpConnection::shutdown()//关闭连接&#123;    // FIXME: use compare and swap    if (state_ == kConnected) &#123;        setState(kDisconnecting);        // FIXME: shared_from_this()?        loop_-&gt;runInLoop(boost::bind(&amp;TcpConnection::shutdownInLoop, this));    &#125;&#125;void TcpConnection::shutdownInLoop()//在loop中关闭写半边，还是可以读数据&#123;    loop_-&gt;assertInLoopThread();    if (!channel_-&gt;isWriting()) &#123;        // we are not writing        socket_-&gt;shutdownWrite();    &#125;&#125;void TcpConnection::setTcpNoDelay(bool on)//设置TCP延迟连接&#123;    socket_-&gt;setTcpNoDelay(on);&#125;void TcpConnection::connectEstablished()//这个建立连接是TcpConnection类中的channel加入到对应的比如Tcpclient或者Tcpserver类所属的eventloop中&#123;    loop_-&gt;assertInLoopThread();    assert(state_ == kConnecting);//设置正在连接状态    setState(kConnected);    LOG_TRACE &lt;&lt; &quot;[3] usecount=&quot; &lt;&lt; shared_from_this().use_count();    channel_-&gt;tie(shared_from_this());    channel_-&gt;enableReading();    // TcpConnection所对应的通道加入到Poller关注    connectionCallback_(shared_from_this());    LOG_TRACE &lt;&lt; &quot;[4] usecount=&quot; &lt;&lt; shared_from_this().use_count();&#125;void TcpConnection::connectDestroyed()//取消连接，从对应的Eventloop上的epoll队列中去除&#123;    loop_-&gt;assertInLoopThread();    if (state_ == kConnected) &#123;        setState(kDisconnected);        channel_-&gt;disableAll();        connectionCallback_(shared_from_this());    &#125;    channel_-&gt;remove();//将channel从epoll队列中移除&#125;void TcpConnection::handleRead(Timestamp receiveTime)//处理读事件的函数&#123;    /*    loop_-&gt;assertInLoopThread();    int savedErrno = 0;    ssize_t n = inputBuffer_.readFd(channel_-&gt;fd(), &amp;savedErrno);    if (n &gt; 0)    &#123;      messageCallback_(shared_from_this(), &amp;inputBuffer_, receiveTime);    &#125;    else if (n == 0)    &#123;      handleClose();    &#125;    else    &#123;      errno = savedErrno;      LOG_SYSERR &lt;&lt; &quot;TcpConnection::handleRead&quot;;      handleError();    &#125;    */    /*    loop_-&gt;assertInLoopThread();    int savedErrno = 0;    char buf[65536];    ssize_t n = ::read(channel_-&gt;fd(), buf, sizeof buf);    if (n &gt; 0)    &#123;      messageCallback_(shared_from_this(), buf, n);    &#125;    else if (n == 0)    &#123;      handleClose();    &#125;    else    &#123;      errno = savedErrno;      LOG_SYSERR &lt;&lt; &quot;TcpConnection::handleRead&quot;;      handleError();    &#125;    */    loop_-&gt;assertInLoopThread();    int savedErrno = 0;    ssize_t n = inputBuffer_.readFd(channel_-&gt;fd(), &amp;savedErrno);//直接将数据读到inputBuffer_缓冲区    if (n &gt; 0) &#123;        messageCallback_(shared_from_this(), &amp;inputBuffer_, receiveTime);    &#125; else if (n == 0) &#123;        handleClose();//如果读到的数据为0，就自动退出    &#125; else &#123;        errno = savedErrno;        LOG_SYSERR &lt;&lt; &quot;TcpConnection::handleRead&quot;;        handleError();    &#125;&#125;// 监听到写事件了，就调用这个函数，此时服务器已经把要写的内容写到outputBuffer_中去了，所以要写的内容从读指针处开始void TcpConnection::handleWrite() &#123;    loop_-&gt;assertInLoopThread();    if (channel_-&gt;isWriting())//查看是否有写事件需要关注    &#123;        ssize_t n = sockets::write(channel_-&gt;fd(),                                   outputBuffer_.peek(),                                   outputBuffer_.readableBytes());//写到文件描述符中去        if (n &gt; 0) &#123;            outputBuffer_.retrieve(n);//处理读写指针            if (outputBuffer_.readableBytes() == 0)     // 发送缓冲区已清空            &#123;                channel_-&gt;disableWriting();        // 停止关注POLLOUT事件，以免出现busy loop                if (writeCompleteCallback_)        // 回调writeCompleteCallback_                &#123;                    // 应用层发送缓冲区被清空，就回调用writeCompleteCallback_                    // 发送给IO线程进行处理                    loop_-&gt;queueInLoop(boost::bind(writeCompleteCallback_, shared_from_this()));                &#125;                if (state_ == kDisconnecting)    // 发送缓冲区已清空并且连接状态是kDisconnecting, 要关闭连接                &#123;                    shutdownInLoop();        // 关闭写连接                &#125;            &#125; else &#123;                LOG_TRACE &lt;&lt; &quot;I am going to write more data&quot;;            &#125;        &#125; else &#123;            LOG_SYSERR &lt;&lt; &quot;TcpConnection::handleWrite&quot;;            // if (state_ == kDisconnecting)            // &#123;            //   shutdownInLoop();            // &#125;        &#125;    &#125; else &#123;        LOG_TRACE &lt;&lt; &quot;Connection fd = &quot; &lt;&lt; channel_-&gt;fd()                  &lt;&lt; &quot; is down, no more writing&quot;;    &#125;&#125;void TcpConnection::handleClose()//关闭事件处理，也是epoll如果发生关闭事件的回调函数&#123;    loop_-&gt;assertInLoopThread();    LOG_TRACE &lt;&lt; &quot;fd = &quot; &lt;&lt; channel_-&gt;fd() &lt;&lt; &quot; state = &quot; &lt;&lt; state_;    assert(state_ == kConnected || state_ == kDisconnecting);    // we don&#39;t close fd, leave it to dtor, so we can find leaks easily.    setState(kDisconnected);    channel_-&gt;disableAll();    TcpConnectionPtr guardThis(shared_from_this());    connectionCallback_(guardThis);        // 在结束前，最后一次处理一下，这一行，可以不调用    LOG_TRACE &lt;&lt; &quot;[7] usecount=&quot; &lt;&lt; guardThis.use_count();    // must be the last line    closeCallback_(guardThis);    // 调用TcpServer::removeConnection    LOG_TRACE &lt;&lt; &quot;[11] usecount=&quot; &lt;&lt; guardThis.use_count();&#125;void TcpConnection::handleError()//处理错误的函数，也是epoll如果发生错误事件的回调函数&#123;    int err = sockets::getSocketError(channel_-&gt;fd());    LOG_ERROR &lt;&lt; &quot;TcpConnection::handleError [&quot; &lt;&lt; name_              &lt;&lt; &quot;] - SO_ERROR = &quot; &lt;&lt; err &lt;&lt; &quot; &quot; &lt;&lt; strerror_tl(err);&#125;</code></pre><h3 id="timer"><a href="#timer" class="headerlink" title="timer"></a>timer</h3><p>Muduo的定时器功能主要由三个class实现，TimerId，Timer，TimerQueue，TimerQueue的接口只有两个addTimer()和cancel()，addTimer()是提供给EventLoop使用的， EventLoop会把它封装成更好用的三个函数：runAt()、runAfter()、runEvery()。</p><p><strong>大体实现</strong></p><p>muduo 定时器封装了 Timer.h 里面保存的是超时时间和回调函数, TimerQueue.h 使用set容器保存多个定时器, 然后在TimerQueue中使用timerfd_create创建一个timerfd句柄, 插入定时器A后先比较A的触发时间和TimerQueue的触发时间, 如果A的触发时间比其小就使用timerfd_settime重置TimerQueue的timerfd的触发时间, TimerQueue中的timerfd的触发时间永远与保存的定时器中触发时间最小的那个相同, 然后timerfd触发可读后, 遍历保存的多个定时器, 看看有没有同时到期的, 有执行回调函数</p><p>TimerQueue的封装是为了让未到期的时间Timer有序的排列起来，这样，能够更具当前时间找到已经到期的Timer也能高效的添加和删除Timer。</p><p>所谓的到期与未到期，与当前在当前时间之前表示已经到期，之后则是未到期。为了方便计算，muduo重载了operator&lt;主要是用来比较微秒大小。</p><p>到期的时间应该被清除去执行相应的回调，未到期的时间则应该有序的排列起来。</p><p> 对于TimerQueue的数据结构，作者提出了几个方案。</p><p>1.传统线性表，查找复杂度为O(n)</p><p>2.二叉堆实现优先级队列，不过C++标准的make_heap()不能高效地完成删除操作。</p><p> 最终，为了防止时间相同所导致的Key相同的情况，使用set和pair</p><pre><code>typedef std::pair&lt;Timestamp, Timer*&gt;Entry;typedef std::set&lt;Entry&gt;TimerList;TimerList timers_;</code></pre><p><strong>timerfd介绍</strong></p><p>这节介绍muduo中定时器的实现。先看一个2.6内核新增的有关定时的系统调用，基于这几个系统调用可以实现基于文件描述符的定时器。使文件描述符在某一特定时间可读。</p><pre><code class="c++">#include &lt;sys/timerfd.h&gt;    int timerfd_create(int clockid, int flags);    int timerfd_settime(int fd, int flags,           const struct itimerspec * new_value,           struct itimerspec * old_value);    int timerfd_gettime(int fd, struct itimerspec *curr_value);</code></pre><p>1、timerfd_create用于创建一个定时器文件，函数返回值是一个文件句柄fd。</p><p>2、timerfd_settime用于设置新的超时时间，并开始计时。flag为0表示相对时间，为1表示绝对时间。new_value为这次设置的新时间，old_value为上次设置的时间。返回0表示设置成功。</p><p>3、timerfd_gettime用于获得定时器距离下次超时还剩下的时间。如果调用时定时器已经到期，并且该定时器处于循环模式（设置超时时间时struct itimerspec::it_interval不为0），那么调用此函数之后定时器重新开始计时。</p><p><strong>TimerId介绍</strong></p><p>TimerId非常简单，它被设计用来取消Timer的，它的结构很简单，只有一个Timer指针和其序列号。</p><pre><code class="c++">/*封装了timer类到构造和析构函数中，我的理解就是RAII的思想 * TimerId非常简单，它被设计用来取消Timer的，它的结构很简单，只有一个Timer指针和其序列号。*/#ifndef MUDUO_NET_TIMERID_H#define MUDUO_NET_TIMERID_H#include &lt;muduo/base/copyable.h&gt;namespace muduo &#123;    namespace net &#123;        class Timer;////// An opaque identifier, for canceling Timer.///        class TimerId : public muduo::copyable &#123;        public:            TimerId()                    : timer_(NULL),                      sequence_(0) &#123;            &#125;            TimerId(Timer *timer, int64_t seq)                    : timer_(timer),                      sequence_(seq) &#123;            &#125;            // default copy-ctor, dtor and assignment are okay            friend class TimerQueue;//友元，就是可以访问类的私有成员变量，但不是类中的成员        private:            Timer *timer_;            int64_t sequence_;        &#125;;    &#125;&#125;#endif  // MUDUO_NET_TIMERID_H</code></pre><p><strong>Timer</strong></p><p>Timer封装了定时器的一些参数，例如超时回调函数、超时时间、定时器是否重复、重复间隔时间、定时器的序列号。其函数大都是设置这些参数，run()用来调用回调函数，restart()用来重启定时器（如果设置为重复）。其源码相对简单</p><pre><code class="c++">/*计时器类*/#ifndef MUDUO_NET_TIMER_H#define MUDUO_NET_TIMER_H#include &lt;boost/noncopyable.hpp&gt;#include &lt;muduo/base/Atomic.h&gt;#include &lt;muduo/base/Timestamp.h&gt;#include &lt;muduo/net/Callbacks.h&gt;namespace muduo &#123;    namespace net &#123;////// Internal class for timer event.///        class Timer : boost::noncopyable &#123;        public:            Timer(const TimerCallback &amp;cb, Timestamp when, double interval)                    : callback_(cb),//回调函数                      expiration_(when),//超时时间                      interval_(interval),//如果重复，间隔时间                      repeat_(interval &gt; 0.0),//如果间隔大于0，就重复                      sequence_(s_numCreated_.incrementAndGet()) &#123;&#125;//当前定时器的序列号            //调用回调函数.            void run() const &#123;                callback_();            &#125;            Timestamp expiration() const &#123; return expiration_; &#125;//返回超时时刻            bool repeat() const &#123; return repeat_; &#125;//返回是否重复            int64_t sequence() const &#123; return sequence_; &#125;//返回定时器序号            void restart(Timestamp now);//重新开始            static int64_t numCreated() &#123; return s_numCreated_.get(); &#125;//返回最新的序号值        private:            const TimerCallback callback_;        // 定时器回调函数            Timestamp expiration_;                // 下一次的超时时间戳类            const double interval_;                // 超时时间间隔，如果是一次性定时器，该值为0            const bool repeat_;                    // 是否重复            const int64_t sequence_;                // 定时器序号，不会重复            static AtomicInt64 s_numCreated_;        // 定时器计数，当前已经创建的定时器数量        &#125;;    &#125;&#125;#endif  // MUDUO_NET_TIMER_H</code></pre><p><strong>TimerQueue</strong></p><p>虽然TimerQueue中有Queue，但是其实现时基于Set的，而不是Queue。这样可以高效地插入、删除定时器，且找到当前已经超时的定时器。TimerQueue的public接口只有两个，添加和删除。</p><pre><code>void addTimerInLoop(Timer* timer);void cancelInLoop(TimerId timerId);</code></pre><p>定时器管理类，其中timer类就是TimerQueue需要管理的元素，而timerId就是一个简单的timer封装，避免销毁和创建操作</p><p>但是要注意的是timer并没有自己计时的功能，所以需要依靠timerfd这个系统函数统一计时timerfd是一个系统计时函数，当所设置的时间到了，会通过timerfd这个文件描述符进行提示通信，而其他计时函数可能是通过信号量，或者其他方式，但是都没有文件描述符好，并且也可以用timerfd监听。</p><p>如何使用timerfd来为所有的计时器计时：timerfd每次都设置在计时器列表中到期时间最近的那个到期时间，这样timerfd到期以后，也就是最近的那个计时器到期，所以每次都是手动重置timerfd的计时时间，为最近的计时器到期时间</p><p>内部有channel，和timerfd关联。添加新的Timer后，在超时后，timerfd可读，会处理channel事件，之后调用Timer的回调函数；在timerfd的事件处理后，还有检查一遍超时定时器，如果其属性为重复还有再次添加到定时器集合中。</p><p>内部有两种类型的Set</p><pre><code>typedef std::pair&lt;Timestamp, Timer*&gt; Entry;typedef std::set&lt;Entry&gt; TimerList;typedef std::pair&lt;Timer*, int64_t&gt; ActiveTimer;typedef std::set&lt;ActiveTimer&gt; ActiveTimerSet;</code></pre><p>TimerQueue.h</p><pre><code class="c++">#ifndef MUDUO_NET_TIMERQUEUE_H#define MUDUO_NET_TIMERQUEUE_H#include &lt;set&gt;#include &lt;vector&gt;#include &lt;boost/noncopyable.hpp&gt;#include &lt;muduo/base/Mutex.h&gt;#include &lt;muduo/base/Timestamp.h&gt;#include &lt;muduo/net/Callbacks.h&gt;#include &lt;muduo/net/Channel.h&gt;namespace muduo &#123;    namespace net &#123;        class EventLoop;        class Timer;        class TimerId;////// A best efforts timer queue./// No guarantee that the callback will be on time.///        class TimerQueue : boost::noncopyable &#123;        public:            TimerQueue(EventLoop *loop);            ~TimerQueue();            ///            /// Schedules the callback to be run at given time,            /// repeats if @c interval &gt; 0.0.            ///            /// Must be thread safe. Usually be called from other threads.            // 一定是线程安全的，可以跨线程调用。通常情况下被其它线程调用。            TimerId addTimer(const TimerCallback &amp;cb,                             Timestamp when,                             double interval);            void cancel(TimerId timerId);        private:            // FIXME: use unique_ptr&lt;Timer&gt; instead of raw pointers.            // unique_ptr是C++ 11标准的一个独享所有权的智能指针            // 无法得到指向同一对象的两个unique_ptr指针            // 但可以进行移动构造与移动赋值操作，即所有权可以移动到另一个对象（而非拷贝构造）            typedef std::pair&lt;Timestamp, Timer *&gt; Entry;            typedef std::set &lt;Entry&gt; TimerList;            typedef std::pair&lt;Timer *, int64_t&gt; ActiveTimer;            typedef std::set &lt;ActiveTimer&gt; ActiveTimerSet;            //set中存储的是pair类型，那么默认先按照pair的第一个元素排序，如果相同，再按照第二个元素排序。            //所以这两种set都是存放定时器的列表，但是一个根据定时器的到时时间来存储，            //一个根据定时器地址来存储，但是存储的定时器都是同一个，目的是为了区分同一到期时间的定时器？？？            // 以下成员函数只可能在其所属的I/O线程中调用，因而不必加锁。            // 服务器性能杀手之一是锁竞争，所以要尽可能少用锁            void addTimerInLoop(Timer *timer);            void cancelInLoop(TimerId timerId);            // called when timerfd alarms            void handleRead();//timerfdChannel_的读函数            // move out all expired timers            // 返回超时的定时器列表            std::vector &lt;Entry&gt; getExpired(Timestamp now);            void reset(const std::vector &lt;Entry&gt; &amp;expired, Timestamp now);            bool insert(Timer *timer);            EventLoop *loop_;        // 所属EventLoop            const int timerfd_;            //过一段事件，就筛选一次，看看TimerList中有多少定时器到时间了，就处理一下，但是这样延迟很高，不太理解            Channel timerfdChannel_;//与timefd绑定            // Timer list sorted by expiration            TimerList timers_;    // timers_是按到期时间排序，也是存放未到时间的定时器            // for cancel()            // timers_与activeTimers_保存的是相同的数据            // timers_是按到期时间排序，activeTimers_是按对象地址排序            ActiveTimerSet activeTimers_;//还未到时间的定时器,这里面存放的定时器是和timers_一样的，只是顺序不同            bool callingExpiredTimers_; /* atomic *///是否在处理过期定时器的标志            ActiveTimerSet cancelingTimers_;    // 保存的是被取消的定时器            // 用这个列表的作用是，当出现一个循环的计时器被取消时，就要通过reset函数中对            //ActiveTimerSet列表来暂停对这个计时器的重置        &#125;;    &#125;&#125;#endif  // MUDUO_NET_TIMERQUEUE_H</code></pre><p>TimerQueue.cc</p><pre><code class="c++">#define __STDC_LIMIT_MACROS#include &lt;muduo/net/TimerQueue.h&gt;#include &lt;muduo/base/Logging.h&gt;#include &lt;muduo/net/EventLoop.h&gt;#include &lt;muduo/net/Timer.h&gt;#include &lt;muduo/net/TimerId.h&gt;#include &lt;boost/bind.hpp&gt;#include &lt;sys/timerfd.h&gt;namespace muduo &#123;    namespace net &#123;        namespace detail &#123;            // 创建定时器            int createTimerfd() &#123;                int timerfd = ::timerfd_create(CLOCK_MONOTONIC,                                               TFD_NONBLOCK | TFD_CLOEXEC);//CLOCK_MONOTONIC参数表明计时器的时间是从系统打开开始计时的                //CLOCK_MONOTONIC表示的是时间类型                if (timerfd &lt; 0) &#123;                    LOG_SYSFATAL &lt;&lt; &quot;Failed in timerfd_create&quot;;                &#125;                return timerfd;            &#125;            // 计算超时时刻与当前时间的时间差            struct timespec howMuchTimeFromNow(Timestamp when) &#123;                int64_t microseconds = when.microSecondsSinceEpoch()                                       - Timestamp::now().microSecondsSinceEpoch();                if (microseconds &lt; 100) &#123;                    microseconds = 100;                &#125;                struct timespec ts;                ts.tv_sec = static_cast&lt;time_t&gt;(                        microseconds / Timestamp::kMicroSecondsPerSecond);                ts.tv_nsec = static_cast&lt;long&gt;(                        (microseconds % Timestamp::kMicroSecondsPerSecond) * 1000);                return ts;            &#125;            // 清除定时器，避免一直触发//处理超时事件。超时后，timerfd变为可读            void readTimerfd(int timerfd, Timestamp now) &#123;                uint64_t howmany;                ssize_t n = ::read(timerfd, &amp;howmany, sizeof howmany);                LOG_TRACE &lt;&lt; &quot;TimerQueue::handleRead() &quot; &lt;&lt; howmany &lt;&lt; &quot; at &quot; &lt;&lt; now.toString();                if (n != sizeof howmany) &#123;                    LOG_ERROR &lt;&lt; &quot;TimerQueue::handleRead() reads &quot; &lt;&lt; n &lt;&lt; &quot; bytes instead of 8&quot;;                &#125;            &#125;            // 重置定时器的超时时间（不是周期性的定时器，时间到expiration就结束了）            // 在这里面itimerspec.it_interval都是设置的0，每次都是计时结束以后手动重新设置，然后再计时的。            void resetTimerfd(int timerfd, Timestamp expiration) &#123;                // wake up loop by timerfd_settime()                struct itimerspec newValue;                struct itimerspec oldValue;                bzero(&amp;newValue, sizeof newValue);                bzero(&amp;oldValue, sizeof oldValue);                newValue.it_value = howMuchTimeFromNow(expiration);                int ret = ::timerfd_settime(timerfd, 0, &amp;newValue, &amp;oldValue);                if (ret) &#123;                    LOG_SYSERR &lt;&lt; &quot;timerfd_settime()&quot;;                &#125;            &#125;        &#125;    &#125;&#125;using namespace muduo;using namespace muduo::net;using namespace muduo::net::detail;TimerQueue::TimerQueue(EventLoop *loop)        : loop_(loop),          timerfd_(createTimerfd()),          timerfdChannel_(loop, timerfd_),//timerfd相关的channel          timers_(),          callingExpiredTimers_(false) &#123;    timerfdChannel_.setReadCallback(            boost::bind(&amp;TimerQueue::handleRead, this));    // we are always reading the timerfd, we disarm it with timerfd_settime.    timerfdChannel_.enableReading();//设置关注读事件，并且加入epoll队列&#125;TimerQueue::~TimerQueue() &#123;    ::close(timerfd_);    // do not remove channel, since we&#39;re in EventLoop::dtor();    for (TimerList::iterator it = timers_.begin();         it != timers_.end(); ++it) &#123;        delete it-&gt;second;    &#125;&#125;TimerId TimerQueue::addTimer(const TimerCallback &amp;cb,                             Timestamp when,                             double interval)//创建并增加Timer进队列中&#123;    Timer *timer = new Timer(cb, when, interval);    loop_-&gt;runInLoop(            boost::bind(&amp;TimerQueue::addTimerInLoop, this, timer));    //addTimerInLoop(timer);    return TimerId(timer, timer-&gt;sequence());&#125;void TimerQueue::cancel(TimerId timerId)//取消&#123;    loop_-&gt;runInLoop(            boost::bind(&amp;TimerQueue::cancelInLoop, this, timerId));    //cancelInLoop(timerId);&#125;void TimerQueue::addTimerInLoop(Timer *timer) &#123;    loop_-&gt;assertInLoopThread();    // 插入一个定时器，有可能会使得最早到期的定时器发生改变    bool earliestChanged = insert(timer);    if (earliestChanged) &#123;        // 重置timefd定时器的超时时刻(timerfd_settime)        resetTimerfd(timerfd_, timer-&gt;expiration());    &#125;&#125;void TimerQueue::cancelInLoop(TimerId timerId)//取消的回调函数//取消计时器，就是把该计时器从两个队列中删除，//现在有一种特殊情况，就是如果刚好在处理定时器的过程中，并且这个要取消的定时器就是在被处理的，并且是循环定时器，那么如果不加入cancelingTimers_列表//就会出现，在重置时又把这个定时器重启了，但是这个定时器应该是要被取消的&#123;    loop_-&gt;assertInLoopThread();    assert(timers_.size() == activeTimers_.size());    ActiveTimer timer(timerId.timer_, timerId.sequence_);    // 查找该定时器    ActiveTimerSet::iterator it = activeTimers_.find(timer);    if (it != activeTimers_.end()) &#123;        size_t n = timers_.erase(Entry(it-&gt;first-&gt;expiration(), it-&gt;first));        assert(n == 1);        (void) n;        delete it-&gt;first; // FIXME: no delete please,如果用了unique_ptr,这里就不需要手动删除了        activeTimers_.erase(it);    &#125;//用activeTimers_列表来搜索，然后找到先删除timers_，再删除activeTimers_    else if (callingExpiredTimers_)        //如果在未到时间的定时器中没有找到，并且线程正在处理过期的定时器，那么可能这个定时器正在被处理，就将这些定时器放到cancelingTimers_数组中    &#123;        // 已经到期，并且正在调用回调函数的定时器，为了在重置时，避免被重置，而是被忽略        cancelingTimers_.insert(timer);    &#125;    assert(timers_.size() == activeTimers_.size());&#125;void TimerQueue::handleRead()//TimerChannel的回调函数，也就是当timefd定时器到时的时候，就会调用这个函数&#123;    loop_-&gt;assertInLoopThread();    Timestamp now(Timestamp::now());    readTimerfd(timerfd_, now);        // 清除该事件，避免一直触发    // 获取该时刻之前所有的定时器列表(即超时定时器列表)    std::vector &lt;Entry&gt; expired = getExpired(now);    callingExpiredTimers_ = true;//处理到期的定时器    cancelingTimers_.clear();//每次处理前，把要取消的定时器列表清空    // safe to callback outside critical section    for (std::vector&lt;Entry&gt;::iterator it = expired.begin();         it != expired.end(); ++it) &#123;        // 这里回调定时器timer处理函数        it-&gt;second-&gt;run();    &#125;    callingExpiredTimers_ = false;    // 不是一次性定时器，需要重启    reset(expired, now);//如果之前处理定时器回调函数时间较长，那么在这段时间中，已经有定时器到期了，轻则产生延迟，重则&#125;// rvostd::vector &lt;TimerQueue::Entry&gt; TimerQueue::getExpired(Timestamp now)//得到已经过期的计时器&#123;    assert(timers_.size() == activeTimers_.size());    std::vector &lt;Entry&gt; expired;//存放已经过期的定时器    Entry sentry(now, reinterpret_cast&lt;Timer *&gt;(UINTPTR_MAX));//我理解是找了一个指针可以取到的最大数，为了避免和其他指针冲突，    //因为这个指针没有什么意义，仅仅是为了构成一个Entry结构体，有意义的是第一个元素now    // 返回第一个未到期的Timer的迭代器    // lower_bound的含义是返回第一个值&gt;=sentry的元素的iterator    // 即*end &gt;= sentry，从而end-&gt;first &gt; now    TimerList::iterator end = timers_.lower_bound(sentry);    assert(end == timers_.end() || now &lt; end-&gt;first);    // 将到期的定时器插入到expired中    std::copy(timers_.begin(), end, back_inserter(expired));//back_inserter是迭代器的一种操作，效果和expired.push_back()一样    // 从timers_中移除到期的定时器    timers_.erase(timers_.begin(), end);    // 从activeTimers_中移除到期的定时器    for (std::vector&lt;Entry&gt;::iterator it = expired.begin();         it != expired.end(); ++it) &#123;        ActiveTimer timer(it-&gt;second, it-&gt;second-&gt;sequence());        size_t n = activeTimers_.erase(timer);        assert(n == 1);        (void) n;//避免编译器出现变量n未使用的警告？？？    &#125;    assert(timers_.size() == activeTimers_.size());    return expired;&#125;void TimerQueue::reset(const std::vector &lt;Entry&gt; &amp;expired, Timestamp now)//重启两种定时器，一种是timefd，另外一种是定时器列表中需要重复的定时器&#123;    Timestamp nextExpire;    //重启定时器列表中过期的定时器，如果需要重复的话    for (std::vector&lt;Entry&gt;::const_iterator it = expired.begin();         it != expired.end(); ++it) &#123;        ActiveTimer timer(it-&gt;second, it-&gt;second-&gt;sequence());        // 如果是重复的定时器并且是未取消定时器，则重启该定时器        if (it-&gt;second-&gt;repeat()            &amp;&amp; cancelingTimers_.find(timer) == cancelingTimers_.end()) &#123;            it-&gt;second-&gt;restart(now);            insert(it-&gt;second);        &#125; else//不需要重复就删除这个定时器        &#123;            // 一次性定时器或者已被取消的定时器是不能重置的，因此删除该定时器            // FIXME move to a free list            delete it-&gt;second; // FIXME: no delete please        &#125;    &#125;    //重启timefd，设置的时间就是定时器列表中最快到期的时间    if (!timers_.empty()) &#123;        // 获取最早到期的定时器超时时间        nextExpire = timers_.begin()-&gt;second-&gt;expiration();    &#125;    if (nextExpire.valid()) &#123;        // 重置定时器的超时时刻(timerfd_settime)        resetTimerfd(timerfd_, nextExpire);    &#125;&#125;bool TimerQueue::insert(Timer *timer)//把定时器插入到timers_和activeTimers_队列中去&#123;    loop_-&gt;assertInLoopThread();    assert(timers_.size() == activeTimers_.size());    // 最早到期时间是否改变    bool earliestChanged = false;//这个变量的意义是显示最早到期时间是否改变，通俗点说就是这个插入的定时器的位置在timers_的    //首位，也就是这个插入的定时器的到期时间是timers_中已经存储的定时器中最早的，那么这个标志位就会置true    Timestamp when = timer-&gt;expiration();//超时时刻    TimerList::iterator it = timers_.begin();    // 如果timers_为空或者when小于timers_中的最早到期时间    if (it == timers_.end() || when &lt; it-&gt;first) &#123;        earliestChanged = true;//表示定时器最早，所以置true    &#125;    //要分别插入到两个set中    &#123;        // 插入到timers_中        std::pair&lt;TimerList::iterator, bool&gt; result                = timers_.insert(Entry(when, timer));        assert(result.second);        (void) result;    &#125;    &#123;        // 插入到activeTimers_中        std::pair&lt;ActiveTimerSet::iterator, bool&gt; result                = activeTimers_.insert(ActiveTimer(timer, timer-&gt;sequence()));        assert(result.second);        (void) result;    &#125;    assert(timers_.size() == activeTimers_.size());    return earliestChanged;//返回最早到期的时间有没有改变&#125;</code></pre><h3 id="EventLoop"><a href="#EventLoop" class="headerlink" title="EventLoop"></a>EventLoop</h3><p><code>EventLoop</code> 整合了 <code>Channel</code> 和 <code>Poller</code> 提供更方便的接口来使用，主要功能为：处理 <code>Channel</code>、处理定时事件、处理任务事件。主要接口如下：</p><pre><code class="c++">class EventLoop : noncopyable&#123; public:  // EventLoop  void loop();  void quit();  // 任务事件  void wakeup();  void runInLoop(Functor cb);  void queueInLoop(Functor cb);  // 定时器  TimerId runAt(Timestamp time, TimerCallback cb);  TimerId runAfter(double delay, TimerCallback cb);  TimerId runEvery(double interval, TimerCallback cb);  void cancel(TimerId timerId);  // 处理 Channel  void updateChannel(Channel* channel);  void removeChannel(Channel* channel);  bool hasChannel(Channel* channel);&#125;;</code></pre><p><code>EventLoop</code> 的用法是先注册 <code>Channel</code>，如 <code>listening fd</code>，然后调用 <code>loop()</code> 一直循环处理各种任务，在 <code>loop</code> 中可以注册新的 <code>Channel</code>、定时事件和任务事件：</p><pre><code>void EventLoop::loop()&#123;  while (!quit_)  &#123;    activeChannels_.clear();    pollReturnTime_ = poller_-&gt;poll(kPollTimeMs, &amp;activeChannels_);    for (Channel* channel : activeChannels_)    &#123;      currentActiveChannel_ = channel;      currentActiveChannel_-&gt;handleEvent(pollReturnTime_);    &#125;    doPendingFunctors();  &#125;&#125;</code></pre><p>先来说任务事件，使用场景主要是其他线程想要在 <code>EventLoop</code> 线程做些工作，比如 <code>EventLoop</code> 线程把耗时的任务放到 <code>threadpool</code> 中执行，完成后通知 <code>EventLoop</code> 线程获取结果。 最常见的实现方式是用 <code>pipe(2)</code>：<code>EventLoop</code> 注册读事件，其他线程把结果保存在队列中，然后写 <code>pipe</code>，<code>EventLoop</code> 线程就会唤醒处理。<code>Muduo</code> 也是类似实现，只是用 <code>eventfd(2)</code> 来唤醒。</p><h2 id="一个简单的例子"><a href="#一个简单的例子" class="headerlink" title="一个简单的例子"></a>一个简单的例子</h2><p>首先从最简单的 echo server 入手，来介绍 muduo 的基本使用，同时也方便后面概念的理解。</p><pre><code class="cpp">void onMessage(const muduo::net::TcpConnectionPtr&amp; conn,                           muduo::net::Buffer* buf,                           muduo::Timestamp time)&#123;  conn-&gt;send(buf);&#125;int main()&#123;    muduo::net::EventLoop loop;    muduo::net::InetAddress listenAddr(2007);    TcpServer server(&amp;loop, listenAddr);    server.setMessageCallback(onMessage);    server.start();    loop.loop();&#125;</code></pre><p>echo-server 的代码量非常简洁。一个典型的 muduo 的 TcpServer 工作流程如下：</p><ol><li>建立一个事件循环器 EventLoop(reactor)</li><li>建立对应的业务服务器 TcpServer，并指定它的reactor和地址</li><li>设置 TcpServer 的 Callback</li><li>启动 server</li><li>开启事件循环</li></ol><p>陈硕认为，TCP 网络编程的本质是处理三个半事件，即：</p><ol><li>连接的建立</li><li>连接的断开：包括主动断开和被动断开</li><li>消息到达，文件描述符可读。</li><li>消息发送完毕。这个算半个事件。</li></ol><p>我们接下来分析下 muduo 是怎么处理和实现这三个半事件的</p><h2 id="连接的建立"><a href="#连接的建立" class="headerlink" title="连接的建立"></a>连接的建立</h2><p>在我们单纯使用 linux 的 API，编写一个简单的 Tcp 服务器时，建立一个新的连接通常需要四步：</p><blockquote><p>步骤 1. socket() &#x2F;&#x2F; 调用 socket 函数建立监听 socket<br>步骤 2. bind() &#x2F;&#x2F; 绑定地址和端口<br>步骤 3. listen() &#x2F;&#x2F; 开始监听端口<br>步骤 4. accept() &#x2F;&#x2F; 返回新建立连接的 fd</p></blockquote><p>我们接下来分析下，这四个步骤在 muduo 中都是何时进行的：</p><p>首先在 TcpServer 对象构建时，TcpServer 的属性 acceptor 同时也被建立。<br>在 Acceptor 的构造函数中分别调用了 socket 函数和 bind 函数完成了 <strong>步骤 1</strong>和<strong>步骤 2</strong>。<br>即，当 <code>TcpServer server(&amp;loop, listenAddr)</code> 执行结束时，监听 socket 已经建立好，并已绑定到对应地址和端口了。</p><p>而当执行 <code>server.start()</code> 时，主要做了两个工作：</p><ol><li>在监听 socket 上启动 listen 函数，也就是 <strong>步骤 3</strong>；</li><li>将监听 socket 的可读事件注册到 EventLoop 中。</li></ol><p>此时，程序已完成对socket的监听，但还不够，因为此时程序的主角 <code>EventLoop</code> 尚未启动。<br>当调用 <code>loop.loop()</code> 时，程序开始循环监听该 socket 的可读事件。</p><p>当新连接请求建立时，可读事件触发，此时该事件对应的 callback 在 EventLoop::loop() 中被调用。<br>该事件的 callback 实际上就是 Acceptor::handleRead() 方法。</p><p>在 Acceptor::handleRead() 方法中，做了三件事：</p><ol><li>调用了 accept 函数，完成了 <strong>步骤 4</strong>，实现了连接的建立。得到一个已连接 socket 的 fd。</li><li>创建 TcpConnection 对象。</li><li>将已连接 socket 的可读事件注册到 EventLoop 中。</li></ol><p>这里还有一个需要注意的点，创建的 TcpConnnection 对象是个 shared_ptr，该对象会被保存在 TcpServer 的 connections 中。这样才能保证引用计数大于 0，对象不被释放。</p><p>至此，一个新的连接已完全建立好，该连接的socket可读事件也已注册到 EventLoop 中了。</p><h2 id="消息的读取"><a href="#消息的读取" class="headerlink" title="消息的读取"></a>消息的读取</h2><p>上节讲到，在新连接建立的时候，会将新连接的 socket 的可读事件注册到 EventLoop 中。<br>假如客户端发送消息，导致已连接 socket 的可读事件触发，该事件对应的 callback 同样也会在 EventLoop::loop() 中被调用。</p><p>该事件的 callback 实际上就是 TcpConnection::handleRead 方法。<br>在 TcpConnection::handleRead 方法中，主要做了两件事：</p><ol><li>从 socket 中读取数据，并将其放入 inputbuffer 中</li><li>调用 messageCallback，执行业务逻辑。</li></ol><pre><code class="c++">ssize_t n = inputBuffer_.readFd(channel_-&gt;fd(), &amp;savedErrno);if (n&gt; 0)&#123;    messageCallback_(shared_from_this(), &amp;inputBuffer_, receiveTime);&#125;</code></pre><p>messageCallback 是在建立新连接时，将 <code>TcpServer::messageCallback</code> 方法 bind 到了 <code>TcpConnection::messageCallback</code> 的方法。</p><p><code>TcpServer::messageCallback</code> 就是业务逻辑的主要实现函数。通常情况下，我们可以在里面实现消息的编解码、消息的分发等工作，这里就不再深入探讨了。</p><p>在我们上面给出的示例代码中，echo-server 的 messageCallback 非常简单，就是直接将得到的数据，重新 send 回去。在实际的业务处理中，一般都会调用 TcpConnection::send() 方法，给客户端回复消息。</p><p>这里需要注意的是，在 messageCallback 中，用户会有可能会把任务抛给自定义的 Worker 线程池处理。<br>但是这个在 Worker 线程池中任务，<strong>切忌直接对 Buffer 的操作</strong>。因为 Buffer 并不是线程安全的。</p><p>我们需要记住一个准则:</p><blockquote><p><strong>所有对 IO 和 buffer 的读写，都应该在 IO 线程中完成。</strong></p></blockquote><p>一般情况下，先在交给 Worker 线程池之前，应该现在 IO 线程中把 Buffer 进行切分解包等动作。将解包后的消息交由线程池处理，避免多个线程操作同一个资源。</p><h2 id="消息的发送"><a href="#消息的发送" class="headerlink" title="消息的发送"></a>消息的发送</h2><p>用户通过调用 TcpConnection::send() 向客户端回复消息。由于 muduo 中使用了 OutputBuffer，因此消息的发送过程比较复杂。</p><p>首先需要注意的是线程安全问题, 上文说到对于消息的读写必须都在 EventLoop 的同一个线程 (通常称为 IO 线程) 中进行：<br>因此，TcpConnection::send 必须要保证线程安全性，它是这么做的：</p><pre><code class="c++">void TcpConnection::send(const StringPiece&amp; message)&#123;  if (state_ == kConnected)  &#123;    if (loop_-&gt;isInLoopThread())    &#123;      sendInLoop(message);    &#125;    else    &#123;      loop_-&gt;runInLoop(          boost::bind(&amp;TcpConnection::sendInLoop,                      this,     // FIXME                      message.as_string()));    &#125;  &#125;&#125;</code></pre><p>检测 send 的时候，是否在当前 IO 线程，如果是的话，直接进行写相关操作 <code>sendInLoop</code>。<br>如果不在一个线程的话，需要将该任务抛给 IO 线程执行 <code>runInloop</code>, 以保证 write 动作是在 IO 线程中执行的。我们后面会讲解 <code>runInloop</code> 的具体实现。</p><p>在 sendInloop 中，做了下面几件事：</p><ol><li>假如 OutputBuffer 为空，则直接向 socket 写数据</li><li>如果向 socket 写数据没有写完，则统计剩余的字节个数，并进行下一步。没有写完可能是因为此时 socket 的 TCP 缓冲区已满了。</li><li>如果此时 OutputBuffer 中的旧数据的个数和未写完字节个数之和大于 highWaterMark，则将 highWaterMarkCallback 放入待执行队列中</li><li><strong>将对应 socket 的可写事件注册到 EventLoop 中</strong></li></ol><p>注意：直到发送消息的时候，muduo 才会把 socket 的可写事件注册到了 EventLoop 中。在此之前只注册了可读事件。</p><p>连接 socket 的可写事件对应的 callback 是 TcpConnection::handleWrite()<br>当某个 socket 的可写事件触发时，TcpConnection::handleWrite 会做两个工作：</p><ol><li>尽可能将数据从 OutputBuffer 中向 socket 中 write 数据</li><li>如果 OutputBuffer 没有剩余的，则 <strong>将该 socket 的可写事件移除</strong>，并调用 writeCompleteCallback</li></ol><p><strong>为什么要移除可写事件</strong></p><p>因为当 OutputBuffer 中没数据时，我们不需要向 socket 中写入数据。但是此时 socket 一直是处于可写状态的， 这将会导致 TcpConnection::handleWrite() 一直被触发。然而这个触发毫无意义，因为并没有什么可以写的。</p><p>所以 muduo 的处理方式是，当 OutputBuffer 还有数据时，socket 可写事件是注册状态。当 OutputBuffer 为空时，则将 socket 的可写事件移除。</p><p>此外，highWaterMarkCallback 和 writeCompleteCallback 一般配合使用，起到限流的作用。在《linux 多线程服务器端编程》一书的 8.9.3 一节中有详细讲解。这里就不再赘述了</p><h2 id="连接的断开"><a href="#连接的断开" class="headerlink" title="连接的断开"></a>连接的断开</h2><p>我们看下 muduo 对于连接的断开是怎么处理的。<br>连接的断开分为被动断开和主动断开。主动断开和被动断开的处理方式基本一致，因此本文只讲下被动断开的部分。</p><p>被动断开即客户端断开了连接，server 端需要感知到这个断开的过程，然后进行的相关的处理。</p><p>其中感知远程断开这一步是在 Tcp 连接的可读事件处理函数 <code>handleRead</code> 中进行的：当对 socket 进行 read 操作时，返回值为 0，则说明此时连接已断开。</p><p>接下来会做四件事情：</p><ol><li>将该 TCP 连接对应的事件从 EventLoop 移除</li><li>调用用户的 ConnectionCallback</li><li>将对应的 TcpConnection 对象从 Server 移除。</li><li>close 对应的 fd。此步骤是在析构函数中自动触发的，当 TcpConnection 对象被移除后，引用计数为 0，对象析构时会调用 close。</li></ol><h2 id="runInLoop-的实现"><a href="#runInLoop-的实现" class="headerlink" title="runInLoop 的实现"></a>runInLoop 的实现</h2><p>在讲解消息的发送过程时候，我们讲到为了保证对 buffer 和 socket 的写动作是在 IO 线程中进行，使用了一个 <code>runInLoop</code> 函数，将该写任务抛给了 IO 线程处理。</p><p>我们接下来看下 <code>runInLoop</code> 的实现：</p><pre><code class="cpp">void EventLoop::runInLoop(const Functor&amp; cb)&#123;  if (isInLoopThread())  &#123;    cb();  &#125;  else  &#123;    queueInLoop(cb);  &#125;&#125;</code></pre><p>这里可以看到，做了一层判断。如果调用时是此 EventLoop 的运行线程，则直接执行此函数。<br>否则调用 <code>queueInLoop</code> 函数。我们看下 <code>queueInLoop</code> 的实现。</p><pre><code class="cpp">void EventLoop::queueInLoop(const Functor&amp; cb)&#123;  &#123;  MutexLockGuard lock(mutex_);  pendingFunctors_.push_back(cb);  &#125;  if (!isInLoopThread() || callingPendingFunctors_)  &#123;    wakeup();  &#125;&#125;</code></pre><p>这里有两个动作：</p><ol><li>加锁，然后将该函数放到该 EventLoop 的 pendingFunctors_队列中。</li><li>判断是否要唤醒 EventLoop，如果是则调用 wakeup() 唤醒该 EventLoop。</li></ol><p>这里有几个问题：</p><ul><li>为什么要唤醒 EventLoop？</li><li>wakeup 是怎么实现的?</li><li>pendingFunctors_是如何被消费的?</li></ul><h3 id="为什么要唤醒-EventLoop"><a href="#为什么要唤醒-EventLoop" class="headerlink" title="为什么要唤醒 EventLoop"></a>为什么要唤醒 EventLoop</h3><p>我们首先调用了 <code>pendingFunctors_.push_back(cb)</code>, 将该函数放在 pendingFunctors_中。EventLoop 的每一轮循环在最后会调用 doPendingFunctors 依次执行这些函数。</p><p>而 EventLoop 的唤醒是通过 epoll_wait 实现的，如果此时该 EventLoop 中迟迟没有事件触发，那么 epoll_wait 一直就会阻塞。 这样会导致，pendingFunctors_中的任务迟迟不能被执行了。</p><p>所以必须要唤醒 EventLoop ，从而让pendingFunctors_中的任务尽快被执行。</p><h3 id="wakeup-是怎么实现的"><a href="#wakeup-是怎么实现的" class="headerlink" title="wakeup 是怎么实现的"></a>wakeup 是怎么实现的</h3><p>muduo 这里采用了对 eventfd 的读写来实现对 EventLoop 的唤醒。</p><p>在 EventLoop 建立之后，就创建一个 eventfd，并将其可读事件注册到 EventLoop 中。</p><p><code>wakeup()</code> 的过程本质上是对这个 eventfd 进行写操作，以触发该 eventfd 的可读事件。这样就起到了唤醒 EventLoop 的作用。</p><pre><code class="cpp">void EventLoop::wakeup()&#123;  uint64_t one = 1;  sockets::write(wakeupFd_, &amp;one, sizeof one);&#125;</code></pre><p>很多库为了兼容 macOS，往往使用 pipe 来实现这个功能。muduo 采用了 eventfd，性能更好些，但代价是不能支持 macOS 了。不过 muduo 似乎从一开始的定位就不打算支持？</p><h3 id="doPendingFunctors-的实现"><a href="#doPendingFunctors-的实现" class="headerlink" title="doPendingFunctors 的实现"></a>doPendingFunctors 的实现</h3><p>本部分讲下 <code>doPendingFunctors</code> 的实现，muduo 是如何处理这些待处理的函数的，以及中间用了哪些优化操作。<br>代码如下所示：</p><pre><code class="cpp">void EventLoop::doPendingFunctors()&#123;  std::vector&lt;Functor&gt; functors;  callingPendingFunctors_ = true;  &#123;  MutexLockGuard lock(mutex_);  functors.swap(pendingFunctors_);  &#125;  for (size_t i = 0; i &lt; functors.size(); ++i)  &#123;    functors[i]();  &#125;  callingPendingFunctors_ = false;&#125;</code></pre><p>从代码可以看到，函数非常简单。大概只有十行代码，但是这十行代码中却有两个非常巧妙的地方。</p><ol><li><strong>callingPendingFunctors_的作用</strong></li></ol><p>从代码可以看出，如果 callingPendingFunctors_为 false，则说明此时尚未开始执行 doPendingFunctors 函数。<br>这个有什么作用呢，我们需要结合下 queueInLoop 中，对是否执行 wakeup() 的判断</p><pre><code class="none">if (!isInLoopThread() || callingPendingFunctors_)&#123;  wakeup();&#125;</code></pre><p>这里还需要结合下 EventLoop 循环的实现，其中 <code>doPendingFunctors()</code> 是 <strong>每轮循环的最后一步处理</strong>。<br>如果调用 queueInLoop 和 EventLoop 在同一个线程，且 callingPendingFunctors_为 false 时，则说明：<strong>此时尚未执行到 doPendingFunctors()。</strong><br>那么此时即使不用 wakeup，也可以在之后照旧执行 doPendingFunctors() 了。</p><p>这么做的好处非常明显，可以减少对 eventfd 的 IO 读写。</p><ol><li><strong>锁范围的减少</strong><br>在此函数中，有一段特别的代码：</li></ol><pre><code class="cpp">std::vector&lt;Functor&gt; functors;&#123;  MutexLockGuard lock(mutex_);  functors.swap(pendingFunctors_);&#125;</code></pre><p>这个作用是 pendingFunctors_和 functors 的内容进行交换，实际上就是此时 functors 持有了 pendingFunctors_的内容，而 pendingFunctors_被清空了。</p><p>这个好处是什么呢？<br>如果不这么做，直接遍历 pendingFunctors_, 然后处理对应的函数。这样的话，锁会一直等到所有函数处理完才会被释放。在此期间，queueInLoop 将不可用。</p><p>而以上的写法，可以极大减小锁范围，整个锁的持有时间就是 swap 那一下的时间。待处理函数执行的时候，其他线程还是可以继续调用 queueInLoop。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/muduo%E6%97%A5%E5%BF%97/"/>
      <url>/2023/01/22/muduo%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<h1 id="muduo日志"><a href="#muduo日志" class="headerlink" title="muduo日志"></a>muduo日志</h1><p>日志（logging）有两种：</p><ul><li>诊断日志（diagnostic log） 即log4j等常用日志库提供的日志功能。</li><li>交易日志（transaction log） 即数据库的write-ahead log用于记录状态变更， 通过回放日志可以逐步恢复每一次修改之后的状态。</li></ul><p>本章的日志是前一个意思， 即文本的、 供人阅读的日志， 通常用于故障诊断和追踪（trace），也可用于性能分析。日志通常是分布式<br>系统中事故调查时的唯一线索， 用来追寻蛛丝马迹， 查出元凶。  </p><p>对于关键进程， 日志通常要记录：</p><ul><li>收到的每条内部消息的id（还可以包括关键字段、 长度、 hash等） ；</li><li>收到的每条外部消息的全文；</li><li>发出的每条消息的全文， 每条消息都有全局唯一的id；</li><li>关键内部状态的变更， 等等。</li></ul><p>每条日志都有时间戳， 这样就能完整追踪分布式系统中一个事件的来龙去脉。 也只有这样才能查清楚发生故障时究竟发生了什么， 比如业务处理流程卡在了哪一步。</p><p>一个日志库大体可分为前端（frontend） 和后端（backend） 两部分。 前端是供应用程序使用的接口（API） ， 并生成日志消息（log<br>message） ； 后端则负责把日志消息写到目的地（destination）。   </p><p>在多线程程序中， 前端和后端都与单线程程序无甚区别， 无非是每个线程有自己的前端， 整个程序共用一个后端。 但难点在于将日志数据从多个前端高效地传输到后端。 <strong>这是一个典型的多生产者-单消费者问题</strong>， 对生产者（前端） 而言， 要尽量做到低延迟、 低CPU开销、 无阻塞； 对消费者（后端） 而言， 要做到足够大的吞吐量， 并占用较少资源。</p><p>对C++程序而言， 最好整个程序（包括主程序和程序库） 都使用相同的日志库， 程序有一个整体的日志输出， 而不要各个组件有各自的日志输出。 从这个意义上讲， 日志库是个singleton。  </p><h2 id="功能需求"><a href="#功能需求" class="headerlink" title="功能需求"></a>功能需求</h2><ul><li>日志消息有多种级别（ level） ， 如TRACE、 DEBUG、 INFO、WARN、 ERROR、 FATAL等。</li><li>日志消息可能有多个目的地（ appender） ， 如文件、 socket、SMTP等。</li><li>日志消息的格式可配置（ layout） ， 例如org.apache.log4j.PatternLayout。</li><li>可以设置运行时过滤器（ filter） ， 控制不同组件的日志消息的级别和目的地。</li></ul><p>在上面这几项中， 我认为除了第一项之外， 其余三项都是非必需的功能。  </p><p>日志的输出级别在运行时可调， 这样同一个可执行文件可以分别在QA测试环境的时候输出DEBUG级别的日志， 在生产环境输出INFO级<br>别的日志。调整日志的输出级别不需要重新编译， 也不需要重启进程。</p><p>对于分布式系统中的服务进程而言， 日志的目的地（ destination）只有一个： 本地文件。 <strong>往网络写日志消息是不靠谱的</strong>， 因为诊断日志的功能之一正是诊断网络故障。往网络写日志消息的另一个坏处是增加网络带宽消耗。</p><p>以本地文件为日志的destination， 那么<strong>日志文件的滚动（ rolling）是必需的</strong>， 这样可以简化日志归档的实现。 rolling的条件通常有两个： 文件大小（ 例如每写满1GB就换下一个文件） 和时间（ 例如每天零点新建一个日志文件， 不论前一个文件有没有写满） 。 muduo日志库的LogFile会自动根据文件大小和时间来主动滚动日志文件。</p><p>一个典型的日志文件的文件名如下：</p><pre><code>logfile_test.2012060-144022.hostname.3605.log</code></pre><p>文件名由以下几部分组成：  </p><ul><li>第1部分logfile_test是进程的名字。 通常是main()函数参数中argv[0]的basename(3)， 这样容易区分究竟是哪个服务程序的日志。 必要时还可以把程序版本加进去。</li><li>第2部分是文件的创建时间（GMT时区）。这样很容易通过文件名来选择某一时间范围内的日志， 例如用通配符*.20120603-14*表示2012年6月3日下午2点（GMT）左右的日志文件。</li><li>第3部分是机器名称。这样即便把日志文件拷贝到别的机器上也能追溯其来源。</li><li>第4部分是进程id。如果一个程序一秒之内反复重启， 那么每次都会生成不同的日志文件。</li><li>第5部分是统一的后缀名.log。同样是为了便于周边配套脚本的编写。</li></ul><p><strong>日志文件压缩与归档（archive）不是日志库应有的功能</strong>， 而应该交给专门的脚本去做， 这样C++和Java的服务程序可以共享这一基础设<br>施，并且更改时也不必动业务程序， 改改周边配套脚本就行了。 </p><p><strong>磁盘空间监控也不是日志库的必备功能。</strong> 有人或许曾经遇到日志文件把磁盘占满的情况， 因此希望日志库能限制空间使用，例如只分配10GB磁盘空间， 用满之后就冲掉旧日志， 重复利用空间。 殊不知如果出现程序死循环拼命写日志的异常情况， 那么往往是开头的几条日志最关键， 它往往反映了引发异常（busy-loop） 的原因（例如收到某条非法消息） ， 后面都是无用的垃圾日志。</p><p>往文件写日志的一个常见问题是， 万一程序崩溃， 那么最后若干条日志往往就丢失了， 因为日志库不能每条消息都flush硬盘， 更不能每条日志都open&#x2F;close文件，这样性能开销太大。 muduo日志库用两个办法来应对这一点， 其一是定期（默认3秒） 将缓冲区内的日志消息flush到硬盘； 其二是每条内存中的日志消息都带有cookie（或者叫哨兵值&#x2F;sentry） ， 其值为某个函数的地址， 这样通过在core dump文件中查找cookie就能找到尚未来得及写入磁盘的消息。</p><p>日志消息的格式是固定的， 不需要运行时配置， 这样可节省每条日志解析格式字符串的开销。 我认为日志的格式在项目的整个生命周期几乎不会改变。因为我们经常会为不同目的编写parse日志的脚本，可能要和一年之前的日志文件的同类数据做对比。如果在此期间日志格式变了， 势必会增加很多无谓的工作量。 如果真的需要调整消息格式， 直接修改代码并重新编译即可。</p><p>日志消息格式有几个要点：</p><ul><li>尽量每条日志占一行。 这样很容易用awk、 sed、 grep等命令行工具来快速联机分析日志， 比方说要查看“2012-06-03 08:02:00”至“2012-06-03 08:02:59”这1分钟内每秒打印日志的条数（直方图），可以运行$ grep -o ‘^20120603 08:02:..’ | sort | uniq -c</li><li>时间戳精确到微秒。 每条消息都通过gettimeofday(2)获得当前时间， 这么做不会有什么性能损失。 因为在x86-64 Linux上，gettimeofday(2)不是系统调用， 不会陷入内核。</li><li>始终使用GMT时区。 对于跨洲的分布式系统而言，可省去本地时区转换的麻烦（别忘了主要西方国家大多实行夏令时），更易于追查事件的顺序。</li><li>打印线程id。便于分析多线程程序的时序，也可以检测死锁。这里的线程id是指调用LOG_INFO &lt;&lt;的线程。</li><li>打印日志级别。在线查错的时候先看看有无ERROR日志，通常可加速定位问题。</li><li>打印源文件名和行号。修复bug的时候不至于搞错对象。</li></ul><p>muduo日志消息的默认格式如下：</p><pre><code class="test">日期      时间      微秒    线程   级别  正文    源文件名:行号20120603 08:02:46.125770Z 23261 INFO Hello - test.cc:51</code></pre><p>每行日志的前4个字段的宽度是固定的， 以空格分隔， 便于用脚本解析。 另外， 应该避免在日志格式（特别是消息id）中出现正则表达<br>式的元字符（meta character） ， 例如’[‘和’]’等等， 这样在用less(1)查看日志文件的时候查找字符串更加便捷。</p><p>运行时的日志过滤器（filter） 或许是有用的， 例如控制不同部件（程序库） 的输出日志级别， 但我认为这应该放到编译期去做， 整个程序有一个整体的输出级别就足够好了。 同时我认为一个程序同时写多个日志文件是非常罕见的需求， 这可以事后留给log archiver来分流， 不必做到日志库中。 不实现filter自然也能减小生成每条日志的运行时开销， 可以提高日志库的性能。</p><h2 id="性能需求"><a href="#性能需求" class="headerlink" title="性能需求"></a>性能需求</h2><p>高效性体现在几方面：</p><ul><li>每秒写几千上万条日志的时候没有明显的性能损失。</li><li>能应对一个进程产生大量日志数据的场景， 例如1GB&#x2F;min。</li><li>不阻塞正常的执行流程。</li><li>在多线程程序中， 不造成争用（contention） 。 这里列举一些具体的性能指标， 考虑往普通7200rpm SATA硬盘写日志文件的情况：磁盘带宽约是110MB&#x2F;s， 日志库应该能瞬时写满这个带宽（不必持续太久） 。</li></ul><p>以上是“高性能”日志库的最低指标。 如果磁盘带宽更高， 那么日志库的预期性能指标也会相应提高。  </p><p>muduo日志库在现在的PC上能写到每秒200万条消息， 带宽足够撑满两个千兆网连接或4个SATA组成的RAID10， 性能是达标的。<br>为了实现这样的性能指标， muduo日志库的实现有几点优化措施值得一提：</p><ul><li>时间戳字符串中的日期和时间两部分是缓存的， 一秒之内的多条日志只需重新格式化微秒部分。 </li><li>日志消息的前4个字段是定长的， 因此可以避免在运行期求字符串长度（不会反复调用strlen） 。 因为编译器认识memcpy()函数， 对于定长的内存复制， 会在编译期把它inline展开为高效的目标代码。</li><li>线程id是预先格式化为字符串， 在输出日志消息时只需简单拷贝几个字节。 见CurrentThread::tidString()。</li><li>每行日志消息的源文件名部分采用了编译期计算来获得basename， 避免运行期strrchr(3)开销。 见SourceFile class， 这里利用了gcc的内置函数。</li></ul><h2 id="多线程异步日志"><a href="#多线程异步日志" class="headerlink" title="多线程异步日志"></a>多线程异步日志</h2><p>线程安全的多线程日志的解决思路</p><ul><li>用一个全局锁保护IO，或者每个线程单独写一个日志文件。性能堪忧，前者造成所有线程抢占一个锁，后者会让业务线程阻塞在写磁盘操作上</li><li>每个进程只写一个日志文件，用一个背景线程负责收集日志消息，并写入日志文件，其他业务线程只需往这个日志线程中发送日志消息，称为“异步日志”(本文采用)</li></ul><p>在多线程服务程序中， 异步日志是必需的， 因为如果在网络IO线程或业务线程中直接往磁盘写数据的话，写操作偶尔可能阻塞长达数秒之久（原因很复杂， 可能是磁盘或磁盘控制器复位）。这可能导致请求方超时， 或者耽误发送心跳消息， 在分布式系统中更可能造成多米诺骨牌效应， 例如误报死锁引发自动failover等。 <strong>因此， 在正常的实时业务处理流程中应该彻底避免磁盘IO</strong>， 这在使用one loop per thread模型的非阻塞服务端程序中尤为重要， 因为线程是复用的， 阻塞线程意味着影响多个客户连接。</p><p>我们需要一个“队列”来将日志前端的数据传送到后端（日志线程） ， 但这个“队列”不必是现成的BlockingQueue&lt;std::string&gt;， 因为不<br>用每次产生一条日志消息都通知（notify()） 接收方。</p><p><strong>muduo日志库采用的是双缓冲（double buffering） 技术</strong>， 基本思路是准备两块buffer： A和B， 前端负责往buffer A填数据（日志消<br>息） ， 后端负责将buffer B的数据写入文件。 当buffer A写满之后， 交换A和B， 让后端将buffer A的数据写入文件， 而前端则往buffer B填入新的日志消息， 如此往复。   </p><p>用两个buffer的好处是在新建日志消息的时候不必等待磁盘文件操作， 也避免每条新日志消息都触发（唤醒） 后端日志线程。 换言之， 前端不是将一条条日志消息分别传送给后端， 而是将多条日志消息拼成一个大的buffer传送给后端， 相当于批处理， 减少了线程唤醒的频度， 降低开销。 另外， 为了及时将日志消息写入文件， 即便buffer A未满， 日志库也会每3秒执行一次上述交换写入操作。  </p><h2 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h2><p>Muduo日志的代码由 Logging.h&#x2F;cc, LogStream.h&#x2F;cc , LogFile.h&#x2F;cc , AsyncLogging.h&#x2F;cc 这四对组成。把整体分为三个模块来考虑：日志生成、多线程日志传递、日志打印。</p><h3 id="日志生成"><a href="#日志生成" class="headerlink" title="日志生成"></a>日志生成</h3><p>这一模块要做的工作就是接收用户的信息，将其与日志格式内的其他信息（日期、时间、线程、行号等）进行拼接组合，形成一条字符串，这个字符串就是最后要输出的日志。</p><h4 id="预定义宏"><a href="#预定义宏" class="headerlink" title="预定义宏"></a>预定义宏</h4><p>这部分由 Logging.h&#x2F;cc 以及 LogStream.h&#x2F;cc 组合完成。首先外部代码对日志库所有的访问入口都是通过定义好的宏来：</p><pre><code class="c++">//define后接if，可以在满足if的条件时才进行宏定义。\是换行符#define LOG_TRACE if (muduo::Logger::logLevel() &lt;= muduo::Logger::TRACE) \  muduo::Logger(__FILE__, __LINE__, muduo::Logger::TRACE, __func__).stream()#define LOG_DEBUG if (muduo::Logger::logLevel() &lt;= muduo::Logger::DEBUG) \  muduo::Logger(__FILE__, __LINE__, muduo::Logger::DEBUG, __func__).stream()#define LOG_INFO if (muduo::Logger::logLevel() &lt;= muduo::Logger::INFO) \  muduo::Logger(__FILE__, __LINE__).stream()#define LOG_WARN muduo::Logger(__FILE__, __LINE__, muduo::Logger::WARN).stream()#define LOG_ERROR muduo::Logger(__FILE__, __LINE__, muduo::Logger::ERROR).stream()#define LOG_FATAL muduo::Logger(__FILE__, __LINE__, muduo::Logger::FATAL).stream()#define LOG_SYSERR muduo::Logger(__FILE__, __LINE__, false).stream()#define LOG_SYSFATAL muduo::Logger(__FILE__, __LINE__, true).stream()</code></pre><p><strong>__FILE__，__LINE__是预定义宏，目的是获取文件名和行号</strong></p><p>标准C语言预处理要求定义某些对象宏，每个预定义宏的名称一两个下划线字符开头和结尾，这些预定义宏不能被取消定义（#undef）或由编程人员重新定义。</p><p>__LINE__  ：当前程序行的行号，表示为十进制整型常量<br>__FILE__  ：当前源文件名，表示字符串型常量<br>__DATE__ ：转换的日历日期，表示为Mmm dd yyyy 形式的字符串常量，Mmm是由asctime产生的。<br>__TIME__  ：转换的时间，表示”hh:mm:ss”形式的字符串型常量，是有asctime产生的。（asctime貌似是指的一个函数）<br>__STDC__ ：编辑器为ISO兼容实现时位十进制整型常量<br>__STDC_VERSION__  ：如何实现复合C89整部1，则这个宏的值为19940SL；如果实现符合C99，则这个宏的值为199901L；否则数值是未定义<br>__STDC_EOBTED__ ：(C99)实现为宿主实现时为1,实现为独立实现为0<br>__STDC_IEC_559__ ：(C99)浮点数实现复合IBC 60559标准时定义为1，否者数值是未定义<br>__STDC_IEC_559_COMPLEX__： (C99)复数运算实现复合IBC 60559标准时定义为1，否者数值是未定义<br>__STDC_ISO_10646__ ：(C99)定义为长整型常量，yyyymmL表示wchar_t值复合ISO 10646标准及其指定年月的修订补充，否则数值未定义<br>C++中还定义了 __cplusplus用来定义是否是C++编译器。<br><strong>另外 gcc还支持__func__,和__FUNCTION__</strong>,它指示所在的函数名，但是这个关键字不被windows下的vc6.0支持</p><p><strong>gcc还使用 __thread宏作为内置的线程局部存储设施</strong>，存取效率可以和全局变量相比，它只能修饰POD类型。**__thread变量每一个线程有一份独立实体**，各个线程的值互不干扰，可以用来修饰那些带有全局性且值可能变，但是又不值得用全局变量保护的变量。</p><p><strong>我们以 LOG_INFO 为例</strong></p><pre><code class="c++">// LOG_INFO &lt;&lt; &quot;This is a log.&quot;展开后如下muduo::Logger(__FILE__, __LINE__).stream() &lt;&lt; &quot;This is a log.&quot;</code></pre><p>将这句话放在日志打印的地方意味着什么呢？</p><ol><li>创建一个 Logger(<strong>FILE</strong>, <strong>LINE</strong>) 的匿名对象；</li><li>调用这个匿名对象的 stream() 成员函数；</li><li>调用重载后的 « 操作符，输入日志信息；</li><li>析构该匿名对象，析构函数内会调用真正的output日志信息函数。</li></ol><p>注意，匿名对象的析构发生在该条语句结束后，实际上在实现上，前3步的目的是整合拼接一条完整的日志信息，实际的日志打印动作就发生在第4步析构上。</p><blockquote><p>匿名对象一般会在语句结束后就析构，但如果用匿名对象初始化另外一个同类型的对象，匿名对象转成有名对象，此时匿名对象生命周期变成有名对象的生命周期，不会立即析构</p><p>用匿名对象赋值给另外一个同类型的对象，匿名对象在语句结束后被析构</p></blockquote><h4 id="相关类的代码"><a href="#相关类的代码" class="headerlink" title="相关类的代码"></a>相关类的代码</h4><h5 id="Logger"><a href="#Logger" class="headerlink" title="Logger"></a>Logger</h5><p>下面给出 Logger 类的整体结构：</p><pre><code class="c++">class Logger &#123;    public:    // 定义 LogLevel 枚举类型，注意最后会定义一个NUM_LOG_LEVELS，这是为了方便创建枚举数组    enum LogLevel &#123;        TRACE,        ...        NUM_LOG_LEVELS    &#125;        // SourceFile作用是编译期间从 __FILE__ 中获取文件basename，FILE宏是源文件路径，如/home/test.cpp，记录日志嫌长，代码中用strrchr截取最后一个/后面的名称。在编译时计算的原理是GCC的strrchr()对于字符串字面量可以在编译期求值。    class SourceFile &#123;        ...    &#125;         Logger(...);    LogStream&amp; stream() &#123;return impl_.stream_;&#125;     private:    // Impl 类封装了Logger私有的变量和函数，如文件名，行号，日志等级等等。    class Impl &#123;        ...    &#125;    Impl impl_;&#125;</code></pre><p>可以看到，整个 Logger 类主要由 3 个部分组成，分别是枚举类型的LogLevel，获取文件basename的SourceFile类，私有的Impl类。</p><p>我们从构造函数入手：</p><pre><code class="c++">Logger::Logger(SourceFile file, int line)  : impl_(INFO, 0, file, line)&#123;&#125;</code></pre><p>初始化一个 Logger 其实是初始化它的 Impl 内部对象，Logger对外的构造函数有很多，但内部类的构造函数只有一种，Logger不同的构造函数调用了相同的Impl的构造函数。</p><pre><code class="c++">Logger::Impl::Impl(LogLevel level, int savedErrno, const SourceFile&amp; file, int line)  : time_(Timestamp::now()),    stream_(),    level_(level),    line_(line),    basename_(file)&#123;  formatTime();  CurrentThread::tid();  stream_ &lt;&lt; T(CurrentThread::tidString(), CurrentThread::tidStringLength()); // T 类是helper class for known string length at compile time，把字符串和字符串的长度整合  stream_ &lt;&lt; T(LogLevelName[level], 6);  if (savedErrno != 0)  &#123;    stream_ &lt;&lt; strerror_tl(savedErrno) &lt;&lt; &quot; (errno=&quot; &lt;&lt; savedErrno &lt;&lt; &quot;) &quot;;  &#125;&#125;</code></pre><p>在构造过程中，首先通过 formatTime() 获取当前时间，并将时间格式化成年月日分秒微秒的形式，然后传递给 stream对象（输出到stream的缓冲区），接着将线程id和日志等级输出到stream缓冲区。</p><blockquote><p><strong>TIP:</strong> 对于一个时间信息： 20180426 14:50:34.345346Z，会将每次打印日志的时间中年月日秒的部分缓存在t_time[64] 这个变量里，同时还单独缓存了每次打印日志的时间中秒的部分，打印日志时会判断跟上次打印日志是不是同一秒，如果是同一秒则直接用缓存的信息，而不需要再重新获取时间并格式化。也就是说，同1s内打印的日志，只有微秒部分是需要被格式化的。这是为了提高性能，因为格式化非常耗时。</p></blockquote><p>构造完成后会将调用Logger的stream()函数返回stream，然后调用stream的&lt;&lt;运算符函数将要记录的日志输出到stream缓冲区，如LOG_INFO &lt;&lt; “This is a log.”中的”This is a log.”</p><p>最后看下析构 Logger 这个匿名对象会发生什么事。</p><pre><code class="c++">Logger::~Logger()&#123;  impl_.finish();  const LogStream::Buffer&amp; buf(stream().buffer());  g_output(buf.data(), buf.length());  // 日志输出函数，可设置  if (impl_.level_ == FATAL)   &#123;    g_flush();  // 日志flush 函数，可设置    abort();  &#125;&#125;</code></pre><p>finish函数会把文件名和行号输出到stream缓冲区，接着析构函数会调用 g_output() 将stream缓冲区的日志输出(默认输出到stdout，如果需要输出到日志文件中需要在使用前设置output函数)。</p><p>这样就完成了一条日志语句的生成，最后生成的日志格式如下：</p><pre><code class="test">日期      时间      微秒    线程   级别  正文    源文件名:行号20120603 08:02:46.125770Z 23261 INFO Hello - test.cc:51</code></pre><h5 id="LogStream"><a href="#LogStream" class="headerlink" title="LogStream"></a>LogStream</h5><p>LogStream是muduo自己实现的流，不用iostream是因为iostream的效率低 </p><p>相关类的结构为：</p><pre><code class="c++">class LogStream &#123;    typedef detail::FixedBuffer&lt;detail::kSmallBuffer&gt; Buffer;    Buffer buffer_;         self&amp; operator&lt;&lt;(const string&amp; v);    self&amp; operator&lt;&lt;(...);&#125; template&lt;int SIZE&gt;class FixedBuffer &#123;    char data_[SIZE];    char* cur_;   // cur_ 指针指向data_数组中有效数据的尾部。     void append(...);     const char* data() const &#123;return data_;&#125;    int length() const &#123;return static_cast&lt;int&gt;(cur_-data_);&#125;&#125;</code></pre><p><code>LogStream</code>在构造过程中，会初始化一个 <code>FixedBuffer</code> 对象，其中又初始化一个<code>char</code>数组（大小为预先定义的 <code>kSmallBuffer : 4k</code>）。 然后通过重载的操作符，将信息写入到这个数组中。其中<code>Buffer</code>对象提供 <code>data()</code> 和 <code>length()</code> 接口供<code>Logger</code>类使用。</p><p>可以看到<code>Buffer</code>提供的<code>append()</code>接口入参是<code>const char* buf, size_t len</code>，然后内部通过 <code>memcpy</code> 来复制字符串。</p><blockquote><p><strong>TIP:</strong> 回顾 Logger，日志信息的固定格式都为定长的，通过 T 传入stream，这样就直接通过memcpy来拷贝，避免了每次通过 strlen 来获取字符串长度，提高了效率</p></blockquote><h3 id="多线程日志传递"><a href="#多线程日志传递" class="headerlink" title="多线程日志传递"></a>多线程日志传递</h3><h4 id="AsyncLogging"><a href="#AsyncLogging" class="headerlink" title="AsyncLogging"></a>AsyncLogging</h4><p>我们可以很容易的抽象出来一个异步日志库的模式：N个业务线程通过接口将日志信息推送到一个结构内；1 个日志打印线程从这个结构中顺序地打印日志到文件中。这是因为将数据存储到磁盘很耗费时间，所以应该有单独的后台线程来做这件事情，不能阻塞前台线程的运行。</p><p>这是一个很典型的多生产者、单消费者场景。这种场景考虑的点无非就三个方向</p><ol><li>生产者吞吐能力；</li><li>生产者消费者如何高效传递数据；</li><li>消费者吞吐能力。</li></ol><p>Muduo这部分的内容在 AsyncLogging.h&#x2F;cc 中。下面给出 AsyncLogging 类的大体结构。</p><pre><code class="c++">class AsyncLogging &#123;public:    AsyncLogging(...);    ~AsyncLogging() &#123; ..stop()..&#125;;     void append(const char* logline, int len);  // 供 Logger 注册的接口     void start();  // 启动线程    void stop();   // 关闭线程 private:    void threadFunc();  // 异步线程处理逻辑     BufferPtr  currentBuffer_;  // 当前写入的 buffer    BufferPtr  nextBuffer_;     // 下一个备用 buffer    BufferVector  buffers_;     // 写入完毕，待打印的 buffer 集合</code></pre><p>多线程使用AsyncLogging需要一个共享的AsyncLogging对象(单例或全局变量)，并在使用前设置Logger类的output类函数，将函数设置为调用AsyncLogging的append函数将生成的日志存入AsyncLogging的缓冲区。</p><pre><code class="c++">void asyncOutput(const char* msg, int len)&#123;  g_asyncLog-&gt;append(msg, len);&#125;muduo::Logger::setOutput(asyncOutput);</code></pre><p>AsyncLogging的重点是 append 和 threadFunc 函数，前者负责收集业务线程发来的日志消息存储到buffer中，后者是单独的线程，它负责调控 buffer，并调用Logfile将buffer的日志存入到文件中。</p><p>我们称 append 为前台，threadFunc 后台，Muduo logging 的思想为，前台、后台分别 持有 2 个 buffer 和一个 buffervector，buffer暂时缓存写入的日志，buffervector则是存放即将打印的buffer。前台写满一个buffer后，放入它的buffervector，并通知后台，后台来处理buffer的交换和填充。</p><pre><code class="c++">void AsyncLogging::append(const char* logline, int len)&#123;    muduo::MutexLockGuard lock(mutex_);    if (currentBuffer_-&gt;avail() &gt; len)&#123;       // 当前buffer空间够,直接将日志写入        currentBuffer_-&gt;append(logline, len);     &#125; else &#123;        buffers_.push_back(currentBuffer_.release());       // buffer空间不够，代表该buffer已满，该打印了，放入vector        if (nextBuffer_)&#123;       // currentBuffer_放入vector后，若nextBuffer_ 不为空，将nextBuffer_转移给currentBuffer_        currentBuffer_ = boost::ptr_container::move(nextBuffer_);        &#125; else &#123;  // 没有可用 buffer，当短时间之内要输出的日志太多，消费者来不及消费时发生，直接new 一个给currentBuffer_        currentBuffer_.reset(new Buffer);        &#125;        currentBuffer_-&gt;append(logline, len);        cond_.notify();   // 通知后台事件发生，vector不为空，可以取数据打印    &#125;&#125;</code></pre><p>这里还少了的逻辑就是何时 next_buffer 会被填充。看 threadFunc() 的代码:</p><pre><code class="c++">void AsyncLogging::threadFunc() &#123;    BufferPtr newBuffer1(new Buffer);    BufferPtr newBuffer2(new Buffer);    BufferVector buffersToWrite;    LogFile output(basename_, rollSize_, false);    while (running_) &#123;        &#123;            muduo::MutexLockGuard lock(mutex_);            if (buffers_.empty())  // vector为空则等待，需要注意这是if不是while，这是为了每隔一个flush间隔就打印一次            &#123;                cond_.waitForSeconds(flushInterval_);  // 条件变量，等一个flush间隔或者前台唤醒(buffer满时)            &#125;            buffers_.push_back(std::move(currentBuffer_));  // 把当前在写的 buffer 也放到vector中            currentBuffer_ = std::move(newBuffer1);  // 把 newbuffer1 移交给 currBuffer            buffersToWrite.swap(buffers_);   // 将vector和空的后台vector进行交换，相当于将vector中的数据先进行转移再处理，这是为了减少临界区的时间。若直接用vector打印，那么在取数据的时候，append无法将数据添加到vector中            if (!nextBuffer_)&#123;   // 若nextBuffer为空，移交 newbuffer2 给前台 nextBuffer                nextBuffer_ = std::move(newBuffer2);;            &#125;        &#125;        if (buffersToWrite.size() &gt; 25) //堆积的日志过多时直接丢弃，只保留前面两块缓冲区的日志        &#123;              char buf[256];              snprintf(buf, sizeof buf, &quot;Dropped log messages at %s, %zd larger buffers\n&quot;,                   Timestamp::now().toFormattedString().c_str(),                   buffersToWrite.size()-2);              fputs(buf, stderr);              output.append(buf, static_cast&lt;int&gt;(strlen(buf)));              buffersToWrite.erase(buffersToWrite.begin()+2, buffersToWrite.end());        &#125;        for (const auto&amp; buffer : buffersToWrite)        &#123;              output.append(buffer-&gt;data(), buffer-&gt;length()); //将vector中的每个buffer调用Logfile输出        &#125;        if (!newBuffer1)&#123;              newBuffer1 = std::move(buffersToWrite.back()); //输出完的buffer还给newBuffer1，重复利用buffer，避免重新申请空间              buffersToWrite.pop_back();              newBuffer1-&gt;reset();        &#125;        if (!newBuffer2)&#123;            newBuffer2 = buffersToWrite.pop_back(); //输出完的buffer还给newBuffer2，重复利用buffer，避免重新申请空间            newBuffer2-&gt;reset();        &#125;      &#125;&#125;</code></pre><p>可以看到AsyncLogging一共有4个buffer，前台生产者两个，后台消费者两个，前台正常情况下最多能同时写满两个buffer，若日志生产过多消费者速度跟不上时会直接申请空间作为新的buffer。后台两个buffer是作为前台buffer的备用，后台在从前台buffer取数据时会将后台空的buffer给前台使用，而前台的buffer取完数据之后就放在后台作为备用，这样就把4个buffer循环利用起来了。</p><p><strong>如果日志堆积过多时会直接丢弃后面的日志</strong>，只保留前面两个缓冲区的日志。</p><p><strong>值得一提的是这里大量使用了交换指针的技巧来避免生产者和消费者之间的竞争</strong>，消费者在从buffer取数据时不会直接取出，而是先将buffer的指针跟空的buffer进行交换，再取出数据，这样消费者在取数据的同时还不影响生产者的生产，减少了临界区的竞争。</p><h3 id="日志打印"><a href="#日志打印" class="headerlink" title="日志打印"></a>日志打印</h3><p>使用是 fwrite_unlocked()(因为是单独的线程负责打印，不涉及到多线程，所以不需要加锁) 和 fflush() 接口。</p><p>打印时会记录打印的数据大小和时间，以便于日志滚动。日志滚动会自动根据文件大小和时间来主动生成新的日志文件。</p><h2 id="其他方案"><a href="#其他方案" class="headerlink" title="其他方案"></a>其他方案</h2><p>当然在前端和后端之间高效传递日志消息的办法不止这一种， <strong>比方说使用常规的消息队列</strong>BlockingQueue&lt;std::string&gt;在前后端之间传递日志消息， 其中每个std::string是一条消息。 这种做法每条日志消息都要分配内存， 特别是在前端线程分配的内存要由后端线程释放， 因此对malloc的实现要求较高， 需要针对多线程特别优化。 另外， 如果用这种方案， 那么需要修改LogStream的Buffer， 使之直接将日志写到std::string中， 可节省一次内存拷贝。</p><p>muduo现在的异步日志实现用了一个全局锁。 尽管临界区很小， 但是如果线程数目较多， 锁争用（lock contention） 也可能影响性能。 <strong>一种解决办法是像Java的ConcurrentHashMap那样用多个桶子（bucket） ， 前端写日志的时候再按线程id哈希到不同的bucket中</strong>， 以减少锁的争用。这种方案的后端实现较为复杂。为了简化实现， 目前muduo日志库只允许指定日志文件的名字， 不允许指定其路径。 日志库会把日志文件写到当前路径， 因此可以在启动脚本（shell脚本）里改变当前路径， 以达到相同的目的。Linux默认会把core dump写到当前目录， 而且文件名是固定的core。 <strong>为了不让新的core dump文件冲掉旧的， 我们可以通过sysctl设置kernel.core_pattern参数</strong>（也可以修改 ） ， 让每次core dump都产生不同的文件。 例如设为%e.%t.%p.%u.core， 其中各个<br>参数的意义见man 5 core。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>与Log相关的类包括FileUtil、LogFile、AsyncLogging、LogStream、Logging。 其中前4个类每一个类都含有一个append函数，Log的设计也是主要围绕这个<strong>append</strong>函数展开的。</p><ul><li>FileUtil是最底层的文件类，封装了Log文件的打开、写入并在类析构的时候关闭文件，底层使用了标准IO，该append函数直接向文件写。</li><li>LogFile进一步封装了FileUtil，并设置了一个循环次数，每过这么多次就flush一次。</li><li>AsyncLogging是核心，它负责启动一个log线程，专门用来将log写入LogFile，应用了“双缓冲技术”，其实有4个以上的缓冲区，但思想是一样的。AsyncLogging负责(定时到或被填满时)将缓冲区中的数据写入LogFile中。</li><li>LogStream主要用来格式化输出，重载了&lt;&lt;运算符，同时也有自己的一块缓冲区，这里缓冲区的存在是为了缓存一行，把多个&lt;&lt;的结果连成一块。</li><li>Logging是对外接口，Logging类内涵一个LogStream对象，主要是为了每次打log的时候在log之前和之后加上固定的格式化的信息，比如打log的行、文件名等信息。</li></ul><h2 id="实现中用到的技术"><a href="#实现中用到的技术" class="headerlink" title="实现中用到的技术"></a>实现中用到的技术</h2><p>1.用枚举表示日志级别，有限种类的物品都可以用枚举表示；枚举中最后一个变量设置为NUM_LOG_LEVELS，这是为了方便创建数组，代码中最好不要直接出现数字，可以将数字代替为变量，这样方便后续修改。</p><pre><code class="c++">enum LogLevel&#123;  TRACE,  DEBUG,  INFO,  WARN,  ERROR,  FATAL,  NUM_LOG_LEVELS,&#125;;const char* LogLevelName[Logger::NUM_LOG_LEVELS] =&#123;  &quot;TRACE &quot;,  &quot;DEBUG &quot;,  &quot;INFO  &quot;,  &quot;WARN  &quot;,  &quot;ERROR &quot;,  &quot;FATAL &quot;,&#125;;</code></pre><p>2.使用宏定义将创建匿名对象并调用函数的过程简化，简化了接口，方便用户使用。</p><pre><code class="c++">#define LOG_TRACE if (muduo::Logger::logLevel() &lt;= muduo::Logger::TRACE) \  muduo::Logger(__FILE__, __LINE__, muduo::Logger::TRACE, __func__).stream()</code></pre><p>3.使用预定义宏__FILE__，__LINE__等，方便的获取文件名和行号。</p><p>4.在编译期计算文件的basename，原理还需研究。</p><p>5.使用了内部类，适合什么场景使用还需研究。</p><p>6.使用getenv()获取环境变量进行初始化。</p><p>7.比较复杂的类型或者需要改名方便看出用途的类型，用typedef或using来简化。</p><pre><code class="c++">typedef muduo::detail::FixedBuffer&lt;muduo::detail::kLargeBuffer&gt; Buffer;typedef std::vector&lt;std::unique_ptr&lt;Buffer&gt;&gt; BufferVector;typedef BufferVector::value_type BufferPtr;</code></pre><p>8.使用clang的注解进行检查，防止出错，具体参考clang线程安全注解文档。</p><pre><code class="c++">muduo::Condition cond_ GUARDED_BY(mutex_);BufferPtr currentBuffer_ GUARDED_BY(mutex_);BufferPtr nextBuffer_ GUARDED_BY(mutex_);BufferVector buffers_ GUARDED_BY(mutex_);</code></pre><p>9.线程析构前先join。</p><p>10.在vector中用unique_ptr保存变量，这样做的好处是保证存储的变量只有一份，而且外界传入时必须使用std::move()，这样会调用移动构造函数提高效率。</p><pre><code class="c++">std::vector&lt;std::unique_ptr&lt;Buffer&gt;&gt; BufferVector;</code></pre><p>11.在使用缓冲区前，先调用bzero函数初始化缓冲区为0。</p><p>12.使用static_cast和implicit_cast进行类型转换，保证类型转换的安全性。</p><p>13.不使用可重入锁，而使用不可重入锁+一个函数分为加锁版和无锁版。</p><p>14.使用全局变量和全局函数时，在前面加上::</p><p>15.使用main函数的arcv[0]获取文件名</p><pre><code class="c++">//argv是参数数组，其中argv[0]存储了文件的全名(包括路径)，argc是数组中变量的个数int main(int argc, char* argv[])&#123;  strncpy(name, argv[0], sizeof name - 1);&#125;</code></pre><p>16.使用和空变量交换的方式来处理生产者和消费者之间的共享变量，这样可以有效减少竞争</p><p><strong>实现中涉及的函数</strong></p><ul><li><p>fflush()，C 库函数 <strong>int fflush(FILE *stream)</strong> 刷新流 stream 的输出缓冲区。</p></li><li><p>fwrite()，C 库函数 <strong>size_t fwrite(const void *ptr, size_t size, size_t nmemb, FILE *stream)</strong> 把 <strong>ptr</strong> 所指向的数组中的数据写入到给定流 <strong>stream</strong> 中。</p></li><li><p>sprintf()，C 库函数 <strong>int sprintf(char *str, const char *format, …)</strong> 发送格式化输出到 <strong>str</strong> 所指向的字符串。</p></li><li><p>getenv()，C 库函数 <strong>char *getenv(const char *name)</strong> 搜索 name 所指向的环境字符串，并返回相关的值给字符串。</p></li><li><p>strrchr()，C 库函数 <strong>char *strrchr(const char *str, int c)</strong> 在参数 <strong>str</strong> 所指向的字符串中搜索最后一次出现字符 <strong>c</strong>（一个无符号字符）的位置。</p></li><li><p>vector.reserve()，用于初始化vector的大小；vector.resize()函数用于修改vector的大小，若修改后更小，会删除后面多出的元素。</p><p>reserve是容器预留空间，但并不真正创建元素对象，在创建对象之前，不能引用容器内的元素，因此当加入新的元素时，需要用push_back()&#x2F;insert()函数。</p><p>resize是改变容器的大小，并且创建对象，因此，调用这个函数之后，就可以引用容器内的对象了，因此当加入新的元素时，用operator[]操作符，或者用迭代器来引用元素对象。</p></li></ul><p><strong>为了实现性能指标，本日志设计中几点优化：</strong></p><ul><li>时间戳字符串中的日期和时间两部分是缓存的,一秒之内的多条日志只需格式化微妙即可</li><li>日志消息的前四段是定长的,可避免运行时字串长度的计算</li><li>线程id是预先格式化的字符串</li><li>原文件名部分通过编译期计算来获得,避免运行期strrchr()的开销</li><li>单独的io线程负责持久化日志数据到磁盘，工作线程只将日志写入缓冲区，这样不会影响工作线程的效率</li><li>使用多缓冲设计，有效提高效率</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/Linux%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%BC%96%E7%A8%8B%EF%BC%9A%E4%BD%BF%E7%94%A8muduo%20C++%E7%BD%91%E7%BB%9C%E5%BA%93/"/>
      <url>/2023/01/22/Linux%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%BC%96%E7%A8%8B%EF%BC%9A%E4%BD%BF%E7%94%A8muduo%20C++%E7%BD%91%E7%BB%9C%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux多线程服务端编程：使用muduo-C-网络库"><a href="#Linux多线程服务端编程：使用muduo-C-网络库" class="headerlink" title="Linux多线程服务端编程：使用muduo C++网络库"></a>Linux多线程服务端编程：使用muduo C++网络库</h1><h2 id="线程安全的对象生命期管理"><a href="#线程安全的对象生命期管理" class="headerlink" title="线程安全的对象生命期管理"></a>线程安全的对象生命期管理</h2><h3 id="class线程安全的三个条件"><a href="#class线程安全的三个条件" class="headerlink" title="class线程安全的三个条件"></a><strong>class线程安全的三个条件</strong></h3><ul><li>多个线程访问表现出正确的行为</li><li>无论操作系统如何调度，以及线程的执行顺序如何</li><li>调用端代码不需要额外的同步与协调动作</li></ul><p>由此，STL大多数的class都不是线程安全的，需要外部加锁才能同时访问</p><h3 id="线程安全的对象构造方法"><a href="#线程安全的对象构造方法" class="headerlink" title="线程安全的对象构造方法"></a><strong>线程安全的对象构造方法</strong></h3><ul><li>不要在构造函数中注册任何回调</li><li>不要在构造函数把this指针传给跨线程的对象,最后一行也不行</li></ul><p>原因:构造期间对象还没有完成初始化，this泄漏给了别的对象（自身创建的子对象除外），别的线程有可能访问这个半成品对象。即使构造函数的最后一行也不要泄露 this，因为 Foo 有可能是个基类，基类先于派生类构造，执行完 Foo::Foo() 的最后一行代码还会继续执行派生类的构造函数，这时派生类的对象还处于构造中，仍然不安全。  </p><h3 id="线程安全的对象析构方法"><a href="#线程安全的对象析构方法" class="headerlink" title="线程安全的对象析构方法"></a><strong>线程安全的对象析构方法</strong></h3><p>析构函数中不宜使用锁：</p><ul><li>调用析构函数的时候，正常逻辑来说这个对象已经没有其他线程在使用了，用锁也没有效果；</li><li>即使使用了锁，析构函数抢到了锁，其他线程还在等待这个锁，析构函数中锁被析构掉了，其他线程就是未定义行为。</li></ul><h3 id="使用指针时该如何判断指针是否还存活"><a href="#使用指针时该如何判断指针是否还存活" class="headerlink" title="使用指针时该如何判断指针是否还存活"></a><strong>使用指针时该如何判断指针是否还存活</strong></h3><p>我们无法保证执行一个对象的成员函数时这个对象没有被析构，即使在析构后将对象指针置nullptr也一样。</p><pre><code class="c++">//线程A~P()&#123;    delete xxx;    this = nullptr;&#125;//线程Bif(p != nullptr) //执行完这一步后去执行线程A&#123;    p-&gt;update();&#125;</code></pre><p>如上完全可以在线程B执行完判空语句进入循环后，转而执行线程A的析构函数，从而导致线程B对空指针操作。</p><p>以观察者模式为例，observer对象注册自己到Observable，后者保存有前者的指针，一旦某个事件发生，Observable就通过observer指针调用其成员方法。多线程情况下，Observable无法得知当前调用的observer指针是否还有效，即使使用锁也不行。</p><p>解决方法：使用智能指针。使用weak_ptr保存指针，可以清楚的知道指针是否存活：如果weak_ptr可以转化为shared_ptr，证明指针还有效，否则无效。不打算决定对象的生死，就使用weak_ptr管理对象指针；否则使用shared_ptr。</p><p>即使能判断指针是否存活，即不会存在使用已经销毁或者正在销毁的指针了！但是不代表没有其他问题：<br>（1）锁争用造成的延时；<br>（2）死锁。</p><p>如果同时读写一个class的两个对象，会存在死锁现象，比如swap（a,b)与swap(b,a)在两个线程中同时执行，会发生死锁。swap(a,b)先给a上锁，swap(b,a)先给b上锁，这两个函数并发执行时，可能会出现swap(a,b)拿到a锁swap(b,a)拿到b锁的死锁情况。(哲学家进餐问题)</p><p>解决办法：使用相同的顺序加锁，如根据对象地址大小来决定顺序。</p><h3 id="如何减少锁争用造成的延迟。"><a href="#如何减少锁争用造成的延迟。" class="headerlink" title="如何减少锁争用造成的延迟。"></a><strong>如何减少锁争用造成的延迟。</strong></h3><p>使用锁会降低程序的效率，使得并行的程序串行化，解决锁争用的方法是：尽量减少临界区的大小；<br>解决方法：local copy的方式，在临界区外创建副本。（<strong>适用于拷贝代价不大的对象</strong>）</p><blockquote><p>读操作，临界区内拷贝出来，临界区外使用副本读取；</p></blockquote><blockquote><p>写操作，临界区外定义副本，完成要完成的操作，临界区内直接赋值或者swap；</p></blockquote><pre><code class="c++">void read()&#123;    shared_ptr&lt;Foo&gt; localPtr;    &#123;        MutexLockGuard lock(mutex);        localPtr = globalPtr; //将全局对象拷贝一份给本地副本    &#125;    do(localPtr);&#125;void write()&#123;    shared_ptr&lt;Foo&gt; newPtr(new Foo); //在临界区外创建新对象    &#123;        MutexLockGuard lock(mutex);        globalPtr = newPtr; //将新对象拷给全局对象    &#125;    do(newPtr);&#125;</code></pre><p>注意到上面的read()和write()在临界区之外都没有再访问globalPtr，而是用了一个指向同一Foo对象的本地副本。这样可以避免在临界区内创建和析构，减少了临界区大小。 </p><h3 id="shared-ptr的使用技巧与坑"><a href="#shared-ptr的使用技巧与坑" class="headerlink" title="shared_ptr的使用技巧与坑"></a>shared_ptr的使用技巧与坑</h3><p>坑：</p><p>1.shared_ptr会延长对象的生命周期。</p><p> 某些函数实参采用非引用类型shared_ptr类型，调用这个函数的时候就会发生shared_ptr的拷贝操作，使得对象指针的引用计数值变大。如果这个函数返回一个对象，这个对象也中也存在这个shared_ptr的指针，那么shared_ptr对象的声明周期就被延长了。</p><p>例子：std::bind函数，基本作用是，为一个函数指针提供默认参数。其实参就会被拷贝一份出来。（模板参数，不论什么类型都会发生拷贝行为）</p><p>2.shared_ptr的拷贝代价比指针要大。<br>毕竟还要保存引用计数等变量，修改引用计数等行为。（建议使用引用传递）</p><p>3.不能同时使用两个shared_ptr，容易引起误会；<br> 类内（成员函数）使用shared_ptr<this>与类外使用shared_ptr同时使用时，会造成析构两次的问题。<br> 解释：类内部使用share_ptr<this>的需求可以使用：shared_from_this() 代替this;</p><p>4.shared_ptr<T>的线程安全性，它的线程安全性级别和std::string是一样的。它的计数操作是原子操作，但是多线程对它的并发读写是不安全的，因为他有两个操作，一个是修改地址一个是修改计数。可以想一下，现在有一个智能指针x指向一片内存，先对它读，比如y&#x3D;x;，读一半（只修改了y的地址，但是计数还是1），此时再进行写操作，比如x&#x3D;z，全部执行完，那么x指向z的内存，x原来指的内存因为计数减一被释放，这时再进行y&#x3D;x读操作的另一半（计数加一），但是内存已经释放了。 </p><p>所以多线程读写shared_ptr<T>需要保护临界区。 </p><p>使用技巧：</p><ol><li><p>作为函数参数时，建议使用const reference传递;</p></li><li><p>在创建shared_ptr对象时，可以手动指定析构函数，这样可以保证可以跨dll来删除。</p><p>解释：windows下的进程会有好几个堆，每个dll都会有一个堆，一个堆里申请的需要在这个堆释放，所以存在跨模块释放的问题；shared_ptr通过指定析构函数，使得释放时，可以释放对应堆的对象。</p></li><li><p>shared_ptr的析构如果可能发生在关键进程，可以用一个专门的线程来处理析构，使用BlockQueue<shared_ptr>来转移对象到析构线程；</p></li><li><p>ower持有指向child的shared_ptr，child持有指向ower的weak_ptr；<br> 解释：ower可以决定子对象的生死，child只负责使用，不可以控制父对象的生死</p></li></ol><h3 id="对象池中需要注意的点"><a href="#对象池中需要注意的点" class="headerlink" title="对象池中需要注意的点"></a>对象池中需要注意的点</h3><p>场景：对象池A类中包含了很多B类对象。B类对象可以是暂存在A类中的，用于回调；也可能是被A类所使用。</p><p><strong>需求：A类中的B类对象如果不使用了及时释放掉，以节省内存。不使用了的概念是没有线程在使用了</strong></p><p>第一版：</p><pre><code class="c++">class Item &#123;&#125;;class Factory &#123;private:  std::map&lt;std::string, shared_ptr&lt;Item&gt;&gt; data_;  mutable std::mutex lock_;public:shared_ptr&lt;Item&gt;  get(const std::string&amp; key);    //使用shared_ptr作为返回值，因为出去使用的对象认为不能随便释放掉。&#125;;</code></pre><p>这一版存在的问题是使用shared_ptr保存Item对象，这会导致Item对象的生命周期由Factory控制，有可能一直无法析构，显然与需求不符。</p><p>可以使用weak_ptr来解决这个问题。</p><p>第二版：</p><pre><code class="c++">class Item &#123;&#125;;class Factory &#123;private:  std::map&lt;std::string, weak_ptr&lt;Item&gt;&gt; data_;  mutable std::mutex lock_;public:shared_ptr&lt;Item&gt;  get(const std::string&amp; key)&#123;  shared_ptr&lt;Item&gt; ret;  lock_.lock();  ret = data_[key].lock(); //weak提升为shared_ptr  if(!ret) &#123;      ret.reset(new Item());      data_[key] = ret;  &#125;  lock_.unlock();  return ret;    &#125;&#125;;</code></pre><p>解决了第一版的问题，Item可以正常析构了，但是仍有一个问题存在。Item析构后，不会在Factory的map中将对应的Item erase掉，这会导致即使Item析构了，map的size也不会减少，所以析构后还必须在Factory的map中将对应的Item erase掉。</p><p>可以给shared_ptr定制析构函数来实现。</p><p>第三版：</p><pre><code class="c++">class Item &#123;&#125;;class Factory &#123;private:    std::map&lt;std::string, weak_ptr&lt;Item&gt;&gt; data_;    mutable std::mutex lock_;    void deleteItem(Item* item)    &#123;        if(item)        &#123;            lock_.lock();            data_.erase(item-&gt;key());        &#125;        delete item;    &#125;public:    shared_ptr&lt;Item&gt;  get(const std::string&amp; key)    &#123;      shared_ptr&lt;Item&gt; ret;      lock_.lock();      ret = data_[key].lock(); //weak提升为shared_ptr      if(!ret) &#123;        ret.reset(new Item(),std::bind(&amp;Factory::deleteItem,this,_1));        data_[key] = ret;      &#125;      lock_.unlock();      return ret;        &#125;   &#125;;</code></pre><p>如上在Factory中get函数创建Item时用std::bind绑定Item的定制析构函数，在shared_ptr析构时自动调用。但这仍存在问题，Item析构时需要调用Factory的deleteItem方法，但Item析构时Factory可能已经不存在。</p><p>解决方法是延长Factory的生命周期，使用shared_ptr保存Factory的this指针，同时Factory必须保存在堆上，栈对象的生命周期是无法控制的(同理栈对象也不能用于多线程，因为生命周期无法控制)</p><p>第四版：</p><pre><code class="c++">class Factory : public std::enable_shared_from_this&lt;Factory&gt; &#123;    //必须继承这个类；     //类内部需要使用shared_ptr&lt;this&gt;的地方，使用shared_from_this()来代替。     //类内部需要使用weak_ptr&lt;this&gt;的地方，使用std::weak_ptr&lt;Factory&gt;(shared_from_this())就好了（就是使用shared_from_this()来生成了下weak_ptr()）    //ret.reset(new Item(),std::bind(&amp;Factory::deleteItem,this,_1))变为    //ret.reset(new Item(),std::bind(&amp;Factory::deleteItem,shared_from_this(),_1))&#125;;</code></pre><p>enable_shared_from_this这是一个以其派生类为模板类型实参的基类模板， 继承它之后， 用shared_from_this()就可以表示shared_ptr<this>。</p><p>现在仍存在最后一个问题，std::bind中绑定了Factory的shared_ptr<this>，这会导致Factory的生命周期被延长，从而导致Factory无法析构。</p><p>解决方法是将shared_ptr<this>改为weak_ptr<this>，这样就不会延长Factory的生命周期了，在Item析构前先通过weak_ptr<this>判断Factory是否存在。</p><p>第五版：</p><pre><code class="c++">class Factory : public std::enable_shared_from_this&lt;Factory&gt; &#123;    //必须继承这个类；     //类内部需要使用shared_ptr&lt;this&gt;的地方，使用shared_from_this()来代替。     //类内部需要使用weak_ptr&lt;this&gt;的地方，使用std::weak_ptr&lt;Factory&gt;(shared_from_this())就好了（就是使用shared_from_this()来生成了下weak_ptr()）    //ret.reset(new Item(),std::bind(&amp;Factory::deleteItem,shared_from_this(),_1))变为    //ret.reset(new Item(),std::bind(&amp;Factory::deleteItem,std::weak_ptr&lt;Factory&gt;(shared_from_this()),_1))    //在deleteItem增加通过weak_ptr判断Factory是否存在的步骤。&#125;;</code></pre><p>这种技术称为弱回调</p><h3 id="多线程编程建议"><a href="#多线程编程建议" class="headerlink" title="多线程编程建议"></a>多线程编程建议</h3><p>尽量减少使用跨线程的对象 ，用流水线， 生产者消费者， 任务队列这些有规律的机制， 最低限度地共享数据。 这是我所知最好的多线程编程的建议了  </p><h2 id="线程同步精要"><a href="#线程同步精要" class="headerlink" title="线程同步精要"></a>线程同步精要</h2><h3 id="线程同步原则"><a href="#线程同步原则" class="headerlink" title="线程同步原则"></a>线程同步原则</h3><p>线程同步的四项原则，按重要性排列：</p><ol><li>首要原则是尽量最低限度地共享对象，减少需要同步的场合。一个对象能不暴露给别的线程就不要暴露；如果要暴露，优先考虑const对象；实在不行才暴露可修改的对象，并用同步措施来充分保护它。</li><li>其次是使用高级的并发编程构件，如任务队列TaskQueue、生产者消费者队列Producer Consumer Queue、倒计时锁存器CountDownLatch等等。</li><li>最后不得已必须使用底层同步原语（primitives）时，只用非递归的互斥器和条件变量，慎用读写锁，不要用信号量。</li><li>除了使用atomic整数之外，不自己编写lock-free代码，也不要用“内核级”同步原语。不凭空猜测“哪种做法性能会更好”，比如spin lock vs. mutex。</li></ol><h3 id="mutex的使用建议"><a href="#mutex的使用建议" class="headerlink" title="mutex的使用建议"></a>mutex的使用建议</h3><p>主要原则：</p><ul><li>用RAII手法封装mutex的创建、销毁、加锁、解锁这四个操作。即保证锁的生效期间等于一个作用域（scope），不会因异常而忘记解锁。</li><li>只用非递归的mutex（即不可重入的mutex)。</li><li>不手工调用lock()和unlock()函数，一切交给栈上的Guard对象的构造和析构函数负责。Guard对象的生命期正好等于临界区。这样我们保证始终在同一个函数同一个scope里对某个mutex加锁和解锁。避免在foo()里加锁，然后跑到bar()里解锁；也避免在不同的语句分支中分别加锁、解锁。这种做法被称为Scoped Locking。</li><li>在每次构造Guard对象的时候，思考一路上（调用栈上）已经持有的锁，防止因加锁顺序不同而导致死锁（deadlock）。由于Guard对象是栈上对象，看函数调用栈就能分析用锁的情况，非常便利。</li></ul><p>次要原则：</p><ul><li>不使用跨进程的mutex， 进程间通信只用TCP sockets。</li><li>加锁、解锁在同一个线程， 线程a不能去unlock线程b已经锁住的mutex（RAII自动保证）。</li><li>别忘了解锁（RAII自动保证）。</li><li>不重复解锁（RAII自动保证）。</li><li>必要的时候可以考虑用PTHREAD_MUTEX_ERRORCHECK来排<br>错</li></ul><h4 id="只使用非递归mutex的原因"><a href="#只使用非递归mutex的原因" class="headerlink" title="只使用非递归mutex的原因"></a>只使用非递归mutex的原因</h4><p>mutex分为递归（recursive） 和非递归（non-recursive） 两种， 这是POSIX的叫法， 另外的名字是可重入（reentrant）与非可重入。   </p><p>它们的唯一区别在于： 同一个线程可以重复对可递归mutex加锁， 但是不能重复对非递归mutex加锁。<strong>在同一个线程里多次对非递归锁加锁会立刻导致死锁。</strong></p><p>选择非递归mutex的原因不是因为性能，非递归mutex性能要更好一点但是好的有限(递归锁需要保存线程id记录持有锁的线程，还要多一个计数器计算当前线程lock了递归锁几次，只有全部都unlock后才能真正释放锁)，而递归锁可以重复加锁比非递归方便的多。</p><p><strong>非递归锁的优点恰恰在于在同一个线程里多次对非递归锁加锁会立刻导致死锁，</strong>这能帮助我们思考代码对锁的需求，并且及早（在编码阶段） 发现问题。</p><p>递归锁因为方便可能会隐藏代码里的一些问题。典型情况是你以为拿到一个锁就能修改对象了，没想到外层代码已经拿到了锁，正在修改（或读取）同一个对象呢。来看一个具体的例子  </p><pre><code class="c++">Mutexlock mutex;std::vector&lt;Foo&gt; foos;void pushFoo(const FOO&amp; f)&#123;    MutexLockGuard lock(mutex);    foos.push_back(f);&#125;void traverse()&#123;    MutexLockGuard lock(mutex);    for(auto it = foos.begin(); it != foos.end(); ++it)    &#123;        it-&gt;do(); //对Foo对象进行一些操作        pushFoo(*it);        it-&gt;do(); //扩容后it失效，对it调用do函数导致coredump    &#125;&#125;</code></pre><p>如上所示，如果在traverse函数中调用了pushFoo函数，表面看上去没事，但是在pushFoo中调用了vector的push_back函数，如果vector进行扩容并重新分配空间，这会导致vector的迭代器失效，从而导致traverse中的it失效，程序崩溃。所以边遍历vector边修改是不对的，而在使用递归锁的时候可能会让你无法发现这个错误。</p><p>所以递归锁可能会导致你原来以为不会发生改变的对象发生改变，你在写程序时很可能无法注意到这一点，从而导致程序在特定情况下出现错误。</p><p>而非递归锁虽然会导致死锁，但是死锁很容易debug，把各个线程的调用栈打出来， 只要每个函数不是特别长， 很容易看出来是怎么死的。 或者可以用PTHREAD_MUTEX_ERRORCHECK一下子就能找到错误（前提是MutexLock带debug选项）。  </p><p>如果一定要边遍历vector边修改，有两种做法：一是把修改推后， 记住遍历中试图添加或删除哪些元素， 等遍历结束了再依记录修<br>改foos； 二是用copy-on-write。</p><p>如果一个函数既可能在已加锁的情况下调用， 又可能在未加锁的情况下调用，也就是有用到递归锁的需求时，那么就将函数拆成两个函数加锁版和不加锁版<br>1．加锁版跟原来的函数同名， 函数加锁，并在内部调用不加锁版。<br>2．不加锁版给函数名加上后缀WithLockHold， 不加锁，把原来的函数体除了加锁部分搬过来。  </p><pre><code class="c++">void pushFoo(const FOO&amp; f)&#123;    MutexLockGuard lock(mutex);    pushFooWithLockHold(f)&#125;void pushFooWithLockHold(const FOO&amp; f)&#123;    foos.push_back(f);&#125;</code></pre><p>如上所示，但在使用不可递归锁时可能会导致新的问题，一是在本线程加了锁的情况下误调用了加锁版，导致死锁，可以用debug死锁的办法解决。二是在其他线程加了锁的情况下(不希望对象被修改)，本线程误调用了不加锁版导致对象被修改，从而导致数据损坏。可以通过在不加锁版函数头检测锁有没有被本线程持有来解决。如下所示：</p><pre><code class="c++">void pushFooWithLockHold(const FOO&amp; f)&#123;    assert(mutex.isLockedByThisThread()); //muduo::MutexLock提供了该函数    foos.push_back(f);&#125;</code></pre><h3 id="死锁的建议"><a href="#死锁的建议" class="headerlink" title="死锁的建议"></a>死锁的建议</h3><p><strong>死锁常见的两个例子：</strong></p><ul><li>同一线程发生死锁。<strong>同一个类中有锁的一个函数辗转调用了另一个有锁的函数。</strong></li><li>两个线程发生死锁。<strong>两个类中持有锁的两对函数相互调用。</strong></li></ul><p><strong>死锁的检测与预防</strong></p><p>预防：</p><ol><li>严格控制锁的调用顺序，用锁之前需要想调用栈上都有了哪些锁；</li><li>将锁内调用的函数同时定义一个无锁版，锁内调用那个无锁版；</li></ol><p>检测：死锁之后，打开core文件或者使用gdb命令查看线程调用栈：</p><pre><code class="shell">thread apply all bt</code></pre><p>看到线程阻塞在一个锁上（__lll_lock_wait）就是发生了死锁。</p><h3 id="条件变量"><a href="#条件变量" class="headerlink" title="条件变量"></a>条件变量</h3><h4 id="使用条件变量的建议"><a href="#使用条件变量的建议" class="headerlink" title="使用条件变量的建议"></a>使用条件变量的建议</h4><p>如果需要等待某个条件成立， 即等待某个bool表达式为真。我们应该使用条件变量（condition variable） 。 条件变量顾名思义是一个或多个线程等待某个布尔表达式为真， 即等待别的线程“唤醒”它。 条件变量的学名叫管程（monitor） 。  </p><p>wait()函数可使得当前线程阻塞，直至条件变量唤醒。线程阻塞后，该函数会自动解锁，允许其他线程执行。一旦得到notify唤醒，该函数取消阻塞并获取锁，然后函数返回，一般为了避免虚假唤醒，会用while循环判断条件。</p><p>notify()：因为只唤醒等待队列中的第一个线程；不存在锁争用，所以能够立即获得锁。其余的线程不会被唤醒，需要等待再次调用notify_one()或者notify_all()。</p><p>notifyAll()：会唤醒所有等待队列中阻塞的线程，存在锁争用，只有一个线程能够获得锁。其余未获取锁的线程接着会继续尝试获得锁(类似于轮询)，而不会再次阻塞。当持有锁的线程释放锁时，这些线程中的一个会获得锁。而其余的会接着尝试获得锁。</p><p>条件变量的notify通常代表资源可用（生产者模式）；notifyAll通常代表状态变化。（比如倒计时系统，可以开始做事了的那种）</p><blockquote><p>虚假唤醒：线程被唤醒后发现条件不满足的情况。一种情况是跟操作系统底层有关，wait有时会在没有唤醒的情况下返回。在不同的平台，原因可能不一样。另一种情况是被条件变量唤醒的线程在本线程内真正执行「加锁并返回」前，另一个线程插了进来，完整地进行了一套「拿锁、改条件、还锁」的操作。假设是在等待消费队列，一个线程A被nodify，但是还没有获得锁时，另一个线程B获得了锁，并消费掉了队列中的数据。B退出或wait后，A获得了锁，而这时条件已不满足。</p></blockquote><p>对于wait端：</p><ul><li>必须与mutex一起使用；wait函数和bool表达式的判断需要在mutex的保护下（如果wait不用mutex保护可能导致notify在wait之前发生，从而导致wait永远无法被唤醒）；</li><li>把bool表达式的判断和wait()放到while循环中，而不能是if</li></ul><pre><code class="c++">std::unique_lock&lt;std::mutex&gt; lock(mtx);while(queue.empty()) &#123;  cond.wait();&#125;//在锁的保护下，从queue中获取变量。</code></pre><p>对于signal端</p><ul><li>notify、notifyAll函数不一定在已上锁的情况下调用；</li><li>调用notify之前一般要修改bool表达式；（修改bool表达式要有锁保护）</li></ul><pre><code class="cpp">std::unique_lock&lt;std::mutex&gt; lock(mtx);queue.push_back(x);cond.notify();</code></pre><h4 id="使用CountDownLatch"><a href="#使用CountDownLatch" class="headerlink" title="使用CountDownLatch"></a>使用CountDownLatch</h4><p>mutex和条件变量是非常底层的同步原语， 很少直接使用， 一般都是用它来实现高层的同步措施， 如BlockingQueue<T>或CountDownLatch。<strong>在多线程开发时尽量用高层同步设施（线程池、 队列、 倒计时）；</strong></p><p>倒计时（CountDownLatch）是一种常用且易用的同步手段。它主要有两种用途：</p><ul><li>主线程发起多个子线程， 等这些子线程各自都完成一定的任务之后， 主线程才继续执行。 通常用于主线程等待多个子线程完成初始化。</li><li>主线程发起多个子线程， 子线程都等待主线程， 主线程完成其他一些任务之后通知所有子线程开始执行。 通常用于多个子线程等待主线程发出“起跑”命令。</li></ul><p><strong>倒计时的接口和实现</strong></p><pre><code class="c++">class CountDownLatch:boost::nocopyable&#123;public:    explicit CountDownLatch(int count); //倒数几次    void wait(); //等待计数值变为0    void countDown(); //计数减1private:    mutable MutexLock mutex_;    Condition condition_;    int count_;&#125;void CountDownLatch::wait()&#123;    MutexLockGuard lock(mutex_);    while(count_ &gt; 0)    &#123;        condition_.wait();    &#125;&#125;void CountDownLatch::countDown()&#123;    MutexLockGuard lock(mutex_);    --count_;    if(count == 0)    &#123;        condition_.notifyAll();    &#125;&#125;</code></pre><h3 id="不要使用读写锁和信号量"><a href="#不要使用读写锁和信号量" class="headerlink" title="不要使用读写锁和信号量"></a>不要使用读写锁和信号量</h3><p><strong>不使用读写锁有以下原因</strong></p><ul><li>程序员可能会不小心在读锁保护的函数中调用了会修改状态的函数。 这种错误的后果跟无保护并发读写共享数据是一样的。</li><li>从性能方面来说， 读写锁不见得比普通mutex更高效。 无论如何读锁加锁的开销不会比mutex小， 因为它要更新当前读者的数目。 如果临界区很小， 锁竞争不激烈， 那么mutex往往会更快。</li><li>读锁可能允许提升（upgrade）为写锁， 也可能不允许提升。考虑之前mutex的使用建议中的pushFoo()和traverse()函数， 如果用读写锁来保护foos对象， 那么pushFoo()应该持有写锁， 而traverse()应该持有读锁。 如果允许把读锁提升为写锁， 后果跟使用递归锁一样， 会造成迭代器失效，程序崩溃。 如果不允许提升， 后果跟使用非递归锁一样， 会造成死锁。 我宁愿程序死锁， 留个“全尸”好查验。</li><li>通常读锁是可重入的，写锁是不可重入的。 但是为了防止写者饥饿，写锁通常会阻塞后来的读锁， 因此读锁在重入的时候可能死锁。 另外， 在追求低延迟读取的场合也不适用读写锁。</li></ul><p>遇到并发读写， 如果条件合适， 我通常会用copy on write的办法， 而不用读写锁， 同时避免读者被写者阻塞。 如果确实对并发读写有极高的性能要求， 可以考虑read-copy-update。</p><p><strong>不使用信号量的原因</strong></p><p>因为条件变量配合互斥器可以完全替代其功能， 而且更不易用错。 信号量的另一个问题在于它有自己的计数值， 而通常我们自己的数据结构也有长度值， 这就造成了同样的信息存了两份， 需要时刻保持一致， 这增加了程序员的负担和出错的可能。   </p><h3 id="线程安全的单例模式"><a href="#线程安全的单例模式" class="headerlink" title="线程安全的单例模式"></a>线程安全的单例模式</h3><p>单例模式指在整个系统生命周期里，保证一个类只能产生一个实例，确保该类的<strong>唯一性</strong>。</p><p><strong>单例模式分类</strong></p><p>单例模式可以分为<strong>懒汉式</strong>和<strong>饿汉式</strong>，两者之间的区别在于<strong>创建实例的时间不同</strong>：</p><ul><li><strong>懒汉式</strong>：指系统运行中，实例并不存在，只有当需要使用该实例时，才会去创建并使用实例。<strong>（这种方式要考虑线程安全，否则可能会构造多个实例）</strong></li><li><strong>饿汉式</strong>：指系统一运行，就初始化创建实例，当需要时，直接调用即可。<strong>（本身就线程安全，没有多线程的问题）</strong></li></ul><p><strong>单例类特点</strong></p><ul><li>构造函数和析构函数为<strong>private</strong>类型，目的<strong>禁止</strong>外部构造和析构</li><li>拷贝构造和赋值构造函数为<strong>private</strong>类型，目的是<strong>禁止</strong>外部拷贝和赋值，确保实例的唯一性</li><li>类里有个获取实例的<strong>静态函数</strong>，可以全局访问</li></ul><p><strong>用局部静态变量实现单例模式</strong></p><p>非局部静态变量是线程安全的，而局部静态变量在C++11后也是线程安全的</p><pre><code class="c++">class Single&#123;public:    // 获取单实例对象    static Single &amp;GetInstance();private:    // 禁止外部构造    Single();    // 禁止外部析构    ~Single();    // 禁止外部拷贝构造    Single(const Single &amp;signal);    // 禁止外部赋值操作    const Single &amp;operator=(const Single &amp;signal);&#125;;Single&amp; Single::GetInstance()&#123;    // 局部静态特性的方式实现单实例    static Single signal;    return signal;&#125;</code></pre><p><strong>用pthread_once_t实现单例模式</strong>  </p><pre><code class="c++">//如果once_control为0，init_routine()就会执行。pthread_once()成功返回之后，once_control会变为2int pthread_once(pthread_once_t *once_control, void (*init_routine) (void))；/* 功能：本函数使用初值为PTHREAD_ONCE_INIT的once_control变量保证init_routine()函数在本进程执行序列中仅执行一次。在多线程编程环境下，尽管pthread_once()调用会出现在多个线程中，init_routine()函数仅执行一次，究竟在哪个线程中执行是不定的，是由内核调度来决定。 */</code></pre><pre><code class="c++">template&lt;typename T&gt;class Singleton : noncopyable&#123; public:  Singleton() = delete;  ~Singleton() = delete;  static T&amp; instance()  &#123;    pthread_once(&amp;ponce_, &amp;Singleton::init);    assert(value_ != NULL);    return *value_;  &#125; private:  static void init()  &#123;    value_ = new T();  &#125; private:  static pthread_once_t ponce_;  static T*             value_;&#125;;template&lt;typename T&gt;pthread_once_t Singleton&lt;T&gt;::ponce_ = PTHREAD_ONCE_INIT;template&lt;typename T&gt;T* Singleton&lt;T&gt;::value_ = NULL;</code></pre><h3 id="不要将sleep-用于线程同步"><a href="#不要将sleep-用于线程同步" class="headerlink" title="不要将sleep()用于线程同步"></a>不要将sleep()用于线程同步</h3><p>sleep()&#x2F;usleep()&#x2F;nanosleep()只能出现在测试代码中，比如写单元测试的时候；或者用于有意延长临界区，加速复现死锁的情况。</p><p>在程序的正常执行中， 如果需要等待一段已知的时间， 应该往event loop里注册一个timer， 然后在timer的回调函数里接着干活， 因为线程是个珍贵的共享资源，不能轻易浪费（阻塞也是浪费）。如果等待某个事件发生，那么应该采用条件变量或IO事件回调，不能用sleep来轮询。</p><h2 id="多线程服务器的适用场合与常用编程模型"><a href="#多线程服务器的适用场合与常用编程模型" class="headerlink" title="多线程服务器的适用场合与常用编程模型"></a>多线程服务器的适用场合与常用编程模型</h2><h3 id="单线程服务器的常用编程模型"><a href="#单线程服务器的常用编程模型" class="headerlink" title="单线程服务器的常用编程模型"></a>单线程服务器的常用编程模型</h3><p>常用Reactor模型，也就是IO多路复用+非阻塞IO。程序的基本结构是一个事件循环（event loop），以事件驱动（event-driven）和事件回调的方式实现业务逻辑。</p><p>业务逻辑就是程序循环阻塞在select&#x2F;poll&#x2F;epoll上， 接收到请求时触发IO回调函数进行处理。</p><p>Reactor模型的优点很明显， 编程不难， 效率也不错。不仅可以用于读写socket，连接的建立，甚至DNS解析都可以用非阻塞方式进行， 以提高并发度和吞吐量，对于IO密集的应用是个不错的选择。lighttpd就是这样，它内部的fdevent结构十分精妙，值得学习。  </p><p>基于事件驱动的编程模型也有其本质的缺点， 它要求事件回调函数必须是非阻塞的。 对于涉及网络IO的请求响应式协议， 它容易割裂业务逻辑， 使其散布于多个回调函数之中， 相对不容易理解和维护。 现代的语言有一些应对方法（例如coroutine）。</p><blockquote><p>IO多路复用搭配非阻塞IO的原因1.select&#x2F;poll&#x2F;epoll返回的并不一定可读，有可能因为数据检验错误被系统丢弃或者数据已被其他线程读取，或者等等未知的情况导致不可读，若使用阻塞IO有可能导致线程阻塞无法及时接收后续请求。2.多路复用只会告诉你 fd 对应的 socket 可读了，但不会告诉你有多少的数据可读，如果使用阻塞IO只能读一次，读多次就可能阻塞线程；而使用非阻塞IO则可以循环读一直读到返回不可读为止，效率更高。</p></blockquote><h3 id="多线程服务器的常用编程模型"><a href="#多线程服务器的常用编程模型" class="headerlink" title="多线程服务器的常用编程模型"></a>多线程服务器的常用编程模型</h3><ul><li>每个请求创建一个线程， 使用阻塞式IO操作。 在Java 1.4引入NIO之前， 这是Java网络编程的推荐做法。 可惜伸缩性不佳。</li><li>使用线程池， 同样使用阻塞式IO操作。与第1种相比，这是提高性能的措施。</li><li>使用non-blocking IO＋IO multiplexing。 即Java NIO的方式。</li><li>Leader&#x2F;Follower等高级模式。</li></ul><p>推荐使用多Reactor多线程+线程池作为C++多线程服务端编程模型。</p><p>这个模型也叫one (event) loop per thread+ thread pool。</p><ul><li>event loop（也叫IO loop） 用作IO multiplexing， 配合non-blocking IO和定时器。</li><li>thread pool用来做计算， 具体可以是任务队列或生产者消费者队列。</li></ul><p>程序里具体用几个loop、 线程池的大小等参数需要根据应用来设定， 基本的原则是“阻抗匹配”， 使得CPU和IO都能高效地运作。</p><pre><code class="c">//阻抗匹配原则C = CPU数量P = CPU繁忙时间 / 总运行时间   // 0&lt;P&lt;=1T = 所需设置线程数T = C / P</code></pre><h4 id="使用blocking-queue和线程池"><a href="#使用blocking-queue和线程池" class="headerlink" title="使用blocking queue和线程池"></a>使用blocking queue和线程池</h4><p>对于没有IO而光有计算任务的线程， 使用event loop有点浪费， 我会用一种补充方案， 即用blocking queue实现的任务队列<br>（TaskQueue）</p><h5 id="blocking-queue实现"><a href="#blocking-queue实现" class="headerlink" title="blocking queue实现"></a>blocking queue实现</h5><h5 id="用blocking-queue实现线程池"><a href="#用blocking-queue实现线程池" class="headerlink" title="用blocking queue实现线程池"></a>用blocking queue实现线程池</h5><h3 id="进程通信只使用tcp的原因"><a href="#进程通信只使用tcp的原因" class="headerlink" title="进程通信只使用tcp的原因"></a>进程通信只使用tcp的原因</h3><p>如果强调本主机共享只读数据，当然是共享内存好，但是如果是进程间的消息传递，使用TCP会有一些列优点。</p><ul><li>TCP很容易跨主机使用，方便扩展，其他方式无法跨机器；</li><li>TCP是双向的，而管道是单向的且需要进程为父子关系，相比TCP很不方便；</li><li>TCP资源在进程结束时会被系统自动回收(都是文件描述符)，即使程序意外退出，也不会给系统留下垃圾，不用担心由于进程崩溃而导致资源无法释放的问题（这种情况只能重启操作系统，跨进程锁就有这个风险）；</li><li>使用TCP进行通信，进程一方崩溃，操作系统会关闭连接，另一方可以很快的知道（应用层心跳也是需要有的）；</li><li>出现问题方便记录与重现：使用wireshark&#x2F;tcpdump抓包就可以。</li><li>任何一个进程都能单独重启。 换句话说，TCP连接是可再生的， 连接的任何一方都可以退出再启动， 重建连接之后就能继续工作， 这对开发牢靠的分布式系统意义重大。</li></ul><h4 id="分布式系统使用tcp长连接的优点"><a href="#分布式系统使用tcp长连接的优点" class="headerlink" title="分布式系统使用tcp长连接的优点"></a>分布式系统使用tcp长连接的优点</h4><p>1.容易定位分布式系统中服务的依赖关系：</p><pre><code class="shell">netstat -tnpa | grep :port   </code></pre><p>在机器上运行上述指令就能立刻列出用到某服务的客户端地址（Foreign列），然后在客户端的机器上用netstat或lsof命令找出是哪个进程发起的连接。</p><p>2.可以通过发送队列和接受队列实时了解服务器的故障信息（可以用于监控）</p><pre><code class="undefined">netstat -tn</code></pre><p>在正常运行的时候， netstat打印的Recv-Q和Send-Q都应该接近0，或者在0附近摆动。</p><p>如果Recv-Q保持不变或持续增加，则通常意味着服务进程的处理速度变慢，可能发生了死锁或阻塞。 </p><p>如果Send-Q保持不变或持续增加， 有可能是对方服务器太忙、来不及处理，也有可能是网络中间某个路由器或交换机故障造成丢包， 甚至对方服务器掉线， 这些因素都可能表现为数据发送不出去。 </p><p>通过持续监控Recv-Q和Send-Q就能及早预警性能或可用性故障。   </p><h3 id="使用多线程还是单线程"><a href="#使用多线程还是单线程" class="headerlink" title="使用多线程还是单线程"></a>使用多线程还是单线程</h3><p>如果要在一台多核机器上提供一种服务或执行一个任务， 可用的模式有<br>1． 运行一个单线程的进程；<br>2． 运行一个多线程的进程；<br>3． 运行多个单线程的进程；<br>4． 运行多个多线程的进程。<br>简单地总结如下：<br>模式1是不可伸缩的（scalable） ， 不能发挥多核机器的计算能力。模式3是目前公认的主流模式。 它有以下两种子模式：</p><ul><li>3a：简单地把模式1中的进程运行多份</li><li>3b：主进程+woker进程， 如果必须绑定到一个TCP port， 比如httpd+fastcgi</li></ul><p>模式2是被很多人所鄙视的， 认为多线程程序难写， 而且与模式3相比并没有什么优势。模式4更是千夫所指， 它不但没有结合2和3的优点， 反而汇聚了二者的缺点。</p><p>本文主要想讨论的是模式2和模式3b的优劣， 即： 什么时候一个服务器程序应该是多线程的。   </p><p>从性能上讲， 无论是IO bound还是CPU bound的服务， 多线程都没有什么优势。  </p><ul><li>对于静态Web服务器， 或者FTP服务器， CPU的负载较轻， 主要瓶颈在磁盘IO和网络IO方面。 这时候往往一个单线程的程序（模式1） 就能撑满IO。 用多线程并不能提高吞吐量， 因为IO硬件容量已经饱和了。同理， 这时增加CPU数目也不能提高吞吐量。</li><li>CPU跑满的情况比较少见， 这里我只好虚构一个例子。 假设有一个服务， 它的输入是n个整数， 问能否从中选出m个整数， 使其和为0（这里n＜100, m＞0）。 这是著名的subset sum问题， 是NP-Complete的。 对于这样一个“服务”， 哪怕很小的n值也会让CPU算死。 比如n＝30， 一次的输入不过200字节（32-bit整数） ， CPU的运算时间却能长达几分钟。 对于这种应用， 模式3a是最适合的， 能发挥多核的优势， 程序也简单。</li></ul><h4 id="适合使用单线程的场合"><a href="#适合使用单线程的场合" class="headerlink" title="适合使用单线程的场合"></a>适合使用单线程的场合</h4><p>有两种场合必须使用单线程：</p><ul><li>程序可能会fork(2)(如看门狗进程)</li><li>限制程序的CPU占用率</li></ul><blockquote><p>看门狗进程：当我们编写服务器代码时，为了让自己的服务器在意外崩溃时能够及时的重启，软件看门狗就显示出它的作用了，该看门狗进程是通过fork一个子进程（业务进程），父进程一旦捕获到了子进程的结束信号就重新再fork一个子进程来实现的。</p></blockquote><p>单线程程序能限制程序的CPU占用率， 比如在一个8核的服务器上， 一个单线程程序即便占满1个core， 其CPU使用率也只有12.5％。在这种最坏的情况下，系统还是有87.5％的计算资源可供其他服务进程使用。<br>因此对于一些辅助性的程序， 如果它必须和主要服务进程运行在同一台机器的话（比如它要监控其他服务进程的状态），那么做成单线程的能避免过分抢夺系统的计算资源。 比方说如果要把生产服务器上的日志文件压缩后备份到NFS上，那么应该使用普通单线程压缩工具（gzip&#x2F;bzip2）。</p><h4 id="单线程的优缺点"><a href="#单线程的优缺点" class="headerlink" title="单线程的优缺点"></a>单线程的优缺点</h4><p><strong>优点</strong></p><p>从编程的角度， 单线程程序的优势无须赘言：简单。</p><p><strong>缺点</strong></p><p>单线程Event loop有一个明显的缺点，它是非抢占的（non-preemptive）。假设事件a的优先级高于事件b， 处理事件a需要1ms， 处理事件b需要10ms。如果事件b稍早于a发生， 那么当事件a到来时， 程序已经离开了poll(2)调用， 并开始处理事件b。 事件a要等上10ms才有机会被处理， 总的响应时间为11ms。 这等于发生了优先级反转。 这个缺点可以用多线程来克服， 这也是多线程的主要优势。  </p><h4 id="适合使用多线程的场合"><a href="#适合使用多线程的场合" class="headerlink" title="适合使用多线程的场合"></a>适合使用多线程的场合</h4><p>多线程的适用场景是： 提高响应速度， 让IO和“计算”相互重叠， 降低延迟。 虽然多线程不能提高绝对性能， 但能提高平均响应性<br>能。  </p><p>一个程序要做成多线程的， 大致要满足：</p><ul><li>有多个CPU可用。 单核机器上多线程没有性能优势（但或许能简化并发业务逻辑的实现） 。</li><li>线程间有共享数据， 即内存中的全局状态。 如果没有共享数据，用模型3b就行。 虽然我们应该把线程间的共享数据降到最低， 但不代表没有。</li><li>共享的数据是可以修改的， 而不是静态的常量表。 如果数据不能修改， 那么可以在进程间用shared memory， 模式3就能胜任。</li><li>提供非均质的服务。 即事件的响应有优先级差异， 我们可以用专门的线程来处理优先级高的事件。 防止优先级反转。</li><li>latency和throughput同样重要， 不是逻辑简单的IO bound或CPU bound程序。 换言之， 程序要有相当的计算量。</li><li>利用异步操作。 比如logging。 无论往磁盘写log file， 还是往log server发送消息都不应该阻塞critical path。</li><li>能scale up。 一个好的多线程程序应该能享受增加CPU数目带来的好处， 目前主流是8核， 很快就会用到16核的机器了。</li><li>具有可预测的性能。 随着负载增加， 性能缓慢下降， 超过某个临界点之后会急速下降。 线程数目一般不随负载变化。</li><li>多线程能有效地划分责任与功能， 让每个线程的逻辑比较简单，任务单一， 便于编码。 而不是把所有逻辑都塞到一个event loop里， 不同类别的事件之间相互影响。</li></ul><p>举个例子，假设要管理一个Linux服务器机群， 这个机群里有8个计算节点， 1个控制节点。 机器的配置都是一样的， 双路四核CPU， 千兆网互联。 现在需要编写一个简单的机群管理软件（参考LLNL的SLURM20），这个软件由3个程序组成：</p><ul><li>运行在控制节点上的master， 这个程序监视并控制整个机群的状态。</li><li>运行在每个计算节点上的slave， 负责启动和终止job， 并监控本机的资源。</li><li>供最终用户使用的client命令行工具， 用于提交job。</li></ul><p>根据前面的分析， slave是个“看门狗进程”， 它会启动别的job进程， 因此必须是个单线程程序。 另外它不应该占用太多的CPU资源， 这<br>也适合单线程模型。 master应该是个模式2的多线程程序，原因如下：</p><ul><li>它独占一台8核的机器， 如果用模型1， 等于浪费了87.5％的CPU资源。</li><li>整个机群的状态应该能完全放在内存中， 这些状态是共享且可变的。 如果用模式3， 那么进程之间的状态同步会成大问题。 而如果大量使用共享内存， 则等于是掩耳盗铃， 是披着多进程外衣的多线程程序。因为一个进程一旦在临界区内阻塞或crash， 其他进程会全部死锁。</li><li>master的主要性能指标不是throughput， 而是latency， 即尽快地响应各种事件。 它几乎不会出现把IO或CPU跑满的情况。</li><li>master监控的事件有优先级区别， 一个程序正常运行结束和异常崩溃的处理优先级不同， 计算节点的磁盘满了和机箱温度过高这两种报警条件的优先级也不同。 如果用单线程， 则可能会出现优先级反转。</li><li>假设master和每个slave之间用一个TCP连接， 那么master采用2个或4个IO线程来处理8个TCP connections能有效地降低延迟。</li><li>master要异步地往本地硬盘写log， 这要求logging library有自己的IO线程。</li><li>master有可能要读写数据库， 那么数据库连接这个第三方library可能有自己的线程， 并回调master的代码。</li><li>master要服务于多个clients， 用多线程也能降低客户响应时间。 也就是说它可以再用2个IO线程专门处理和clients的通信。</li><li>master还可以提供一个monitor接口， 用来广播推送（pushing） 机群的状态， 这样用户不用主动轮询（polling） 。 这个功能如果用单独的线程来做， 会比较容易实现， 不会搞乱其他主要功能。</li></ul><p>最终master一共开了10个线程：</p><ul><li>4个用于和slaves通信的IO线程。</li><li>1个logging线程。</li><li>1个数据库IO线程。</li><li>2个和clients通信的IO线程。</li><li>1个主线程， 用于做些背景工作， 比如job调度。</li><li>1个pushing线程， 用于主动广播机群的状态。</li></ul><p>虽然线程数目略多于core数目， 但是这些线程很多时候都是空闲的， 可以依赖OS的进程调度来保证可控的延迟。  </p><p>综上所述， master用多线程方式编写是自然且高效的  。</p><p>一个多线程服务程序中的线程大致可分为3类：</p><ul><li>IO线程， 这类线程的主循环是IO multiplexing， 阻塞地等在select&#x2F;poll&#x2F;epoll_wait系统调用上。 这类线程也处理定时事件。 当然它的功能不止IO， 有些简单计算也可以放入其中， 比如消息的编码或解码。</li><li>计算线程， 这类线程的主循环是blocking queue， 阻塞地等在condition variable上。 这类线程一般位于thread pool中。 这种线程通常不涉及IO， 一般要避免任何阻塞操作。</li><li>第三方库所用的线程， 比如logging，又比如database connection。</li></ul><p>服务器程序一般不会频繁地启动和终止线程。 甚至， 在我写过的程序里， create thread只在程序启动的时候调用， 在服务运行期间是不调用的。</p><h4 id="多线程答疑"><a href="#多线程答疑" class="headerlink" title="多线程答疑"></a>多线程答疑</h4><p><strong>多线程能提高并发度吗？</strong><br>如果指的是“并发连接数”， 则不能。32位虚拟地址空间最多支持开300线程左右，这远远低于基于事件的单线程程序所能轻松达到的并<br>发连接数（成千上万）。所谓“基于事件”， 指的是用IO multiplexing event loop的编程模型， 又称Reactor模式， 在前文中已有介<br>绍。<br>那么采用前文中推荐的one loop per thread呢？ 至少不逊于单线程程序。 实际上单个event loop处理1万个并发长连接并不罕见， 一个multiloop的多线程程序应该能轻松支持5万并发链接。<br>小结：thread per connection不适合高并发场合， 其scalability不佳。one loop per thread的并发度足够大， 且与CPU数目成正比  </p><p><strong>多线程能提高吞吐量吗？</strong><br>对于计算密集型服务， 不能。<br>假设有一个耗时的计算服务， 用单线程算需要0.8s。 在一台8核的机器上， 我们可以启动8个线程一起对外服务（如果内存够用， 启动8个进程也一样） 。 这样完成单个计算仍然要0.8s， 但是由于这些进程的计算可以同时进行， 理想情况下吞吐量可以从单线程的1.25qps（query per second） 上升到10qps。（实际情况可能要打个八折——如果不是打对折的话。）</p><p>假如改用并行算法， 用8个核一起算， 理论上如果完全并行，加速比高达8， 那么计算时间是0.1s， 吞吐量还是10qps， 但是首次请求的响应时间却降低了很多。 实际上根据Amdahl’s law， 即便算法的并行度高达95％， 8核的加速比也只有6， 计算时间为0.133s， 这样会造成吞吐量下降为7.5qps。 不过以此为代价， 换得响应时间的提升， 在有些应用场合也是值得的  </p><p><strong>多线程能降低响应时间吗？</strong><br>如果设计合理， 充分利用多核资源的话， 可以。 在突发（burst） 请求时效果尤为明显。  </p><p><strong>多线程程序如何让IO和“计算”相互重叠， 降低latency？</strong><br>基本思路是， 把IO操作（通常是写操作） 通过Blocking Queue交给别的线程去做， 自己不必等待。</p><p>例1:日志（logging） 在多线程服务器程序中，日志（logging）至关重要， 本例仅考虑写log file的情况， 不考虑log server。<br>在一次请求响应中，可能要写多条日志消息，而如果用同步的方式写文件（fprintf或fwrite），多半会降低性能， 因为：</p><ul><li>文件操作一般比较慢， 服务线程会等在IO上， 让CPU闲置， 增加响应时间。</li><li>就算有buffer， 还是不灵。 多个线程一起写， 为了不至于把buffer写错乱， 往往要加锁。 这会让服务线程互相等待， 降低并发度。 （同时用多个log文件不是办法， 除非你有多个磁盘，且保证log files分散在不同的磁盘上，否则还是要受到磁盘IO瓶颈的制约。）</li></ul><p>解决办法是单独用一个logging线程， 负责写磁盘文件，通过一个或多个Blocking Queue对外提供接口。 别的线程要写日志的时候， 先把消息（字符串） 准备好， 然后往queue里一塞就行， 基本不用等待。 这样服务线程的计算就和logging线程的磁盘IO相互重叠， 降低了服务线程的响应时间。</p><p>尽管logging很重要， 但它不是程序的主要逻辑， 因此对程序的结构影响越小越好， 最好能简单到如同一条printf语句， 且不用担心其他性能开销。 而一个好的多线程异步logging库能帮我们做到这一点。</p><p><strong>除了你推荐的Reactor＋thread poll，还有别的多线程编程模型吗？</strong><br>有， Proactor。如果一次请求响应中要和别的进程打多次交道， 那么Proactor模型往往能做到更高的并发度。当然， 代价是代码变得支离破碎， 难以理解。<br>举HTTP proxy为例， 一次HTTP proxy的请求如果没有命中本地cache， 那么它多半会：</p><ul><li>解析域名（不要小看这一步， 对于一个陌生的域名， 解析可能要花几秒的时间） ；</li><li>建立连接；</li><li>发送HTTP请求；</li><li>等待对方回应；</li><li>把结果返回给客户。</li></ul><p>这5步中跟2个server发生了3次round-trip， 每次都可能花几百毫秒：</p><ul><li>向DNS问域名， 等待回复；</li><li>向对方的HTTP服务器发起连接， 等待TCP三路握手完成；</li><li>向对方发送HTTP request， 等待对方response。</li></ul><p>而实际上HTTP proxy本身的运算量不大，如果用线程池， 池中线程的数目会很庞大， 不利于操作系统的管理调度。这时我们有两个解决思路：</p><ol><li><p>把“域名已解析”、 “连接已建立”、 “对方已完成响应”做成event， 继续按照Reactor的方式来编程。 这样一来， 每次客户请求就不能用一个函数从头到尾执行完成， 而要分成多个阶段， 并且要管理好请求的状态（“目前到了第几步？ ”） 。</p></li><li><p>用回调函数， 让系统来把任务串起来。 比如收到用户请求， 如果没有命中本地缓存， 那么需要执行：</p><ul><li><p>立刻发起异步的DNS解析startDNSResolve()， 告诉系统在解析完之后调用DNSResolved()函数；</p></li><li><p>在DNSResolved()中， 发起TCP连接请求， 告诉系统在连接建立之后调用connectionEstablished()；</p></li><li><p>在connectionEstablished()中发送HTTP request， 告诉系统在收到响应之后调用httpResponsed()；</p></li><li><p>最后，在httpResponsed()里把结果返回给客户。</p></li></ul></li></ol><p>NET大量采用的BeginInvoke&#x2F;EndInvoke操作也是这个编程模式。 当然， 对于不熟悉这种编程方式的人， 代码会显得很难看。 有关Proactor模式的例子可参看Boost.Asio的文档， 这里不再多说。</p><p>Proactor模式依赖操作系统或库来高效地调度这些子任务， 每个子任务都不会阻塞， 因此能用比较少的线程达到很高的IO并发度。</p><p>Proactor能提高吞吐， 但不能降低延迟。 另外， 在没有语言直接支持的情况下，Proactor模式让代码非常破碎， 在C++中使用Proactor是很痛苦的。 因此最好在“线程”很廉价的语言中使用这种方式， 这时runtime往往会屏蔽细节， 程序用单线程阻塞IO的方式来处理TCP连接。  </p><p><strong>模式2和模式3a该如何取舍？</strong><br>模式2是一个多线程的进程， 模式3a是多个相同的单线程进程。</p><p>我认为， 在其他条件相同的情况下， 可以根据工作集（work set）的大小来取舍。 工作集是指服务程序响应一次请求所访问的内存大小。如果工作集较大， 那么就用多线程， 避免CPU cache换入换出， 影响性能； 否则， 就用单线程多进程， 享受单线程编程的便利。 </p><p>举例来说，如果程序有一个较大的本地cache， 用于缓存一些基础参考数据（in-memory look-up table），几乎每次请求都会访问cache， 那么多线程更适合一些， 因为可以避免每个进程都自己保留一份cache， 增加内存使用。</p><p>memcached这个内存消耗大户用多线程服务端就比在同一台机器上运行多个memcached instance要好。（但是如果你在16GiB内存的机器上运行32-bit memcached， 那么此时多instance是必需的。 ）</p><p>求解Sudoku用不了多大内存。 如果单线程编程更方便的话， 可以用单线程多进程来做。再在前面加一个单线程的load balancer，仿<br>lighttpd＋fastcgi的成例。</p><p>线程不能减少工作量， 即不能减少CPU时间。 如果解决一个问题需要执行一亿条指令 ，那么用多线程只会让这个数字增加。 但是通过合理调配这一亿条指令在多个核上的执行情况， 我们能让工期提早结束。 这听上去像统筹方法， 其实也确实是统筹方法。  </p><h2 id="C-多线程系统编程精要"><a href="#C-多线程系统编程精要" class="headerlink" title="C++多线程系统编程精要"></a>C++多线程系统编程精要</h2><p>学习多线程编程面临的最大的思维方式的转变有两点：</p><ul><li>当前线程可能随时会被切换出去， 或者说被抢占（preempt）了。</li><li>多线程程序中事件的发生顺序不再有全局统一的先后关系</li></ul><p>当线程被切换回来继续执行下一条语句（指令） 的时候， 全局数据（包括当前进程在操作系统内核中的状态） 可能已经被其他线程修改<br>了。  </p><p>在单CPU系统中， 理论上我们可以通过记录CPU上执行的指令的先后顺序来推演多线程的实际交织（interweaving） 运行的情况。 <strong>在多核系统中， 多个线程是并行执行的， 我们甚至没有统一的全局时钟来为每个事件编号。</strong> 在没有适当同步的情况下， 多个CPU上运行的多个线程中的事件发生先后顺序是无法确定的。 在引入适当同步后， 事件之间才有了happens-before关系  </p><h3 id="基本线程原语的选用"><a href="#基本线程原语的选用" class="headerlink" title="基本线程原语的选用"></a>基本线程原语的选用</h3><p>用C&#x2F;C++编写跨平台的多线程程序不是普遍的需求， 因此本书只谈现代Linux下的多线程编程。   </p><p>POSIX threads的函数有110多个，真正常用的不过十几个，这11个最基本的Pthreads函数是：</p><ul><li>2个： 线程的创建和等待结束（join）。</li><li>4个： mutex的创建、 销毁、 加锁、 解锁。</li><li>5个： 条件变量的创建、 销毁、 等待、 通知、 广播。</li></ul><p><strong>用这三样东西（thread、 mutex、condition） 可以完成任何多线程编程任务。</strong> 当然我们一般也不会直接使用它们（mutex除外） ， 而是使用更高层的封装， 例如ThreadPool和CountDownLatch等。</p><p>除此之外， Pthreads还提供了其他一些原语， 有些是可以酌情使用的：</p><ul><li>pthread_once。其实不如直接用全局变量。</li><li>pthread_key。 可以考虑用__thread替换之。 不建议使用：</li><li>pthread_rwlock。读写锁通常应慎用</li><li>sem_。 避免用信号量（semaphore）。它的功能与条件变量重合， 但容易用错。</li><li>pthread_{cancel, kill}。 程序中出现了它们， 则通常意味着设计出了问题</li></ul><h3 id="C-x2F-C-系统库的线程安全性"><a href="#C-x2F-C-系统库的线程安全性" class="headerlink" title="C&#x2F;C++系统库的线程安全性"></a>C&#x2F;C++系统库的线程安全性</h3><p>线程的出现立刻给系统函数库带来了冲击， 破坏了20年来一贯的编程传统和假定。如：</p><ul><li>errno不再是一个全局变量， 因为每个线程可能会执行不同的系统库函数。</li><li>有些“纯函数”不受影响， 例如memset&#x2F;strcpy&#x2F;snprintf等等。</li><li>有些影响全局状态或者有副作用的函数可以通过加锁来实现线程安全， 例如malloc&#x2F;free、 printf、 fread&#x2F;fseek等等。</li><li>有些返回或使用静态空间的函数不可能做到线程安全， 因此要提供另外的版本， 例如asctime_r&#x2F;ctime_r&#x2F;gmtime_r、 stderror_r、strtok_r等等。</li><li>传统的fork()并发模型不再适用于多线程程序。</li></ul><p>现在glibc库函数大部分都是线程安全的。 特别是FILE*系列函数是安全的， glibc甚至提供了非线程安全的版本以应对某些特殊场合的性能需求。 <strong>尽管单个函数是线程安全的， 但两个或多个函数放到一起就不再安全了。</strong> 例如fseek()和fread()都是安全的， 但是对某个文件“先seek再read”这两步操作中间有可能会被打断， 其他线程有可能趁机修改了文件的当前位置， 让程序逻辑无法正确执行。在这种情况下， 我们可以用flockfile(FILE*)和funlockfile(FILE*)函数来显式地加锁。 并且由于FILE*的锁是可重入的， 加锁之后再调用fread()不会造成死锁。  </p><p>由此可见， 编写线程安全程序的一个难点在于线程安全是不可组合的（composable），一个函数foo()调用了两个线程安全的函数， 而这个foo()函数本身很可能不是线程安全的。 即便现在大多数glibc库函数是线程安全的， 我们也不能像写单线程程序那样编写代码。   </p><ul><li>不用担心系统调用的线程安全性、因为系统调用对于用户态程序来说是原子的。但是需要注意它的使用对内核状态的改变可能会影响其他线程</li><li>C++标准容器库和std::string 不是线程安全的，只有std::allocator是线程安全的。这是为了避免不必要的性能开销  </li><li>C++库中的绝大多数泛型算法是线程安全的,因为这些都是无状态纯函数。 只要输入区间是线程安全的， 那么泛型函数就是线程安<br>全的。  </li><li>C++的iostream不是线程安全的。因为在一行中连续流式输出等价于多次函数调用，即便ostream::operator&lt;&lt;()做到了线程安全， 也不能保证其他线程不会在两次函数调用之间向stdout输出其他字符。</li></ul><h3 id="Linux上的线程标识"><a href="#Linux上的线程标识" class="headerlink" title="Linux上的线程标识"></a>Linux上的线程标识</h3><p>POSIX threads库用pthread_t作为当前进程的标识符。pthread_t不一定是一个数值类型（整数或指针） ， 也有可能是一个结构体， 因此Pthreads专门提供了pthread_equal函数用于对比两个线程标识符是否相等。 这就带来一系列问题， 包括：</p><ul><li>无法打印输出pthread_t， 因为不知道其确切类型。 也就没法在日志中用它表示当前线程的id。</li><li>无法比较pthread_t的大小或计算其hash值， 因此无法用作关联容器的key。</li><li>无法定义一个非法的pthread_t值， 用来表示绝对不可能存在的线程id， 因此MutexLock class没有办法有效判断当前线程是否已经持有本锁。</li><li>pthread_t值只在进程内有意义， 与操作系统的任务调度之间无法建立有效关联。 比方说在&#x2F;proc文件系统中找不到pthread_t对应的task。</li></ul><p>另外， glibc的Pthreads实现实际上把pthread_t用作一个结构体指针（它的类型是unsigned long） ， 指向一块动态分配的内存， 而且这块内存是反复使用的。 这就造成pthread_t的值很容易重复。 <strong>Pthreads只保证同一进程之内， 同一时刻的各个线程的id不同； 不能保证同一进程先后多个线程具有不同的id， 更不要说一台机器上多个进程之间的id唯一性了</strong>。  </p><p>因此， pthread_t并不适合用作程序中对线程的标识符。</p><p><strong>在Linux上，建议使用gettid(2)系统调用的返回值作为线程id</strong>， 这么做的好处有：</p><ul><li>它的类型是pid_t， 其值通常是一个小整数， 便于在日志中输出。</li><li>在现代Linux中， 它直接表示内核的任务调度id， 因此在&#x2F;proc文件系统中可以轻易找到对应项： &#x2F;proc&#x2F;tid或&#x2F;prod&#x2F;pid&#x2F;task&#x2F;tid。</li><li>在其他系统工具中也容易定位到具体某一个线程， 例如在top(1)中我们可以按线程列出任务， 然后找出CPU使用率最高的线程id， 再根据程序日志判断到底哪一个线程在耗用CPU。</li><li>任何时刻都是全局唯一的， 并且由于Linux分配新pid采用递增轮回办法， 短时间内启动的多个线程也会具有不同的线程id。</li><li>0是非法值， 因为操作系统第一个进程init的pid是1。</li></ul><h3 id="线程的创建与销毁的守则"><a href="#线程的创建与销毁的守则" class="headerlink" title="线程的创建与销毁的守则"></a>线程的创建与销毁的守则</h3><p>线程的创建和销毁是编写多线程程序的基本要素</p><p><strong>线程的创建原则：</strong></p><ul><li><p>程序库不应该在未提前告知的情况下创建自己的“背景线程”</p></li><li><p>尽量用相同的方式创建线程</p></li><li><p>进入main函数之前不应该启动线程</p></li><li><p>程序中线程的创建最好在初始化阶段全部完成</p></li></ul><p>原因如下：</p><p>线程是稀缺资源，  因此我们在设计一个服务端程序的时候要精心规划线程的数目， 特别是根据机器的CPU数目来设置工作线程的数目， 并为关键任务保留足够的计算资源。 如果程序库在背地里使用了额外的线程来执行任务， 我们这种资源规划就漏算了。 可能会导致高估系统的可用资源，结果处理关键任务不及时， 达不到预设的性能指标。还有一个重要原因是， 一旦程序中有不止一个线程， 就很难安全地fork()了 。 因此“库”不能偷偷创建线程。 如果确实有必要使用背景线程， 至少应该让使用者知道。</p><p>理想情况下， 程序里的线程都是用同一个class创建的（muduo::Thread），这样容易在线程的启动和销毁阶段做一些统一的簿<br>记（bookkeeping） 工作。 比如说调用一次muduo::CurrentThread::tid()把当前线程id缓存起来， 以后再取线程id就不会陷入内核了。 也可以统计当前有多少活动线程， 进程一共创建了多少线程， 每个线程的用途分别是什么。但是这不是总能做到的， 有些第三方库（C语言库） 会自己启动线程， 这样的“野生”线程就没有纳入全局的ThreadManager管理之中。muduo::CurrentThread::tid()必须要考虑被这种“野生”线程调用的可能，因此它必须每次都检查缓存的线程id是否有效， 而不能假定在线程启动阶段已经缓存好了id， 直接返回缓存值就行了。 如果库提供异步回调，一定要明确说明会在哪个（哪些） 线程调用用户提供的回调函数， 这样用户可以知道在回调函数中能不能执行耗时的操作， 会不会阻塞其他任务的执行。</p><p>在main()函数之前不应该启动线程， 因为这会影响全局对象的安全构造。 C++保证在进入main()之前完成全局对象的构造。同时，各个编译单元之间的对象构造顺序是不确定的， 我们也有一些办法来影响初始化顺序， 保证在初始化某个全局对象时使用到的其他全局对象都是构造完成的。 但无论如何这些全局对象的构造是依次进行的，都在主线程中完成， 无须考虑并发与线程安全。如果其中一个全局对象创建了线程， 那就危险了。 因为这破坏了初始化全局对象的基本假设。万一将来代码改动之后造成该线程访问了未经初始化的全局对象， 那么这种隐晦错误查起来就很费劲了。 或许你想用锁来保证全局对象初始化完成， 但是怎么保证这个全局的锁对象的构造能在线程启动之前完成呢？ 因此，<strong>全局对象不能创建线程</strong>。 如果一个库需要创建线程， 那么应该进入main()函数之后再调用库的初始化函数做。  </p><p>不要为了每个计算任务， 每次请求去创建线程。 一般也不会为每个网络连接创建线程， 除非并发连接数与CPU数相近。 一个服务程序的线程数目应该与当前负载无关， 而应该与机器的CPU数目有关， 即load average有比较小（最好不大于CPU数目） 的上限。 这样尽量避免出现thrashing， 不会因为负载急剧增加而导致机器失去正常响应。 这么做的重要原因是， 在机器失去响应期间， 我们无法探查它究竟在做什么， 也没办法立刻终止有问题的进程， 防止损害进一步扩大。 <strong>如果有实时性方面的要求， 线程数目不应该超过CPU数目</strong>， 这样可以基本保证新任务总能及时得到执行， 因为总有CPU是空闲的。 <strong>最好在程序的初始化阶段创建全部工作线程， 在程序运行期间不再创建或销毁线程。</strong> 借助muduo::ThreadPool和muduo::EventLoop， 我们很容易就能把计算任务和IO任务分配到已有的线程， 代价只有新建线程的几分之一。  </p><p><strong>线程的销毁方式：</strong></p><ul><li><p>自然死亡。从线程的主函数返回，线程正常退出</p></li><li><p>非正常死亡，抛出异常或触发致命信号</p></li><li><p>自杀。 自己调用pthread_exit()退出</p></li><li><p>他杀。其他线程调用pthread_cancle()</p></li></ul><p><strong>注意，线程正常退出的方式只有一个，自然死亡，任何从外部强行终止线程的做法和想法都是错误的</strong></p><p>因为强行终止线程的话（无论是自杀还是他杀），它没有机会清理资源。 也没有机会释放已经持有的锁，其他线程如果再想对同一个mutex加锁， 那么就会立刻死锁。  </p><p>如果确实需要强行终止一个耗时很长的计算任务， 而又不想在计算期间周期性地检查某个全局退出标志， 那么可以考虑把那一部分代码<br>fork()为新的进程， 这样杀一个进程比杀本进程内的线程要安全得多。 当然， fork()的新进程与本进程的通信方式也要慎重选取， 最好用文件描述符（pipe(2)&#x2F;socketpair(2)&#x2F;TCP socket）来收发数据， 而不要用共享内存和跨进程的互斥器等IPC， 因为这样仍然有死锁的可能。  </p><p>最后， 我认为<strong>如果能做到前面提到的“程序中线程的创建最好能在初始化阶段全部完成”， 则线程是不必销毁的</strong>， 伴随进程一直运行， 彻<br>底避开了线程安全退出可能面临的各种困难， 包括Thread对象生命期管理、 资源释放等等。  </p><h4 id="exit-3-在C-中不是线程安全的"><a href="#exit-3-在C-中不是线程安全的" class="headerlink" title="exit(3)在C++中不是线程安全的"></a>exit(3)在C++中不是线程安全的</h4><p><strong>exit(3)函数在C++中的作用除了终止进程， 还会析构全局对象和已经构造完的函数静态对象</strong>。 这有潜在的死锁可能，还有可能导致其他线程在调用全局对象时对象已被析构，所以多线程要慎用exit()</p><pre><code class="c++">void callExit()&#123;    exit(1);&#125;class GlobalObject&#123;public:    void doit()    &#123;        MutexLockGuard lock(mutex_);        callExit();    &#125;        ~GlobalObject()    &#123;        MutexLockGuard lock(mutex_); //发生死锁            &#125;private:    MutexLock mutex_;&#125;GlobalObject g_obj;int main()&#123;    g_obj.doit();&#125;</code></pre><p>GlobalObject::doit()函数辗转调用了exit()， 从而触发了全局对象g_obj的析构。 GlobalObject的析构函数会试图加锁mutex_， 而此时<br>mutex_已经被GlobalObject::doit()锁住了， 于是造成了死锁。  </p><p>这其实不是exit()的过错， 而是全局对象析构的问题。 C++标准没有照顾全局对象在多线程环境下的析构， 据我看似乎也没有更好的办法。<strong>如果确实需要主动结束线程， 则可以考虑用_exit(2)系统调用。</strong> 它不会试图析构全局对象， 但是也不会执行其他任何清理工作， 比如flush标准输出。<br>由此可见， 安全地退出一个多线程的程序并不是一件容易的事情。何况这里还没有涉及如何安全地退出其他正在运行的线程， 这<strong>需要精心设计共享对象的析构顺序， 防止各个线程在退出时访问已失效的对象。在编写长期运行的多线程服务程序的时候， 可以不必追求安全地退出，而是让进程进入拒绝服务状态， 然后就可以直接杀掉了。</strong>  </p><h3 id="善用-thread关键字"><a href="#善用-thread关键字" class="headerlink" title="善用__thread关键字"></a>善用__thread关键字</h3><p>__thread是GCC内置的线程局部存储设施（thread local storage）。它的实现非常高效， 比pthread_key_t快很多， _thread变量的存取效率可与全局变量相比 。</p><p>_thread变量每一个线程有一份独立实体，各个线程的值互不干扰。可以用来修饰那些带有全局性且值可能变，但是又不值得用全局锁保护的变量。</p><p><strong>_thread使用规则： 只能用于修饰POD类型， 不能修饰class类型，因为无法自动调用构造函数和析构函数。</strong> _thread可以用于修饰全局变量、 函数内的静态变量， 但是不能用于修饰函数的局部变量或者class的普通成员变量。 另外， _thread变量的初始化只能用编译期常量。 例如：  </p><pre><code class="c++">_thread string obj(&quot;hufei&quot;); //错误，不能调用对象的构造函数_thread string* obj = new string; //错误，初始化必须用编译期常量_thread string* obj = NULL; //正确，记住需要手工初始化并销毁对象    </code></pre><p>使用举例：</p><pre><code class="cpp">__thread int count = 0;int main()&#123;    //创建线程A    //创建线程B    //此时A和B线程都有一个实体 count，二者并不相同&#125;</code></pre><h3 id="多线程与IO"><a href="#多线程与IO" class="headerlink" title="多线程与IO"></a>多线程与IO</h3><p>在进行多线程网络编程的时候，能否多个线程同时读写同一个socket文件描述符？ </p><p>首先， 操作文件描述符的系统调用本身是线程安全的， 我们不用担心多个线程同时操作文件描述符会造成进程崩溃或内核崩溃。但是， 多个线程同时操作同一个socket文件描述符确实很麻烦， 我认为是得不偿失的。 需要考虑的情况如下：  </p><ul><li>如果一个线程正在阻塞地read(2)某个socket， 而另一个线程close(2)了此socket。</li><li>如果一个线程正在阻塞地accept(2)某个listening socket， 而另一个线程close(2)了此socket。</li><li>更糟糕的是， 一个线程正准备read(2)某个socket， 而另一个线程close(2)了此socket； 第三个线程又恰好open(2)了另一个文件描述符， 其fd号码正好与前面的socket相同。 这样程序的逻辑就混乱了。</li></ul><p>现在假设不考虑关闭文件描述符， 只考虑读和写， 情况也不见得多好。 因为socket读写的特点是不保证完整性， 读100字节有可能只返回20字节， 写操作也是一样的。</p><ul><li>如果两个线程同时read同一个TCP socket， 两个线程几乎同时各自收到一部分数据， 如何把数据拼成完整的消息？ 如何知道哪部分数据先到达？</li><li>如果两个线程同时write同一个TCP socket， 每个线程都只发出去半条消息， 那接收方收到数据如何处理？</li><li>如果给每个TCP socket配一把锁， 让同时只能有一个线程读或写此socket， 似乎可以“解决”问题， 但这样还不如直接始终让同一个线程来操作此socket来得简单</li></ul><p>如此看来， 理论上只有read和write可以分到两个线程去， 因为TCP socket是双向IO。 问题是真的值得把read和write拆开成两个线程吗？  </p><p>为了简单起见， 我认为多线程程序应该遵循的原则是： <strong>每个文件描述符只由一个线程操作</strong>， 从而轻松解决消息收发的顺序性问题， 也避免了关闭文件描述符的各种race condition。 一个线程可以操作多个文件描述符， 但一个线程不能操作别的线程拥有的文件描述符。   </p><p>epoll也遵循相同的原则。  <strong>我们应该把对同一个epoll fd的操作（添加、 删除、 修改、 等待）都放到同一个线程中执行。</strong></p><p> 这条规则有两个例外： 对于磁盘文件， 在必要的时候多个线程可以同时调用pread(2)&#x2F;pwrite(2)来读写同一个文件； 对于UDP， 由于协议本身保证消息的原子性， 在适当的条件下（比如消息之间彼此独立） 可以多个线程同时读写同一个UDP文件描述符。  </p><h3 id="用RAII包装文件描述符"><a href="#用RAII包装文件描述符" class="headerlink" title="用RAII包装文件描述符"></a>用RAII包装文件描述符</h3><p>linux的文件描述符是小整数，程序刚启动时候，0是标准输入，1是标准输出，2是标准错误。因此新打开的文件描述符是3，因为POSIX标准要求每次新打开文件（含socket） 的时候必须使用当前最小可用的文件描述符号码。</p><p>POSIX这种分配文件描述符的方式稍不注意就会造成串话。   如：</p><ul><li>第一个线程read某个socket，第二个线程几乎同时close此socket，第三个线程又打开了另一个文件描述符，与之前的相同，则会导致第一个线程会读不到属于他的数据。不仅如此， 还把第三个线程的功能也破坏了， 因为第一个线程把数据读走了  </li><li>一个线程从fd＝8收到了比较耗时的请求， 它开始处理这个请求， 并记住要把响应结果发给fd＝8。 但是在处理过程中， fd＝8断开连接， 被关闭了，又有新的连接到来， 碰巧使用了相同的fd＝8。 当线程完成响应的计算， 把结果发给fd＝8时， 接收方已经物是人非， 后果难以预料。</li></ul><p>如何解决：</p><ul><li>用全局表存储文件描述符，读写时加锁。效率太低，不推荐</li><li>RAII。 用Socket对象包装文件描述符， 所有对此文件描述符的读写操作都通过此对象进行， 在对象的析构函数里关闭文件描述符。 这样一来， 只要Socket对象还活着， 就不会有其他Socket对象跟它有一样的文件描述符， 也就不可能串话。（用shared_ptr来管理TcpConnection的生命期）</li></ul><h3 id="RAII与fork"><a href="#RAII与fork" class="headerlink" title="RAII与fork()"></a>RAII与fork()</h3><p>如果用RAII管理资源，在程序会fork()的情况下，可能会导致析构了不存在的资源。如下：</p><pre><code class="c++">int main()&#123;    Foo foo;    fork();    foo.doit();&#125; //析构函数会被调用两次，父子进程各一次。</code></pre><p>这是因为fork()后子进程不会继承对象的所有资源，所以子进程析构时可能会析构不存在的对象。</p><p>fork()之后， 子进程继承了父进程的几乎全部状态， 但也有少数例外。 子进程会继承地址空间和文件描述符， <strong>因此用于管理动态内存和文件描述符的RAII class都能正常工作</strong>。 但是子进程不会继承：  </p><ul><li>父进程的内存锁， mlock(2)、 mlockall(2)。</li><li>父进程的文件锁， fcntl(2)。</li><li>父进程的某些定时器， setitimer(2)、 alarm(2)、 timer_create(2)等等。</li></ul><p>比方说用RAII技法封装timer_create()&#x2F;timer_delete()， 在子进程中析构函数调用timer_delete()可能会出错， 因为试图释放一个不存在的资源。 或者更糟糕地把其他对象持有的timer给释放了（如果碰巧新建的timer_t与之重复的话）。因此， 我们在编写服务端程序的时候， “是否允许fork()”是在一开始就应该慎重考虑的问题， 在一个没有为fork()做好准备的程序中使用fork()， 会遇到难以预料的问题。  </p><p>当然若fork后的子进程立即调用exec()执行其它程序隔断了父子关系则不会出现上述情形。</p><h3 id="多线程与fork"><a href="#多线程与fork" class="headerlink" title="多线程与fork()"></a>多线程与fork()</h3><p>多线程与fork()的协作性很差。 这是POSIX系列操作系统的历史包袱。 因为长期以来程序都是单线程的。</p><p>fork()一般不能在多线程程序中调用， 因为Linux的fork()只克隆当前线程的thread of control， 不克隆其他线程。 <strong>fork()之后， 除了当前线程之外， 其他线程都消失了。</strong> 也就是说不能一下子fork()出一个和父进程一样的多线程子进程。 Linux没有forkall()这样的系统调用， forkall()其实也是很难办的（从语意上） ， 因为其他线程可能等在condition variable上， 可能阻塞在系统调用上， 可能等着mutex以跨入临界区， 还可能在密集的计算中， 这些都不好全盘搬到子进程里。</p><p>fork()之后子进程中只有一个线程， 其他线程都消失了， 这就造成一个危险的局面。 <strong>其他线程可能正好位于临界区之内， 持有了某个锁，而它突然死亡， 再也没有机会去解锁了。 如果子进程试图再对同一个mutex加锁， 就会立刻死锁。</strong> 在fork()之后， 子进程就相当于处于signal handler之中， 你不能调用线程安全的函数（除非它是可重入的） ， 而只能调用异步信号安全（async-signal-safe） 的函数。 比方说， fork()之后， 子进程不能调用：</p><ul><li>malloc(3)。 因为malloc()在访问全局状态时几乎肯定会加锁。</li><li>任何可能分配或释放内存的函数， 包括new、 map::insert()、snprintf33……</li><li>任何Pthreads函数。 你不能用pthread_cond_signal()去通知父进程，只能通过读写pipe(2)来同步34。</li><li>printf()系列函数， 因为其他线程可能恰好持有stdout&#x2F;stderr的锁。</li><li>除了man 7 signal中明确列出的“signal安全”函数之外的任何函数。</li></ul><p><strong>总结</strong>：多线程下，fork()只会克隆当前线程，并且还有造成死锁的风险，不要在多线程下使用fork，除非fork后的子进程立即调用exec()执行其它程序</p><h3 id="多线程与signal"><a href="#多线程与signal" class="headerlink" title="多线程与signal"></a>多线程与signal</h3><p>Linux&#x2F;Unix的信号（signal） 与多线程可谓是水火不容，signal会打断正在运行的thread of control， 在signal handler中只能调用<br>可重入（reentrant）函数(线程安全不一定可重入)。</p><p>还有一点， <strong>如果signal handler中需要修改全局数据， 那么被修改的变量必须是sig_atomic_t类型的。</strong> 否则被打断的函数在恢复执行后很可能不能立刻看到signal handler改动后的数据， 因为编译器有可能假定这个变量不会被他处修改， 从而优化了内存访问。  </p><p>在多线程时代， signal的语义更为复杂。 信号分为两类： 发送给某一线程（SIGSEGV） ， 发送给进程中的任一线程（SIGTERM） ， 还要考虑掩码（mask） 对信号的屏蔽等。 <strong>特别是在signal handler中不能调用任何Pthreads函数， 不能通过condition variable来通知其他线程。</strong>在多线程程序中， 使用signal的第一原则是不要使用signal。 包括：</p><ul><li>不要用signal作为IPC的手段， 包括不要用SIGUSR1等信号来触发服务端的行为。 如果确实需要， 可以用增加监听端口的方式来实现双向的、 可远程访问的进程控制。</li><li>也不要使用基于signal实现的定时函数， 包括alarm&#x2F;ualarm&#x2F;setitimer&#x2F;timer_create、 sleep&#x2F;usleep等等。</li><li>不主动处理各种异常信号（SIGTERM、 SIGINT等等） ， 只用默认语义： 结束进程。 有一个例外： SIGPIPE， 服务器程序通常的做法是忽略此信号， 否则如果对方断开连接， 而本机继续write的话， 会导致程序意外终止。</li><li>在没有别的替代方法的情况下（比方说需要处理SIGCHLD信号），把异步信号转换为同步的文件描述符事件。 传统的做法是在signal handler里往一个特定的pipe(2)写一个字节， 在主程序中从这个pipe读取， 从而纳入统一的IO事件处理框架中去。 现代Linux的做法是采用signalfd(2)把信号直接转换为文件描述符事件， 从而从根本上避免使用signal handler。</li></ul><blockquote><p>SIGPIPE信号:如果客户端关闭了socket（close），而服务端调用了一次write，服务端就会接收到一个RST Segment，如果服务端再次调用write，这个时候就会产生SIGPIPE信号，默认情况下会终止进程</p></blockquote><h3 id="多线程C-程序编写原则"><a href="#多线程C-程序编写原则" class="headerlink" title="多线程C++程序编写原则"></a>多线程C++程序编写原则</h3><ul><li>线程是宝贵的， 一个程序可以使用几个或十几个线程。 一台机器上不应该同时运行几百个、 几千个用户线程， 这会大大增加内核scheduler的负担， 降低整体性能。</li><li>线程的创建和销毁是有代价的， 一个程序最好在一开始创建所需的线程， 并一直反复使用。 不要在运行期间反复创建、 销毁线程， 如果必须这么做， 其频度最好能降到1分钟1次（ 或更低）。</li><li>每个线程应该有明确的职责， 例如IO线程（ 运行EventLoop::loop()，处理IO事件）、计算线程（位于ThreadPool中，负责计算） 等等。</li><li>线程之间的交互应该尽量简单， 理想情况下，线程之间只用消息传递（ 例如BlockingQueue） 方式交互。如果必须用锁，那么最好避免一个线程同时持有两把或更多的锁， 这样可彻底防止死锁。</li><li>要预先考虑清楚一个mutable shared对象将会暴露给哪些线程， 每个线程是读还是写， 读写有无可能并发进行。</li></ul><h2 id="高效的多线程日志"><a href="#高效的多线程日志" class="headerlink" title="高效的多线程日志"></a>高效的多线程日志</h2><p>日志（logging）有两种：</p><ul><li>诊断日志（diagnostic log） 即log4j等常用日志库提供的日志功能。</li><li>交易日志（transaction log） 即数据库的write-ahead log用于记录状态变更， 通过回放日志可以逐步恢复每一次修改之后的状态。</li></ul><p>本章的日志是前一个意思， 即文本的、 供人阅读的日志， 通常用于故障诊断和追踪（trace），也可用于性能分析。日志通常是分布式<br>系统中事故调查时的唯一线索， 用来追寻蛛丝马迹， 查出元凶。  </p><p>对于关键进程， 日志通常要记录：</p><ul><li>收到的每条内部消息的id（还可以包括关键字段、 长度、 hash等） ；</li><li>收到的每条外部消息的全文；</li><li>发出的每条消息的全文， 每条消息都有全局唯一的id6；</li><li>关键内部状态的变更， 等等。</li></ul><p>每条日志都有时间戳， 这样就能完整追踪分布式系统中一个事件的来龙去脉。 也只有这样才能查清楚发生故障时究竟发生了什么， 比如业务处理流程卡在了哪一步。</p><p>一个日志库大体可分为前端（frontend） 和后端（backend） 两部分。 前端是供应用程序使用的接口（API） ， 并生成日志消息（log<br>message） ； 后端则负责把日志消息写到目的地（destination）。   </p><p>在多线程程序中， 前端和后端都与单线程程序无甚区别， 无非是每个线程有自己的前端， 整个程序共用一个后端。 但难点在于将日志数据从多个前端高效地传输到后端。 <strong>这是一个典型的多生产者-单消费者问题</strong>， 对生产者（前端） 而言， 要尽量做到低延迟、 低CPU开销、 无阻塞； 对消费者（后端） 而言， 要做到足够大的吞吐量， 并占用较少资源。</p><p>对C++程序而言， 最好整个程序（包括主程序和程序库） 都使用相同的日志库， 程序有一个整体的日志输出， 而不要各个组件有各自的日志输出。 从这个意义上讲， 日志库是个singleton。  </p><h3 id="功能需求"><a href="#功能需求" class="headerlink" title="功能需求"></a>功能需求</h3><ul><li>日志消息有多种级别（ level） ， 如TRACE、 DEBUG、 INFO、WARN、 ERROR、 FATAL等。</li><li>日志消息可能有多个目的地（ appender） ， 如文件、 socket、SMTP等。</li><li>日志消息的格式可配置（ layout） ， 例如org.apache.log4j.PatternLayout。</li><li>可以设置运行时过滤器（ filter） ， 控制不同组件的日志消息的级别和目的地。</li></ul><p>在上面这几项中， 我认为除了第一项之外， 其余三项都是非必需的功能。  </p><p>日志的输出级别在运行时可调， 这样同一个可执行文件可以分别在QA测试环境的时候输出DEBUG级别的日志， 在生产环境输出INFO级<br>别的日志。调整日志的输出级别不需要重新编译， 也不需要重启进程。</p><p>对于分布式系统中的服务进程而言， 日志的目的地（ destination）只有一个： 本地文件。 <strong>往网络写日志消息是不靠谱的</strong>， 因为诊断日志的功能之一正是诊断网络故障。往网络写日志消息的另一个坏处是增加网络带宽消耗。</p><p>以本地文件为日志的destination， 那么日志文件的滚动（ rolling）是必需的， 这样可以简化日志归档（ archive）的实现。 rolling的条件通常有两个： 文件大小（ 例如每写满1GB就换下一个文件） 和时间（ 例如每天零点新建一个日志文件， 不论前一个文件有没有写满） 。 muduo日志库的LogFile会自动根据文件大小和时间来主动滚动日志文件。</p><p>一个典型的日志文件的文件名如下：</p><pre><code>logfile_test.2012060-144022.hostname.3605.log</code></pre><p>文件名由以下几部分组成：  </p><ul><li>第1部分logfile_test是进程的名字。 通常是main()函数参数中argv[0]的basename(3)， 这样容易区分究竟是哪个服务程序的日志。 必要时还可以把程序版本加进去。</li><li>第2部分是文件的创建时间（GMT时区）。这样很容易通过文件名来选择某一时间范围内的日志， 例如用通配符*.20120603-14*表示2012年6月3日下午2点（GMT）左右的日志文件。</li><li>第3部分是机器名称。这样即便把日志文件拷贝到别的机器上也能追溯其来源。</li><li>第4部分是进程id。如果一个程序一秒之内反复重启， 那么每次都会生成不同的日志文件。</li><li>第5部分是统一的后缀名.log。同样是为了便于周边配套脚本的编写。</li></ul><p><strong>日志文件压缩与归档（archive）不是日志库应有的功能</strong>， 而应该交给专门的脚本去做， 这样C++和Java的服务程序可以共享这一基础设<br>施，并且更改时也不必动业务程序， 改改周边配套脚本就行了。 </p><p><strong>磁盘空间监控也不是日志库的必备功能。</strong> 有人或许曾经遇到日志文件把磁盘占满的情况， 因此希望日志库能限制空间使用，例如只分配10GB磁盘空间， 用满之后就冲掉旧日志， 重复利用空间。 殊不知如果出现程序死循环拼命写日志的异常情况， 那么往往是开头的几条日志最关键， 它往往反映了引发异常（busy-loop） 的原因（例如收到某条非法消息） ， 后面都是无用的垃圾日志。</p><p>往文件写日志的一个常见问题是， 万一程序崩溃， 那么最后若干条日志往往就丢失了， 因为日志库不能每条消息都flush硬盘， 更不能每条日志都open&#x2F;close文件，这样性能开销太大。 muduo日志库用两个办法来应对这一点， 其一是定期（默认3秒） 将缓冲区内的日志消息flush到硬盘； 其二是每条内存中的日志消息都带有cookie（或者叫哨兵值&#x2F;sentry） ， 其值为某个函数的地址， 这样通过在core dump文件中查找cookie就能找到尚未来得及写入磁盘的消息。</p><p>日志消息的格式是固定的， 不需要运行时配置， 这样可节省每条日志解析格式字符串的开销。 我认为日志的格式在项目的整个生命周期几乎不会改变。   因为我们经常会为不同目的编写parse日志的脚本，可能要和一年之前的日志文件的同类数据做对比。如果在此期间日志格式变了， 势必会增加很多无谓的工作量。 如果真的需要调整消息格式， 直接修改代码并重新编译即可。   </p><p>日志消息格式有几个要点：</p><ul><li>尽量每条日志占一行。 这样很容易用awk、 sed、 grep等命令行工具来快速联机分析日志， 比方说要查看“2012-06-03 08:02:00”至“2012-06-03 08:02:59”这1分钟内每秒打印日志的条数（直方图），可以运行$ grep -o ‘^20120603 08:02:..’ | sort | uniq -c</li><li>时间戳精确到微秒。 每条消息都通过gettimeofday(2)获得当前时间， 这么做不会有什么性能损失。 因为在x86-64 Linux上，gettimeofday(2)不是系统调用， 不会陷入内核。</li><li>始终使用GMT时区。 对于跨洲的分布式系统而言，可省去本地时区转换的麻烦（别忘了主要西方国家大多实行夏令时），更易于追查事件的顺序。</li><li>打印线程id。便于分析多线程程序的时序，也可以检测死锁。这里的线程id是指调用LOG_INFO &lt;&lt;的线程。</li><li>打印日志级别。在线查错的时候先看看有无ERROR日志，通常可加速定位问题。</li><li>打印源文件名和行号。修复bug的时候不至于搞错对象。</li></ul><p>每行日志的前4个字段的宽度是固定的， 以空格分隔， 便于用脚本解析。 另外， 应该避免在日志格式（特别是消息id）中出现正则表达<br>式的元字符（meta character） ， 例如’[‘和’]’等等， 这样在用less(1)查看日志文件的时候查找字符串更加便捷。</p><p>运行时的日志过滤器（filter） 或许是有用的， 例如控制不同部件（程序库） 的输出日志级别， 但我认为这应该放到编译期去做， 整个程序有一个整体的输出级别就足够好了。 同时我认为一个程序同时写多个日志文件是非常罕见的需求， 这可以事后留给log archiver来分流， 不必做到日志库中。 不实现filter自然也能减小生成每条日志的运行时开销， 可以提高日志库的性能。</p><h3 id="性能需求"><a href="#性能需求" class="headerlink" title="性能需求"></a>性能需求</h3><p>高效性体现在几方面：</p><ul><li>每秒写几千上万条日志的时候没有明显的性能损失。</li><li>能应对一个进程产生大量日志数据的场景， 例如1GB&#x2F;min。</li><li>不阻塞正常的执行流程。</li><li>在多线程程序中， 不造成争用（contention） 。 这里列举一些具体的性能指标， 考虑往普通7200rpm SATA硬盘写日志文件的情况：磁盘带宽约是110MB&#x2F;s， 日志库应该能瞬时写满这个带宽（不必持续太久） 。</li></ul><p>以上是“高性能”日志库的最低指标。 如果磁盘带宽更高， 那么日志库的预期性能指标也会相应提高。  </p><p>muduo日志库在现在的PC上能写到每秒200万条消息， 带宽足够撑满两个千兆网连接或4个SATA组成的RAID10， 性能是达标的。<br>为了实现这样的性能指标， muduo日志库的实现有几点优化措施值得一提：</p><ul><li>时间戳字符串中的日期和时间两部分是缓存的， 一秒之内的多条日志只需重新格式化微秒部分。 </li><li>日志消息的前4个字段是定长的， 因此可以避免在运行期求字符串长度（不会反复调用strlen） 。 因为编译器认识memcpy()函数， 对于定长的内存复制， 会在编译期把它inline展开为高效的目标代码。</li><li>线程id是预先格式化为字符串， 在输出日志消息时只需简单拷贝几个字节。 见CurrentThread::tidString()。</li><li>每行日志消息的源文件名部分采用了编译期计算来获得basename， 避免运行期strrchr(3)开销。 见SourceFile class， 这里利用了gcc的内置函数。</li></ul><h3 id="多线程异步日志"><a href="#多线程异步日志" class="headerlink" title="多线程异步日志"></a>多线程异步日志</h3><p>线程安全的多线程日志的解决思路</p><ul><li>用一个全局锁保护IO，或者每个线程单独写一个日志文件。性能堪忧，前者造成所有线程抢占一个锁，后者会让业务线程阻塞在写磁盘操作上</li><li>每个进程只写一个日志文件，用一个背景线程负责收集日志消息，并写入日志文件，其他业务线程只需往这个日志线程中发送日志消息，称为“异步日志”(本文采用)</li></ul><p>在多线程服务程序中， 异步日志是必需的， 因为如果在网络IO线程或业务线程中直接往磁盘写数据的话，写操作偶尔可能阻塞长达数秒之久（原因很复杂， 可能是磁盘或磁盘控制器复位）。这可能导致请求方超时， 或者耽误发送心跳消息， 在分布式系统中更可能造成多米诺骨牌效应， 例如误报死锁引发自动failover等。 <strong>因此， 在正常的实时业务处理流程中应该彻底避免磁盘IO</strong>， 这在使用one loop per thread模型的非阻塞服务端程序中尤为重要， 因为线程是复用的， 阻塞线程意味着影响多个客户连接。</p><p>我们需要一个“队列”来将日志前端的数据传送到后端（日志线程） ， 但这个“队列”不必是现成的BlockingQueue&lt;std::string&gt;， 因为不<br>用每次产生一条日志消息都通知（notify()） 接收方。</p><p><strong>muduo日志库采用的是双缓冲（double buffering） 技术</strong>， 基本思路是准备两块buffer： A和B， 前端负责往buffer A填数据（日志消<br>息） ， 后端负责将buffer B的数据写入文件。 当buffer A写满之后， 交换A和B， 让后端将buffer A的数据写入文件， 而前端则往buffer B填入新的日志消息， 如此往复。   </p><p>用两个buffer的好处是在新建日志消息的时候不必等待磁盘文件操作， 也避免每条新日志消息都触发（唤醒） 后端日志线程。 换言之， 前端不是将一条条日志消息分别传送给后端， 而是将多条日志消息拼成一个大的buffer传送给后端， 相当于批处理， 减少了线程唤醒的频度， 降低开销。 另外， 为了及时将日志消息写入文件， 即便buffer A未满， 日志库也会每3秒执行一次上述交换写入操作。  </p><h2 id="网络编程杂谈"><a href="#网络编程杂谈" class="headerlink" title="网络编程杂谈"></a>网络编程杂谈</h2><h3 id="网络编程本质"><a href="#网络编程本质" class="headerlink" title="网络编程本质"></a>网络编程本质</h3><p>基于事件的非阻塞网络编程是编写高性能并发网络服务程序的主流模式， 头一次使用这种方式编程通常需要转换思维模式。 把原来“主动<br>调用recv(2)来接收数据， 主动调用accept(2)来接受新连接， 主动调用send(2)来发送数据”的思路换成“注册一个收数据的回调， 网络库收到数据会调用我， 直接把数据提供给我， 供我消费。 注册一个接受连接的回调， 网络库接受了新连接会回调我， 直接把新的连接对象传给我， 供我使用。 需要发送数据的时候， 只管往连接中写， 网络库会负责无阻塞地发送。 ”这种编程方式有点像Win32的消息循环， 消息循环中的代码应该避免阻塞， 否则会让整个窗口失去响应， 同理， 事件处理函数也应该避免阻塞， 否则会让网络服务失去响应。</p><p>我认为， TCP网络编程最本质的是处理三个半事件：</p><ul><li><p>连接的建立， 包括服务端接受（accept） 新连接和客户端成功发起（connect） 连接。 TCP连接一旦建立， 客户端和服务端是平等的， 可以各自收发数据。</p></li><li><p>连接的断开， 包括主动断开（close、 shutdown） 和被动断开（read(2)返回0） 。</p></li><li><p>消息到达， 文件描述符可读。 这是最为重要的一个事件， 对它的处理方式决定了网络编程的风格（阻塞还是非阻塞， 如何处理分包，应用层的缓冲如何设计， 等等） 。</p></li><li><p>消息发送完毕， 这算半个。 对于低流量的服务， 可以不必关心这个事件； 另外， 这里的“发送完毕”是指将数据写入操作系统的缓冲</p><p>区， 将由TCP协议栈负责数据的发送与重传， 不代表对方已经收到数据</p></li></ul><h3 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h3><ul><li>如果要主动关闭连接， 如何保证对方已经收到全部数据？ 如果应用层有缓冲（这在非阻塞网络编程中是必需的， 见下文） ， 那么如何保证先发送完缓冲区中的数据， 然后再断开连接？ 直接调用close(2)恐怕是不行的。</li><li>如果主动发起连接， 但是对方主动拒绝， 如何定期（带back-off地） 重试？</li><li>非阻塞网络编程该用边沿触发（edge trigger） 还是电平触发（leveltrigger） ？如果是电平触发， 那么什么时候关注EPOLLOUT事件？ 会不会造成busy-loop？ 如果是边沿触发， 如何防止漏读造成的饥饿？epoll(4)一定比poll(2)快吗？</li><li>在非阻塞网络编程中， 为什么要使用应用层发送缓冲区？ 假设应用程序需要发送40kB数据， 但是操作系统的TCP发送缓冲区只有25kB剩余空间， 那么剩下的15kB数据怎么办？ 如果等待OS缓冲区可用， 会阻塞当前线程， 因为不知道对方什么时候收到并读取数据。 因此网络库应该把这15kB数据缓存起来， 放到这个TCP链接的应用层发送缓冲区中， 等socket变得可写的时候立刻发送数据， 这样“发送”操作不会阻塞。 如果应用程序随后又要发送50kB数据， 而此时发送缓冲区中尚有未发送的数据（若干kB） ， 那么网络库应该将这50kB数据追加到发送缓冲区的末尾， 而不能立刻尝试write()， 因为这样有可能打乱数据的顺序。</li><li>在非阻塞网络编程中， 为什么要使用应用层接收缓冲区？ 假如一次读到的数据不够一个完整的数据包， 那么这些已经读到的数据是不是应该先暂存在某个地方， 等剩余的数据收到之后再一并处理？ 见lighttpd关于\r\n\r\n分包的bug。 假如数据是一个字节一个字节地到达， 间隔10ms， 每个字节触发一次文件描述符可读（readable） 事件， 程序是否还能正常工作？ lighttpd在这个问题上出过安全漏洞。</li><li>在非阻塞网络编程中， 如何设计并使用缓冲区？ 一方面我们希望减少系统调用， 一次读的数据越多越划算， 那么似乎应该准备一个大的缓冲区。 另一方面， 我们希望减少内存占用。 如果有10000个并发连接，每个连接一建立就分配各50kB的读写缓冲区(s)的话， 将占用1GB内存，而大多数时候这些缓冲区的使用率很低。 muduo用readv(2)结合栈上空间巧妙地解决了这个问题。</li><li>如果使用发送缓冲区， 万一接收方处理缓慢， 数据会不会一直堆积在发送方， 造成内存暴涨？ 如何做应用层的流量控制？</li><li>如何设计并实现定时器？ 并使之与网络IO共用一个线程， 以避免锁</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/linux/"/>
      <url>/2023/01/22/linux/</url>
      
        <content type="html"><![CDATA[<h1 id="linux"><a href="#linux" class="headerlink" title="linux"></a>linux</h1><h2 id="linux目录结构"><a href="#linux目录结构" class="headerlink" title="linux目录结构"></a>linux目录结构</h2><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\linux_file.jpg" alt="linux_file"></p><p>在 Linux 或 Unix 操作系统中，所有的文件和目录都被组织成以一个根节点开始的倒置的树状结构。</p><p>文件系统的最顶层是由根目录开始的，系统使用 <strong>&#x2F;</strong> 来表示根目录。在根目录之下的既可以是目录，也可以是文件，而每一个目录中又可以包含子目录文件。如此反复就可以构成一个庞大的文件系统。</p><p>在Linux文件系统中有两个特殊的目录，一个用户所在的工作目录，也叫当前目录，可以使用一个点 <strong>.</strong> 来表示；另一个是当前目录的上一级目录，也叫父目录，可以使用两个点 <strong>..</strong> 来表示。</p><ul><li>. ：代表当前的目录，也可以使用 .&#x2F; 来表示；</li><li>.. ：代表上一层目录，也可以 ..&#x2F; 来代表。</li></ul><p>如果一个目录或文件名以一个点 . 开始，表示这个目录或文件是一个隐藏目录或文件(如：.bashrc)。即以默认方式查找时，不显示该目录或文件。</p><p><strong>系统启动必须：</strong></p><ul><li><p><strong>&#x2F;boot：</strong>存放的启动Linux时使用的内核文件，包括连接文件以及镜像文件。</p></li><li><p><strong>&#x2F;etc(<em>Etcetera</em>)：</strong>存放<strong>所有</strong>的系统需要的<strong>配置文件</strong>和<strong>子目录列表，</strong>包括通过系统自动安装的程序的配置文件，如nginx，mysql等配置文件。更改目录下的文件可能会导致系统不能启动</p></li><li><p>**&#x2F;lib(<em>Library</em>)**：存放基本代码库（比如c++库），其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。</p></li><li><p><strong>&#x2F;sys</strong>： 这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。sysfs文件系统集成了下面3种文件系统的信息：针对进程信息的proc文件系统、针对设备的devfs文件系统以及针对伪终端的devpts文件系统。该文件系统是内核设备树的一个直观反映。当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中</p></li></ul><p><strong>指令集合：</strong></p><ul><li><p><strong>&#x2F;bin(<em>Binaries</em>)：</strong>存放着最常用的程序和指令，如文件操作</p></li><li><p><strong>&#x2F;sbin(<em>System-only binaries</em>)：</strong>只有系统管理员能使用的程序和指令，如分区、格式化操作。</p></li></ul><p><strong>外部文件管理：</strong></p><ul><li><p><strong>&#x2F;dev(<em>Device</em>) ：</strong>存放的是Linux的外部设备。<strong>注意：</strong>在Linux中访问设备和访问文件的方式是相同的。</p></li><li><p><strong>&#x2F;media</strong>：一般是<strong>系统自动挂载</strong>可移除的装置，挂载后装置图标<strong>会</strong>出现在桌面窗口的左边栏。如软碟、光碟、DVD、U盘、移动硬盘</p></li><li><p><strong>&#x2F;mnt(<em>Mount</em>)<strong>：一般是用于让</strong>用户自己挂载</strong>其他文件系统，挂载后装置图标<strong>不会</strong>出现在桌面窗口的左边栏。我们可以将光驱挂载在&#x2F;mnt&#x2F;上，然后进入该目录就可以查看光驱里的内容了。</p></li></ul><p><strong>临时文件：</strong></p><ul><li><p><strong>&#x2F;run</strong>：是一个临时文件系统，存储系统启动以来的信息。当系统重启时，这个目录下的文件应该被删掉或清除。如果你的系统上有 &#x2F;var&#x2F;run 目录，应该让它指向 run。</p></li><li><p><strong>&#x2F;lost+found</strong>：这个目录在大多数情况下都是空的。但是如果你正在工作突然停电，或是没有用正常方式关机，在你重新启动机器的时候，有些文件就会找不到应该存放的地方，对于这些文件，系统将他们放在这个目录下。</p></li><li><p><strong>&#x2F;tmp(<em>Temporary files</em>)<strong>：</strong>保存在使用完毕后可随时销毁的缓存文件。</strong>（有可能是由系统或程序产生、也有可能是用户主动放入的临时数据、系统会自动清理）</p></li></ul><p><strong>账户：</strong></p><ul><li><p><strong>&#x2F;root</strong>：系统管理员的home目录。</p></li><li><p><strong>&#x2F;home</strong>：用户的主目录，以用户的账号命名的。</p></li><li><p>**&#x2F;usr(<em>unix shared resources</em>)**：通过系统自动安装的软件目录。类似于windows下的program files目录。</p></li><li><p><strong>&#x2F;usr&#x2F;bin：</strong>系统用户使用的应用程序与指令。</p></li><li><p><strong>&#x2F;usr&#x2F;sbin：</strong>超级用户使用的比较高级的管理程序和系统守护程序。</p></li><li><p><strong>&#x2F;usr&#x2F;src：</strong>内核源代码默认的放置目录。</p></li><li><p><strong>&#x2F;snap</strong>：snap是linux包管理工具，snap目录存放了snap软件包</p></li></ul><p><strong>运行过程中要用：</strong></p><ul><li><p><strong>&#x2F;var(<em>Variable</em>)<strong>：</strong>软件运行产生的不可自动销毁的缓存文件、日志记录</strong>，如日志、数据库文件、缓存文件。</p></li><li><p>**&#x2F;proc(<em>Processes</em>)**：&#x2F;proc是一个位于内存中的伪文件系统(in-memory pseudo-file system)。该目录下保存的不是真正的文件和目录，而是一些“运行时”信息，如系统内存、磁盘io、设备挂载信息和硬件配置信息等。proc目录是一个控制中心，用户可以通过更改其中某些文件来改变内核的运行状态。proc目录也是内核提供给我们的查询中心，我们可以通过这些文件查看有关系统硬件及当前正在运行进程的信息。在Linux系统中，许多工具的数据来源正是proc目录中的内容。例如，lsmod命令就是cat &#x2F;proc&#x2F;modules命令的别名，lspci命令是cat &#x2F;proc&#x2F;pci命令的别名。</p></li></ul><p><strong>扩展用的：</strong></p><ul><li><p>**&#x2F;opt(<em>Optional</em>)**：默认是空的。安装第三方软件，通常是用户自己编译的软件；把软件安装一个文件夹内，包括它的运行文件，所需要的库文件、生成临时文件、产生的内容等所有和该软件相关的都放在该文件夹内，不用时方便删除。</p></li><li><p><strong>&#x2F;srv(<em>Service</em>)<strong>：</strong>主要用来存储本机或本服务器提供的服务或数据。</strong>（用户主动生产的数据、对外提供服务）。如web、ftp、流媒体等</p></li></ul><h2 id="CLI，console，终端，shell区别"><a href="#CLI，console，终端，shell区别" class="headerlink" title="CLI，console，终端，shell区别"></a>CLI，console，终端，shell区别</h2><ul><li><strong>命令行界面</strong> (CLI) &#x3D; 使用文本命令进行交互的用户界面(区别于图形界面GUI)</li><li><strong>终端</strong> (Terminal) &#x3D; <strong>TTY(Teletype电传打字机)</strong> &#x3D; 文本输入&#x2F;输出环境</li><li><strong>控制台</strong> (Console) &#x3D; 一种特殊的终端</li><li><strong>Shell</strong> &#x3D; 命令行解释器，执行用户输入的命令并返回结果</li></ul><p>1.CLI和GUI相对，是两种不同的用户交互风格。</p><p>2.终端</p><p>终端是一种用来让用户输入数据至计算机，以及显示其计算结果的机器。在大型机 (Mainframe) 和小型机 (Minicomputer) 的时代里，计算机曾经非常昂贵且巨大，不像现在这样人手一台。这些笨重的计算机通常被安置在单独的房间内，而操作计算机的人们坐在另外的房间里，通过某些设备与计算机进行交互。这种设备就叫做 <strong>终端</strong> (Terminal)，也叫终端机。早期的终端一般是一种叫做 <strong>电传打字机</strong> (Teletype) 的设备。</p><p>3.控制台</p><p>在历史上，终端是连接到计算机上的一种带输入输出功能的外设。但是有一个终端与众不同，它与计算机主机是一体的，是计算机的一个组成部分。这个特殊的终端就叫做 <strong>控制台</strong> (Console)。顾名思义，控制台是用于管理主机的，只能给系统管理员使用，有着比普通终端更大的权限。一台计算机上一般只有一个控制台，但是可以连接很多个终端。现在 Console 与 Terminal 基本被看作是同义词。</p><p>4.终端模拟器</p><p>随着计算机的进化，我们已经见不到专门的终端硬件了，取而代之的则是键盘与显示器。</p><p>但是没有了终端，我们要怎么与那些传统的、不兼容图形接口的命令行程序（比如说 GNU 工具集里的大部分命令）交互呢？这些程序并不能直接读取我们的键盘输入，也没办法把计算结果显示在我们的显示器上。</p><p>这时候我们就需要一个程序来模拟传统终端的行为，即 <strong>终端模拟器</strong> (Terminal Emulator)。</p><p>对于那些命令行 (CLI) 程序，终端模拟器会「假装」成一个传统终端设备；一个终端模拟器的标准工作流程是这样的：</p><ol><li>捕获你的键盘输入；</li><li>将输入发送给命令行程序（程序会认为这是从一个真正的终端设备输入的）；</li><li>拿到命令行程序的输出结果（STDOUT 以及 STDERR）；</li><li>调用图形接口（比如 X11），将输出结果渲染至显示器。</li></ol><p>在专门的终端硬件已经基本上仅存于计算机博物馆的现代，人们通常图省事儿，直接称呼终端模拟器为「终端」。</p><p>5.shell</p><p>我们需要一个专门的程序，它接受用户输入的命令，然后帮我们与内核沟通，最后让内核完成我们的任务。这个提供用户界面的程序被叫做 <strong>Shell</strong> (壳层)。</p><p> Shell 提供了一个用户操作系统的入口，我们一般是通过 Shell 去调用其他各种各样的应用程序，最后来达成我们的目的。比如说我们想要知道一个文件的内容，我们会在 Shell 中输入命令 <code>cat foo.txt</code>，然后 Shell 会帮我们运行 <code>cat</code> 这个程序，<code>cat</code> 再去调用内核提供的 <code>open</code> 等系统调用来获取文件的内容。虽然并不是 Shell 直接去与内核交互，但广义上可以认为是 Shell 提供了与内核交互的用户界面。</p><p>Shell 通常可以分为两种：<strong>命令行 Shell</strong> 与 <strong>图形 Shell</strong>。顾名思义，前者提供一个命令行界面 (CLI)，后者提供一个图形用户界面 (GUI)。Windows 下的 <code>explorer.exe</code> 就是一个典型的图形 Shell（没错，它确实是，因为它接受来自你的指令，并且会帮你与内核交互完成你的指令）。</p><p>现在我们知道，终端干的活儿是从用户这里接收输入（键盘、鼠标等输入设备），扔给 Shell，然后把 Shell 返回的结果展示给用户（比如通过显示器）。而 Shell 干的活儿是从终端那里拿到用户输入的命令，解析后交给操作系统内核去执行，并把执行结果返回给终端。</p><h2 id="fork，vfork，exec，clone，pthread的区别"><a href="#fork，vfork，exec，clone，pthread的区别" class="headerlink" title="fork，vfork，exec，clone，pthread的区别"></a>fork，vfork，exec，clone，pthread的区别</h2><h3 id="fork"><a href="#fork" class="headerlink" title="fork"></a>fork</h3><p>Linux多进程编程中的可以使用fork函数来创建子进程。fork函数定义在头文件unistd.h中（uni表示unix，std当然是标准库，所以很好记），该函数的声明为<code>pid_t fork(void)</code>其中函数的返回值类型为pid_t，可以理解为一个整型，返回值具体为：</p><ul><li>在父进程中，fork返回新创建的子进程的进程ID；</li><li>在子进程中，fork返回0；</li><li>如果创建子进程失败，则返回一个负值</li></ul><p>fork只简单地将父进程的几乎所有资源全部复制给子进程，然后就相当于父进程的一个副本运行，且无法与父进行共享数据。</p><p><strong>子进程与父进程的区别在于：</strong></p><ul><li>父进程设置的锁，子进程不继承（因为如果是排它锁，被继承的话，矛盾了）</li><li>各自的进程ID和父进程ID不同</li><li>子进程的未决告警被清除；</li><li>子进程的未决信号集设置为空集。</li></ul><p><strong>linux常用fork和exec配合创建新进程</strong>，之所以这样创建新进程有着历史原因。fork、exec在UNIX里的最初的目的是：shell要执行别的东西，干完活再返回给shell，但当年（应该是1960~1970年代）是没有进程的概念的，exec就是把老的shell给干掉，然后去干活，干完活再返回回来。注意，当年是没有进程的概念的，exec就是直接把shell从内存里拿掉。但这样做有一些坏处，就是每次要重新加载shell，于是fork就出现了，让新任务执行（复制一份），shell不动（具体是交换到磁盘上还是怎么操作不太了解），新任务干完活，shell继续跑。<strong>因为当年没有多任务的概念，fork相当于提供了一个虚假的多任务环境</strong>。</p><p>但是这样复制父进程的内存空间开销很大，随着大进程的出现，内存开销开始越来越大，采用了<strong>写时复制技术</strong>来缓解这种大的内存开销。</p><p>写时拷贝（copy-on-write， COW）就是等到修改数据时才真正分配内存空间，这是对程序性能的优化，可以延迟甚至是避免内存拷贝，当然目的就是避免不必要的内存拷贝。在 Linux 系统中，调用 fork 系统调用创建子进程时，并不会把父进程所有占用的内存页复制一份，而是与父进程共用相同的内存页，而当子进程或者父进程对内存页进行修改时才会进行复制。（也就是只有进程空间的某页内存的内容要发生变化时，才会将父进程的该页内存复制一份给子进程。）</p><p><strong>fork因为开销过大，现在基本已经不再使用，而是使用clone和pthread替代。</strong></p><h4 id="fork用法"><a href="#fork用法" class="headerlink" title="fork用法"></a>fork用法</h4><pre><code class="c">int main(void)&#123;    pid_t fpid; //创建一个临时变量用于存放fork的返回值    int count = 0;    fpid = fork();  //创建子进程，父进程与子进程将分别执行此后的代码    if (fpid &lt; 0)   //创建子进程失败时将返回负值      std::cout &lt;&lt; &quot;Error in fork!&quot; &lt;&lt; std::endl;    else if (fpid == 0) &#123;  //子进程中fork的返回值为0，所以将由子进程执行该分支      std::cout &lt;&lt; &quot;Child: parent_pid:&quot; &lt;&lt; getppid() &lt;&lt; &quot; pid:&quot; &lt;&lt; getpid() &lt;&lt; &quot; child_pid:&quot; &lt;&lt; fpid &lt;&lt; std::endl;      count++;  //子进程复制来的count值为0，++之后将为1    &#125;    else &#123;  //父进程中fork的返回值为子进程的pid，所以将由父进程执行该分支      std::cout &lt;&lt; &quot;Parent: parent_pid:&quot; &lt;&lt; getppid() &lt;&lt; &quot; pid:&quot; &lt;&lt; getpid() &lt;&lt; &quot; child_pid:&quot; &lt;&lt; fpid &lt;&lt; std::endl;      count++;  //父进程中count为0，父子进程中的变量等数据是完全独立的    &#125;    std::cout &lt;&lt; &quot;count: &quot; &lt;&lt; count &lt;&lt; std::endl;  //最后输出count的当前值，显示该句父子进程都要执行    return 0;&#125;</code></pre><p>输出结果为：</p><pre><code class="c">Parent: parent_pid:3084 pid:3087 child_pid:3088count: 1Child:  parent_pid:3087 pid:3088 child_pid:0count: 1</code></pre><p>可以看到父进程的中创建的子进程的pid:3088刚好是子进程当前的pid，两个进程输出的count都是1，也就是只进行了一次累加</p><p>父进程使用fork后，父进程和子进程会一起执行接下来的代码，<strong>执行n次fork函数，创建的子进程数为2^n个</strong></p><h3 id="vfork"><a href="#vfork" class="headerlink" title="vfork"></a>vfork</h3><p>vfork和fork类似，但vfork的开销更小，不会复制一份父进程的地址空间，而是共享，并且vfork后父进程会阻塞直到子进程结束。具体来说有以下区别：</p><p>1.vfork保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。</p><p>2.fork要拷贝父进程的进程环境；而vfork则不需要完全拷贝父进程的进程环境，在子进程没有调用exec和exit之前，子进程与父进程共享进程环境，相当于线程的概念，此时父进程阻塞等待。</p><h4 id="为什么会有vfork呢"><a href="#为什么会有vfork呢" class="headerlink" title="为什么会有vfork呢?"></a>为什么会有vfork呢?</h4><p>因为以前的fork当它创建一个子进程时，将会创建一个新的地址空间，并且拷贝父进程的资源，然后将会有两种行为：</p><p>1.执行从父进程那里拷贝过来的代码段</p><p>2.调用一个exec执行一个新的代码段</p><p>当进程调用exec函数时，一个新程序替换了当前进程的正文，数据，堆和栈段。这样，前面的拷贝工作就是白费力气了，这种情况下，聪明的人就想出了vfork。vfork并不复制父进程的进程环境，子进程在父进程的地址空间中运行，所以子进程不能进行写操作，并且在儿子“霸占”着老子的房子时候，要委屈老子一下了，让他在外面歇着（阻塞），一旦儿子执行了exec或者exit后，相当于儿子买了自己的房子了，这时候就相当于分家了。</p><p>因此，如果创建子进程是为了调用exec执行一个新的程序的时候，就应该使用vfork。<strong>但因为现在有了写时复制的技术，fork的开销不再像之前那样巨大，所以vfork基本已经不再使用。</strong></p><h3 id="exec"><a href="#exec" class="headerlink" title="exec"></a>exec</h3><p>exec函数族的作用是根据指定的文件名找到可执行文件，并用它来取代调用进程的内容，换句话说，就是在调用进程内部执行一个可执行文件。这里的可执行文件既可以是二进制文件，也可以是任何Linux下可执行的脚本文件。<br><strong>与一般情况不同，exec函数族的函数执行成功后不会返回</strong>，因为调用进程的实体，包括代码段，数据段和堆栈等都已经被新的内容取代，只留下进程ID等一些表面上的信息仍保持原样，颇有些神似”三十六计”中的”金蝉脱壳”。看上去还是旧的躯壳，却已经注入了新的灵魂。只有调用失败了，它们才会返回一个-1，从原程序的调用点接着往下执行。#include &lt;unistd.h&gt;</p><pre><code class="c">int execl(const char *path, const char *arg, ..., NULL);int execlp(const char *file, const char *arg, ..., NULL);int execle(const char *path, const char *arg, ..., NULL ,char *const envp[]);int execv(const char *path, char *const argv[]);int execvp(const char *file, char *const argv[]);int execve(const char *path, char *const argv[], char *const envp[]);</code></pre><p>exec函数一共有六个，其中execve为内核级系统调用，其他（execl，execle，execlp，execv，execvp）都是调用execve的库函数</p><h3 id="clone"><a href="#clone" class="headerlink" title="clone"></a>clone</h3><p>clone是Linux为创建线程设计的（虽然也可以用clone创建进程）。所以可以说clone是fork的升级版本，不仅可以创建进程或者线程，还可以指定创建新的命名空间（namespace）、有选择的继承父进程的内存、甚至可以将创建出来的进程变成父进程的兄弟进程等等。</p><p>clone函数功能强大，带了众多参数，它提供了一个非常灵活自由的常见进程的方法。因此由他创建的进程要复杂。clone可以让你有选择性的继承父进程的资源，你可以和父进程共享一个虚存空间，从而使创造的是线程，你也可以不和父进程共享，你甚至可以选择创造出来的进程和父进程不再是父子关系，而是兄弟关系。</p><p><strong>clone需要创建自己的栈。</strong></p><pre><code class="c">int clone(int (*fn)(void *), void *child_stack, int flags, void *arg);</code></pre><p>这里fn是函数指针，这个就是指向程序的指针；child_stack是为子进程分配系统堆栈空间的指针（在Linux下系统堆栈空间是2页面，就是8K的内存，其中在这块内存中，低地址上放入了值，这个值就是进程控制块task_struct的值）,flags就是标志用来描述你需要从父进程继承哪些资源， arg就是传给子进程的参数一般为（0）。下面是flags可以取的值</p><p>  CLONE_PARENT   创建的子进程的父进程是调用者的父进程，新进程与创建它的进程成了“兄弟”而不是“父子”</p><p>  CLONE_FS           子进程与父进程共享相同的文件系统，包括root、当前目录、umask</p><p>  CLONE_FILES      子进程与父进程共享相同的文件描述符（file descriptor）表</p><p>  CLONE_NEWNS   在新的namespace启动子进程，namespace描述了进程的文件hierarchy</p><p>  CLONE_SIGHAND   子进程与父进程共享相同的信号处理（signal handler）表</p><p>  CLONE_PTRACE   若父进程被trace，子进程也被trace</p><p>  CLONE_VFORK     父进程被挂起，直至子进程释放虚拟内存资源</p><p>  CLONE_VM           子进程与父进程运行于相同的内存空间</p><p>  CLONE_PID          子进程在创建时PID与父进程一致</p><p>  CLONE_THREAD    Linux 2.4中增加以支持POSIX线程标准，子进程与父进程共享相同的线程群</p><h3 id="pthread"><a href="#pthread" class="headerlink" title="pthread"></a>pthread</h3><p>phtread类库，也即是“POSIX线程”，pthreads定义了一套C语言的类型、函数与常量，它以pthread.h头文件和一个线程库实现。pthread底层是用clone创建线程的。</p><pre><code class="c">数据类型pthread_t：//线程ID(线程标识符,用于声明线程ID)pthread_attr_t：//线程属性操纵函数pthread_create()：//创建一个线程pthread_exit()：//终止当前线程pthread_cancel()：//中断另外一个线程的运行pthread_join()：//阻塞当前的线程，直到另外一个线程运行结束pthread_attr_init()：//初始化线程的属性pthread_attr_setdetachstate()：//设置脱离状态的属性（决定这个线程在终止时是否可以被结合）pthread_attr_getdetachstate()：//获取脱离状态的属性pthread_attr_destroy()：//删除线程的属性pthread_kill()：//向线程发送一个信号同步函数用于mutex和条件变量pthread_mutex_init() //初始化互斥锁pthread_mutex_destroy() //删除互斥锁pthread_mutex_lock()：//占有互斥锁（阻塞操作）pthread_mutex_trylock()：//试图占有互斥锁（不阻塞操作）。即，当互斥锁空闲时，将占有该锁；否则，立即返回。pthread_mutex_unlock(): //释放互斥锁pthread_cond_init()：//初始化条件变量pthread_cond_destroy()：//销毁条件变量pthread_cond_signal(): //唤醒第一个调用pthread_cond_wait()而进入睡眠的线程pthread_cond_wait(): //等待条件变量的特殊条件发生Thread-local storage（或者以Pthreads术语，称作线程特有数据）：pthread_key_create(): //分配用于标识进程中线程特定数据的键pthread_setspecific(): //为指定线程特定数据键设置线程特定绑定pthread_getspecific(): //获取调用线程的键绑定，并将该绑定存储在 value 指向的位置中pthread_key_delete(): //销毁现有线程特定数据键pthread_attr_getschedparam();//获取线程优先级pthread_attr_setschedparam();//设置线程优先级工具函数pthread_equal(): //对两个线程的线程标识号进行比较 pthread_detach(): 分离线程pthread_self(): 查询线程自身线程标识号</code></pre><p>例子：int pthread_create ( pthread_t *thread , const pthread_attr_t *attr , void *(start)(void) , void *arg );</p><p>执行pthread_create，将创建线程，成功则返回0,否则返回-1；<br>参数1返回一个绑定特定函数的线程ID；<br>参数2为线程属性对象指针，用来改变线程的属性；<br>参数3为线程运行的函数指针，被调用的函数必须返回空指针，且只能有一个空指针参数；<br>参数4为传递给被调用函数的参数；</p><h2 id="数据流stdin-stdout-stderr"><a href="#数据流stdin-stdout-stderr" class="headerlink" title="数据流stdin,stdout,stderr"></a>数据流stdin,stdout,stderr</h2><p>数据流，就是数据传输的通道。在Linux中，一个程序启动时，将会自动开启三个数据流通道：标准输入流、标准输出流、标准错误流。本文详细介绍标准数据流的概念及其重定向的使用。</p><p>对应的文件描述符分别是：</p><ul><li>stdin：<code>0</code></li><li>stdout：<code>1</code></li><li>stderr：<code>2</code></li></ul><p>程序运行的时候从输入流读取数据，作为程序的输入，程序运行过程中输出的信息被传送到输出流，类似的，错误信息被传送到错误流。</p><p>标准输入流默认是从键盘输入的信息，除了键盘之外，标准输入流还可以是文件，或者其它程序的输出。</p><p>输出流分为标准输出流和标准错误流，默认情况下，它们都会输出到屏幕。标准输出流也可以被重定向到另外一个程序，或者一个文件。</p><p>在Linux中，标准输入流默认来自键盘输入，标准输出流和标准错误流默认发送到屏幕。在必要的时候，可以对修改输入流的来源、修改输出流的目的，这就是重定向。</p><p>常用的重定向的符号：</p><ol><li><code>&gt;</code>： 将<strong>标准输出流</strong>重定向到文件（清空文件后写入）。</li><li><code>&gt;&gt;</code>：将标准输出流重定向到文件（追加写入）。</li><li><code>&lt;</code>：将文件作为命令的标准输入流。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/IO%E5%AF%86%E9%9B%86%E5%9E%8B%E4%BB%BB%E5%8A%A1%E5%92%8C%E8%AE%A1%E7%AE%97%E5%AF%86%E9%9B%86%E5%9E%8B%E4%BB%BB%E5%8A%A1/"/>
      <url>/2023/01/22/IO%E5%AF%86%E9%9B%86%E5%9E%8B%E4%BB%BB%E5%8A%A1%E5%92%8C%E8%AE%A1%E7%AE%97%E5%AF%86%E9%9B%86%E5%9E%8B%E4%BB%BB%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="IO密集型任务和计算密集型任务"><a href="#IO密集型任务和计算密集型任务" class="headerlink" title="IO密集型任务和计算密集型任务"></a>IO密集型任务和计算密集型任务</h1><p>计算密集型表示该任务需要大量的运算，而没有阻塞，CPU一直全速运行，CPU负载高</p><p>IO密集型系统运作时大部分的状况是CPU在等IO (硬盘&#x2F;内存) 的读写操作，因此，CPU负载并不高。</p><p>计算密集型任务的特点是要进行大量的计算，消耗CPU资源，全靠CPU的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，<strong>所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数，避免线程或进程的切换。</strong></p><blockquote><p>计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。</p></blockquote><p>IO密集型任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。涉及到网络、磁盘IO的任务都是IO密集型任务。当线程进行 I&#x2F;O 操作 CPU 空闲时，启用其他线程继续使用 CPU，以提高 CPU 的使用率。<strong>对于IO密集型任务，线程数越多，CPU效率越高，但也有一个限度。</strong></p><p>线程池设置线程数与CPU计算时间和I&#x2F;O操作时间的比例相关，在此可以引出一个配置线程池大小的原则——<strong>阻抗匹配原则</strong>，其经验公式为：</p><pre><code class="python3">C = CPU数量P = CPU繁忙时间 / 总运行时间   // 0&lt;P&lt;=1T = 所需设置线程数T = C / P</code></pre><p>考虑到P的值并不好评估，T的大小可以上下浮动50%。</p><p>这个公式原理也比较简单，T个线程，每个线程占用P的时间，正好可以占满C个CPU，也就是C &#x3D; T * P。可以验证一下：</p><p>如果P &#x3D; 1.0，C &#x3D; 16，说明这是一个完全的密集计算，此时T &#x3D; 16，也就是有几个CPU设置几个线程，这样能把CPU都利用起来。更多的线程也没用，因为CPU资源已经耗光。</p><p>如果P &#x3D; 0.5，C &#x3D; 16，说明每个线程只有50%的时间在使用CPU，此时T &#x3D; 32，也就是32个50%繁忙的线程，能充分把CPU利用起来。</p><p>如果P &lt; 0.2，这个公式就不适用了，因为线程不能无限开，会消耗大量资源。T可以取一个固定值，比如 8*C。</p><p>综上，CPU繁忙时间占比越高，设置线程数越少，CPU繁忙时间占比越低，设置线程数越多（当然也有限度）。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%8E%9F%E7%90%86/"/>
      <url>/2023/01/22/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="io多路复用原理"><a href="#io多路复用原理" class="headerlink" title="io多路复用原理"></a>io多路复用原理</h1><h2 id="select原理概述"><a href="#select原理概述" class="headerlink" title="select原理概述"></a>select原理概述</h2><p>调用select时，会发生以下事情：</p><ol><li><p>从用户空间拷贝fd_set到内核空间；</p></li><li><p>注册回调函数__pollwait；</p></li><li><p>遍历所有fd，对全部指定设备做一次poll（这里的poll是一个文件操作，它有两个参数，一个是文件fd本身，一个是当设备尚未就绪时调用的回调函数__pollwait，这个函数把设备自己特有的等待队列传给内核，让内核把当前的进程挂载到其中）；</p></li><li><p>当设备就绪时，设备就会唤醒在自己特有等待队列中的【所有】节点，于是当前进程就获取到了完成的信号。poll文件操作返回的是一组标准的掩码，其中的各个位指示当前的不同的就绪状态（全0为没有任何事件触发），根据mask可对fd_set赋值；</p></li><li><p>如果所有设备返回的掩码都没有显示任何的事件触发，就去掉回调函数的函数指针，进入有限时的睡眠状态，再恢复和不断做poll，再作有限时的睡眠，直到其中一个设备有事件触发为止。</p></li><li><p>只要有事件触发，系统调用返回，将fd_set从内核空间拷贝到用户空间，回到用户态，用户就可以对相关的fd作进一步的读或者写操作了。</p></li></ol><h2 id="epoll原理概述"><a href="#epoll原理概述" class="headerlink" title="epoll原理概述"></a>epoll原理概述</h2><p>调用epoll_create时，做了以下事情：</p><p>内核帮我们在epoll文件系统里建了个file结点；</p><p>在内核cache里建了个红黑树用于存储以后epoll_ctl传来的socket；</p><p>建立一个list链表，用于存储准备就绪的事件。</p><p>调用epoll_ctl时，做了以下事情：</p><p>把socket放到epoll文件系统里file对象对应的红黑树上；</p><p>给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。</p><p>调用epoll_wait时，做了以下事情：</p><p>观察list链表里有没有数据。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。而且，通常情况下即使我们要监控百万计的句柄，大多一次也只返回很少量的准备就绪句柄而已，所以，epoll_wait仅需要从内核态copy少量的句柄到用户态而已。</p><p>总结如下：</p><p>一颗红黑树，一张准备就绪句柄链表，少量的内核cache，解决了大并发下的socket处理问题。</p><p>执行epoll_create时，创建了红黑树和就绪链表；</p><p>执行epoll_ctl时，如果增加socket句柄，则检查在红黑树中是否存在，存在立即返回，不存在则添加到树干上，然后向内核注册回调函数，用于当中断事件来临时向准备就绪链表中插入数据;</p><p>执行epoll_wait时立刻返回准备就绪链表里的数据即可。</p><p>两种模式的区别：</p><p>LT模式下，只要一个句柄上的事件一次没有处理完，会在以后调用epoll_wait时重复返回这个句柄，而ET模式仅在第一次返回。</p><p>两种模式的实现：</p><p>如果是ET模式，当一个socket句柄上有事件时，内核会把该句柄插入上面所说的准备就绪list链表，这时我们调用epoll_wait，会把准备就绪的socket拷贝到用户态内存，然后清空准备就绪list链表，最后，epoll_wait检查这些socket，如果是LT模式，并且这些socket上确实有未处理的事件时，又把该句柄放回到刚刚清空的准备就绪链表。所以，LT模式的句柄，只要它上面还有事件，epoll_wait每次都会返回。</p><h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><p>select缺点:</p><p>最大并发数限制：使用32个整数的32位，即32*32&#x3D;1024来标识fd，虽然可修改，但是有以下第二点的瓶颈；</p><p>效率低：每次都会线性扫描整个fd_set，集合越大速度越慢；</p><p>内核&#x2F;用户空间内存拷贝问题。</p><p>epoll的提升：</p><p>本身没有最大并发连接的限制，仅受系统中进程能打开的最大文件数目限制；</p><p>效率提升：只有活跃的socket才会主动的去调用callback函数；</p><p>网上很多博客说epoll使用了共享内存,这个是完全错误的 ,可以阅读源码,会发现完全没有使用共享内存的任何api，而是 使用了copy_from_user跟__put_user进行内核跟用户虚拟空间数据交互.</p><p>当然，以上的优缺点仅仅是特定场景下的情况：高并发，且任一时间只有少数socket是活跃的。</p><p>如果在并发量低，socket都比较活跃的情况下，select就不见得比epoll慢了（就像我们常常说快排比插入排序快，但是在特定情况下这并不成立）。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/csapp/"/>
      <url>/2023/01/22/csapp/</url>
      
        <content type="html"><![CDATA[<h1 id="csapp"><a href="#csapp" class="headerlink" title="csapp"></a>csapp</h1><h2 id="计算机系统漫游"><a href="#计算机系统漫游" class="headerlink" title="计算机系统漫游"></a>计算机系统漫游</h2><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/image-20220512233937399.png" alt="image-20220512233937399"></p><h3 id="计算机技术演变过程"><a href="#计算机技术演变过程" class="headerlink" title="计算机技术演变过程"></a><strong>计算机技术演变过程</strong></h3><p>以hello程序执行为例：</p><p>先由C语言的源文件<code>hello.c</code>编译得到了可执行目标文件<code>hello</code></p><ol><li>shell读入我们输入的字符<code>./hello</code>后，将其逐一读入到CPU的寄存器中，然后再将其存放到主存中。</li><li>输入回车后，shell执行一系列指令将hello目标文件中的代码和数据从磁盘复制到主存。</li><li>CPU开始执行hello的main程序中的机器指令，它将<code>hello, world\n</code>字符串中的字节从主存复制到CPU寄存器，再从CPU寄存器复制到显示设备。</li></ol><p>由此可见执行代码时，会花费大量时间将代码和数据进行复制。而<strong>不同设备之间运行速度差距极大</strong>，在等待复制的过程中cpu浪费了大量的时间，为了加快复制速度和提高cpu利用率，引入了存储器体系结构。</p><h4 id="1-加快代码和数据的复制速度-存储器体系结构"><a href="#1-加快代码和数据的复制速度-存储器体系结构" class="headerlink" title="1.加快代码和数据的复制速度(存储器体系结构)"></a><strong>1.加快代码和数据的复制速度</strong>(存储器体系结构)</h4><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/image-20220512235134334.png" alt="image-20220512235134334"></p><p>根据<strong>局部性原理</strong>可知，程序具有访问局部区域内的数据和代码的趋势，所以在处理器和一个较大较慢的设备之间插入一个更小更快的存储设备，来暂时保存处理器近期可能会需要的数据，使得大部分的内存操作都能在高速缓存内完成，就能极大提高系统速度了。</p><p>存储器层次结构的<strong>主要思想</strong>是将上一层的存储器作为下一层存储器的高速缓存。</p><h4 id="2-简化对硬件的操作-操作系统"><a href="#2-简化对硬件的操作-操作系统" class="headerlink" title="2.简化对硬件的操作(操作系统)"></a><strong>2.简化对硬件的操作(操作系统)</strong></h4><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/image-20220512235848305.png" alt="image-20220512235848305"></p><p>程序并没有直接访问cpu，内存，I&#x2F;O这些硬件设备，真正访问硬件设备的是操作系统。所有程序对硬件的操作都必须通过操作系统来完成。它可以看成是应用程序和硬件之间的一层软件，给程序员提供硬件的抽象。</p><p>操作系统定义：给应用程序提供服务的程序。现代操作系统主要是因为<strong>更好的管理和支持多任务执行</strong>的需求而诞生的。</p><p>这样设计的目的有两个：</p><ol><li>防止硬件被失控的应用程序滥用，提高系统安全性</li><li>提供统一对硬件操作的接口，简化硬件操作</li></ol><p>为了实现这些功能操作系统引入了几个抽象的概念，<strong>抽象就是对外提供统一接口而隐藏内部复杂的细节</strong>，操作系统对于程序来说就是硬件的抽象。</p><p>操作系统将cpu，内存，I&#x2F;O设备抽象为进程；将内存和磁盘I&#x2F;O抽象为虚拟内存；将I&#x2F;O设备抽象为文件的形式。让程序员能够直接通过这层软件很好地调用硬件，避免了过多的硬件细节。</p><h5 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a><strong>进程</strong>和线程</h5><p><strong>为什么引入进程：</strong>为了支持和管理多任务并发执行</p><p>一开始操作系统是单道批处理系统，一个作业单独进入内存并独占系统资源，直到运行结束后下一个作业才能进入内存，当作业进行I&#x2F;O操作时，CPU只能处于等待状态，因此，CPU利用率较低。为此需要引入多道程序并发执行。</p><p>进程看起来在独占地使用硬件(而实际在和其他进程分时共享资源)，为程序员屏蔽了多道程序并发执行时进程调度和进程切换的细节。这样程序员就无需考虑程序之间切换所需操作的硬件，这些由操作系统的内核进行管理。</p><p><strong>为什么引入线程：</strong>为了进一步提高并发度，减少多进程的开销</p><p>对于，线程相比进程能减少开销，体现在：</p><ul><li>线程的<strong>创建</strong>时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；</li><li>线程的<strong>终止</strong>时间比进程快，因为线程释放的资源相比进程少很多；</li><li>同一个进程内的线程<strong>切换</strong>比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；</li><li>由于同一进程的各线程间共享内存和文件资源，那么在线程之间<strong>通信</strong>的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；</li></ul><p>所以，线程比进程不管是时间效率，还是空间效率都要高。</p><p><strong>多线程还是多进程</strong></p><p>多进程模式最大的优点就是稳定性高，因为一个进程崩溃了，不会影响其他进程。著名的Apache最早就是采用多进程模式。</p><p>多进程模式的缺点是创建进程的代价大，在Unix&#x2F;Linux系统下，用<code>fork</code>调用还行，在Windows下创建进程开销巨大。另外，操作系统能同时运行的进程数也是有限的，在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。</p><table><thead><tr><th><strong>对比维度</strong></th><th><strong>多进程</strong></th><th><strong>多线程</strong></th><th><strong>总结</strong></th></tr></thead><tbody><tr><td>数据共享、同步</td><td>数据共享复杂，需要用IPC；数据是分开的，同步简单</td><td>因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂</td><td>各有优势</td></tr><tr><td>内存、CPU</td><td>占用内存多，切换复杂，CPU利用率低</td><td>占用内存少，切换简单，CPU利用率高</td><td>线程占优</td></tr><tr><td>创建销毁、切换</td><td>创建销毁、切换复杂，速度慢</td><td>创建销毁、切换简单，速度很快</td><td>线程占优</td></tr><tr><td>编程、调试</td><td>编程简单，调试简单</td><td>编程复杂，调试复杂</td><td>进程占优</td></tr><tr><td>可靠性</td><td>进程间不会互相影响</td><td>一个线程挂掉将导致整个进程挂掉</td><td>进程占优</td></tr><tr><td>分布式</td><td>适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单</td><td>适应于多核分布式</td><td>进程占优</td></tr></tbody></table><p><strong>需要频繁创建销毁的优先用线程</strong></p><p>这种原则最常见的应用就是Web服务器了，来一个连接建立一个线程，断了就销毁线程，要是用进程，创建和销毁的代价是很难承受的</p><p><strong>需要进行大量计算的优先使用线程</strong></p><p>所谓大量计算，当然就是要耗费很多CPU，切换频繁了，这种情况下线程是最合适的。</p><p>这种原则最常见的是图像处理、算法处理。</p><p><strong>强相关的处理用线程，弱相关的处理用进程</strong></p><p>一般的Server需要完成如下任务：消息收发、消息处理。“消息收发”和“消息处理”就是弱相关的任务，而“消息处理”里面可能又分为“消息解码”、“业务处理”，这两个任务相对来说相关性就要强多了。因此“消息收发”和“消息处理”可以分进程设计，“消息解码”、“业务处理”可以分线程设计。</p><p><strong>可能要扩展到多机分布的用进程，多核分布的用线程</strong></p><p>原因请看上面对比。</p><h5 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a><strong>虚拟内存</strong></h5><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/image-20220513215415380.png" alt="image-20220513215415380"></p><p><strong>为什么引入虚拟内存</strong>：解决多程序系统中内存分配和管理问题</p><ol><li><strong>解决地址空间不隔离问题</strong>：若所有程序都直接访问物理地址，程序所使用的内存空间不是相互隔离的。程序可以很容易改写其他程序的内存数据，以达到破坏的目的，这对于需要安全稳定的计算环境的用户来说是不能容忍的。用户希望他在使用计算机的时候，其中一个任务失败了，至少不会影响其他任务。</li><li><strong>解决内存使用效率低问题：</strong>如果没有有效的内存管理机制，通常需要一个程序执行时，监控程序就将整个程序装入内存中然后开始执行。而当内存没有程序所需的连续空间时，就不得不将其他程序换出到磁盘，效率十分低下。</li><li><strong>解决程序运行地址不确定问题：</strong>程序每次运行时都要给它在内存中分配一块空闲空间，这个空间位置不确定。这会导致程序编写十分困难，因为程序中访问数据和指令跳转的目标地址很多都是固定的。</li></ol><p>虚拟内存屏蔽了虚拟地址到物理地址的转换过程，让程序看起来就像是在独占地使用内存。</p><h5 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h5><p><strong>为什么引入文件：</strong>简化对I&#x2F;O设备的操作，屏蔽操作的细节</p><p>操作系统将所有I&#x2F;O设备看成是文件，而文件是字节序列，这样系统中的所有输入输出可以调用系统函数来读写文件实现，简化了对各种各样的I&#x2F;O设备的操作。</p><h4 id="3-提高计算能力"><a href="#3-提高计算能力" class="headerlink" title="3.提高计算能力"></a>3.提高计算能力</h4><h5 id="线程级并发"><a href="#线程级并发" class="headerlink" title="线程级并发"></a>线程级并发</h5><p><strong>单处理器系统</strong></p><p>多进程和多线程使得多任务并发处理成为可能，提高了cpu利用率</p><p><strong>多处理器系统</strong></p><p>多处理器系统主要分成超线程和多核处理器。</p><p>多核处理器：将多个CPU集成到一个集成电路中，然后使用一个L3高速缓存来在多个核之间共享数据。</p><p>超线程：超线程是在CPU内部仅复制必要的资源(如程序计数器和寄存器文件)，而其他硬件部分只有一部分(如ALU)，让两个线程可同时执行。超线程技术可以让一个核同时运行两个线程，相当于模拟了双核心、双线程运行。</p><h5 id="指令级并行"><a href="#指令级并行" class="headerlink" title="指令级并行"></a>指令级并行</h5><p>一个指令的执行过程通常包含：取指令阶段、解码阶段和执行指令阶段。最初的指令执行过程是每个指令完整经过一整个过程后，才运行下一条指令，但是其实每个阶段使用的都是处理器中不同的硬件部分，这就使得我们可以<strong>流水线</strong>式地运行多个指令，这就达到了差不多一个时钟周期运行一条指令的地步。</p><h5 id="单指令、多数据并行"><a href="#单指令、多数据并行" class="headerlink" title="单指令、多数据并行"></a>单指令、多数据并行</h5><p>很多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为单指令、多数据，即<strong>SIMD并行</strong>。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/CMake%20%E6%A8%A1%E5%9D%97%E5%8C%96%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"/>
      <url>/2023/01/22/CMake%20%E6%A8%A1%E5%9D%97%E5%8C%96%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="CMake-模块化项目管理"><a href="#CMake-模块化项目管理" class="headerlink" title="CMake 模块化项目管理"></a>CMake 模块化项目管理</h1><h2 id="自己项目文件-x2F-目录组织规范"><a href="#自己项目文件-x2F-目录组织规范" class="headerlink" title="自己项目文件&#x2F;目录组织规范"></a>自己项目文件&#x2F;目录组织规范</h2><h3 id="推荐的目录组织方式"><a href="#推荐的目录组织方式" class="headerlink" title="推荐的目录组织方式"></a><strong>推荐的目录组织方式</strong></h3><p><strong>源文件组织格式：</strong></p><ul><li>头文件存储路径：项目名&#x2F;include&#x2F;项目名&#x2F;模块名.h(需要在模块名前面再加一层项目名文件夹，这是为了让不同项目的头文件不会出现命名冲突)</li><li>cpp文件存储路径：项目名&#x2F;src&#x2F;模块名.cpp(直接在src下存储)</li></ul><img src="https://raw.githubusercontent.com/hufei96/Image/main/project_dirctory.png" alt="image-20221215015212928" style="zoom: 33%;" /><p><strong>CMakeLists.txt 引入头文件：</strong></p><pre><code class="cmake">#不要使用include_directories，那会给所有目标添加目录，污染头文件空间target_include_directories(项目名 PUBLIC include)</code></pre><p> <strong>源码文件中使用模块：</strong></p><ul><li>包含时加上项目名：#include &lt;项目名&#x2F;模块名.h&gt;</li><li>使用时加上命名空间：项目名::函数名();</li></ul><p><strong>头文件（项目名&#x2F;include&#x2F;项目名&#x2F;模块名.h）中写：</strong></p><pre><code class="c++">#pragma oncenamespace 项目名 &#123;void 函数名();&#125;</code></pre><p><strong>实现文件（项目名&#x2F;src&#x2F;模块名.cpp）中写：</strong></p><pre><code class="c++">#include &lt;项目名/模块名.h&gt;namespace 项目名 &#123;void 函数名() &#123; 函数实现 &#125;&#125;</code></pre><h3 id="划分子项目"><a href="#划分子项目" class="headerlink" title="划分子项目"></a>划分子项目</h3><p>大型的项目，往往会划分为几个子项目。即使你只有一个子项目，也建议你先创建一个子目录，方便以后追加新的子项目。</p><p>上图的案例中，我们在根目录下，创建了两个子项目 biology 和 pybmain，他们分别在各自的目录下有自己的 CMakeLists.txt。</p><h4 id="根项目和子项目的CMakeLists-txt配置"><a href="#根项目和子项目的CMakeLists-txt配置" class="headerlink" title="根项目和子项目的CMakeLists.txt配置"></a>根项目和子项目的CMakeLists.txt配置</h4><p>根项目的 CMakeLists.txt 负责处理全局有效的设定。而子项目的 CMakeLists.txt 则仅考虑该子项目自身的设定，比如他的头文件目录，要链接的库等等。</p><p><strong>根项目的CMakeLists.txt配置</strong></p><p>在根项目的 CMakeLists.txt 中，设置了默认的构建模式，设置了统一的 C++ 版本等各种选项。然后通过 project 命令初始化了根项目。(<strong>这些设置应该放在project命令之前</strong>)</p><p>随后通过 add_subdirectory 把两个子项目 pybmain 和 biology 添加进来（顺序无关紧要），这会调用 pybmain&#x2F;CMakeLists.txt 和 biology&#x2F;CMakeLists.txt。</p><pre><code class="cmake">cmake_minimum_required(VERSION 3.18)if (NOT CMAKE_BUILD_TYPE)    set(CMAKE_BUILD_TYPE Release)endif()set(CMAKE_CXX_STANDARD 20)set(CMAKE_CXX_STANDARD_REQUIRED ON)set(CMAKE_CXX_EXTENSIONS OFF)set(CMAKE_MODULE_PATH &quot;$&#123;CMAKE_CURRENT_LIST_DIR&#125;/cmake;$&#123;CMAKE_MODULE_PATH&#125;&quot;)project(CppCMakeDemo LANGUAGES CXX)include(MyUsefulFuncs)add_subdirectory(pybmain)add_subdirectory(biology)</code></pre><p><strong>子项目的CMakeLists.txt配置</strong></p><p>子项目的 CMakeLists.txt 就干净许多，只是创建了 biology 这个静态库对象，并通过 GLOB_RECRUSE 为他批量添加了所有位于 src 和 include 下源码和头文件。</p><pre><code class="cmake">file(GLOB_RECURSE srcs CONFIGURE_DEPENDS src/*.cpp include/*.h)add_library(biology STATIC $&#123;srcs&#125;)#使用PUBLIC修饰符，这是为了让链接 biology 的 pybmain 也能够共享 根/biology/include 这个头文件搜索路径target_include_directories(biology PUBLIC include)</code></pre><h4 id="依赖子项目"><a href="#依赖子项目" class="headerlink" title="依赖子项目"></a>依赖子项目</h4><p>依赖另一个子项目，则需要链接他</p><pre><code class="cmake">file(GLOB_RECURSE srcs CONFIGURE_DEPENDS src/*.cpp include/*.h)add_executable(pybmain $&#123;srcs&#125;)target_include_directories(pybmain PUBLIC include)target_link_libraries(pybmain PUBLIC biology)</code></pre><p>由于 PUBLIC 属性具有传染性，根&#x2F;biology&#x2F;include 现在也加入 pybmain 的头文件搜索路径了，因此 pybmain 里可以 #include 到 biology 的头文件。</p><p>同理如果又有一个 target_link_libraries(zxxpig PUBLIC pybmain) 那么 zxxpig 也有 pybmain 和 biology 的所有头文件搜索路径了。</p><h2 id="第三方库-x2F-依赖项配置"><a href="#第三方库-x2F-依赖项配置" class="headerlink" title="第三方库&#x2F;依赖项配置"></a>第三方库&#x2F;依赖项配置</h2><h3 id="怎么链接第三方库"><a href="#怎么链接第三方库" class="headerlink" title="怎么链接第三方库"></a>怎么链接第三方库</h3><p>使用find_package<strong>寻找系统中安装的第三方库</strong>并链接他们(必须先安装)。<strong>在链接前需要先查看库的配置文件</strong>，确定其使用现代CMake还是古代CMake，否则无法知道怎么链接。</p><p><strong>大部分第三方库都需要提前安装好，然后再 find_package 找到他</strong>，然后才能链接。也有少数第三方库为了方便，还支持作为子项目加到你的项目中来，这种就不需要 :: 语法。</p><p><strong>标准方法：</strong></p><pre><code class="cmake">find_package(spdlog REQUIRED)target_link_libraries(yourapp PUBLIC spdlog::spdlog)</code></pre><p><strong>邪教方法：</strong></p><pre><code class="cmake">add_subdirectory(spdlog) # 需要下载好他们的源码放到你的根目录下target_link_libraries(yourapp PUBLIC spdlog)</code></pre><h3 id="find-package-命令用法举例"><a href="#find-package-命令用法举例" class="headerlink" title="find_package 命令用法举例"></a><strong>find_package 命令用法举例</strong></h3><pre><code class="cmake">#查找名为 OpenCV 的包，找不到不报错，事后可以通过 $&#123;OpenCV_FOUND&#125; 查询是否找到。find_package(OpenCV)#查找名为 OpenCV 的包，找不到不报错，也不打印任何信息。find_package(OpenCV QUIET)#查找名为 OpenCV 的包，找不到就报错（并终止 cmake 进程，不再继续往下执行）。find_package(OpenCV REQUIRED) #最常见用法#查找名为 OpenCV 的包，找不到就报错，且必须具有 OpenCV::core 和 OpenCV::videoio 这两个组件，没有组件也报错find_package(OpenCV REQUIRED COMPONENTS core videoio)#查找名为 OpenCV 的包，找不到就报错，可具有 OpenCV::core 和 OpenCV::videoio 这两个组件，没有这两组件不会报错，通过 $&#123;OpenCV_core_FOUND&#125; 查询是否找到 core 组件。find_package(OpenCV REQUIRED OPTIONAL_COMPONENTS core videoio)</code></pre><p><strong>指定find_package搜索包配置文件或是包搜索文件</strong></p><pre><code class="cmake">#只会寻找 FindTBB.cmake，搜索路径：$&#123;CMAKE_MODULE_PATH&#125;（默认为 /usr/share/cmake/Modules）find_package(TBB MODULE REQUIRED)#只会寻找 TBBConfig.cmake，搜索路径：1.$&#123;CMAKE_PREFIX_PATH&#125;/lib/cmake/TBB（默认为 /usr/lib/cmake/TBB）#2.$&#123;TBB_DIR&#125; 或 $ENV&#123;TBB_DIR&#125;find_package(TBB CONFIG REQUIRED)#不指定则两者都会尝试，先尝试 FindTBB.cmake，再尝试 TBBConfig.cmake。find_package(TBB REQUIRED)</code></pre><p><strong>指定库的版本号</strong></p><p>软件行业记录版本迭代普遍采用的是一套所谓的<strong>语义版本号</strong>系统，英文简称 semver。通常他的格式是三个用点分隔开来的十进制数字：&lt;major&gt;.&lt;minor&gt;.&lt;patch&gt;</p><p>例如：1.2.0，0.6.8，18.11.0</p><ul><li>major 称为主版本号，出现功能重大变更，以至于和旧 API 不兼容的时候会增加该号。</li><li>minor 称为次版本号，功能有所变更或增加，但依然和旧的 API 兼容时会增加该号。</li><li>patch 称为补丁版号，功能没有改变，只是修复了一些 bug 就重新发布时会增加该号。</li></ul><p>也有的软件不拘一格，索性用发布的日期作为版本号的三个数字，例如 2022.11.2。不论采用哪种编号方案，都是几个用点分开的数字，并且数字越大越新，且优先比较靠前面的数字。因此为了通用，CMake 支持最多四个点分开的版本号：&lt;major&gt;.&lt;minor&gt;.&lt;patch&gt;.&lt;tweak&gt;。并且如果你写 0.6.8 他会自动帮你把多余的 tweak 默认为 0，也就是说 0.6.8 &#x3D;&#x3D; 0.6.8.0，1.2 &#x3D;&#x3D; 1.2.0 &#x3D;&#x3D; 1.2.0.0。</p><p>比较版本号时，可以用 if (${XXX_VERSION} <strong>VERSION_LESS</strong> 3.1.0) 判断大小。</p><pre><code class="cmake">#查找名为 OpenCV 的包，不限版本，事后可以通过 $&#123;OpenCV_VERSION&#125; 查询找到的版本。find_package(OpenCV REQUIRED)#查找版本在 2.0.1 以上的 OpenCV 包（version &gt;= 2.0.1）。find_package(OpenCV 2.0.1 REQUIRED)#查找版本刚好为 2.0.1 的 OpenCV 包（version == 2.0.1）。find_package(OpenCV 2.0.1 EXACT REQUIRED)#如果没写全，则没写的部分默认为 0。例如下列三者等价：find_package(OpenCV 2 REQUIRED)find_package(OpenCV 2.0 REQUIRED)find_package(OpenCV 2.0.0 REQUIRED)</code></pre><h3 id="find-package实际在寻找什么"><a href="#find-package实际在寻找什么" class="headerlink" title="find_package实际在寻找什么"></a>find_package实际在寻找什么</h3><p>find_package实际是在寻找库的CMake配置文件，形式如 <strong>包名</strong> <strong>+</strong> <strong>Config.cmake</strong> ，这些文件可称为<strong>包配置文件</strong>。</p><p>所以find_package(OpenCV) 实际上是在找一个名为 <strong>OpenCVConfig.cmake</strong> 的文件。(出于历史兼容性考虑，除了 OpenCVConfig.cmake 以外 <strong>OpenCV-config.cmake</strong> 这个文件名也会被 CMake 识别到)；同理，find_package(Qt5) 则是会去找名为 <strong>Qt5Config.cmake</strong> 的文件。</p><p>这些配置文件在你安装库时，会随着 libxx.so 等实际的库文件一起装到你的系统中去。以 Arch Linux 系统中安装Qt5为例：</p><p>包配置文件位于 &#x2F;usr&#x2F;lib&#x2F;cmake&#x2F;Qt5&#x2F;Qt5Config.cmake。</p><p>实际的动态库文件位于 &#x2F;usr&#x2F;lib&#x2F;libQt5Core.so。</p><p>这个配置文件里包含了包的具体信息，包括动态库文件的位置，头文件的目录，链接时需要开启的编译选项等等。而且某些库都具有多个子动态库，例如 Qt 就有 libQt5Core.so、libQt5Widgets.so、libQt5Network.so。因此 CMake 要求所有第三方库作者统一包装成一个 Qt5Config.cmake 文件包含所有相关信息（类似于 nodejs 的 package.json），比你单独的一个个去找动态库文件要灵活的多。</p><p>包配置文件由第三方库的作者（Qt的开发团队）提供，在这个库安装时（Qt的安装程序或apt install等）会自动放到 &#x2F;usr&#x2F;lib&#x2F;cmake&#x2F;XXX&#x2F;XXXConfig.cmake 这个路径（其中XXX是包名），供 CMake 用户找到并了解该包的具体信息。</p><p>&#x2F;usr&#x2F;lib&#x2F;cmake 这个位置是 CMake 和第三方库作者<strong>约定俗成</strong>的，由第三方库的安装程序负责把包配置文件放到这里。如果第三方库的作者比较懒，没提供 CMake 支持（由安装程序提供XXXConfig.cmake），那么得用另外的一套方法（FindXXX.cmake）。</p><h3 id="find-package的搜索路径"><a href="#find-package的搜索路径" class="headerlink" title="find_package的搜索路径"></a>find_package的搜索路径</h3><p><strong>Windows</strong> <strong>系统下的搜索路径</strong></p><pre><code class="c++">&lt;prefix&gt;/&lt;prefix&gt;/cmake/&lt;prefix&gt;/&lt;name&gt;*/&lt;prefix&gt;/&lt;name&gt;*/cmake/&lt;prefix&gt;/&lt;name&gt;*/(lib/&lt;arch&gt;|lib*|share)/cmake/&lt;name&gt;*/&lt;prefix&gt;/&lt;name&gt;*/(lib/&lt;arch&gt;|lib*|share)/&lt;name&gt;*/&lt;prefix&gt;/&lt;name&gt;*/(lib/&lt;arch&gt;|lib*|share)/&lt;name&gt;*/cmake///其中 &lt;prefix&gt; 是变量 $&#123;CMAKE_PREFIX_PATH&#125;，Windows 平台默认为 C:/Program Files。//&lt;name&gt; 是你在 find_package(&lt;name&gt; REQUIRED) 命令中指定的包名。//&lt;arch&gt; 是系统的架构名。</code></pre><p><strong>Unix</strong> <strong>类系统下的搜索路径</strong></p><pre><code class="c++">&lt;prefix&gt;/(lib/&lt;arch&gt;|lib*|share)/cmake/&lt;name&gt;*/&lt;prefix&gt;/(lib/&lt;arch&gt;|lib*|share)/&lt;name&gt;*/&lt;prefix&gt;/(lib/&lt;arch&gt;|lib*|share)/&lt;name&gt;*/cmake/&lt;prefix&gt;/&lt;name&gt;*/(lib/&lt;arch&gt;|lib*|share)/cmake/&lt;name&gt;*/&lt;prefix&gt;/&lt;name&gt;*/(lib/&lt;arch&gt;|lib*|share)/&lt;name&gt;*/&lt;prefix&gt;/&lt;name&gt;*/(lib/&lt;arch&gt;|lib*|share)/&lt;name&gt;*/cmake///其中 &lt;prefix&gt; 是变量 $&#123;CMAKE_PREFIX_PATH&#125;，Unix 平台默认为 /usr。//&lt;name&gt; 是你在 find_package(&lt;name&gt; REQUIRED) 命令中指定的包名。//&lt;arch&gt; 是系统的架构，例如 x86_64-linux-gnu 或 i386-linux-gnu。(用于伺候 Ubuntu 喜欢把库文件套娃在 /usr/lib/x86_64-linux-gnu 目录下)</code></pre><p><strong>举例说明</strong> <strong>find_package</strong> <strong>搜索路径</strong></p><p>以Qt5为例：</p><p>在64 位的 Linux 系统，find_package(Qt5 REQUIRED) 会依次搜索：</p><pre><code class="shell">/usr/lib/cmake/Qt5/Qt5Config.cmake/usr/lib/x86_64-linux-gnu/cmake/Qt5/Qt5Config.cmake/usr/share/cmake/Qt5/Qt5Config.cmake/usr/lib/Qt5/Qt5Config.cmake/usr/lib/x86_64-linux-gnu/Qt5/Qt5Config.cmake/usr/share/Qt5/Qt5Config.cmake/usr/Qt5/lib/cmake/Qt5/Qt5Config.cmake/usr/Qt5/lib/x86_64-linux-gnu/cmake/Qt5/Qt5Config.cmake/usr/Qt5/share/cmake/Qt5/Qt5Config.cmake/usr/Qt5/lib/Qt5/Qt5Config.cmake/usr/Qt5/lib/x86_64-linux-gnu/Qt5/Qt5Config.cmake/usr/Qt5/share/Qt5/Qt5Config.cmake</code></pre><p>64 位的 Windows 系统，find_package(Qt5 REQUIRED) 会依次搜索：</p><pre><code>C:/Program Files/Qt5Config.cmakeC:/Program Files/cmake/Qt5Config.cmakeC:/Program Files/Qt5/Qt5Config.cmakeC:/Program Files/Qt5/cmake/Qt5Config.cmakeC:/Program Files/Qt5/lib/cmake/Qt5/Qt5Config.cmakeC:/Program Files/Qt5/lib/x86_64-windows-gnu/cmake/Qt5/Qt5Config.cmakeC:/Program Files/Qt5/share/cmake/Qt5/Qt5Config.cmakeC:/Program Files/Qt5/lib/Qt5/Qt5Config.cmakeC:/Program Files/Qt5/lib/x86_64-windows-gnu/Qt5/Qt5Config.cmakeC:/Program Files/Qt5/share/Qt5/Qt5Config.cmake</code></pre><p>还有一点，&lt;name&gt; <strong>可以有额外后缀，且不分大小写</strong>（无论 Linux 还是 Windows），例如下面路径同样都是可以被 find_package(Qt5 REQUIRED) 搜索到的。</p><pre><code class="shell">C:/Program Files/Qt5/cmake/Qt5Config.cmakeC:/Program Files/Qt5.12.1/cmake/Qt5Config.cmakeC:/Program Files/qt5dnmd/cmake/Qt5Config.cmake#Linux同理，同样都是可以被 find_package(OpenCV REQUIRED) 搜索到的。/usr/lib/cmake/OpenCV/OpenCVConfig.cmake/usr/lib/cmake/opencv4/OpenCVConfig.cmake</code></pre><h3 id="寻找安装在非标准路径的库"><a href="#寻找安装在非标准路径的库" class="headerlink" title="寻找安装在非标准路径的库"></a>寻找安装在非标准路径的库</h3><p>以 Qt5 为例，如果你安装在下列标准路径，find_package 能够自动找到。</p><p>Windows：C:&#x2F;Program Files&#x2F;Qt5.12.1&#x2F;lib&#x2F;cmake&#x2F;Qt5&#x2F;Qt5Config.cmake。</p><p>Linux：&#x2F;usr&#x2F;lib&#x2F;cmake&#x2F;Qt5&#x2F;Qt5Config.cmake。</p><p>但是假如我的库不是装在这些标准路径，而是我<strong>自定义的路径</strong>，怎么办？而且即使你不自定义安装路径，Windows 版的 Qt 默认安装就会安装到：C:&#x2F;Qt5.12.1&#x2F;msvc2017_64&#x2F;lib&#x2F;cmake&#x2F;Qt5&#x2F;Qt5Config.cmake。</p><p>何况我们同学有的还喜欢装到 D 盘去，<strong>Windows 是非标准路径的重灾区</strong>，他就没有一个统一的 &#x2F;usr&#x2F;lib 目录。然而你一旦把库安装到非标准路径，find_package 是找不到的。</p><p><strong>这时你需要手动指定一个变量告诉他在哪儿</strong>，可以是普通变量 **${Qt5_DIR}**，也可以是环境变量 **$ENV{Qt5_DIR}**，两个中只要设置了任何一个 find_package 都可以识别到。</p><p><strong>设置变量的方法</strong></p><p>以Qt5为例</p><p><strong>Windows下设置变量</strong></p><p>例如我把 Qt5 安装到了 D:&#x2F;Qt5.12.1。首先找到他里面的 Qt5Config.cmake 文件所在位置（可以用文件管理器的“搜索”功能）。</p><p>假如你找到该文件的位置是 D:&#x2F;Qt5.12.1&#x2F;msvc2017&#x2F;lib&#x2F;cmake&#x2F;Qt5&#x2F;Qt5Config.cmake，那么请你设置变量 Qt5_DIR 为 D:&#x2F;Qt5.12.1&#x2F;msvc2017&#x2F;lib&#x2F;cmake&#x2F;Qt5。有三种设置方法：</p><ul><li>单次有效。在 configure 阶段，可以从命令行设置（注意路径要加引号）：</li></ul><pre><code class="shell">cmake -B build -DQt5_DIR=&quot;D:/Qt5.12.1/msvc2017/lib/cmake/Qt5&quot;</code></pre><ul><li><p>全局启用。右键“我的电脑”-&gt;“管理”-&gt;“高级”添加一个环境变量 Qt5_DIR 值为 D:&#x2F;Qt5.12.1&#x2F;msvc2017&#x2F;lib&#x2F;cmake&#x2F;Qt5，然后重启 Visual Studio。这样以后你每次构建任何项目，find_package 都能自动找到这个路径的 Qt5 包了。</p></li><li><p>单项目有效。直接在你自己项目的 CMakeLists.txt 最开头写一行（注意路径要加引号，且一定要加在最前面）</p></li></ul><pre><code class="cmake">set(Qt5_DIR &quot;D:/Qt5.12.1/msvc2017/lib/cmake/Qt5&quot;) </code></pre><p><strong>Linux下设置变量</strong></p><p>例如我把 Qt5 安装到了 &#x2F;opt&#x2F;Qt5.12.1。首先找到他里面的 Qt5Config.cmake 文件所在位置（可以用文件管理器的“搜索”功能）。</p><p>假如你找到该文件的位置是 &#x2F;opt&#x2F;Qt5.12.1&#x2F;lib&#x2F;cmake&#x2F;Qt5&#x2F;Qt5Config.cmake，那么请你设置变量 Qt5_DIR 为 &#x2F;opt&#x2F;Qt5.12.1&#x2F;lib&#x2F;cmake&#x2F;Qt5。有三种设置方法：</p><ul><li>单次有效。在 configure 阶段，可以从命令行设置（注意路径要加引号）：</li></ul><pre><code class="shell">cmake -B build -DQt5_DIR=&quot;/opt/Qt5.12.1/lib/cmake/Qt5&quot;</code></pre><ul><li><p>全局启用。修改你的 ~&#x2F;.bashrc 文件添加环境变量：export Qt5_DIR&#x3D;”&#x2F;opt&#x2F;Qt5.12.1&#x2F;lib&#x2F;cmake&#x2F;Qt5”，然后重启终端。这样以后你每次构建任何项目，find_package 都能自动找到这个路径的 Qt5 包了。</p></li><li><p>单项目有效。直接在你自己项目的 CMakeLists.txt 最开头写一行（注意路径要加引号，且一定要加在最前面）</p></li></ul><pre><code class="cmake">set(Qt5_DIR &quot;/opt/Qt5.12.1/lib/cmake/Qt5&quot;)    </code></pre><p><strong>三种方案利弊分析</strong></p><ul><li><p>单次有效（通过命令行）最安全，<strong>推荐</strong>。</p></li><li><p>全局有效（添加环境变量）可能影响以后其他项目。比如你 A 项目依赖 Qt5.12.1，你设置了环境变量 Qt5_DIR&#x3D;&#x2F;opt&#x2F;Qt5.12.1，后来又搞了个 B 项目依赖 Qt5.10.3，但是你忘了你设置过全局的环境变量指向 5.12.1 了，导致版本冲突。</p></li><li><p>单项目有效（写死在 CMakeLists.txt）虽然方便了你，但是你的 CMakeLists.txt 拿到别人电脑上（例如你通过 GitHub 开源的），可能你 set(Qt5_DIR D:&#x2F;Qt5)，而人家却需要 set(Qt5_DIR E:&#x2F;Qt5) 呢？就冲突了。</p></li></ul><p>因此最推荐单次有效。虽然麻烦，但因为CMake可以缓存变量，实际上只要你不删 build，不需要每次都 -DQt5_DIR 一下。</p><h3 id="学习Qt5的目录组织格式"><a href="#学习Qt5的目录组织格式" class="headerlink" title="学习Qt5的目录组织格式"></a>学习Qt5的目录组织格式</h3><p><strong>Qt5在Windows下的格式</strong></p><p>例如你安装 Qt 时设置安装路径为 D:&#x2F;Qt5.12.1。</p><p>则你会看到他下面有几个子目录：</p><ul><li>D:&#x2F;Qt5.12.1&#x2F;msvc2017_64（由VS2017编译64位版本）</li><li>D:&#x2F;Qt5.12.1&#x2F;mingw_64（由MinGW编译64位版本）</li></ul><p>这几个目录里又分别包含：</p><ul><li>D:&#x2F;Qt5.12.1&#x2F;msvc2017_64&#x2F;include&#x2F;qt&#x2F;QtCore&#x2F;<strong>qstring.h</strong>（实际的头文件，属于 Qt5::Core）</li><li>D:&#x2F;Qt5.12.1&#x2F;msvc2017_64&#x2F;bin&#x2F;<strong>Qt5Core.dll</strong>（实际的动态库文件，对应 Qt5::Core）</li><li>D:&#x2F;Qt5.12.1&#x2F;msvc2017_64&#x2F;lib&#x2F;<strong>Qt5Core.lib</strong>（实际的静态库文件，对应 Qt5::Core）</li><li>D:&#x2F;Qt5.12.1&#x2F;msvc2017_64&#x2F;lib&#x2F;cmake&#x2F;Qt5&#x2F;<strong>Qt5Config.cmake</strong>（包配置文件）</li></ul><p>可以看到尽管是 Windows 版的 Qt，他内部仍然是在模仿 Linux 下 &#x2F;usr 的目录组织格式。</p><p>注意这里的 Qt5Core.dll 位于 bin 目录，而不是 lib 目录，这是为什么呢？因为 <strong>Windows 要求 exe 和 dll 位于同一目录，否则 exe 在运行时就会找不到 dll</strong>。为了符合 Linux 分离 bin 和 lib 的组织格式，又要伺候 Windows 的沙雕同目录规则，我们通常把 dll 动态库文件视为“可执行文件”和 exe 一起放到 bin 目录，而静态库则没有运行时必须同目录的限制，所以可以照常放到 lib 目录。</p><p><strong>Qt5在Linux下的格式</strong></p><p>Linux 用户从源码安装 Qt 这种库时，会有一个 –prefix 选项，指定安装的根路径。</p><p>默认的 –prefix 是 &#x2F;usr，这个路径由全部软件共享，Qt 会把他的文件安装到以下目录：</p><ul><li>&#x2F;usr&#x2F;include&#x2F;qt&#x2F;QtCore&#x2F;<strong>qstring.h</strong>（实际的头文件，对应 Qt5::Core）</li><li>&#x2F;usr&#x2F;lib&#x2F;lib<strong>Qt5Core.so</strong>（实际的动态库文件，对应 Qt5::Core）</li><li>&#x2F;usr&#x2F;lib&#x2F;lib<strong>Qt5Core.a</strong>（实际的静态库文件，对应 Qt5::Core）</li><li>&#x2F;usr&#x2F;lib&#x2F;cmake&#x2F;Qt5&#x2F;<strong>Qt5Config.cmake</strong>（包配置文件，用于 find_package）</li></ul><p>假如你指定 –prefix&#x3D;&#x2F;opt&#x2F;myqtroot，这个路径通常是用户自己手动装的软件，那么就会变成：</p><ul><li>&#x2F;opt&#x2F;myqtroot&#x2F;lib&#x2F;cmake&#x2F;Qt5&#x2F;<strong>Qt5Config.cmake</strong></li></ul><p>伺候这种非常规安装，就需要设置变量 -DQt5_DIR&#x3D;&#x2F;opt&#x2F;myqtroot&#x2F;lib&#x2F;cmake&#x2F;Qt5 了。</p><h3 id="安装库的通用方法"><a href="#安装库的通用方法" class="headerlink" title="安装库的通用方法"></a>安装库的通用方法</h3><p><strong>Makefile 构建系统：</strong></p><pre><code class="shell">./configure --prefix=/usr --with-some-options  # 生成 Makefile（这个 configure 脚本由 Autoconf 生成）make -j 8        # 8 核心编译，生成 libtest.sosudo make install  # 安装，拷贝到 /usr/lib/libtest.so</code></pre><p><strong>CMake 构建系统：</strong></p><pre><code class="shell">cmake -B build -DCMAKE_INSTALL_PREFIX=/usr -DWITH_SOME_OPTIONS=ON # 生成 Makefilecmake --build build --parallel 8         # 8 核心编译，生成 libtest.so#注：如果 -DCMAKE_INSTALL_PREFIX=/usr/local 则会拷贝到 /usr/local/lib/libtest.sosudo cmake --build build --target install  # 安装，拷贝到 /usr/lib/libtest.so</code></pre><h3 id="第三方库没有提供Config文件的解决方法"><a href="#第三方库没有提供Config文件的解决方法" class="headerlink" title="第三方库没有提供Config文件的解决方法"></a>第三方库没有提供Config文件的解决方法</h3><p>绝大多数常用 C++ 库都提供了 CMake 支持（即使他们本身不一定是用 CMake 构建的），这些 <strong>Config</strong> <strong>文件</strong>都是由<strong>第三方库负责</strong>安装到 &#x2F;usr&#x2F;lib&#x2F;cmake。</p><p>但是，也有少数不听话的库，官方不提供 CMake 支持，即安装时不自带 Config 文件。恼人的是，这些不听话的库有些竟然是非常热门的库！例如 Python，CUDA，Jemalloc。</p><p>为了不影响 CMake 用户体验，CMake 发明了 <strong>Find</strong> <strong>文件</strong>（FindXXX.cmake），你不支持我是吧？我支持你！Find 文件会在 <strong>CMake</strong> <strong>安装时负责</strong>安装到 &#x2F;usr&#x2F;share&#x2F;cmake&#x2F;Modules。</p><p>包搜索文件可以在不知道包具体位置信息的情况下搜索他们（在 &#x2F;usr&#x2F;lib 等默认路径搜索）。这些都是 CMake 自带的包搜索文件：</p><ul><li>&#x2F;usr&#x2F;share&#x2F;cmake&#x2F;Modules&#x2F;FindCUDAToolkit.cmake</li><li>&#x2F;usr&#x2F;share&#x2F;cmake&#x2F;Modules&#x2F;FindPython.cmake</li></ul><p><strong>下载和使用包搜索文件</strong></p><p>那么如果有个不太热门的第三方库没提供包配置文件，CMake 也没提供包搜索文件，我们该如何找到他？这就<strong>需要自己提供包搜索文件</strong>了！别担心，你不用自己写，GitHub 上有很多志士仁人已经写过了对应的包搜索文件，你搜一下 FindXXX.cmake 就能找到了。</p><p>虽然 <strong>Config</strong> <strong>文件</strong>通常风格比较统一，都是 XXX::xxx 这种格式。但是不同的 <strong>Find</strong> <strong>文件</strong>，特别是这种网上志士仁人自己编写的文件，风格可能千差万别，很多都还是古代 CMake 的用法，例如 ${XXX_LIBRARIES}。关于具体使用的细节可以打开 FindXXX.cmake 文件查看，他里面前半部分是注释，会讲解如何使用。</p><p>现在你下载这个文件，<strong>放到项目根目录相对路径 cmake&#x2F;FindXXX.cmake。然后在你的 CMakeLists.txt 里最上面写一行：</strong></p><pre><code class="cmake">set(CMAKE_MODULE_PATH &quot;$&#123;CMAKE_CURRENT_LIST_DIR&#125;/cmake;$&#123;CMAKE_MODULE_PATH&#125;&quot;)</code></pre><p>这样你之后的 find_package(XXX) 就会用你下载的这个 FindXXX.cmake 去找包了。</p><h3 id="链接现代古代CMake库的不同"><a href="#链接现代古代CMake库的不同" class="headerlink" title="链接现代古代CMake库的不同"></a>链接现代古代CMake库的不同</h3><p>大多现代的 Find&#x2F;Config 文件，都同时兼容现代和古代的用法。特别古老的 Find 文件，则只能用古代的用法。</p><p><strong>现代和古代的区别</strong></p><p>不管是 Find 类还是 Config 类，<strong>一定要打开相应的 cmake 文件看看注释</strong>，才能确定他是古代风格还是现代风格。</p><p>古代 CMake 的命名规范高度不统一，有的是 ${XXX_LIBRARIES}，有的又是 ${XXX_LIBRARY} 非常沙雕，需要看相应 cmake 文件的注释，才能确定具体是怎么命名的。</p><p>现代 CMake 就好多了，统一用 <strong>包名::组件名</strong> 的格式。但是具体的组件名，还是要查看 cmake 文件中的注释才能确定。例如 CURL::libcurl OpenCV::core Qt5::core TBB::tbb 等。</p><p><strong>链接现代和古代的区别</strong></p><p><strong>古代</strong>（仅用于伺候很老的库）：</p><pre><code class="cmake">find_package(XXX)if (NOT XXX_FOUND)message(FATAL_ERROR “XXX not found”)endif()target_include_directories(yourapp $&#123;XXX_INCLUDE_DIRS&#125;)target_link_libraries(yourapp $&#123;XXX_LIBRARIES&#125;)</code></pre><p><strong>现代</strong>：</p><pre><code class="cmake">find_package(XXX REQUIRED COMPONENTS xxx)target_link_libraries(yourapp XXX::xxx)</code></pre><h3 id="古代CMake常见问题"><a href="#古代CMake常见问题" class="headerlink" title="古代CMake常见问题"></a>古代CMake常见问题</h3><p><strong>链接步骤</strong></p><p>1.target_link_libraries(yourapp <strong>${XXX_LIBRARIES}</strong>)</p><p>2.target_include_directories(yourapp <strong>${XXX_INCLUDE_DIRS}</strong>)</p><p>Q: 我明明链接了 XXX 库，编译时却报错“找不到头文件 XXX.h”怎么办？</p><p>A: 你漏了上面的 2。</p><p>Q: 我明明编译都通过了，链接却报错“undefined symbol：XXXfunc”怎么办？</p><p>A: 你漏了上面的 1。</p><p><strong>解决方法</strong></p><p>打印检查一下这两个变量是不是空的：message(“!!!!!!” <strong>${XXX_INCLUDE_DIRS}</strong>)，如果为空说明你变量名打错了，CMake 特色就是<strong>找不到变量不报错，而是视为空字符串</strong>。去看一下 FindXXX.cmake 里的注释（那就是文档），到底是什么名字。</p><h3 id="总结第三方库的安装和使用"><a href="#总结第三方库的安装和使用" class="headerlink" title="总结第三方库的安装和使用"></a>总结第三方库的安装和使用</h3><p>安装 TBB：</p><pre><code class="shell">cd tbb./configure --prefix=/opt/tbbinstalldir #以安装在自定义路径为例make -j 8sudo make install</code></pre><p>在你的项目里使用 TBB：</p><pre><code class="shell">cd yourappcmake -B build -DTBB_DIR=/opt/tbbinstalldir/lib/cmake/TBBcmake --build build --parallel 8</code></pre><p>CMakeLists.txt 这样写：</p><pre><code class="cmake">project(yourapp)add_executable(yourapp yourmain.cpp)find_package(TBB CONFIG REQUIRED COMPONENTS tbb)target_link_libraries(yourapp PUBLIC TBB::tbb)</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/c++%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/"/>
      <url>/2023/01/22/c++%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="c-异步编程"><a href="#c-异步编程" class="headerlink" title="c++异步编程"></a>c++异步编程</h1><h2 id="std-future"><a href="#std-future" class="headerlink" title="std::future"></a>std::future</h2><p>std::future期待一个返回，从一个异步调用的角度来说，<strong>future更像是函数的返回值</strong>，异步调用往往不知道何时返回，但是如果异步调用的过程需要同步，或者说后一个异步调用需要使用前一个异步调用的结果。这个时候就要用到future。</p><p>线程可以周期性的在这个future上等待一小段时间，检查future是否已经ready，如果没有，该线程可以先去做另一个任务，一旦future就绪，<strong>该future就无法复位（无法再次使用这个future等待这个事件），所以future代表的是一次性事件</strong>。</p><h3 id="future的类型"><a href="#future的类型" class="headerlink" title="future的类型"></a>future的类型</h3><p>在<code>&lt;future&gt;</code>库的头文件中声明了两种future，唯一future（std::future）和共享future（std::shared_future）这两个是参照std::unique_ptr和std::shared_ptr设立的，前者的实例是仅有的一个指向其关联事件的实例，而后者可以有多个实例指向同一个关联事件，当事件就绪时，所有指向同一事件的std::shared_future实例会变成就绪。</p><h3 id="future的使用"><a href="#future的使用" class="headerlink" title="future的使用"></a>future的使用</h3><p>std::future是一个模板，例如<code>std::future&lt;int&gt;</code>，模板参数就是期待返回的类型，虽然future被用于线程间通信，但其本身却并不提供同步访问，必须通过互斥元或其他同步机制来保护访问。</p><p>future使用的时机是当你不需要立刻得到一个结果的时候，你可以开启一个线程帮你去做一项任务，并期待这个任务的返回，但是std::thread并没有提供这样的机制，这就需要用到std::async和std::future（都在<code>&lt;future&gt;</code>头文件中声明）。</p><p>std::async返回一个std::future对象，而不是给你一个确定的值。当你需要使用这个值的时候，对future使用get()，线程就会阻塞直到future就绪，然后返回该值。</p><pre><code class="cpp">#include &lt;future&gt;#include &lt;iostream&gt;int find_result_to_add()&#123;    return 1 + 1;&#125;void do_other_things() &#123;    std::cout &lt;&lt; &quot;Hello World&quot; &lt;&lt; std::endl;&#125;int main()&#123;    std::future&lt;int&gt; result = std::async(find_result_to_add);    do_other_things();    std::cout &lt;&lt; result.get() &lt;&lt; std::endl;    return 0;&#125;</code></pre><h2 id="std-async"><a href="#std-async" class="headerlink" title="std::async"></a>std::async</h2><p><code>std::async</code>跟<code>std::thread</code>类似，区别在于thread无法获取函数的返回值，而async可以。</p><p><code>std::async</code>会自动创建一个线程去调用线程函数，它返回一个<code>std::future</code>，这个future中存储了线程函数返回的结果，当我们需要线程函数的结果时，直接从future中获取，非常方便。</p><p>跟thread类似，async允许你通过将额外的参数添加到调用中，来将附加参数传递给函数。如果传入的函数指针是某个类的成员函数，则还需要将类对象指针传入（直接传入，传入指针，或者是std::ref封装）。</p><p>默认情况下，std::async是否启动一个新线程，或者在等待future时，任务是否同步运行都取决于你给的参数。这个参数为std::launch类型</p><ul><li>std::launch::defered表明该函数会被延迟调用，直到在future上调用get()或者wait()为止</li><li>std::launch::async，表明函数会在自己创建的线程上运行</li><li>std::launch::any &#x3D; std::launch::defered | std::launch::async</li><li>std::launch::sync &#x3D; std::launch::defered</li></ul><pre><code class="dart">enum class launch&#123;    async,deferred,sync=deferred,any=async|deferred&#125;;</code></pre><p><strong>PS：默认选项参数被设置为std::launch::any。如果函数被延迟运行可能永远都不会运行。</strong></p><p>async的原理大概是这样的：std::async先将异步操作用std::packaged_task包装起来，然后将异步操作的结果放到std::promise中，外面再通过future.get&#x2F;wait来获取这个未来的结果。std::async类似封装了<code>thread</code>和<code>packged_task</code>的功能，使得我们使用起来更加方便简单。</p><h2 id="std-packaged-task"><a href="#std-packaged-task" class="headerlink" title="std::packaged_task"></a>std::packaged_task</h2><p><code>std::packaged_task</code>和<code>std::function</code>类似，区别在于<code>std::packaged_task</code>可以用于异步调用，packaged_task.get_future()可以返回<code>std::future</code>，配合future使用可以异步获取函数的返回值。</p><pre><code class="cpp">#include &lt;future&gt;#include &lt;iostream&gt;int add(int a, int b)&#123;    return a + b;&#125;void do_other_things() &#123;    std::cout &lt;&lt; &quot;Hello World&quot; &lt;&lt; std::endl;&#125;int main()&#123;    std::packaged_task&lt;int(int, int)&gt; task(add);    do_other_things();    std::future&lt;int&gt; result = task.get_future();    task(1, 1); //必须要让任务执行，否则在get()获取future的值时会一直阻塞    std::cout &lt;&lt; result.get() &lt;&lt; std::endl;    return 0;&#125;</code></pre><h2 id="std-promise"><a href="#std-promise" class="headerlink" title="std::promise"></a>std::promise</h2><p><code>std::promise&lt;T&gt;</code>与<code>std::future&lt;T&gt;</code>配合使用，区别在于promise只写，而future只读。promise用于写入函数的返回值，而future则可以从promise处获取返回值。</p><p>在创建promise的同时会获得一个future，然后将promise传递给其他线程，当前线程则持有future，future.get()会阻塞直到promise写入返回值。</p><pre><code class="cpp">#include &lt;future&gt;#include &lt;string&gt;#include &lt;thread&gt;#include &lt;iostream&gt;void print(std::promise&lt;std::string&gt;&amp; p)&#123;    p.set_value(&quot;There is the result whitch you want.&quot;);&#125;void do_some_other_things()&#123;    std::cout &lt;&lt; &quot;Hello World&quot; &lt;&lt; std::endl;&#125;int main()&#123;    std::promise&lt;std::string&gt; promise;    std::future&lt;std::string&gt; result = promise.get_future();    std::thread t(print, std::ref(promise));    do_some_other_things();    std::cout &lt;&lt; result.get() &lt;&lt; std::endl; //阻塞直到，p.set_value()执行完成    t.join();    return 0;&#125;</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/c++%E7%B1%BB%E7%9A%84%E9%BB%98%E8%AE%A4%E5%87%BD%E6%95%B0/"/>
      <url>/2023/01/22/c++%E7%B1%BB%E7%9A%84%E9%BB%98%E8%AE%A4%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="c-类的默认函数"><a href="#c-类的默认函数" class="headerlink" title="c++类的默认函数"></a>c++类的默认函数</h1><p>在C++中，一个类有八个默认函数：</p><ul><li><p>默认构造函数；</p></li><li><p>默认拷贝构造函数；</p></li><li><p>默认析构函数；</p></li><li><p>默认重载赋值运算符函数；</p></li><li><p>默认重载取址运算符函数；</p></li><li><p>默认重载取址运算符const函数；</p></li><li><p>默认移动构造函数（C++11）；</p></li><li><p>默认重载移动赋值运算符函数（C++11）。</p></li></ul><p>其中默认移动构造函数和默认重载移动赋值运算符函数是c++11后加入的内容。</p><p><strong>这些函数只有在第一次被调用时，才会被编译器创建。所有这些函数都是inline和public的。</strong></p><p>C++11新增标识符default和delete,控制这些默认函数是否使用。</p><ul><li>default：被标识的默认函数将使用类的默认行为，如：A() &#x3D; default;</li><li>delete：被标识的默认函数将禁用，如：A() &#x3D; delete;</li><li>override：被标识的函数需要强制重写基类虚函数；</li><li>final：被标识的函数禁止重写基类虚函数；</li></ul><pre><code class="c++">class A&#123;public:    // 默认构造函数;    A();    // 默认拷贝构造函数    A(const A&amp;);    // 默认析构函数    ~A();    // 默认重载赋值运算符函数    A&amp; operator = (const A&amp;);    // 默认重载取址运算符函数    A* operator &amp; ();    // 默认重载取址运算符const函数    const A* operator &amp; () const;    // 默认移动构造函数    A(A&amp;&amp;);    // 默认重载移动赋值操作符    A&amp; operator = (const A&amp;&amp;);&#125;;</code></pre><h2 id="默认移动构造函数"><a href="#默认移动构造函数" class="headerlink" title="默认移动构造函数"></a>默认移动构造函数</h2><p>默认移动构造函数只有在<strong>没有自定义拷贝构造函数</strong>、<strong>没有自定义operator&#x3D;<strong>也</strong>没有自定义析构函数</strong>的时候才会自动生成。</p><p>这是因为默认的移动构造函数不会帮你将原对象的资源指针赋值为nullptr而是简单的复制，如果自定义了这些函数，编译器就认为对象内存在资源，而默认实现因为不会将原对象的资源指针赋值为nullptr可能导致资源被意外销毁，因此就不会生成默认的移动构造函数了。</p><p>默认移动构造的实现：C++编译器合成的默认移动函数对于POD类型只是简单把其值拷贝，等同于默认拷贝构造函数；对于string这种自定义了移动构造函数的类才会调用其移动构造函数，发生真正的资源移动。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/"/>
      <url>/2023/01/22/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="自动驾驶"><a href="#自动驾驶" class="headerlink" title="自动驾驶"></a>自动驾驶</h1><h2 id="算法类"><a href="#算法类" class="headerlink" title="算法类"></a>算法类</h2><h3 id="SLAM算法工程师"><a href="#SLAM算法工程师" class="headerlink" title="SLAM算法工程师"></a>SLAM算法工程师</h3><p>SLAM英文全名叫simultaneous localization and mapping，中文名叫<strong>同步定位与建图</strong>。SLAM算法属于<strong>感知—规划—控制</strong>中的<strong>感知类算法</strong>。该算法主要用于自动驾驶车辆的根据<strong>点云数据</strong>对车辆周围环境的地图构建。而其中的点云数据是由两种传感器来进行采集的，包括激光雷达和摄像头</p><h4 id="激光SLAM算法工程师"><a href="#激光SLAM算法工程师" class="headerlink" title="激光SLAM算法工程师"></a><strong>激光SLAM算法工程师</strong></h4><p>激光SLAM的传感器即为激光雷达。</p><p><strong>激光SLAM所需要学习很多滤波算法,如：ESKF、EKF、UKF等。同时需要学习G2O、ceres等用来优化非线性误差函数的c++框架。</strong></p><h4 id="视觉SLAM算法工程师"><a href="#视觉SLAM算法工程师" class="headerlink" title="视觉SLAM算法工程师"></a><strong>视觉SLAM算法工程师</strong></h4><p>视觉SLAM中的传感器即为摄像头，摄像头如果使用深度相机，可以直接获取障碍物的距离，生成点云数据。当然也有用单目、双目、鱼眼摄像机的 视觉SLAM ，这些摄像头需要用其他的方法才能间接的获取周围障碍物的距离。</p><p>学习常用的vSLAM算法，如ORB-SLAM、SVO、DSO、MonoSLAM，VINS以及RGB-D等；ROS机器人操作系统；还需要学习很多滤波算法，如：ESKF、EKF、UKF等。同时需要学习G2O、ceres等用来优化非线性误差函数的c++框架。</p><h3 id="感知融合算法工程师"><a href="#感知融合算法工程师" class="headerlink" title="感知融合算法工程师"></a>感知融合算法工程师</h3><p>在实际的自动驾驶车辆上，SLAM 其实是需要多个传感器进行融合的，取长补短，比如GPS、IMU（惯性导航）等传感器融合的方案，所以自动驾驶算法方向又出现了下面的一个新的岗位，即感知融合算法工程师。</p><p>掌握camera、毫米波雷达(电磁波)、超声波雷达(声波)、激光雷达、惯性导航等相关数据解析融合算法；熟悉感知融合算法发展趋势。</p><h3 id="决策算法工程师"><a href="#决策算法工程师" class="headerlink" title="决策算法工程师"></a>决策算法工程师</h3><p>自动驾驶的决策是指给将知模块传递的信息，如何决策汽车的行为达到驾驶的目标。例如，汽车加速、减速、左转、右转、换道、超车都是决策模块的输出。决策需要考虑到汽车的安全性和舒适性，保证尽快到达目标地点，还需要在旁边的车辆恶意的情况下保证乘客的安全。</p><p>需要学习常用的决策算法，如决策状态机、决策树、马尔可夫决策过程，POMDP等；如果往深里学的话，还需要学习深度学习，学习深度学习框架等。</p><h3 id="规划算法工程师"><a href="#规划算法工程师" class="headerlink" title="规划算法工程师"></a>规划算法工程师</h3><p><strong>规划包括路径规划和速度规划，一般都是做路径规划的比较多。即自动驾驶路径规划工程师。</strong></p><p>规划算法中，自动驾驶车辆首先通过路径规划确定车辆可行驶的路径，然后选择该路径确定可行驶的速度。</p><p>学习常见路径规划算法，例如A<em>、D</em>、RRT等；如果往深里学的话；学习轨迹预测算法，如MDP、POMDP、Came Theory等；学习ROS机器人操作系统；学习深度学习和强化学习技术也是加分项，例如RNN、LSTM、Deep Q-Learning等。</p><h3 id="控制算法工程师"><a href="#控制算法工程师" class="headerlink" title="控制算法工程师"></a>控制算法工程师</h3><p>控制算法方向偏向于传统方向，一般是对车辆横纵向动力学建模，然后开发控制算法，实现车辆运动控制等。</p><p>学习自动控制理论基础；学习车辆动力学模型；学习CarSim等仿真软件；学习ACC、AEB、APA、LKA、LCC等辅助驾驶功能开发的是加分项。</p><h3 id="视觉算法工程师"><a href="#视觉算法工程师" class="headerlink" title="视觉算法工程师"></a><strong>视觉算法工程师</strong></h3><p>该方向主要基于摄像头传感器，主要包括：车道线检测、车辆等障碍物检测、可行驶区域检测、红绿灯等交通信息检测等等。</p><p>需要机器学习的基本算法 ( 降维、分类、回归等 )；需要学习深度学习，深度学习框架；学习计算机视觉和图像处理的常用方法 ( 物体检测、跟踪、分割、分类识别等 ) 。</p><h3 id="仿真方向"><a href="#仿真方向" class="headerlink" title="仿真方向"></a>仿真方向</h3><p>该方向需要参与自动驾驶相关仿真系统的搭建，包括车辆动力学相关仿真，各类虚拟传感器模型和虚拟场景的建模与仿真，根据测试案例搭建测试场景，执行自动驾驶算法仿真测试等等。以下为基于Carla仿真平台的自动驾驶仿真演示视频。</p><p>熟练操作一种常用车辆动力学或无人车相关仿真软件，比如Perscan、Carsim、Carmaker等。熟悉机器人操作系统ROS等。有的仿真岗位纯属于做仿真，但有的岗位需要做仿真环境的开发，这样的岗位对编程要求会更高一些。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7/"/>
      <url>/2023/01/22/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="智能指针的线程安全性"><a href="#智能指针的线程安全性" class="headerlink" title="智能指针的线程安全性"></a>智能指针的线程安全性</h1><p>shared_ptr 有两个数据成员，读写操作不能原子化，shared_ptr 的引用计数本身是线程安全且无锁的，但 shared_ptr 管理的对象本身的读写则不是。</p><p>shared_ptr 是引用计数型智能指针，计数值保存在堆上动态分配的内存中。具体而言，<code>shared_ptr&lt;Foo&gt;</code>包含两个成员，一个是 Foo 类型的指针，指向被管理的对象；一个 ref_count 指针，指向堆上的控制块：</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/shared_ptr.png" alt="shared_ptr"></p><p>由于 shared_ptr 间的拷贝涉及两个成员的复制，而这两步拷贝不会原子性地发生：</p><ul><li>步骤 1：复制 ptr 指针</li><li>步骤 2：复制 ref_count 指针，并递增引用计数（此递增为线程安全的）</li></ul><p><strong>多线程读 shared_ptr 是安全的</strong></p><p> 一个全局的 shared_ptr：</p><pre><code class="cpp">shared_ptr&lt;Foo&gt; global_ptr;</code></pre><p> 线程 1 到 N 运行：</p><pre><code class="cpp">void threadFunc()&#123;    shared_ptr&lt;Foo&gt; local = global_ptr;&#125;</code></pre><p>以上对于 shared_ptr 变量<code>global</code>的读取操作是线程安全的。</p><p><strong>多线程写同一个shared_ptr是不安全的</strong></p><p>考虑以下场景，有三个 shared_ptr：</p><pre><code class="cpp">shared_ptr&lt;Foo&gt; g(new Foo);     // 线程间共享的 shared_ptr 对象shared_ptr&lt;Foo&gt; n(new Foo);     // 线程 B 的局部变量shared_ptr&lt;Foo&gt; x;      // 线程 A 的局部变量</code></pre><p>现在假设让x &#x3D; g，当ptr 指针已经复制而引用计数还没有+1时，也就是步骤1已经发生而步骤2还未发生时，执行g &#x3D; n。</p><p>因为g的引用计数还没有+1，g &#x3D; n会导致g的引用计数减1变为0，g指向的对象销毁，从而导致x指向的对象已经销毁，指针变为野指针。</p><p><strong>为什么要尽量使用 make_shared()</strong></p><p>为了节省一次内存分配，原来 shared_ptr<Foo> x(new Foo); 需要为 Foo 和 ref_count 各分配一次内存，现在用 make_shared() 的话，可以一次分配一块足够大的内存，供 Foo 和 ref_count 对象容身。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/make_shared.png" alt="img"></p><p>不过 Foo 的构造函数参数要传给 make_shared()，后者再传给 Foo::Foo()，这只有在 C++11 里通过 perfect forwarding 才能完美解决。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/"/>
      <url>/2023/01/22/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/</url>
      
        <content type="html"><![CDATA[<h1 id="智能指针"><a href="#智能指针" class="headerlink" title="智能指针"></a>智能指针</h1><p>在传统 C++ 中，『记得』手动释放资源，总不是最佳实践。因为我们很有可能就忘记了去释放资源而导致泄露。 所以通常的做法是对于一个对象而言，我们在构造函数的时候申请空间，而在析构函数（在离开作用域时调用）的时候释放空间， 也就是我们常说的 RAII 资源获取即初始化技术。</p><p>C++11 引入了智能指针的概念，使用了引用计数的想法，让程序员不再需要关心手动释放内存。 这些智能指针包括 <code>std::shared_ptr</code>&#x2F;<code>std::unique_ptr</code>&#x2F;<code>std::weak_ptr</code>，使用它们需要包含头文件 <code>&lt;memory&gt;</code>。</p><p>智能指针解决了忘记释放资源而导致内存泄露的问题，还解决了多线程编程中资源共享的问题(shared_ptr保证线程使用资源时，这个资源没有被其他线程析构)</p><h2 id="unique-ptr"><a href="#unique-ptr" class="headerlink" title="unique_ptr"></a>unique_ptr</h2><p><code>std::unique_ptr</code> 是一种独占的智能指针，它禁止其他智能指针与其共享同一个对象，从而保证代码的安全：</p><pre><code>std::unique_ptr&lt;int&gt; pointer = std::make_unique&lt;int&gt;(10); // make_unique 从 C++14 引入std::unique_ptr&lt;int&gt; pointer2 = pointer; // 非法</code></pre><blockquote><p><code>make_unique</code> 并不复杂，C++11 没有提供 <code>std::make_unique</code>，可以自行实现：</p><pre><code>template&lt;typename T, typename ...Args&gt;std::unique_ptr&lt;T&gt; make_unique( Args&amp;&amp; ...args ) &#123;  return std::unique_ptr&lt;T&gt;( new T( std::forward&lt;Args&gt;(args)... ) );&#125;</code></pre><p>至于为什么没有提供，C++ 标准委员会主席 Herb Sutter 在他的<a href="https://herbsutter.com/gotw/_102/">博客</a>中提到原因是因为『被他们忘记了』。</p></blockquote><p>既然是独占，换句话说就是不可复制。<strong>unique_ptr禁用了拷贝构造和赋值运算符，但是实现了移动拷贝和移动赋值</strong>，需要转移资源控制权时我们可以利用 <code>std::move</code> 将其转移给其他的 <code>unique_ptr</code></p><h2 id="shared-ptr"><a href="#shared-ptr" class="headerlink" title="shared_ptr"></a>shared_ptr</h2><p><code>std::shared_ptr</code> 是一种智能指针，它能够记录多少个 <code>shared_ptr</code> 共同指向一个对象，从而消除显式的调用 <code>delete</code>，当引用计数变为零的时候就会将对象自动删除。shared_ptr可以延长对象的生命周期，解决了多线程编程中资源共享的问题(shared_ptr保证线程使用资源时，这个资源没有被其他线程析构)</p><p>shared_ptr 有两个数据成员，读写操作不能原子化，shared_ptr 的引用计数本身是线程安全且无锁的，但 shared_ptr 管理的对象本身的读写则不是。</p><p><strong>shared_ptr 是引用计数型智能指针，计数值保存在堆上动态分配的内存中</strong>。具体而言，<code>shared_ptr&lt;Foo&gt;</code>包含两个成员，一个是 Foo 类型的指针，指向被管理的对象；一个 ref_count 指针，指向堆上的控制块：</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/shared_ptr.png" alt="shared_ptr"></p><p>由于 shared_ptr 间的拷贝涉及两个成员的复制，而这两步拷贝不会原子性地发生：</p><ul><li>步骤 1：复制 ptr 指针</li><li>步骤 2：复制 ref_count 指针，并递增引用计数（此递增为线程安全的）</li></ul><p>因为使用 <code>std::shared_ptr</code> 仍然需要使用 <code>new</code> 来调用，这使得代码出现了某种程度上的不对称。</p><p><code>std::make_shared</code> 就能够用来消除显式的使用 <code>new</code>，所以<code>std::make_shared</code> 会分配创建传入参数中的对象， 并返回这个对象类型的<code>std::shared_ptr</code>指针。例如：</p><pre><code class="cpp">#include &lt;iostream&gt;#include &lt;memory&gt;int main() &#123;    // auto pointer = new int(10); // illegal, no direct assignment    // Constructed a std::shared_ptr    auto pointer = std::make_shared&lt;int&gt;(10);    // The shared_ptr will be destructed before leaving the scope    return 0;&#125;</code></pre><p><code>std::shared_ptr</code> 可以通过 <code>get()</code> 方法来获取原始指针，通过 <code>reset()</code> 来减少一个引用计数， 并通过<code>use_count()</code>来查看一个对象的引用计数。</p><p><strong>为什么要尽量使用 make_shared()</strong></p><p>为了节省一次内存分配，原来 shared_ptr<Foo> x(new Foo); 需要为 Foo 和 ref_count 各分配一次内存，现在用 make_shared() 的话，可以一次分配一块足够大的内存，供 Foo 和 ref_count 对象容身。</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/make_shared.png" alt="img"></p><p>不过 Foo 的构造函数参数要传给 make_shared()，后者再传给 Foo::Foo()，这只有在 C++11 里通过 perfect forwarding 才能完美解决。</p><h2 id="weak-ptr"><a href="#weak-ptr" class="headerlink" title="weak_ptr"></a>weak_ptr</h2><p><code>std::shared_ptr</code>在对象互相引用时依然存在着资源无法释放的问题。看下面这个例子：</p><pre><code class="c++">struct A &#123;    std::shared_ptr&lt;B&gt; pointer;    ~A() &#123;        std::cout &lt;&lt; &quot;A 被销毁&quot; &lt;&lt; std::endl;    &#125;&#125;;struct B &#123;    std::shared_ptr&lt;A&gt; pointer;    ~B() &#123;        std::cout &lt;&lt; &quot;B 被销毁&quot; &lt;&lt; std::endl;    &#125;&#125;;int main() &#123;    auto a = std::make_shared&lt;A&gt;();    auto b = std::make_shared&lt;B&gt;();    a-&gt;pointer = b;    b-&gt;pointer = a;&#125;</code></pre><p>运行结果是 A, B 都不会被销毁，这是因为 a,b 内部的 pointer 同时又引用了 <code>a,b</code>，这使得 <code>a,b</code> 的引用计数均变为了 2，而离开作用域时，<code>a,b</code> 智能指针被析构，却只能造成这块区域的引用计数减一，这样就导致了 <code>a,b</code> 对象指向的内存区域引用计数不为零，而外部已经没有办法找到这块区域了，也就造成了内存泄露，如图：</p><p><img src="https://raw.githubusercontent.com/hufei96/Image/main/pointers1.png"></p><p>根本原因在于A中持有B对象的shared_ptr，这保证了B一定比A晚析构（shared_ptr保证你在使用资源时一定没有析构）。而B中持有A对象的shared_ptr，这保证了A一定比B晚析构。这构成了矛盾，从而导致A，B都无法析构。</p><p>解决这个问题的办法就是使用弱引用指针 <code>std::weak_ptr</code>，<code>std::weak_ptr</code>是一种弱引用（相比较而言 <code>std::shared_ptr</code> 就是一种强引用）。弱引用不会引起引用计数增加。<strong>weak_ptr需要用shared_ptr进行初始化</strong>。<strong>weak_ptr无法保证资源一定更晚析构，它只能检测资源是否析构</strong>。在使用时需要提升到shared_ptr再进行使用，这一步操作是原子的。</p><p><code>std::weak_ptr</code> 没有 <code>*</code> 运算符和 <code>-&gt;</code> 运算符，<strong>所以不能够对资源进行操作</strong>，它可以用于检查 <code>std::shared_ptr</code> 是否存在，其 <code>expired()</code> 方法能在资源未被释放时，会返回 <code>false</code>，否则返回 <code>true</code>；除此之外，它也可以用于获取指向原始对象的 <code>std::shared_ptr</code> 指针，其 <code>lock()</code> 方法在原始对象未被释放时，返回一个指向原始对象的 <code>std::shared_ptr</code> 指针，进而访问原始对象的资源，否则返回<code>nullptr</code>。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E5%BC%82%E5%B8%B8/"/>
      <url>/2023/01/22/%E5%BC%82%E5%B8%B8/</url>
      
        <content type="html"><![CDATA[<h1 id="异常和异常安全"><a href="#异常和异常安全" class="headerlink" title="异常和异常安全"></a>异常和异常安全</h1><p>程序运行时常会碰到一些异常情况，例如：</p><ul><li>做除法的时候除数为 0；（<strong>c++无法捕获除0异常</strong>，需要自行提前判断）</li><li>用户输入年龄时输入了一个负数；</li><li>用 new 运算符动态分配空间时，空间不够导致无法分配；</li><li>访问数组元素时，下标越界；打开文件读取时，文件不存在。</li></ul><p>这些异常情况，如果不能catch处理，则会不断向上抛出，直到程序崩溃。</p><p>所谓“处理”，可以是让程序沿一条不会出错的路径继续执行；也可能是不得不结束程序，但在结束前做一些必要的工作，如记录错误到文件中、将内存中的数据写入文件、关闭打开的文件等。</p><p><strong>进程崩溃是一种保护机制</strong>，是为了防止继续犯下更大的错误。比如说用户原本有10块钱，消费了1块钱，但是扣减一块钱的过程失败了，如果继续执行下去，就会按照用户仍然拥有10块钱处理，可能会造成严重的损失。</p><p><strong>是操作系统决定让进程崩溃的</strong>，而不是CPU。当操作系统实在不知道如何让一个线程继续执行下去了，就会让它所在的整个进程崩溃。</p><h2 id="异常处理基本语法"><a href="#异常处理基本语法" class="headerlink" title="异常处理基本语法"></a>异常处理基本语法</h2><h3 id="throw"><a href="#throw" class="headerlink" title="throw"></a>throw</h3><p>C++ 通过 throw 语句和 try…catch 语句实现对异常的处理。throw 语句的语法如下：</p><pre><code class="cpp">throw 表达式;</code></pre><p>该语句拋出一个异常。异常是一个表达式，其值的类型可以是基本类型，也可以是类。</p><p>函数 A 在执行过程中发现异常时可以不加处理，而只是“拋出一个异常”给 A 的调用者，假定为函数 B。拋出异常而不加处理会导致函数 A 立即中止，在这种情况下，函数 B 可以选择捕获 A 拋出的异常进行处理，也可以选择置之不理。如果置之不理，这个异常就会被拋给 B 的调用者，以此类推,直到main函数，若main函数也不处理，则程序崩溃。</p><h3 id="try…catch"><a href="#try…catch" class="headerlink" title="try…catch"></a>try…catch</h3><p>try…catch 语句的语法如下：</p><pre><code class="cpp">try &#123;  语句组&#125;catch(异常类型) &#123;  异常处理代码&#125;...catch(异常类型) &#123;  异常处理代码&#125;</code></pre><p>catch 可以有多个，但至少要有一个。</p><p>try…catch 语句的执行过程是：</p><ul><li>执行 try 块中的语句，如果执行的过程中没有异常拋出，那么执行完后就执行最后一个 catch 块后面的语句，所有 catch 块中的语句都不会被执行；</li><li>如果 try 块执行的过程中拋出了异常，那么拋出异常后立即跳转到第一个和拋出的异常类型匹配的 catch 块中执行（称作异常被该 catch 块“捕获”），执行完后再跳转到最后一个 catch 块后面继续执行。</li></ul><h4 id="能够捕获任何异常的-catch-语句"><a href="#能够捕获任何异常的-catch-语句" class="headerlink" title="能够捕获任何异常的 catch 语句"></a>能够捕获任何异常的 catch 语句</h4><p>如果希望不论拋出哪种类型的异常都能捕获，可以编写如下 catch 块,这样的 catch 块能够捕获任何还没有被捕获的异常。</p><pre><code class="cpp">catch(...) &#123;  ...&#125;</code></pre><h4 id="异常再抛出"><a href="#异常再抛出" class="headerlink" title="异常再抛出"></a>异常再抛出</h4><p>有时，虽然在函数中对异常进行了处理，但是还是希望能够通知调用者，以便让调用者知道发生了异常，从而可以作进一步的处理。此时可以在 catch 块中继续拋出异常。如下：</p><pre><code class="c++"> int CountTax(int salary) &#123;    try &#123;        if( salary &lt; 0 )            throw string(&quot;zero salary&quot;);        cout &lt;&lt; &quot;counting tax&quot; &lt;&lt; endl;    &#125;    catch (string s ) &#123;        cout &lt;&lt; &quot;CountTax error : &quot; &lt;&lt; s &lt;&lt; endl;        throw; //throw没有指明拋出什么样的异常，因此拋出的就是 catch 块捕获到的异常，即 string(&quot;zero salary&quot;)。    &#125;</code></pre><h3 id="函数的异常声明列表"><a href="#函数的异常声明列表" class="headerlink" title="函数的异常声明列表"></a>函数的异常声明列表</h3><p>为了增强程序的可读性和可维护性，使程序员在使用一个函数时就能看出这个函数可能会拋出哪些异常，C++ 允许在函数声明和定义时，加上它所能拋出的异常的列表，具体写法如下：</p><pre><code class="cpp">void func() throw (int, double, A, B, C);</code></pre><p>上面的写法表明 func 可能拋出 int 型、double 型以及 A、B、C 三种类型的异常。异常声明列表可以在函数声明时写，也可以在函数定义时写。如果两处都写，则两处应一致。</p><p>如果异常声明列表如下编写：</p><pre><code class="cpp">void func() throw ();//c++11后被noexcept关键字取代</code></pre><p>则说明 func 函数不会拋出任何异常。</p><h3 id="c-标准异常类"><a href="#c-标准异常类" class="headerlink" title="c++标准异常类"></a>c++标准异常类</h3><p><img src="C:\Users\hufei\AppData\Roaming\Typora\typora-user-images\image-20220411235618732.png" alt="image-20220411235618732"></p><p>C++语言本身或者标准库抛出的异常都是 exception 的子类</p><h2 id="用noexcept修饰函数"><a href="#用noexcept修饰函数" class="headerlink" title="用noexcept修饰函数"></a>用noexcept修饰函数</h2><ul><li>noexcept对性能有帮助。</li></ul><p>因为在调用noexcept函数时不需要记录异常的错误处理所以编译器可以生成更高效的代码（但实际编译器是否优化noexcept不一定，但理论上noexcept给了编译器更多优化的机会）。编译器在编译一个非noexcept的函数时有可能会生成很多冗余的代码，这些代码虽然只在出错的时候执行，但还是会对instruction cache造成影响，进而影响程序整体的性能。发生异常时要退栈并返回，所以编译器要生成这部分的代码，如果是noexcept函数就不需要生成了。</p><ul><li>如果noexcept的函数执行时出了异常，程序会马上terminate。</li></ul><p><strong>请注意，这也包括所有noexcept函数调用的函数。</strong>比如f是noexcept，g不是，f调用了g，但g throw exception，程序会马上terminate。甚至你在f外面用了try catch也没用。</p><ul><li>noexcept最有用的地方是用在move constructor和move assignment上，你的move操作如果不是noexcept的，很多情况下即使逻辑上可以move，编译器也会执行copy。</li></ul><p><strong>对使用noexcept使用的建议</strong></p><ul><li>默认不使用。</li></ul><p>大部分情况下，你都很难避免bad_alloc的异常，即使这个函数不直接allocate，有可能编译器执行代码时还是需要allocate。比如最简单的a &#x3D; b，如果a和b是一个自定义的type，有可能这个type有类似vector，string这些需要allocate的member，那这个赋值语句就可能报错。而且即使这个type现在没有这样的member，以后说不定代码改来改去就加了一个这样的成员。如果你给a&#x3D;b加上了noexcept，那以后加这样一个member，你还得把noexcept去掉。不使用noexcept是最future-proof的。</p><ul><li><p>move constructor&#x2F;move assignment operator 如果不会抛出异常，一定用noexcept。</p></li><li><p>destructor一定用noexcept。(析构函数现在已经默认为noexcept，除非手动声明为noexcept(false))</p></li><li><p>简单的leaf function，像是int，pointer这类的getter，setter用noexcept。因为不可能出错。</p></li></ul><h2 id="异常的好处"><a href="#异常的好处" class="headerlink" title="异常的好处"></a>异常的好处</h2><ol><li>简化错误处理的过程，与检查函数返回的错误码相比，使用异常进行错误处理更加简洁。</li><li>让错误处理逻辑从业务逻辑的代码中独立出来</li><li>异常可以把库的提供者不能明确要怎么处理的情况抛出来，让能明确怎么处理的调用者自己去处理。比如，std::stoi，std::stoll等C++标准库函数，当参数为0时，就会抛异常，因为库的提供者并不知道调用者要怎么处理，有的人想返回0，有的调用者想返回-1，有的调用者想终止程序。所以此时应该抛异常，让调用者自行处理</li></ol><p>使用错误码意味着你每调用一个可能会出现错误的函数的时候，都要判断是否成功，然后再继续执行后面的语句。导致你的这段代码中充斥着大量的if else。特别的在函数调用层数过多时，很多情况下一层出的错，往上传十八层才能真正处理，其它函数都是在 if err !&#x3D; OK { return err }。</p><p>在错误处理逻辑和正常的业务逻辑混杂的情况，使用异常处理可以让错误处理逻辑从业务逻辑的代码中独立出来，如：</p><pre><code class="java">FileReader fr = new FileReader(&quot;path&quot;);if (fr == null) &#123;        System.err.println(&quot;Open File Error&quot;); &#125; else &#123;        BufferedReader br = new BufferedReader(fr);        while (br.ready()) &#123;                String line = br.readLine();                if (line == null) &#123;                        System.err.println(&quot;Read Line Error&quot;);                &#125; else &#123;                        System.out.println(line);                &#125;        &#125; &#125;</code></pre><p>若使用异常进行处理,则明显简洁很多：</p><pre><code class="java">try &#123;       FileReader fr = new FileReader(&quot;path&quot;);        BufferedReader br = new BufferedReader(fr);       while (br.ready()) &#123;                String line = br.readLine();                System.out.println(line);        &#125; &#125;catch (IOException e) &#123;        e.printStackTrace(); &#125;</code></pre><h2 id="使用异常的建议"><a href="#使用异常的建议" class="headerlink" title="使用异常的建议"></a>使用异常的建议</h2><p>应该谨慎的使用异常处理，不可滥用。<strong>不要在任何地方 try-catch，除非你确定这是必要的</strong>。因为异常会影响性能，<strong>异常比函数调用要慢几十倍</strong>。并且很多时候没办法对异常进行有效的处理，不如让程序直接崩溃（如new不出来，或者碰到了预料之外的情况）。如果碰到预料之外的异常时不崩溃而是让程序继续执行，会导致难以排查出错误。</p><p>首先，调用处<strong>针对异常有对策时才 catch</strong>，否则放行（继续向上抛）。</p><p>其次，只有在针对某种异常有特殊对策时，才针对这种异常做特殊处理，否则统一处理。</p><p>当然，<strong>对策是看需求的</strong>，没有银弹，不要指望一招鲜吃遍天。</p><p>比如到了必须转换错误报告方法的地方：这个函数往上就不接受异常了（这个函数是个 C 接口、系统回调、noexcept 函数之类的），那么在这个函数里 catch，根据异常信息返回不同的错误码。</p><p>比如 HTTP 服务器处理请求时，常见的对策是对任何异常都记录日志并向客户端返回状态码为 500 的响应。那么我们要做的就是把所有处理请求的代码 try 起来，catch 所有异常并处理。无所谓它是 MyCustomException 还是 std::bad_alloc。</p><p>确有应对方案的时候也可以 catch：比如加载文本的时候 UTF-8 解码抛出异常发现不合法的字节，我们可以 catch 住去尝试 GBK 解码。</p><p><strong>本质上就是看需求来定</strong>，而不是看程序代码来定。</p><h2 id="异常安全"><a href="#异常安全" class="headerlink" title="异常安全"></a>异常安全</h2><p><em><strong>异常安全</strong></em>的意思就是，<em><strong>当程序在异常发生的时候，程序可以回退的很干净</strong></em>。什么是回退的很干净呢？其实就是函数在发生异常的时候<em><strong>不会泄露资源</strong></em>或者<em><strong>不会发生任何数据结构的破坏</strong></em>。如果说一个函数是异常安全的，那么它必须满足上面提到的两个条件。</p><p><em>异常安全</em>分为三个级别：</p><ul><li>基本级别：可能发生异常，且在异常发生的时候代码保证做了任何必要的清理工作，即程序在合法阶段，但是一些数据结构可能已经被函数更改，不一定是调用之前的状态，但是基本是保证符合对象正常的要求的；</li><li>强烈级别：可能发生异常，且在发生异常时代码保证函数对数据做的任何修改都可以被回滚。即如果调用成功，则完全成功；如果调用失败，则对象依旧是调用之前的状态；</li><li>无异常：即函数保证不会抛出异常（比如标准库的swap函数等）。</li></ul><h3 id="异常安全的反例和处理方案"><a href="#异常安全的反例和处理方案" class="headerlink" title="异常安全的反例和处理方案"></a>异常安全的反例和处理方案</h3><p>一个函数如果是异常安全的，那么它必须满足两个条件：</p><ul><li>一是不泄露任何资源（已申请的资源被正确释放）</li><li>二是不破坏任何数据结构（无野指针等）</li></ul><p>下面我们通过两个反例来说明这两个条件分别表示什么意思：</p><ul><li><strong>第一个是造成资源泄漏的例子：</strong></li></ul><pre><code class="cpp">void Type::Func()&#123;    Lock(&amp;mutex);    DoSomething();    UnLock(&amp;mutex);&#125;</code></pre><p>上面的代码表示首先获得互斥锁，中间做一些其他事，最后释放互斥锁。我们从异常安全的角度分析，如果*DoSomething()<em>函数内部出现了异常，那么</em>UnLock(&amp;mutex)*将不会被执行，互斥锁就永远不会被释放，就造成了资源泄漏。</p><ul><li><strong>第二个是造成数据破坏的例子</strong></li></ul><p>假设一个类Type，其中一个成员是指向一块资源的指针，我们通过重载”&#x3D;”操作符来进行说明：</p><pre><code class="cpp">class Type&#123;public:    Type&amp; operator = (const Type&amp; t)    &#123;        if (this == &amp;t)            return *this;        else        &#123;            delete m_t;            m_t = new T(t-&gt;m_t);            return *this;        &#125;    &#125;private:    T* m_t;&#125;;</code></pre><p>这段代码首先判断是否是自我复制，如果是的话，直接返回this指针指向的对象；如果不是，则首先安全释放当前指向的资源，再创建一块与被复制的对象资源一样的资源并指向它，最后返回复制好的对象。从异常安全的角度分析，一旦*new T(t-&gt;m_t)*执行时抛出异常，m_t将指向一块已经被删除的资源，并没有真正指向一块与被复制的对象一样的资源，此时m_t数据遭到了破坏。</p><p><strong>解决方案：</strong></p><ul><li><strong>资源泄漏问题解决方案</strong></li></ul><p>对于<em>资源泄漏</em>问题，解决方案是我们可以用对象来管理资源(即RAII技术，对于指针变量，也可以使用RAII技术进行管理)。我们在函数中不直接对互斥锁进行操作，而是用到一个管理互斥锁的对象MutexLock ml：</p><pre><code class="cpp">void Type::Func()&#123;    MutexLock ml(&amp;mutex);    DoSomething();&#125;</code></pre><p>对象ml在初始化之后，自动对mutex上锁，然后做其他事。最后我们不用负责释放互斥锁，即使在DoSomething()函数中抛出了异常，在退出函数的时候，也会对ml自动调用析构函数，就不用担心互斥锁未被正常释放的问题。</p><ul><li><strong>数据破坏问题解决方案</strong></li></ul><p>对于数据破坏问题，一个策略是<em><strong>copy and swap</strong></em>。就是：先对原对象作出一个副本，在副本上作必要的修改。如果出现任何异常，原对象仍然能保持不变。</p><pre><code class="cpp">Type&amp; Type::operator = (const Type&amp; t)&#123;    Type tmp(t);    swap(m_t, tmp-&gt;m_t);    return *this;&#125;</code></pre><p>上述函数首先创建一个被复制对象t的副本tmp，此时原对象尚未有任何修改，这样即使申请资源时有异常抛出，也不会影响到原对象。如果创建成功，则通过swap函数对临时对象的资源和原对象资源进行交换，标准库的swap函数承诺不抛出异常，这样原对象将成功便成对象t的复制副本。对于这个函数，我们可以认为其实强烈保证异常安全的。</p><h3 id="构造函数中的异常处理"><a href="#构造函数中的异常处理" class="headerlink" title="构造函数中的异常处理"></a>构造函数中的异常处理</h3><p><strong>在构造函数内抛出异常需要格外小心</strong>，可能会导致内存泄漏</p><p>在构造函数中抛出异常是C++中通知对象构造失败的唯一方法。</p><p>但是<strong>C++仅能 delete 被完全构造的对象</strong>，只有一个对象的构造函数完全运行完毕，这个对象才被完全地构造。所以如果在构造函数中抛出一个异常而不在构造函数内捕获，这样对象就只是部分被构造，<strong>它的析构函数将不会被执行，即使你手动进行delete。</strong>如：</p><pre><code class="cpp">class person &#123;public:    person()    &#123;        a=new A();        b=new B();//此时抛出异常        cout &lt;&lt; &quot;构造一个对象！&quot; &lt;&lt; endl;    &#125;    ~person()    &#123;        delete a;        delete b;        cout &lt;&lt; &quot;销毁一个对象！&quot; &lt;&lt; endl;    &#125;private:    A* a;    B* b;&#125;;int main()&#123;    try     &#123;        person p;    &#125;     catch(exception e)     &#123;        cout &lt;&lt; e.what() &lt;&lt; endl;    &#125;;    return 0;&#125;</code></pre><p>若构造b的时候,b&#x3D;new B()抛出异常，此时person的析构函数将不会执行，并且会导致a对象内存泄漏。所以构造函数抛出异常可能会导致已申请的资源无法释放，从而造成内存泄漏</p><p><strong>解决方法：</strong></p><p>1.在构造函数内将可能发生异常的部分try catch，先释放资源再把异常抛到外界</p><pre><code class="cpp">class person &#123;public:    person()    &#123;        try        &#123;            a=new A();            b=new B(); //发生异常                    &#125;        catch(...)        &#123;            delete a;            delete b;            throw;        &#125;    &#125;    ~person()    &#123;        delete a;        delete b;        cout &lt;&lt; &quot;销毁一个对象！&quot; &lt;&lt; endl;    &#125;private:    A* a;    B* b;&#125;;</code></pre><p>2.使用二段式构造和工厂函数</p><p>构造函数中只进行不会发生异常的操作，如基本类型的初始化，把可能发生异常的操作如资源申请放到另外的函数中。</p><pre><code class="cpp">class person &#123;public:    person()&#123;&#125;;    ~person()    &#123;        delete a;        delete b;        cout &lt;&lt; &quot;销毁一个对象！&quot; &lt;&lt; endl;    &#125;    void init()    &#123;        a = new A();        b = new B();    &#125;private:    A* a;    B* b;&#125;;</code></pre><p>如上所示将资源申请放到init函数中，这样即使发生异常也能正常的析构person对象。</p><p>但是<strong>二段式构造不符合RAII</strong>，无法用智能指针管理二段式构造的对象，因此一般不考虑这种方法。</p><p>并且二段式构造还有一个缺陷，就是构造之后忘记调用init，<strong>解决这个缺陷需要用工厂函数</strong>，工厂函数将new和init都封装起来，调用工厂函数就可以返回新的对象。</p><pre><code class="c++">person getInstance()&#123;    person  p;    p.init();    return p;&#125;</code></pre><p>3.使用智能指针(推荐)</p><p>将对象内的子对象都用智能指针管理，智能指针是栈对象，在发生异常时会发生stack unwinding，自动将栈上的对象析构，这样就可以把申请的资源自动释放了。</p><pre><code class="c++">class person &#123;public:    person()    &#123;        a = make_unique&lt;A&gt;();        b = make_unique&lt;B&gt;();    &#125;;    ~person()&#123;&#125;;private:    unique_ptr&lt;A&gt; a;    unique_ptr&lt;B&gt; b;&#125;;</code></pre><h3 id="析构函数的异常处理"><a href="#析构函数的异常处理" class="headerlink" title="析构函数的异常处理"></a>析构函数的异常处理</h3><p>析构函数不允许抛出异常，所以如果析构函数中有可能会抛出异常的操作，必须手动将这部分操作try catch，保证析构函数不会向外抛出异常。</p><p><strong>原因如下：</strong></p><p>1.如果析构函数析构到一半抛出异常，剩下的资源释放无法进行，会导致内存泄漏。</p><pre><code class="cpp">~person()&#123;    delete a;    throw;    delete b; //无法进行&#125;</code></pre><p>如上在delete a和delete b之间抛出异常将导致b的内存无法释放。</p><p>2.在异常没有catch前连续抛出两次异常是未定义行为，系统会直接终止程序，如果析构函数可以抛出异常就可能导致这种事情发生。</p><p>想象一下一个对象的析构函数抛出了异常，然后程序会进行stack unwind直到被catch住为止，中间这部分的栈对象会全部析构掉，如果在析构这部分栈对象的时候又抛出了异常，那么就在异常没有catch前就连续抛出了两次异常，程序会直接终止。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
      <url>/2023/01/22/%E7%BA%BF%E7%A8%8B%E6%B1%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h1><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>建立一个线程数组，数组大小就是线程池线程数量。线程会不断从任务队列中取出任务执行，有新的任务时将任务塞入任务队列。</p><h2 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h2><p><strong>执行任务队列中的任务时需要try catch</strong>，这是为了发生异常时快速找到错误。</p><pre><code class="cpp">void ThreadPool::runInThread()&#123;  try  &#123;    if (threadInitCallback_)    &#123;      threadInitCallback_();    &#125;    while (running_)    &#123;      Task task(take());      if (task)      &#123;        task();      &#125;    &#125;  &#125;  catch (const Exception&amp; ex)  &#123;    fprintf(stderr, &quot;exception caught in ThreadPool %s\n&quot;, name_.c_str());    fprintf(stderr, &quot;reason: %s\n&quot;, ex.what());    fprintf(stderr, &quot;stack trace: %s\n&quot;, ex.stackTrace());    abort();  &#125;  catch (const std::exception&amp; ex)  &#123;    fprintf(stderr, &quot;exception caught in ThreadPool %s\n&quot;, name_.c_str());    fprintf(stderr, &quot;reason: %s\n&quot;, ex.what());    abort(); // abort 函数用于终止 C++ 程序。 exit 与 abort 之间的差异在于，exit 允许执行 C++ 运行时终止处理（调用全局对象析构函数）。 abort 可立即终止程序。 abort 函数绕过初始化的全局静态对象的一般析构过程。 它还绕过使用 atexit 函数指定的任何特殊处理。  &#125;  catch (...)  &#123;    fprintf(stderr, &quot;unknown exception caught in ThreadPool %s\n&quot;, name_.c_str());    throw; // rethrow  &#125;&#125;</code></pre><p><strong>线程池停止运行时必须对所有线程调用join()，还需要唤醒所有阻塞的线程</strong>，这是为了防止线程池的线程还没有终止时线程池就析构了，这样会提前销毁线程资源，导致程序直接终止。线程池停止运行后，任务队列会禁止接收新的任务，被阻塞的线程会被唤醒并终止，已经在执行任务的线程在当前任务执行完成后会终止(尽管任务队列中还有任务也不会继续执行)。</p><pre><code class="c++">void ThreadPool::stop()&#123;  &#123;  MutexLockGuard lock(mutex_);  running_ = false;  notEmpty_.notifyAll();  notFull_.notifyAll();  &#125;  for (auto&amp; thr : threads_)  &#123;    thr-&gt;join();  &#125;&#125;</code></pre><p><strong>用void()函数作为中std::function的模板参数</strong>，即匹配无返回值无形参的函数，如果要执行带形参的任务可以使用std::bind，如果要执行带返回值的任务可以使用std::future。</p><pre><code class="c++">typedef std::function&lt;void ()&gt; Task;</code></pre><p><strong>需要限制任务队列大小</strong>，否则qps过高或者任务用时过长时，会造成任务堆积在任务队列，导致cpu和内存飙升服务器挂掉。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%98%9F%E5%88%97/"/>
      <url>/2023/01/22/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%98%9F%E5%88%97/</url>
      
        <content type="html"><![CDATA[<h1 id="线程安全的多线程队列"><a href="#线程安全的多线程队列" class="headerlink" title="线程安全的多线程队列"></a>线程安全的多线程队列</h1><h2 id="队列类型"><a href="#队列类型" class="headerlink" title="队列类型"></a>队列类型</h2><p>在并发编程中，有时候需要使用线程安全的队列。如果要实现一个线程安全的队列有两种方式：一种是使用阻塞算法，另一种是使用非阻塞算法。</p><p>使用阻塞算法的队列可以用一个锁（入队和出队用同一把锁）或两个锁（入队和出队用不同的锁）等方式来实现。非阻塞的实现方式则可以使用自旋+CAS的方式来实现。</p><p><strong>阻塞队列与非阻塞队列</strong></p><p>阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作支持阻塞的插入和移除方法。</p><p>支持阻塞的插入方法put：当队列满时，队列会阻塞插入元素的线程，直到队列不满。</p><p>支持阻塞的移除方法take：在队列为空时，获取元素的线程会等待队列变为非空。</p><p>阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器。</p><p>非阻塞队列：若队列为空从中获取元素则会返回空，若队列满了插入元素则会抛出异常。</p><p><strong>有界队列与无界队列</strong></p><p>有界队列：就是有固定大小的队列。比如设定了固定大小的ArrayBlockingQueue，又或者大小为0，只是在生产者和消费者中做中转用的SynchronousQueue。</p><p>无界队列：指的是没有设置固定大小的队列。这些队列的特点是可以直接入列，直到溢出。当然现实几乎不会有到这么大的容量（超过 Integer.MAX_VALUE），所以从使用者的体验上，就相当于 “无界”。线程池中一般使用有界队列，防止任务堆积导致内存满载。</p><h3 id="阻塞无界队列的实现"><a href="#阻塞无界队列的实现" class="headerlink" title="阻塞无界队列的实现"></a>阻塞无界队列的实现</h3><p>使用deque作为基本数据结构，无界队列可以一直生产，所以不用等待队列中有位置才生产，每生产一个产品就notify一个消费者。消费take时要判断有无产品。</p><p>所以<strong>只需要一个mutex锁，一个条件变量notEmpty</strong>，消费者用来等待notEmpty有产品可以消费</p><h3 id="阻塞有界队列的实现"><a href="#阻塞有界队列的实现" class="headerlink" title="阻塞有界队列的实现"></a>阻塞有界队列的实现</h3><p>使用循环队列作为基本数据结构，用front和tail存储队列首部和尾部的下标，front指向队列的第一个元素，tail指向队列插入的下一个元素，入队时queue[tail] &#x3D; data，出队时 data &#x3D; queue[front]。为了区分空队和满队的情况，队列必须空出一个位置，空队时tail等于front，满队时front &#x3D; (tail + 1)%size。</p><h2 id="多线程队列算法优化"><a href="#多线程队列算法优化" class="headerlink" title="多线程队列算法优化"></a>多线程队列算法优化</h2><p>对于一个队列来说有两个最主要的动作：添加（enqueue）和删除（dequeue）节点。</p><p>在一个（或多个）线程在对一个队列进行enqueue操作的同时可能会有一个（或多个）线程对这个队列进行dequeue操作。因为enqueue和dequeue都是对同一个队列里的节点进行操作，为了保证线程安全，一般在实现中都会在队列的结构体中加入一个队列锁，在进行enqueue和dequeue时都会先锁住整个队列然后再进行相关的操作。</p><p>但是，这其中其实有一个潜在的性能瓶颈：enqueue和dequeue操作都要锁住整个队列，这在线程少的时候可能没什么问题，但是只要线程数一多，这个锁竞争所产生的性能瓶颈就会越来越严重。</p><p>如果我们仔细想一想enqueue和dequeue的具体操作就会发现他们的操作其实不一定是冲突的。例如：如果所有的enqueue操作都是往队列的尾部插入新节点，而所有的dequeue操作都是从队列的头部删除节点，那么enqueue和dequeue大部分时候都是相互独立的，我们大部分时候根本不需要锁住整个队列，白白损失性能！那么一个很自然就能想到的算法优化方案就呼之欲出了：**我们可以把那个队列锁拆成两个：一个队列头部锁（head lock)和一个队列尾部锁(tail lock)**。设计思路是对了，但是如果再仔细思考一下它的实现的话我们会发现其实不太容易，因为有两个特殊情况：第一种就是往空队列里插入第一个节点的时候，第二种就是从只剩最后一个节点的队列中删除的时候。</p><p>当我们向空队列中插入第一个节点的时候，我们需要同时修改队列的head和tail指针，使他们同时指向这个新插入的节点，换句话说，我们此时即需要拿到head lock又需要拿到tail lock。而另一种情况是对只剩一个节点的队列进行dequeue的时候，我们也是需要同时修改head和tail指针使他们指向NULL，亦即我们需要同时获得head和tail lock。有经验的同学会立刻发现我们进入危险区了！是什么危险呢？死锁！多线程编程中最臭名昭著的一种bug就是死锁了。例如，如果线程A在锁住了资源1后还想要获取资源2，而线程B在锁住了资源2后还想要获取资源1，这时两个线程谁都不能获得自己想要的那个资源，两个线程就死锁了。所以我们要小心奕奕的设计这个算法以避免死锁，例如保证enqueue和dequeue对head lock和tail lock的请求顺序（lock ordering）是一致的。但是这样设计出来的算法很容易就会包含多次的加锁&#x2F;解锁操作，这些都会造成不必要的开销，尤其是在线程数很多的情况下反而可能导致性能的下降。</p><p>好在有聪明人早在96年就想到了一个更妙的算法。这个算法也是用了head和tail两个锁，但是它有一个关键的地方是它在队列初始化的时候head和tail指针不为空，而是指向一个空节点。在enqueue的时候只要向队列尾部添加新节点就好了。而dequeue的情况稍微复杂点，它要返回的不是头节点，而是head-&gt;next，即头节点的下一个节点。先来看伪代码：</p><pre><code class="c++">typedef struct node_t &#123;    TYPE value;     node_t *next&#125; NODE; typedef struct queue_t &#123;    NODE *head;     NODE *tail;    LOCK q_h_lock;    LOCK q_t_lock;&#125; Q; initialize(Q *q) &#123;   node = new_node()   // Allocate a free node   node-&gt;next = NULL   // Make it the only node in the linked list   q-&gt;head = q-&gt;tail = node   // Both head and tail point to it   q-&gt;q_h_lock = q-&gt;q_t_lock = FREE   // Locks are initially free&#125; enqueue(Q *q, TYPE value) &#123;   node = new_node()       // Allocate a new node from the free list   node-&gt;value = value     // Copy enqueued value into node   node-&gt;next = NULL       // Set next pointer of node to NULL   lock(&amp;q-&gt;q_t_lock)      // Acquire t_lock in order to access Tail      q-&gt;tail-&gt;next = node // Link node at the end of the queue      q-&gt;tail = node       // Swing Tail to node   unlock(&amp;q-&gt;q_t_lock)    // Release t_lock｝ dequeue(Q *q, TYPE *pvalue) &#123;   lock(&amp;q-&gt;q_h_lock)   // Acquire h_lock in order to access Head      node = q-&gt;head    // Read Head      new_head = node-&gt;next       // Read next pointer      if new_head == NULL         // Is queue empty?         unlock(&amp;q-&gt;q_h_lock)     // Release h_lock before return         return FALSE             // Queue was empty      endif      *pvalue = new_head-&gt;value   // Queue not empty, read value      q-&gt;head = new_head  // Swing Head to next node   unlock(&amp;q-&gt;q_h_lock)   // Release h_lock   free(node)             // Free node   return TRUE            // Queue was not empty, dequeue succeeded&#125;</code></pre><p>发现玄机了么？是的，这个算法中队列总会包含至少一个节点。dequeue每次返回的不是头节点，而是头节点的下一个节点中的数据：如果head-&gt;next不为空的话就把这个节点的数据取出来作为返回值，同时再把head指针指向这个节点，此时旧的头节点就可以被free掉了。这个在队列初始化时插入空节点的技巧使得enqueue和dequeue彻底相互独立了。但是，还有一个小地方在实现的时候需要注意：对第一个空节点的next指针的读写。想象一下，当一个线程对一个空队列进行第一次enqueue操作时刚刚运行完第25行的代码（对该空节点的next指针进行写操作）；而此时另一个线程对这个队列进行第一次dequeue操作时恰好运行到第33行（对该空节点的next指针进行读操作），它们其实还是有冲突！不过，好在一般来讲next指针是32位数据，而现代的CPU已经能保证多线程程序中内存对齐了的32位数据读写操作的原子性，而一般来讲编译器会自动帮你对齐32位数据，所以这个不是问题。唯一需要注意的是我们要确保enqueue线程是先让要添加的新节点包含好数据再把新节点插入链表（也就是不能先插入空节点，再往节点中填入数据），那么dequeue线程就不会拿到空的节点。其实我们也可以把q_t_lock理解成生产者的锁，q_h_lock理解成消费者的锁，这样生产者（们）和消费者（们）的操作就相互独立了，只有在多个生产者对同一队列进行添加操作时，以及多个消费者对同一队列进行删除操作时才需要加锁以使访问互斥。</p><p>通过使用这个算法，我成功的把一个32线程程序的性能提升了11%！可见多线程中的锁竞争对性能影响之大！此算法出自一篇著名的论文：M. Michael and M. Scott. Simple, Fast, and Practical Non-Blocking and Blocking Concurren Queue Algorithms </p><p>如果还想做更多优化的话可以参考这篇论文实现相应的Non Blocking版本的算法，性能还能有更多提升。当然了，这个算法早已被集成到java.util.concurrent里了（即LinkedBlockingQueue），其他的并行库例如Intel的TBB多半也有类似的算法，如果大家能用上现成的库的话就不要再重复造轮子了。为什么别造并行算法的轮子呢？因为高性能的并行算法实在太难正确地实现了，尤其是Non Blocking，Lock Free之类的“火箭工程”。有多难呢？Doug Lea提到java.util.concurrent中一个Non Blocking的算法的实现大概需要1年的时间，总共约500行代码。所以，对最广大的程序员来说，别去写Non Blocking, Lock Free的代码，只管用就行了。</p><p>多线程队列算法有很多种，大家应根据不同的应用场合选取最优算法（例如是CPU密集型还是IO密集型）。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"/>
      <url>/2023/01/22/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h1><p>多线程安全问题：</p><p>当一个对象能被多个线程同时看到时，那么对象的销毁时机就会变得模糊不清，可能出现多种竞态条件（race condition）：</p><ul><li>在即将析构一个对象时，从何而知此刻是否有别的线程正在执行该对象的成员函数？</li><li>如何保证在执行成员函数期间，对象不会在另一个线程被析构？</li><li>在调用某个对象的成员函数之前，如何得知这个对象还活着？它的析构函数会不会碰巧执行到一半</li></ul><p>而当成员变量包含指针时，<strong>判断一个指针是不是合法指针没有高效的办法，这是C&#x2F;C++ 指针问题的根源。</strong></p><h2 id="对象构造的线程安全"><a href="#对象构造的线程安全" class="headerlink" title="对象构造的线程安全"></a>对象构造的线程安全</h2><p>对象构造要做到线程安全，唯一的要求是在构造期间不要泄露 this 指针，即</p><ul><li>不要在构造函数中注册任何回调；</li><li>也不要在构造函数中把 this 传给跨线程的对象，即使是构造函数的最后一行也不能传给其他对象。</li></ul><p>之所以这样规定，是因为在构造函数执行期间对象还没有完成初始化，如果this被泄露给了其他对象（其自身创建的子对象除外），那么别的线程有可能访问这个半成品对象，这会造成难以预料的后果。  </p><p>即使构造函数的最后一行也不要泄露 this，因为 Foo 有可能是个基类，基类先于派生类构造，执行完 Foo::Foo() 的最后一行代码还会继续执行派生类的构造函数，这时 派生类的对象还处于构造中，仍然不安全。  </p><h2 id="对象析构的线程安全"><a href="#对象析构的线程安全" class="headerlink" title="对象析构的线程安全"></a>对象析构的线程安全</h2><p>析构函数中不宜使用锁：</p><ul><li>调用析构函数的时候，正常逻辑来说这个对象已经没有其他线程在使用了，用锁也没有效果；</li><li>即使使用了锁，析构函数抢到了锁，其他线程还在等待这个锁，析构函数中锁被析构掉了，其他线程就是未定义行为。</li></ul><p><strong>使用指针时该如何判断指针是否还存活</strong></p><p>我们无法保证执行一个对象的成员函数时这个对象没有被析构，即使在析构后将对象指针置nullptr也一样。</p><pre><code class="c++">//线程A~P()&#123;    delete xxx;    this = nullptr;&#125;//线程Bif(p != nullptr) //执行完这一步后去执行线程A&#123;    p-&gt;update();&#125;</code></pre><p>如上完全可以在线程B执行完判空语句进入循环后，转而执行线程A的析构函数，从而导致线程B对空指针操作。</p><p>以观察者模式为例，observer对象注册自己到Observable，后者保存有前者的指针，一旦某个事件发生，Observable就通过observer指针调用其成员方法。多线程情况下，Observable无法得知当前调用的observer指针是否还有效，即使使用锁也不行。</p><p>解决方法：使用智能指针。使用weak_ptr保存指针，可以清楚的知道指针是否存活：如果weak_ptr可以转化为shared_ptr，证明指针还有效，否则无效。不打算决定对象的生死，就使用weak_ptr管理对象指针；否则使用shared_ptr。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/01/22/%E7%8E%B0%E4%BB%A3CMake/"/>
      <url>/2023/01/22/%E7%8E%B0%E4%BB%A3CMake/</url>
      
        <content type="html"><![CDATA[<h1 id="现代CMake"><a href="#现代CMake" class="headerlink" title="现代CMake"></a>现代CMake</h1><h2 id="为什么要使用现代CMake"><a href="#为什么要使用现代CMake" class="headerlink" title="为什么要使用现代CMake"></a>为什么要使用现代CMake</h2><p>现代 CMake 指的是 CMake 3.x，古代 CMake 指的是 CMake 2.x。许多人认识的 CMake 都是古代 CMake，现代 CMake 和古代 CMake 相比，使用更方便，功能更强大。</p><p>例如：</p><pre><code class="c++">//古代CMake构建步骤复杂mkdir build//需要先创建 build 目录      cd build//切换到 build 目录cmake ..//在 build 目录运行 cmake &lt;源码目录&gt; 生成 Makefilemake -j4//执行本地的构建系统 make 真正开始构建（4进程并行）sudo make install//让本地的构建系统执行安装步骤cd ..//回到源码目录//现代CMake提供了更方便的 -B 和 --build 指令，不同平台，统一命令cmake -B build// 在源码目录用 -B 直接创建 build 目录并生成 build/Makefilecmake --build build -j4// 自动调用本地的构建系统在 build 里构建，即：make -C build -j4sudo cmake --build build --target install// 调用本地的构建系统执行 install 这个目标，即安装//cmake -B build 免去了先创建 build 目录再切换进去再指定源码目录的麻烦。//cmake --build build 统一了不同平台（Linux 上会调用 make，Windows 上调用 devenv.exe）//结论：从现在开始，如果在命令行操作 cmake，请使用更方便的 -B 和 --build 命令。</code></pre><h2 id="CMake命令行选项"><a href="#CMake命令行选项" class="headerlink" title="CMake命令行选项"></a>CMake命令行选项</h2><p>CMake 项目的构建分为两步：</p><ul><li>第一步是 cmake -B build，称为配置阶段（configure），这时只检测环境并生成构建规则，会在 build 目录下生成本地构建系统能识别的项目文件（Makefile 或是 .sln）</li><li>第二步是 cmake –build build，称为构建阶段（build），这时才实际调用编译器来编译代码，生成可执行文件</li></ul><p><strong>-B和–build</strong></p><p>-B用来生成构建系统文件(makefile,ninja)，而–build则用来调用本地的构建系统生成可执行文件。</p><p>-B免去了先创建 build 目录再切换进去再指定源码目录的麻烦。–build统一了不同平台，<strong>如果没有–build这条命令，就需要根据底层构建系统的不同调用不同的构建命令</strong>，比如make或者ninja。</p><pre><code class="c++">cmake -B build// 在源码目录用 -B 直接创建 build 目录并生成 build/Makefilecmake --build build -j4// 自动调用本地的构建系统在 build 里构建，即：make -C build -j4</code></pre><p><strong>-D</strong></p><p>-D用于指定配置变量（又称缓存变量）。</p><p>在配置阶段(生成makefile的阶段)可以通过 -D 设置缓存变量。第二次配置时，之前的 -D 添加仍然会被保留。</p><pre><code class="c++">//设置安装路径为 /opt/openvdb-8.0（会安装到 /opt/openvdb-8.0/lib/libopenvdb.so）make -B build -DCMAKE_INSTALL_PREFIX=/opt/openvdb-8.0//设置构建模式为Release（编译期会开启全部优化，区别于Debug模式）cmake -B build -DCMAKE_BUILD_TYPE=Release//第二次配置时没有 -D 参数，但是之前的 -D 设置的变量都会被保留cmake -B build//（此时缓存里仍有你之前定义的 CMAKE_BUILD_TYPE 和 CMAKE_INSTALL_PREFIX）</code></pre><p><strong>-G</strong></p><p>-G用于指定要用的生成器。</p><p><strong>CMake 是一个跨平台的构建系统，可以从 CMakeLists.txt 生成不同类型的构建系统</strong>（比如 Linux 的 make，Windows 的 MSBuild），从而让构建规则可以只写一份，跨平台使用。过去的软件（例如 TBB）要跨平台，只好 Makefile 的构建规则写一份，MSBuild 也写一份。</p><p>现在只需要写一次 CMakeLists.txt，他会视不同的操作系统，生成不同构建系统的规则文件。那个和操作系统绑定的构建系统（make、MSBuild）称为本地构建系统（native buildsystem）。负责从 CMakeLists.txt 生成本地构建系统构建规则文件的，称为生成器（generator）。</p><p>Linux 系统上的 CMake 默认用是 Unix Makefiles 生成器；Windows 系统默认是 Visual Studio 2019 生成器；MacOS 系统默认是 Xcode 生成器。可以用 -G 参数改用别的生成器，例如 cmake -GNinja 会生成 Ninja 这个构建系统的构建规则。Ninja 是一个高性能，跨平台的构建系统，Linux、Windows、MacOS 上都可以用。</p><p>事实上，MSBuild 是单核心的构建系统，Makefile 虽然多核心但因历史兼容原因效率一般。而 Ninja 则是专为性能优化的构建系统，他和 CMake 结合都是行业标准了。</p><p>性能上：Ninja &gt; Makefile &gt; MSBuild。Makefile 启动时会把每个文件都检测一遍，浪费很多时间。特别是有很多文件，但是实际需要构建的只有一小部分，从而是 I&#x2F;O Bound 的时候，Ninja 的速度提升就很明显。</p><pre><code class="c++">//指定生成ninja的构建规则cmake -Gninja -B build</code></pre><h2 id="添加源文件"><a href="#添加源文件" class="headerlink" title="添加源文件"></a>添加源文件</h2><h3 id="单个源文件处理"><a href="#单个源文件处理" class="headerlink" title="单个源文件处理"></a>单个源文件处理</h3><p>1.<strong>add_executable添加源文件</strong></p><pre><code class="cmake">add_executable(main main.cpp)</code></pre><p>2.<strong>先创建目标，稍后再添加源文件</strong></p><pre><code class="cmake">add_executable(main)target_sources(main PUBLIC main.cpp)</code></pre><h3 id="多个源文件处理"><a href="#多个源文件处理" class="headerlink" title="多个源文件处理"></a>多个源文件处理</h3><p>1.<strong>逐个文件添加即可</strong></p><pre><code class="cmake">add_executable(main)target_sources(main PUBLIC main.cpp other.cpp)</code></pre><p>2.<strong>使用变量存储文件名</strong></p><pre><code class="cmake">#set设置变量，$&#123;var&#125;引用add_executable(main)set(sources main.cpp other.cpp)target_sources(main PUBLIC $&#123;sources&#125;)</code></pre><p><strong>TIP</strong>:可以在添加时加上.h头文件，这样在 VS 里可以出现在“Header Files”一栏</p><pre><code class="cmake">add_executable(main)set(sources main.cpp other.cpp other.h)target_sources(main PUBLIC $&#123;sources&#125;)</code></pre><h3 id="GLOB批量添加源文件"><a href="#GLOB批量添加源文件" class="headerlink" title="GLOB批量添加源文件"></a>GLOB批量添加源文件</h3><p>使用 <strong>GLOB</strong> 自动查找当前目录下指定扩展名的文件，实现批量添加源文件</p><pre><code class="cmake">add_executable(main)file(GLOB sources *.cpp *.h)target_sources(main PUBLIC $&#123;sources&#125;)</code></pre><p><strong>缺陷和改进</strong>：set设置的变量在第一次配置后会缓存在文件中，后续多次构建不会更新。启用 <strong>CONFIGURE_DEPENDS</strong> 选项，当添加新文件时，自动更新变量(<strong>推荐</strong>)</p><pre><code class="cmake">add_executable(main)file(GLOB sources CONFIGURE_DEPENDS *.cpp *.h)target_sources(main PUBLIC $&#123;sources&#125;)</code></pre><h3 id="添加子目录源文件"><a href="#添加子目录源文件" class="headerlink" title="添加子目录源文件"></a>添加子目录源文件</h3><p>上述方法添加子目录源文件必须把路径名和后缀名的排列组合全部写出来，过于麻烦。</p><pre><code class="cmake">add_executable(main)file(GLOB sources CONFIGURE_DEPENDS *.cpp *.h mylib/*.cpp mylib/*.h)target_sources(main PUBLIC $&#123;sources&#125;)</code></pre><p><strong>改进</strong>：</p><p>1.用 <strong>aux_source_directory</strong>，自动搜集需要的文件后缀名</p><pre><code class="cmake">add_executable(main)aux_source_directory(. sources) #搜索当前目录aux_source_directory(mylib sources) #搜索mylib目录target_sources(main PUBLIC $&#123;sources&#125;)</code></pre><p>2.使用 <strong>GLOB_RECURSE</strong> 自动包含所有子文件夹下的文件</p><pre><code class="cmake">add_executable(main)file(GLOB_RECURSE sources CONFIGURE_DEPENDS *.cpp *.h)target_sources(main PUBLIC $&#123;sources&#125;)</code></pre><p><strong>缺陷</strong>：因为<strong>GLOB_RECURSE</strong>自动包含所有子文件夹的文件，所以它会把 <strong>build</strong> 目录里生成的临时 .cpp 文件也加进来</p><p><strong>解决方案</strong>：要么把源码统一放到 src 目录下，要么要求使用者不要把 build 放到和源码同一个目录里，建议把源码放到 src 目录下，然后在文件名前面添加src路径(<strong>推荐</strong>)</p><pre><code class="cmake">add_executable(main)file(GLOB_RECURSE sources CONFIGURE_DEPENDS src/*.cpp src/*.h)target_sources(main PUBLIC $&#123;sources&#125;)</code></pre><h2 id="项目配置变量"><a href="#项目配置变量" class="headerlink" title="项目配置变量"></a>项目配置变量</h2><h3 id="CMAKE-BUILD-TYPE"><a href="#CMAKE-BUILD-TYPE" class="headerlink" title="CMAKE_BUILD_TYPE"></a><strong>CMAKE_BUILD_TYPE</strong></h3><p>CMAKE_BUILD_TYPE 是 CMake 中一个特殊的变量，用于控制构建类型，他的值可以是：</p><ul><li>Debug 调试模式，完全不优化，生成调试信息，方便调试程序</li><li>Release 发布模式，优化程度最高，性能最佳，但是编译比 Debug 慢</li><li>MinSizeRel 最小体积发布，生成的文件比 Release 更小，不完全优化，减少二进制体积</li><li>RelWithDebInfo 带调试信息发布，生成的文件比 Release 更大，因为带有调试的符号信息</li></ul><p>默认情况下 CMAKE_BUILD_TYPE 为空字符串，这时相当于 Debug</p><p><strong>各种构建模式在编译器选项上的区别</strong></p><ul><li>Debug: <code>-O0 -g</code></li><li>Release: <code>-O3 -DNDEBUG</code></li><li>MinSizeRel: <code>-Os -DNDEBUG</code></li><li>RelWithDebInfo: <code>-O2 -g -DNDEBUG</code></li></ul><p>注意定义了 NDEBUG 宏会使 assert 被去除掉。</p><p><strong>修改变量的默认值</strong></p><p>如何让 CMAKE_BUILD_TYPE 在用户没有指定的时候为 Release，指定的时候保持用户指定的值不变呢。通过 if (NOT CMAKE_BUILD_TYPE) 判断是否为空，如果空则自动设为 Release 模式。</p><pre><code class="cmake">if(NOT CMAKE_BUILD_TYPE)    set(CMAKE_BUILD_TYPE Release)endif()</code></pre><h3 id="project"><a href="#project" class="headerlink" title="project"></a>project</h3><p>project会初始化项目信息，并把当前 <strong>CMakeLists.txt</strong>所在位置作为根目录，设置了project后会初始化一系列跟project相关的变量。</p><pre><code class="cmake">cmake_minimum_required(VERSION 3.15)project(hellocmake)message(&quot;PROJECT_NAME: $&#123;PROJECT_NAME&#125;&quot;)message(&quot;PROJECT_SOURCE_DIR: $&#123;PROJECT_SOURCE_DIR&#125;&quot;)message(&quot;PROJECT_BINARY_DIR: $&#123;PROJECT_BINARY_DIR&#125;&quot;)message(&quot;CMAKE_CURRENT_SOURCE_DIR: $&#123;CMAKE_CURRENT_SOURCE_DIR&#125;&quot;) #表示当前源码目录的位置，如~/hellocmakemessage(&quot;CMAKE_CURRENT_BINARY_DIR: $&#123;CMAKE_CURRENT_BINARY_DIR&#125;&quot;) #表示当前输出目录的位置，如~/hellocmake/buildadd_executable(main main.cpp)</code></pre><p><strong>PROJECT_x_DIR</strong> <strong>和</strong> <strong>CMAKE_CURRENT_x_DIR</strong> <strong>的区别</strong></p><ul><li>PROJECT_SOURCE_DIR 表示最近一次调用 project 的 CMakeLists.txt 所在的源码目录。</li><li>CMAKE_CURRENT_SOURCE_DIR 表示当前 CMakeLists.txt 所在的源码目录。</li><li>CMAKE_SOURCE_DIR 表示最为外层 CMakeLists.txt 的源码根目录。</li></ul><p>利用 PROJECT_SOURCE_DIR 可以实现从子模块里直接获得项目最外层目录的路径。<strong>不建议用</strong> CMAKE_SOURCE_DIR，那样会让你的项目无法被人作为子模块使用。</p><p><strong>其他相关变量</strong></p><ul><li>PROJECT_SOURCE_DIR：当前项目源码路径（存放main.cpp的地方）</li><li>PROJECT_BINARY_DIR：当前项目输出路径（存放main.exe的地方）</li><li>CMAKE_SOURCE_DIR：根项目源码路径（存放main.cpp的地方）</li><li>CMAKE_BINARY_DIR：根项目输出路径（存放main.exe的地方）</li><li>PROJECT_IS_TOP_LEVEL：BOOL类型，表示当前项目是否是（最顶层的）根项目</li><li>PROJECT_NAME：当前项目名</li><li>CMAKE_PROJECT_NAME：根项目的项目名</li></ul><p><strong>用项目名代替PROJECT_NAME</strong></p><p>可以用项目名代替PROJECT_NAME。除此之外CMake 的 <strong>${}</strong> 表达式还可以嵌套使用</p><pre><code class="cmake">cmake_minimum_required(VERSION 3.15)project(hellocmake VERSION 0.2.3)message(&quot;PROJECT_NAME: $&#123;PROJECT_NAME&#125;&quot;)message(&quot;PROJECT_VERSION: $&#123;PROJECT_VERSION&#125;&quot;)message(&quot;PROJECT_SOURCE_DIR: $&#123;PROJECT_SOURCE_DIR&#125;&quot;)message(&quot;PROJECT_BINARY_DIR: $&#123;PROJECT_BINARY_DIR&#125;&quot;)message(&quot;hellocmake_VERSION: $&#123;hellocmake_VERSION&#125;&quot;) #直接用hellocmake拼接_VERSION也可以使用message(&quot;hellocmake_SOURCE_DIR: $&#123;hellocmake_SOURCE_DIR&#125;&quot;)message(&quot;hellocmake_BINARY_DIR: $&#123;hellocmake_BINARY_DIR&#125;&quot;)message(&quot;hellocmake_SOURCE_DIR: $&#123;$&#123;PROJECT_NAME&#125;_SOURCE_DIR&#125;&quot;) #在表达式内嵌套project_name，效果一样add_executable(main main.cpp)</code></pre><p><strong>设置子模块为project</strong></p><p>子模块里也可以用 <strong>project</strong>命令，将当前目录作为一个独立的子项目。</p><p>这样一来 PROJECT_SOURCE_DIR <strong>就会是子模块的源码目录而不是外层了</strong>。这时候 CMake 会认为这个子模块是个独立的项目，会额外做一些初始化。他的构建目录 PROJECT_BINARY_DIR 也会变成 build&#x2F;&lt;源码相对路径&gt;。这样在 MSVC 上也会看见子项目的生成。</p><p><strong>project的LANGUAGES字段</strong></p><p>project(项目名 LANGUAGES 使用的语言列表…) 指定了该项目使用了哪些编程语言。</p><p>目前支持的语言包括：</p><ul><li>C：C语言</li><li>CXX：C++语言</li><li>ASM：汇编语言</li><li>Fortran：老年人的编程语言</li><li>CUDA：英伟达的 CUDA（3.8 版本新增）</li><li>OBJC：苹果的 Objective-C（3.16 版本新增）</li><li>OBJCXX：苹果的 Objective-C++（3.16 版本新增）</li><li>ISPC：一种因特尔的自动 SIMD 编程语言（3.18 版本新增）</li></ul><p>如果不指定 LANGUAGES，默认为 C 和 CXX。</p><pre><code class="cmake">cmake_minimum_required(VERSION 3.15)project(hellocmake LANGUAGES CXX)set(CMAKE_BUILD_TYPE Release)add_executable(main main.cpp)</code></pre><p>也可以先设置 <strong>LANGUAGES NONE</strong>，之后再调用 **enable_language(CXX)**。这样可以把 enable_language 放到 if 语句里，从而只有某些选项开启才启用某语言之类的</p><pre><code class="cmake">cmake_minimum_required(VERSION 3.15)project(hellocmake LANGUAGES NONE)enable_language(CXX)add_executable(main main.cpp)</code></pre><p><strong>project的version字段</strong></p><p>project(项目名 VERSION x.y.z) 可以把当前项目的版本号设定为 x.y.z。之后可以通过 PROJECT_VERSION 来获取当前项目的版本号。</p><ul><li>PROJECT_VERSION_MAJOR 获取 x（主版本号）。</li><li>PROJECT_VERSION_MINOR 获取 y（次版本号）。</li><li>PROJECT_VERSION_PATCH 获取 z（补丁版本号）。</li></ul><p><strong>其他的一些项目字段</strong></p><p>CMake 官方还提供了一些project字段，但用的较少。</p><pre><code class="cmake">cmake_minimum_required(VERSION 3.15)project(hellocmake    DESCRIPTION &quot;A free, open-source, online modern C++ course&quot;    HOMEPAGE_URL https://github.com/parallel101/course    )message(&quot;PROJECT_NAME: $&#123;PROJECT_NAME&#125;&quot;)message(&quot;PROJECT_DESCRIPTION: $&#123;PROJECT_DESCRIPTION&#125;&quot;)message(&quot;PROJECT_HOMEPAGE_URL: $&#123;PROJECT_HOMEPAGE_URL&#125;&quot;)add_executable(main main.cpp)</code></pre><h3 id="CMAKE-CXX-STANDARD"><a href="#CMAKE-CXX-STANDARD" class="headerlink" title="CMAKE_CXX_STANDARD"></a>CMAKE_CXX_STANDARD</h3><p>CMAKE_CXX_STANDARD 是一个整数，表示要用的 C++ 标准。比如需要 C++17 那就设为 17，需要 C++23 就设为 23。</p><p>CMAKE_CXX_STANDARD_REQUIRED 是 BOOL 类型，可以为 ON 或 OFF，默认 OFF。他表示是否一定要支持你指定的 C++ 标准：如果为 OFF 则 CMake 检测到编译器不支持 C++17 时不报错，而是默默调低到 C++14 给你用；为 ON 则发现不支持报错，更安全。</p><p>CMAKE_CXX_EXTENSIONS 也是 BOOL 类型，默认为 ON。设为 ON 表示启用 GCC 特有的一些扩展功能；OFF 则关闭 GCC 的扩展功能，只使用标准的 C++。<strong>要兼容其他编译器（如 MSVC）的项目，都会设为 OFF 防止不小心用了 GCC 才有的特性。</strong></p><p>此外，<strong>最好是在 project 指令前设置 CMAKE_CXX_STANDARD 这一系列变量</strong>，这样 CMake 可以在 project 函数里对编译器进行一些检测，看看他能不能支持 C++17 的特性。</p><pre><code class="cmake">cmake_minimum_required(VERSION 3.15)set(CMAKE_CXX_STANDARD 17)set(CMAKE_CXX_STANDARD_REQUIRED ON)set(CMAKE_CXX_EXTENSIONS ON)project(hellocmake LANGUAGES CXX)add_executable(main main.cpp)</code></pre><p><strong>TIP</strong>:请勿直接修改 CMAKE_CXX_FLAGS 来添加 -std&#x3D;c++17，因为这并不能兼容所有的编译器(如MSVC)；此外如果 CMake 已经自动根据 CMAKE_CXX_STANDARD 的默认值 11 添加 -std&#x3D;c++11 选项了，手动添加 -std&#x3D;c++17 选项会造成冲突。</p><h3 id="cmake-minimum-required"><a href="#cmake-minimum-required" class="headerlink" title="cmake_minimum_required"></a><strong>cmake_minimum_required</strong></h3><p><strong>cmake_minimum_required</strong> 指定最低所需的 CMake 版本。</p><p>假如你写的 CMakeLists.txt 包含了 3.15 版本才有的特性，如果用户在老版本上使用，就会出现各种奇怪的错误。因此最好在第一行加个 cmake_minimum_required(VERSION 3.15)，表示本 CMakeLists.txt 至少需要 CMake 版本 3.15 以上才能运行。如果用户的 CMake 版本小于 3.15，会正常报错提示版本过低，而不是等到某处用到 3.15 版本才有的特性时才出错。</p><pre><code class="cmake">cmake_minimum_required(VERSION 3.15...3.20)project(hellocmake LANGUAGES CXX)message(&quot;CMAKE_VERSION: $&#123;CMAKE_VERSION&#125;&quot;)message(&quot;CMAKE_MINIMUM_REQUIRED_VERSION: $&#123;CMAKE_MINIMUM_REQUIRED_VERSION&#125;&quot;)add_executable(main main.cpp)</code></pre><p><strong>TIP</strong>:虽然名字叫 minimum_required，实际上不光是 &gt;&#x3D; 3.15 就不出错这么简单。根据你指定的不同的版本号，还会决定接下来一系列 CMake 指令的行为。此外，你还可以通过 3.15…3.20 来表示最高版本不超过 3.20。这会对 cmake_policy 有所影响，稍后再提。</p><h3 id="其他变量"><a href="#其他变量" class="headerlink" title="其他变量"></a>其他变量</h3><ul><li>CMAKE_BUILD_TOOL: 执行构建过程的工具。该变量设置为CMake构建时输出所需的程序。对于VS 6， CMAKE_BUILD_TOOL设置为msdev， 对于Unix，它被设置为make 或 gmake。 对于 VS 7， 它被设置为devenv. 对于Nmake构建文件，它的值为nmake。</li><li>CMAKE_DL_LIBS: 包含dlopen和dlclose的库的名称。</li><li>CMAKE_COMMAND: 指向cmake可执行程序的全路径。</li><li>CMAKE_CTEST_COMMAND: 指向ctest可执行程序的全路径。</li><li>CMAKE_EDIT_COMMAND: cmake-gui或ccmake的全路径。</li><li>CMAKE_EXECUTABLE_SUFFIX: 该平台上可执行程序的后缀。</li><li>CMAKE_SIZEOF_VOID_P: void指针的大小。</li><li>CMAKE_SKIP_RPATH: 如果为真，将不添加运行时路径信息。默认情况下是如果平台支持运行时信息，将会添加运行时信息到可执行程序当中。这样从构建树中运行程序将很容易。为了在安装过程中忽略掉RPATH，使用CMAKE_SKIP_INSTALL_RPATH。</li><li>CMAKE_GENERATOR: 构建工程的产生器。它将产生构建文件 (e.g. “Unix Makefiles”, “Visual Studio 2019”, etc.)</li></ul><h2 id="添加子模块"><a href="#添加子模块" class="headerlink" title="添加子模块"></a>添加子模块</h2><p>大型的项目，往往会划分为几个子项目。即使你只有一个子项目，也建议你先创建一个子目录，方便以后追加新的子项目。</p><img src="https://raw.githubusercontent.com/hufei96/Image/main/project_dirctory.png" alt="image-20221215015212928" style="zoom: 33%;" /><p>上图的案例中，我们在根目录下，创建了两个子项目 biology 和 pybmain，他们分别在各自的目录下有自己的 CMakeLists.txt。</p><h3 id="子项目的头文件怎么处理"><a href="#子项目的头文件怎么处理" class="headerlink" title="子项目的头文件怎么处理"></a>子项目的头文件怎么处理</h3><p>可以通过 target_include_directories 指定目标文件的头文件搜索目录，将搜索目录指定为子项目的include文件夹，这样甚至可以用 &lt;xx.h&gt; 来引用子项目的头文件了，因为<strong>通过 target_include_directories 指定的路径会被视为与系统路径等价</strong>，</p><blockquote><p>TIP:&lt;cstdio&gt; 这种形式表示<strong>不要在当前目录下搜索</strong>，只在系统目录里搜索，”hello.h” 这种形式则<strong>优先搜索当前目录</strong>下有没有这个文件，找不到再搜索系统目录。</p></blockquote><p>难道每个目标文件用到子项目的库时都得再指定一遍搜索路径吗？</p><p>不需要，<strong>我们只需要在子项目的CMakeLists.txt中指定自身的头文件搜索路径</strong>，链接他的可执行文件会<strong>自动添加这个路径作为头文件目录</strong>：</p><pre><code class="cmake">#biology下的CMakeLists.txtfile(GLOB_RECURSE srcs CONFIGURE_DEPENDS src/*.cpp include/*.h)add_library(biology STATIC $&#123;srcs&#125;)#这条语句让链接 biology 的目标文件也能够共享/biology/include 这个头文件搜索路径target_include_directories(biology PUBLIC include)</code></pre><p>此外，如果不希望让引用biology的可执行文件自动添加这个路径，把 <strong>PUBLIC</strong> 改成 <strong>PRIVATE</strong> 即可。这就是他们的用途：决定一个属性要不要在被 link 的时候传播。</p><h3 id="根项目和子项目的CMakeLists-txt配置"><a href="#根项目和子项目的CMakeLists-txt配置" class="headerlink" title="根项目和子项目的CMakeLists.txt配置"></a>根项目和子项目的CMakeLists.txt配置</h3><p>根项目的 CMakeLists.txt 负责处理全局有效的设定。而子项目的 CMakeLists.txt 则仅考虑该子项目自身的设定，比如他的头文件目录，要链接的库等等。</p><p><strong>根项目的CMakeLists.txt配置</strong></p><p>在根项目的 CMakeLists.txt 中，设置了默认的构建模式，设置了统一的 C++ 版本等各种选项。然后通过 project 命令初始化了根项目。(<strong>这些设置应该放在project命令之前</strong>)</p><p>随后通过 add_subdirectory 把两个子项目 pybmain 和 biology 添加进来（顺序无关紧要），这会调用 pybmain&#x2F;CMakeLists.txt 和 biology&#x2F;CMakeLists.txt。</p><pre><code class="cmake">cmake_minimum_required(VERSION 3.18)if (NOT CMAKE_BUILD_TYPE)    set(CMAKE_BUILD_TYPE Release)endif()set(CMAKE_CXX_STANDARD 20)set(CMAKE_CXX_STANDARD_REQUIRED ON)set(CMAKE_CXX_EXTENSIONS OFF)set(CMAKE_MODULE_PATH &quot;$&#123;CMAKE_CURRENT_LIST_DIR&#125;/cmake;$&#123;CMAKE_MODULE_PATH&#125;&quot;)project(CppCMakeDemo LANGUAGES CXX)include(MyUsefulFuncs)add_subdirectory(pybmain)add_subdirectory(biology)</code></pre><p><strong>子项目的CMakeLists.txt配置</strong></p><p>子项目的 CMakeLists.txt 就干净许多，只是创建了 biology 这个静态库对象，并通过 GLOB_RECRUSE 为他批量添加了所有位于 src 和 include 下源码和头文件。</p><pre><code class="cmake">file(GLOB_RECURSE srcs CONFIGURE_DEPENDS src/*.cpp include/*.h)add_library(biology STATIC $&#123;srcs&#125;)#这条语句让链接 biology 的目标文件也能够共享/biology/include 这个头文件搜索路径target_include_directories(biology PUBLIC include)</code></pre><h3 id="依赖子项目"><a href="#依赖子项目" class="headerlink" title="依赖子项目"></a>依赖子项目</h3><p>依赖另一个子项目，则需要链接他</p><pre><code class="cmake">file(GLOB_RECURSE srcs CONFIGURE_DEPENDS src/*.cpp include/*.h)add_executable(pybmain $&#123;srcs&#125;)target_include_directories(pybmain PUBLIC include)target_link_libraries(pybmain PUBLIC biology)</code></pre><p>由于 PUBLIC 属性具有传染性，根&#x2F;biology&#x2F;include 现在也加入 pybmain 的头文件搜索路径了，因此 pybmain 里可以 #include 到 biology 的头文件。</p><p>同理如果又有一个 target_link_libraries(zxxpig PUBLIC pybmain) 那么 zxxpig 也有 pybmain 和 biology 的所有头文件搜索路径了。</p><h2 id="链接库"><a href="#链接库" class="headerlink" title="链接库"></a>链接库</h2><h3 id="生成和链接静态库"><a href="#生成和链接静态库" class="headerlink" title="生成和链接静态库"></a><strong>生成和链接静态库</strong></h3><pre><code class="cmake">add_library(mylib STATIC mylib.cpp) # mylib.cpp编译为静态库libmylib.aadd_executable(main main.cpp)target_link_libraries(main PUBLIC mylib) # 链接mylib</code></pre><h3 id="生成和链接动态库"><a href="#生成和链接动态库" class="headerlink" title="生成和链接动态库"></a><strong>生成和链接动态库</strong></h3><pre><code class="cmake">add_library(mylib SHARED mylib.cpp) # mylib.cpp编译成动态库 libmylib.so文件add_executable(main main.cpp)target_link_libraries(main PUBLIC mylib)</code></pre><p>windows对动态库很不友好，如果一定要使用的话，需要在实现处加上__declspec(dllexport)用于导出符号，也就是定义该函数的dll；在声明处加上__declspec(dllimport)用于导入，也就是使用该函数。</p><pre><code class="c++">//mylib.cpp#ifdef _MSC_VER__declspec(dllexport)#endifvoid say_hello() &#123;    printf(&quot;hello world&quot;);&#125;//mylib.h#pragma once#ifdef _MSC_VER__declspec(dllimport)#endifvoid say_hello();</code></pre><h3 id="生成和链接对象库"><a href="#生成和链接对象库" class="headerlink" title="生成和链接对象库"></a><strong>生成和链接对象库</strong></h3><p>大型项目经常将源文件分为组，可能在单独的子目录中，分别需要不同的包含目录和预处理器定义。为此CMake 开发了对象库的概念。</p><p>对象库类似于静态库，但不生成 .a 文件，只由 CMake 记住该库生成了哪些对象文件, <strong>对象库是 CMake 自创的，绕开了编译器和操作系统的各种繁琐规则，保证了跨平台统一性。</strong>在自己的项目中，<strong>推荐全部用对象库(OBJECT)替代静态库(STATIC)避免跨平台的麻烦。</strong>对象库仅仅作为组织代码的方式，而实际生成的可执行文件只有一个，减轻了部署的困难。</p><pre><code class="cmake">add_library(mylib OBJECT mylib.cpp)add_executable(main main.cpp)target_link_libraries(main PUBLIC mylib)</code></pre><h3 id="静态库的麻烦"><a href="#静态库的麻烦" class="headerlink" title="静态库的麻烦"></a><strong>静态库的麻烦</strong></h3><p><strong>GCC</strong> 编译器自作聪明，会自动剔除没有引用符号的那些对象。也就是说如果没有用到引用的库，那么这个库可能不会进行链接，在库中定义的全局变量也会失效，如果我们想用静态库在执行main函数之前做一些全局初始化的操作，那么很可能会失败。</p><p>使用对象库或动态库可以避免这个问题。也可以设置对象属性告诉编译器不要自动剔除没有引用符号的链接库。</p><pre><code class="c++">//mylib.cppstatic int unused = printf(&quot;mylib initialized&quot;); //未执行//main.cppint main()&#123;    printf(&quot;main function&quot;);&#125;</code></pre><h3 id="add-library无参数时，是静态库还是动态库"><a href="#add-library无参数时，是静态库还是动态库" class="headerlink" title="add_library无参数时，是静态库还是动态库"></a><strong>add_library无参数时，是静态库还是动态库</strong></h3><p>会根据 <strong>BUILD_SHARED_LIBS 这个变量的值决定是动态库还是静态库</strong>。ON 则相当于 SHARED，OFF 则相当于 STATIC。</p><p>如果未指定 BUILD_SHARED_LIBS 变量，则<strong>默认为 STATIC。</strong>因此，如果发现一个项目里的 add_library 都是无参数的，意味着你可以用：cmake -B build -DBUILD_SHARED_LIBS:BOOL&#x3D;ON 来让他全部生成为动态库。</p><p>要让 BUILD_SHARED_LIBS 默认为 ON，可以用下图这个方法：如果该变量没有定义，则设为 ON，否则保持用户指定的值不变。这样当用户没有指定 BUILD_SHARED_LIBS 这个变量时，会默认变成 ON。也就是说除非用户指定了 -DBUILD_SHARED_LIBS:BOOL&#x3D;OFF 才会生成静态库，否则默认是生成动态库。</p><pre><code class="cmake">if (NOT DEFINED BUILD_SHARED_LIBS)    set(BUILD_SHARED_LIBS ON)endif()add_library(mylib mylib.cpp)add_executable(main main.cpp)target_link_libraries(main PUBLIC mylib)</code></pre><h3 id="动态库无法链接静态库解决方法"><a href="#动态库无法链接静态库解决方法" class="headerlink" title="动态库无法链接静态库解决方法"></a><strong>动态库无法链接静态库解决方法</strong></h3><p>我们一般使用动态库链接动态库时，可以这样处理:</p><pre><code class="cmake">add_library(otherlib STATIC otherlib.cpp)add_library(mylib SHARED mylib.cpp)target_link_libraries(mylib PUBLIC otherlib)add_executable(main main.cpp)target_link_libraries(main PUBLIC mylib)</code></pre><p>但是会报错，解决: <strong>让静态库编译时也生成位置无关的代码(PIC)，这样才能装在动态库里</strong></p><pre><code class="cmake">add_library(otherlib STATIC otherlib.cpp)set_property(TARGET otherlib PROPERTY POSITION_INDEPENDENT_CODE ON) # 只针对otherlib库add_library(mylib SHARED mylib.cpp)target_link_libraries(mylib PUBLIC otherlib)add_executable(main main.cpp)target_link_libraries(main PUBLIC mylib)</code></pre><p>或者全局设置</p><pre><code class="cmake">set(CMAKE_POSITION_INDEPENDENT_CODE ON)add_library(otherlib STATIC otherlib.cpp)add_library(mylib SHARED mylib.cpp)target_link_libraries(mylib PUBLIC otherlib)add_executable(main main.cpp)target_link_libraries(main PUBLIC mylib)</code></pre><h3 id="找不到dll解决办法"><a href="#找不到dll解决办法" class="headerlink" title="找不到dll解决办法"></a>找不到dll解决办法</h3><p>这是因为你的 dll 和 exe 不在同一目录。Windows 比较蠢，他只会找当前 exe 所在目录，然后查找 PATH，找不到就报错。而你的 dll 在其他目录，因此 Windows 会找不到 dll。</p><ul><li><p>解决1：把 dll 所在位置加到你的 PATH 环境变量里去，一劳永逸。</p></li><li><p>解决2：把这个 dll，以及这个 dll 所依赖的其他 dll，全部拷贝到和 exe 文件同一目录下。</p></li><li><p>解决3：设置CMake让 CMake 把 dll 自动生成在 exe 同一目录</p><p>归根到底还是因为 CMake 把定义在顶层模块里的 main 放在 build&#x2F;main.exe。而 mylib 因为是定义在 mylib 这个子模块里的，因此被放到了 build&#x2F;mylib&#x2F;mylib.dll。所以，可以设置 mylib 的这些属性，让 mylib.dll 文件输出到 PROJECT_BINARY_DIR，也就是项目根目录（main 所在的位置）。这样 main.exe 在运行时就能找到 mylib.dll 了。</p><pre><code class="cmake">add_library(mylib SHARED mylib.h mylib.cpp)set_property(TARGET mylib PROPERTY LIBRARY_OUTPUT_DIRECTORY $&#123;PROJECT_BINARY_DIR&#125;)set_property(TARGET mylib PROPERTY ARCHIVE_OUTPUT_DIRECTORY $&#123;PROJECT_BINARY_DIR&#125;)set_property(TARGET mylib PROPERTY RUNTIME_OUTPUT_DIRECTORY $&#123;PROJECT_BINARY_DIR&#125;)set_property(TARGET mylib PROPERTY LIBRARY_OUTPUT_DIRECTORY_DEBUG $&#123;PROJECT_BINARY_DIR&#125;)set_property(TARGET mylib PROPERTY ARCHIVE_OUTPUT_DIRECTORY_DEBUG $&#123;PROJECT_BINARY_DIR&#125;)set_property(TARGET mylib PROPERTY RUNTIME_OUTPUT_DIRECTORY_DEBUG $&#123;PROJECT_BINARY_DIR&#125;)set_property(TARGET mylib PROPERTY LIBRARY_OUTPUT_DIRECTORY_RELEASE $&#123;PROJECT_BINARY_DIR&#125;)set_property(TARGET mylib PROPERTY ARCHIVE_OUTPUT_DIRECTORY_RELEASE $&#123;PROJECT_BINARY_DIR&#125;)set_property(TARGET mylib PROPERTY RUNTIME_OUTPUT_DIRECTORY_RELEASE $&#123;PROJECT_BINARY_DIR&#125;)</code></pre></li></ul><p>所以在windows下使用动态链接库要设置6个属性，非常麻烦。而 Linux 系统支持 RPATH，CMake 会让生成出来可执行文件的 RPATH 字段指向他链接了的 .so 文件所在目录，运行时会优先从 RPATH 里找链接库，所以即使不在同目录也能找到。</p><p>需要手动修改或查看一个 ELF 文件的 RPATH，可以用 chrpath 或 patchelf 命令。</p><h2 id="对象的属性"><a href="#对象的属性" class="headerlink" title="对象的属性"></a>对象的属性</h2><p>许多 CMake 中的对象比如目标，目录和源文件都拥有属性。属性是一个特定对象所拥有的的键值对。访问属性最通用的方法是通过 <code>set_property</code>和 <code>get_property</code>命令。这些命令可以让你设置和获取一个 CMake 对象的属性。你可以查看 <code>cmake-properties</code>手册，其中列出了所有支持的属性。</p><h3 id="目标的一些选项"><a href="#目标的一些选项" class="headerlink" title="目标的一些选项"></a>目标的一些选项</h3><pre><code class="cmake">#除了头文件搜索目录以外，还有这些选项，PUBLIC 和 PRIVATE 对他们同理：target_include_directories(myapp PUBLIC /usr/include/eigen3)  # 添加头文件搜索目录target_link_libraries(myapp PUBLIC hellolib)                               # 添加要链接的库target_add_definitions(myapp PUBLIC MY_MACRO=1)             # 添加一个宏定义target_add_definitions(myapp PUBLIC -DMY_MACRO=1)         # 与 MY_MACRO=1 等价target_compile_options(myapp PUBLIC -fopenmp)                     # 添加编译器命令行选项target_sources(myapp PUBLIC hello.cpp other.cpp)                    # 添加要编译的源文件#以及可以通过下列指令（不推荐使用），把选项加到所有接下来的目标去：include_directories(/opt/cuda/include)     # 添加头文件搜索目录link_directories(/opt/cuda)                       # 添加库文件的搜索路径add_definitions(MY_MACRO=1)             # 添加一个宏定义add_compile_options(-fopenmp)             # 添加编译器命令行选项</code></pre><h3 id="使用set-property设置属性"><a href="#使用set-property设置属性" class="headerlink" title="使用set_property设置属性"></a>使用set_property设置属性</h3><pre><code class="cmake">#采用 C++17 标准进行编译（默认 11）set_property(TARGET main PROPERTY CXX_STANDARD 17)#如果编译器不支持 C++17，则直接报错（默认 OFF）set_property(TARGET main PROPERTY CXX_STANDARD_REQUIRED ON)#在 Windows 系统中，运行时不启动控制台窗口，只有 GUI 界面（默认 OFF）set_property(TARGET main PROPERTY WIN32_EXECUTABLE ON)#告诉编译器不要自动剔除没有引用符号的链接库（默认 OFF）set_property(TARGET main PROPERTY LINK_WHAT_YOU_USE ON)#设置动态链接库的输出路径（默认 $&#123;CMAKE_BINARY_DIR&#125;）set_property(TARGET main PROPERTY LIBRARY_OUTPUT_DIRECTORY $&#123;CMAKE_SOURCE_DIR&#125;/lib)#设置静态链接库的输出路径（默认 $&#123;CMAKE_BINARY_DIR&#125;）set_property(TARGET main PROPERTY ARCHIVE_OUTPUT_DIRECTORY $&#123;CMAKE_SOURCE_DIR&#125;/lib)#设置可执行文件的输出路径（默认 $&#123;CMAKE_BINARY_DIR&#125;）set_property(TARGET main PROPERTY RUNTIME_OUTPUT_DIRECTORY $&#123;CMAKE_SOURCE_DIR&#125;/bin)</code></pre><h3 id="批量设置多个属性"><a href="#批量设置多个属性" class="headerlink" title="批量设置多个属性"></a>批量设置多个属性</h3><p>使用<code>set_target_properties</code>批量设置多个属性</p><pre><code class="cmake">set_target_properties(main PROPERTIES    CXX_STANDARD 17           # 采用 C++17 标准进行编译（默认 11）    CXX_STANDARD_REQUIRED ON  # 如果编译器不支持 C++17，则直接报错（默认 OFF）    WIN32_EXECUTABLE ON       # 在 Windows 系统中，运行时不启动控制台窗口，只有 GUI 界面（默认 OFF）    LINK_WHAT_YOU_USE ON      # 告诉编译器不要自动剔除没有引用符号的链接库（默认 OFF）    LIBRARY_OUTPUT_DIRECTORY $&#123;CMAKE_SOURCE_DIR&#125;/lib   # 设置动态链接库的输出路径（默认 $&#123;CMAKE_BINARY_DIR&#125;）    ARCHIVE_OUTPUT_DIRECTORY $&#123;CMAKE_SOURCE_DIR&#125;/lib   # 设置静态链接库的输出路径（默认 $&#123;CMAKE_BINARY_DIR&#125;）    RUNTIME_OUTPUT_DIRECTORY $&#123;CMAKE_SOURCE_DIR&#125;/bin   # 设置可执行文件的输出路径（默认 $&#123;CMAKE_BINARY_DIR&#125;）    )</code></pre><h3 id="设置变量和设置属性的区别"><a href="#设置变量和设置属性的区别" class="headerlink" title="设置变量和设置属性的区别"></a>设置变量和设置属性的区别</h3><p>通过set设置的变量全局有效，会让之后创建的所有对象都享有同样的属性；而set_property只对单个对象有效。</p><pre><code class="cmake">#相当于改变了各个属性的初始默认值。要注意此时 set(CMAKE_xxx) 必须在 add_executable 之前才有效。set(CMAKE_CXX_STANDARD 17)set(CMAKE_CXX_STANDARD_REQUIRED ON)set(CMAKE_WIN32_EXECUTABLE ON)set(CMAKE_LINK_WHAT_YOU_USE ON)set(CMAKE_LIBRARY_OUTPUT_DIRECTORY $&#123;CMAKE_SOURCE_DIR&#125;/lib)set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY $&#123;CMAKE_SOURCE_DIR&#125;/lib)set(CMAKE_RUNTIME_OUTPUT_DIRECTORY $&#123;CMAKE_SOURCE_DIR&#125;/bin)add_executable(main main.cpp)</code></pre><p>注意使用set时记得加引号，否则用空格隔开的会变成分号分割的列表，这可能会造成严重的后果(如在message中列表中的字符串可能视为message的关键字)</p><pre><code class="cmake">set(myvar hello world)#其实等价于：set(myvar “hello;world”)#正确的写法set(myvar &quot;hello world&quot;)</code></pre><h2 id="链接第三方库"><a href="#链接第三方库" class="headerlink" title="链接第三方库"></a>链接第三方库</h2><p>以使用tbb库为例</p><h3 id="直接链接"><a href="#直接链接" class="headerlink" title="直接链接"></a>直接链接</h3><pre><code class="cmake">add_executable(main main.cpp)target_link_libraries(main PUBLIC tbb)</code></pre><p>如果这样直接指定 tbb，CMake 会让链接器在<strong>系统的库目录</strong>里查找 tbb，他会找到 &#x2F;usr&#x2F;lib&#x2F;libtbb.so 这个系统自带的，但这<strong>对于没有一个固定库安装位置的 Windows 系统并不适用</strong>。</p><p>此外，他还要求 tbb 的头文件就在 &#x2F;usr&#x2F;include 这个系统默认的头文件目录，这样才能 #include &lt;tbb&#x2F;parallel_for.h&gt; 不出错，<strong>如果 tbb 的头文件在其他地方就需要再加一个 target_include_directories</strong> 设置额外的头文件查找目录。</p><h3 id="写出完整路径"><a href="#写出完整路径" class="headerlink" title="写出完整路径"></a>写出完整路径</h3><pre><code class="cmake">add_executable(main main.cpp)target_link_libraries(main PUBLIC c:/Users/archibate/installed/tbb/tbb.dll)</code></pre><p>也可以直接写出全部路径，这样也可以让没有默认系统路径的 Windows 找到安装在奇怪位置的 tbb……不过这样根本不跨平台，你这样改了别人如果装在不同地方就出错了。(<strong>不推荐</strong>)</p><p>顺便一提，**CMake 的路径分割符始终是 &#x2F;。即使在 Windows 上，也要把所有的 \ 改成 &#x2F;**，这是出于跨平台的考虑。请放心，CMake 会自动在调用 MSVC 的时候转换成 \，你可以放心的用 ${x}&#x2F;bin 来实现和 Python 的 os.path.join(x, ‘bin’) 一样的效果。</p><h3 id="使用find-package"><a href="#使用find-package" class="headerlink" title="使用find_package"></a><strong>使用find_package</strong></h3><p>更好的做法是用 CMake 的 find_package 命令。</p><p>find_package(TBB REQUIRED) 会查找 &#x2F;usr&#x2F;lib&#x2F;cmake&#x2F;TBB&#x2F;TBBConfig.cmake 这个配置文件，并根据里面的配置信息创建 TBB::tbb 这个伪对象（他实际指向真正的 tbb 库文件路径 &#x2F;usr&#x2F;lib&#x2F;libtbb.so），之后通过 target_link_libraries 链接 TBB::tbb 就可以正常工作了。</p><pre><code class="cmake">add_executable(main main.cpp)find_package(TBB REQUIRED)target_link_libraries(main PUBLIC TBB::tbb)</code></pre><p>TBB::tbb 是一个伪对象(imported)，除了他会指向 &#x2F;usr&#x2F;lib&#x2F;libtbb.so 之外，TBBConfig.cmake 还会给 TBB::tbb 添加一些 PUBLIC 属性，用于让链接了他的对象带上一些 flag 之类的。</p><p>比如，TBB 安装在 &#x2F;opt&#x2F;tbb 目录下，头文件在 &#x2F;opt&#x2F;tbb&#x2F;include 里，那么这时 TBBConfig.cmake 里就会有：</p><pre><code class="cmake">target_include_directories(TBB::tbb PUBLIC /opt/tbb/include)</code></pre><p>这样 main 在链接了 TBB::tbb 的时候也会被“传染”上 &#x2F;opt&#x2F;tbb&#x2F;include 这个目录，不用调用者手动添加了。再比如，TBB::tbb 链接了另一个库 Blosc::blosc，那这个库也会自动链接到 main 上，无需调用者手动添加。</p><p>比如 spdlog 的 spdlog-config.cmake 就会定义 SPDLOG_NOT_HEADER_ONLY 这个宏为 PUBLIC。从而实现直接 #include &lt;spdlog&#x2F;spdlog.h&gt; 时候是纯头文件，而 find_package(spdlog REQUIRED) 时却变成预编译链接库的版本。（其实不是 PUBLIC 而是 INTERFACE，因为伪对象没有实体）</p><p><strong>TBBConfig.cmake 这个配置文件的由来</strong></p><p>不论是 TBBConfig.cmake 还是 FindTBB.cmake，这个文件通常由库的作者提供，在 Linux 的包管理器安装 tbb 后也会自动安装这个文件。<strong>少部分对 CMake 不友好的第三方库，需要自己写FindXXX.cmake 才能使用。</strong></p><p>一些老年项目作者喜欢在项目里自己塞几个 FindXXX.cmake，然而版本可能和系统里的不一样，比如用 3.0 的 finder 去找 2.0 的包，容易出现一些奇奇怪怪的错误。<strong>不建议大家这样用自己创建一个 cmake&#x2F; 目录来存用到的所有库的 finder</strong>，尽量用系统自带的，可以保证用的是系统自带库的那个配置。</p><p><strong>和find_package(TBB CONFIG REQUIRED)的区别</strong> </p><p>通过 find_package(TBB CONFIG REQUIRED)，添加了一个 CONFIG 选项。这样他会优先查找 TBBConfig.cmake（系统自带的）而不是 FindTBB.cmake（项目作者常把他塞在 cmake&#x2F; 目录里并添加到 CMAKE_MODULE_PATH）。这样能保证寻找包的这个 .cmake 脚本是和系统自带的 tbb 版本是适配的，而不是项目作者当年下载的那个版本的 .cmake 脚本。</p><p>当然，如果你坚持要用 find_package(TBB REQUIRED) 也是可以的。</p><p>没有 CONFIG 选项：先找 FindTBB.cmake，再找 TBBConfig.cmake，找不到则报错</p><p><strong>有 CONFIG 选项：只会找 TBBConfig.cmake，找不到则报错</strong></p><p>此外，一些老年项目（例如 OpenVDB）只提供 Find 而没有 Config 文件，这时候就必须用 find_package(OpenVDB REQUIRED) 而不能带 CONFIG 选项。</p><p><strong>find_package()不加REQUIRED</strong></p><pre><code class="cmake">add_executable(main main.cpp)find_package(TBB)#TBB_FOUND也可以换成TARGET TBB:tbb。还可以复合操作例如NOT TARGET TBB::tbb AND TARGET Eigen3::eigen表示找得到 TBB 但是找不到 Eigen3 的情况if (TBB_FOUND)    message(STATUS &quot;TBB found at: $&#123;TBB_DIR&#125;&quot;)    target_link_libraries(main PUBLIC TBB::tbb)    target_compile_definitions(main PUBLIC WITH_TBB) #在可执行程序中定义 WITH_TBB 宏else()    message(WARNING &quot;TBB not found! using serial for&quot;)endif()</code></pre><p>如果没有 REQUIRED 选项，找不到时将不会报错。只会设置 xx_FOUND 变量为flase，这样可以根据这个变量的值进行一些处理。如上</p><p>找到了会把 TBB_FOUND 设为 TRUE，TBB_DIR 设为 TBBConfig.cmake 所在路径。</p><p>找不到会把 TBB_FOUND 设为 FALSE，TBB_DIR 为空。</p><p>这里我们在找到 TBB 时定义 WITH_TBB 宏，稍后 .cpp 里就可以根据有没有宏进行判断，在有宏和没宏时分别进行不同的处理。</p><pre><code class="c++">#ifdef WITH_TBB//进行找到TBB库时的操作#endif#ifndef WITH_TBB//进行没找到库时的操作#endif</code></pre><h3 id="指定find-package的组件"><a href="#指定find-package的组件" class="headerlink" title="指定find_package的组件"></a>指定find_package的组件</h3><p>有多个组件的库直接find_package会出错(如Qt5)，此时需要指定用到的组件。</p><p>find_package 生成的伪对象(imported target)都按照“包名::组件名”的格式命名。你可以在 find_package 中通过 COMPONENTS 选项，后面跟随一个列表表示需要用的组件。</p><pre><code class="cmake">cmake_minimum_required(VERSION 2.10)project(hellocmake CXX)add_executable(main main.cpp)find_package(TBB COMPONENTS tbb tbbmalloc tbbmalloc_proxy REQUIRED)target_link_libraries(main PUBLIC TBB::tbb TBB::tbbmalloc TBB::tbbmalloc_proxy)</code></pre><h3 id="在windows上找包"><a href="#在windows上找包" class="headerlink" title="在windows上找包"></a>在windows上找包</h3><p>Windows没有固定的安装路径，假设你的 Qt5 安装在 C:\Qt\Qt5.14.2，则你去找找这个目录：C:\Qt\Qt5.14.2\msvc2019_64\lib\cmake\</p><p>你会看到里面有个 Qt5Config.cmake 。现在，有四种方法让 CMake 找得到他。</p><p>1.第一种是设置 CMAKE_MODULE_PATH 变量，添加一下包含 Qt5Config.cmake 这个文件的目录路径 </p><pre><code class="cmake">add_executable(main main.cpp)find_package(TBB REQUIRED)target_link_libraries(main PUBLIC TBB::tbb)set(CMAKE_MODULE_PATH $&#123;CMAKE_MODULE_PATH&#125; C:/Qt/Qt5.14.2/msvc2019_64/lib/cmake)find_package(Qt5 REQUIRED COMPONENTS Widgets Gui REQUIRED)target_link_libraries(main PUBLIC Qt5::Widgets Qt5::Gui)</code></pre><p>2.第二种是设置 Qt5_DIR 这个变量为 C:\Qt\Qt5.14.2\msvc2019_64\lib\cmake。这样只有 Qt5 这个包会去这个目录里搜索 Qt5Config.cmake，更有针对性。</p><pre><code class="cmake">add_executable(main main.cpp)set(Qt5_DIR C:/Qt/Qt5.14.2/msvc2019_64/lib/cmake)find_package(Qt5 REQUIRED COMPONENTS Widgets Gui REQUIRED)target_link_libraries(main PUBLIC Qt5::Widgets Qt5::Gui)</code></pre><p>3.**第三种(推荐)**，直接在命令行通过 -DQt5_DIR&#x3D;”xxx” 指定，这样不用修改 CMakeLists.txt。</p><pre><code class="shell">cmake -B build -DQt5_DIR=&quot;C:/Qt/Qt5.14.2/msvc2019_64/lib/cmake&quot; </code></pre><p>4.第四种，通过设置环境变量 Qt5_DIR 也是可以的，但是对 Windows 用户设置环境变量比较麻烦。</p><pre><code class="shell">export Qt5_DIR=&quot;C:/Qt/Qt5.14.2/msvc2019_64/lib/cmake&quot; cmake -B build</code></pre><h2 id="输出和变量"><a href="#输出和变量" class="headerlink" title="输出和变量"></a>输出和变量</h2><p>使用message在运行 <strong>cmake -B build</strong> 时打印字符串（用于调试）</p><pre><code class="cmake">message(&quot;Hello, world!&quot;)#输出如下Hello, world!</code></pre><p>message(STATUS “…”) 表示信息类型是状态信息，打印出来有 <strong>–</strong> 前缀</p><p>message(WARNING “…”) 表示是警告信息</p><p>message(AUTHOR_WARNING “…”)表示是仅仅给项目作者看的警告信息</p><pre><code class="cmake">message(STATUS &quot;Hello, world!&quot;)message(WARNING &quot;This is a warning sign!&quot;)message(AUTHOR_WARNING &quot;This is a warning sign for author!&quot;)#输出如下--Hello, world!#waring的颜色不同,不是普通的白色CMake Warning at CMakeList.txt:2 (message):This is a warning sign!#AUTHOR_WARNING 的不同之处：可以通过 -Wno-dev 关闭，在命令行加上即可cmake -B build -Wno-devCMake Warning at CMakeList.txt:3 (message):This is a warning sign for author!</code></pre><p>message(FATAL_ERROR “…”) 表示是错误信息，会终止 CMake 的运行</p><p>message(SEND_ERROR “…”) 表示是错误信息，但会继续运行</p><pre><code class="cmake">message(STATUS &quot;Hello, world!&quot;)message(FATAL_ERROR &quot;This is an error message!&quot;)message(STATUS &quot;After error...&quot;)#输出--Hello, world!CMake Error at CMakeList.txt:2 (message):This is an error message!#注意后续After error...不会再打印，因为终止运行了，若是SEND_ERROR则会继续运行</code></pre><p>message还可以打印变量的值</p><pre><code class="cmake">set(myvar hello world)message(&quot;myvar is: $&#123;myvar&#125;&quot;)</code></pre><h2 id="变量和缓存"><a href="#变量和缓存" class="headerlink" title="变量和缓存"></a>变量和缓存</h2><p>重复执行 <strong>cmake -B build</strong> 会发现第二次执行要快很多。</p><p>这是因为 CMake 第一遍需要检测编译器和 C++ 特性等比较耗时，检测完会把结果存储到缓存中，这样第二遍运行cmake -B build 时就可以直接用缓存的值，就不需要再检测一遍了。</p><p>find_package 就用到了缓存机制。变量缓存的意义在于能够把 find_package 找到的库文件位置等信息，储存起来。这样下次执行 find_package 时，就会利用上次缓存的变量，直接返回。避免重复执行 cmake -B 时速度变慢的问题。</p><p>然而有时候外部的情况有所更新(如变量改动)，这时候 CMake 里缓存的却是旧的值，会导致一系列问题。缓存是很多 CMake 出错的根源，因此如果出现诡异的错误，可以试试清除缓存。</p><h3 id="清除缓存的方法"><a href="#清除缓存的方法" class="headerlink" title="清除缓存的方法"></a>清除缓存的方法</h3><p>1.最简单的办法就是删除 build 文件夹，然后重新运行 cmake -B build。经典 CMake 笑话：”99%的cmake错误可以用删build解决”。</p><p>2.删除 build&#x2F;CMakeCache.txt 。删 build 虽然彻底，也会导致编译的中间结果（.o文件）都没了，重新编译要花费很长时间。如果只想清除缓存，不想从头重新编译，可以只删除 build&#x2F;CMakeCache.txt 这个文件。这文件里面装的就是缓存的变量，删了他就可以让 CMake 强制重新检测一遍所有库和编译器。</p><h3 id="设置缓存变量"><a href="#设置缓存变量" class="headerlink" title="设置缓存变量"></a>设置缓存变量</h3><p>set(变量名 “变量值” CACHE 变量类型 “注释”)可以设置缓存变量。这样变量的值就会在build&#x2F;CMakeCache.txt中缓存。</p><p>缓存变量有以下类型：</p><ul><li>STRING 字符串，例如 “hello, world”</li><li>FILEPATH 文件路径，例如 “C:&#x2F;vcpkg&#x2F;scripts&#x2F;buildsystems&#x2F;vcpkg.cmake”</li><li>PATH 目录路径，例如 “C:&#x2F;Qt&#x2F;Qt5.14.2&#x2F;msvc2019_64&#x2F;lib&#x2F;cmake&#x2F;”</li><li>BOOL 布尔值，只有两个取值：ON 或 OFF。</li></ul><pre><code class="cmake">cmake_minimum_required(VERSION 3.15)project(hellocmake LANGUAGES CXX)add_executable(main main.cpp)set(myvar &quot;hello&quot; CACHE STRING &quot;this is the docstring.&quot;)message(&quot;myvar is: $&#123;myvar&#125;&quot;)</code></pre><p>缓存bool变量的例子，设置WITH_TBB变量控制是否链接这个库。CMake 对 BOOL 类型缓存的 set 指令提供了一个简写：option</p><p>option(变量名 “描述” 变量值) 等价于：set(变量名 CACHE BOOL 变量值 “描述”)</p><pre><code class="cmake">cmake_minimum_required(VERSION 3.15)project(hellocmake LANGUAGES CXX)add_executable(main main.cpp)#等价于option(WITH_TBB &quot;set to ON to enable TBB, OFF to disable TBB.&quot; ON)set(WITH_TBB ON CACHE BOOL &quot;set to ON to enable TBB, OFF to disable TBB.&quot;)if (WITH_TBB)    target_compile_definitions(main PUBLIC WITH_TBB)    find_package(TBB REQUIRED)    target_link_libraries(main PUBLIC TBB::tbb)endif()</code></pre><h3 id="更新缓存变量"><a href="#更新缓存变量" class="headerlink" title="更新缓存变量"></a>更新缓存变量</h3><p>1.直接在CMakeList.txt中更新，然后使用上述清除缓存的方法删除缓存。</p><p>2.通过命令行参数，在cmake -B时指定变量的值，如更改myvar变量的值：cmake -B build -Dmyvar&#x3D;world</p><p>3.命令行参数太麻烦，直接可视化编辑变量的值(推荐)</p><p>在 Linux 中，可以运行 ccmake -B build 来启动基于终端的可视化缓存编辑菜单。</p><p>在 Windows 则可以 cmake-gui -B build 来启动图形界面编辑各个缓存选项。</p><p>当然，直接用编辑器打开 build&#x2F;CMakeCache.txt 修改后保存也是可以的。</p><p>4.set 可以在后面加一个 FORCE 选项，表示不论缓存是否存在，都强制更新缓存。不过这样会导致没办法用 -Dmyvar&#x3D;othervalue 来更新缓存变量。set(myvar “hello” CACHE STRING “this is the docstring.” FORCE)</p><h2 id="跨平台与编译器"><a href="#跨平台与编译器" class="headerlink" title="跨平台与编译器"></a>跨平台与编译器</h2><h3 id="检测操作系统和编译器"><a href="#检测操作系统和编译器" class="headerlink" title="检测操作系统和编译器"></a>检测操作系统和编译器</h3><p><strong>检测操作系统</strong></p><p>CMAKE_SYSTEM_NAME变量指示主机操作系统，根据不同的操作系统定义不同的宏</p><pre><code class="cmake">add_executable(main)file(GLOB sources CONFIGURE_DEPENDS *.cpp *.h)target_sources(main PUBLIC $&#123;sources&#125;)if (CMAKE_SYSTEM_NAME MATCHES &quot;Windows&quot;)    target_compile_definitions(main PUBLIC MY_NAME=&quot;Bill Gates&quot;)elseif (CMAKE_SYSTEM_NAME MATCHES &quot;Linux&quot;)    target_compile_definitions(main PUBLIC MY_NAME=&quot;Linus Torvalds&quot;)elseif (CMAKE_SYSTEM_NAME MATCHES &quot;Darwin&quot;)    target_compile_definitions(main PUBLIC MY_NAME=&quot;Steve Jobs&quot;)endif()</code></pre><p>CMake还提供了一些简写变量：WIN32, APPLE, UNIX, ANDROID, IOS等</p><pre><code class="cmake">add_executable(main)file(GLOB sources CONFIGURE_DEPENDS *.cpp *.h)target_sources(main PUBLIC $&#123;sources&#125;)if (WIN32)    target_compile_definitions(main PUBLIC MY_NAME=&quot;Bill Gates&quot;)elseif (UNIX AND NOT APPLE)    target_compile_definitions(main PUBLIC MY_NAME=&quot;Linus Torvalds&quot;)elseif (APPLE)    target_compile_definitions(main PUBLIC MY_NAME=&quot;Steve Jobs&quot;)endif()</code></pre><p><strong>检测编译器</strong></p><p>CMAKE_CXX_COMPILER_ID变量指示编译器，根据不同的编译器定义不同的宏。可以设置这个变量的值来指定使用编译器(修改环境变量或设置配置变量)。</p><pre><code class="cmake">add_executable(main)file(GLOB sources CONFIGURE_DEPENDS *.cpp *.h)target_sources(main PUBLIC $&#123;sources&#125;)if (CMAKE_CXX_COMPILER_ID MATCHES &quot;GNU&quot;)    target_compile_definitions(main PUBLIC MY_NAME=&quot;gcc&quot;)elseif (CMAKE_CXX_COMPILER_ID MATCHES &quot;NVIDIA&quot;)    target_compile_definitions(main PUBLIC MY_NAME=&quot;nvcc&quot;)elseif (CMAKE_CXX_COMPILER_ID MATCHES &quot;Clang&quot;)    target_compile_definitions(main PUBLIC MY_NAME=&quot;clang&quot;)elseif (CMAKE_CXX_COMPILER_ID MATCHES &quot;MSVC&quot;)    target_compile_definitions(main PUBLIC MY_NAME=&quot;msvc&quot;)endif()</code></pre><p>CMake 还提供了一些简写变量：MSVC, CMAKE_COMPILER_IS_GNUCC</p><pre><code class="cmake">if (MSVC)    target_compile_definitions(main PUBLIC MY_NAME=&quot;MSVC&quot;)elseif (CMAKE_COMPILER_IS_GNUCC)    target_compile_definitions(main PUBLIC MY_NAME=&quot;GCC&quot;)else ()    target_compile_definitions(main PUBLIC MY_NAME=&quot;other compiler&quot;)endif()</code></pre><h3 id="使用生成器表达式简化操作"><a href="#使用生成器表达式简化操作" class="headerlink" title="使用生成器表达式简化操作"></a>使用生成器表达式简化操作</h3><p>语法：<code>$&lt;$&lt;类型:值&gt;:为真时的表达式&gt;</code></p><p>比如 <code>$&lt;$&lt;PLATFORM_ID:Windows&gt;:MY_NAME=”Bill Gates”&gt;</code></p><p>如果平台为WINDOWS，字符串会变为 MY_NAME&#x3D;”Bill Gates”</p><p>其他平台上则表现为空字符串</p><pre><code class="cmake">add_executable(main)file(GLOB sources CONFIGURE_DEPENDS *.cpp *.h)target_sources(main PUBLIC $&#123;sources&#125;)target_compile_definitions(main PUBLIC    $&lt;$&lt;PLATFORM_ID:Windows&gt;:MY_NAME=&quot;Bill Gates&quot;&gt;    $&lt;$&lt;PLATFORM_ID:Linux&gt;:MY_NAME=&quot;Linus Torvalds&quot;&gt;    $&lt;$&lt;PLATFORM_ID:Darwin&gt;:MY_NAME=&quot;Steve Jobs&quot;&gt;    )</code></pre><p>生成器表达式要匹配多个类型的值时，可以用逗号分割</p><pre><code class="cmake">add_executable(main)file(GLOB sources CONFIGURE_DEPENDS *.cpp *.h)target_sources(main PUBLIC $&#123;sources&#125;)target_compile_definitions(main PUBLIC    $&lt;$&lt;PLATFORM_ID:Windows&gt;:MY_NAME=&quot;DOS-like&quot;&gt;    $&lt;$&lt;PLATFORM_ID:Linux,Darwin,FreeBSD&gt;:MY_NAME=&quot;Unix-like&quot;&gt;    )</code></pre><h2 id="分支和判断"><a href="#分支和判断" class="headerlink" title="分支和判断"></a>分支和判断</h2><p>通常来说 BOOL 类型的变量只有 ON&#x2F;OFF 两种取值。但是由于历史原因，TRUE&#x2F;FALSE 和 YES&#x2F;NO 也可以表示 BOOL 类型。</p><p>if 的特点：**不要给if中的变量加 ${}**，CMake会自动把没加引号的字符串当作变量名求值</p><p>由于历史原因，if 的括号中有着特殊的语法，如果是一个字符串，比如 MYVAR，则他会先看是否有 ${MYVAR} 这个变量。如果有这个变量则会被替换为变量的值来进行接下来的比较，否则保持原来字符串不变。</p><pre><code class="cmake">cmake_minimum_required(VERSION 3.15)set(CMAKE_CXX_STANDARD 17)set(CMAKE_CXX_STANDARD_REQUIRED ON)set(CMAKE_CXX_EXTENSIONS ON)project(hellocmake LANGUAGES C CXX)set(MYVAR OFF)if (MYVAR)    message(&quot;MYVAR is true&quot;)else()    message(&quot;MYVAR is false&quot;)endif()add_executable(main main.cpp)</code></pre><p>如果加了${} ，if (${MYVAR} MATCHES “Hello”) 会被翻译成 if (Hello MATCHES “Hello”)，但是因为找不到名为 Hello 的变量，所以会被直接当成普通的字符串来处理。也就是 if (“Hello” MATCHES “Hello”) 从而会执行真分支，结果正常。</p><p>但是如果定义了Hello的变量，那么就会出错，所以不要给变量加${}。</p><pre><code class="cmake">set(Hello &quot;world&quot;)set(MYVAR Hello)if ($&#123;MYVAR&#125; MATCHES &quot;Hello&quot;)    message(&quot;MYVAR is Hello&quot;) #$&#123;MYVAR&#125;会被替换成world，所以不会执行这条语句else()    message(&quot;MYVAR is not Hello&quot;) #执行endif()</code></pre><p>初学者如果搞不明白，可以把所有不确定的地方都套上一层引号，例如”${MYVAR}”，这样就可以避免被 if 当做变量名来求值了。</p><h2 id="变量与作用域"><a href="#变量与作用域" class="headerlink" title="变量与作用域"></a>变量与作用域</h2><h3 id="变量的作用域"><a href="#变量的作用域" class="headerlink" title="变量的作用域"></a>变量的作用域</h3><p>变量分为普通变量，缓存变量，环境变量。普通变量有着作用域，而<strong>缓存变量和环境变量是不论父子模块都共用的，没有作用域一说。</strong></p><p>普通变量的传播规则：父模块会传给子模块， 子模块不传给父模块(也就是父模块变量在子模块可见，子模块变量在父不可见)</p><p>如果子模块需要向父模块传变量，可以用 set 的 PARENT_SCOPE 选项，把一个变量传递到上一层作用域（也就是父模块）。</p><pre><code class="cmake">#子模块set(MYVAR ON PARENT_SCOPE)#父模块cmake_minimum_required(VERSION 3.15)set(MYVAR OFF)add_subdirectory(mylib) #这条语句之后，变量MYVAR被子模块修改为ONmessage(&quot;MYVAR: $&#123;MYVAR&#125;&quot;)add_executable(main main.cpp)</code></pre><p>如果父模块里没有定义 MYVAR 的话，也可以在子模块中设置缓存变量向外部传变量（不推荐）。但是这样就不光父模块可见了，父模块的父模块，到处都可见。</p><p><strong>除了父子模块之外还有哪些是带独立作用域的</strong></p><ul><li>include 的 XXX.cmake <strong>没有</strong>独立作用域</li><li>add_subdirectory 的 CMakeLists.txt <strong>有</strong>独立作用域</li><li>macro <strong>没有</strong>独立作用域</li><li>function <strong>有</strong>独立作用域（因此 PARENT_SCORE 也可以用于 function 的返回值）</li></ul><h3 id="访问变量"><a href="#访问变量" class="headerlink" title="访问变量"></a>访问变量</h3><p><strong>环境变量的访问方式：$ENV{xx}</strong></p><p>用 ${xx} 访问的是局部变量，局部变量服从刚刚所说的父子模块传播规则。而还有一种特殊的方式可以访问到系统的环境变量（environment variable）：$ENV{xx}。比如 $ENV{PATH} 就是获取 PATH 这个环境变量的值。</p><p><strong>缓存变量的访问方式：$CACHE{xx}</strong></p><p>此外，还可以用 $CACHE{xx} 来访问缓存里的 xx 变量。</p><p><strong>${xx}</strong> <strong>找不到局部变量时，会自动去找缓存变量</strong></p><p>${xx} 当找不到名为 xx 的局部变量时，就会去在缓存里查找名为 xx 的缓存变量。因此很多变量虽然在代码里没被 set，但是他被-D参数固定在缓存里了，所以依然可以找到。</p><h3 id="判断变量是否存在"><a href="#判断变量是否存在" class="headerlink" title="判断变量是否存在"></a>判断变量是否存在</h3><p><strong>if (DEFINED xx)</strong> <strong>判断某变量是否存在</strong></p><p>if (DEFINED MYVAR) 可以判断是否存在 MYVAR 这个局部变量或缓存变量。</p><p>值得注意的是：空字符串（即””）不代表变量不存在。因此即使是空字符串 DEFINED 也认为存在。</p><p><strong>if (xx)</strong> <strong>可以判断某变量是否存在且不为空字符串</strong></p><p>可以直接用 if (xx) 来判断是否为空字符串，因为空字符串等价于 FALSE。</p><p><strong>if (DEFINED ENV{xx})</strong> <strong>判断某环境变量是否存在</strong></p><p>因为 $ENV{xx} 代表环境变量，因此在 set 和 if 中也可以用 ENV{xx} 来表示环境变量。因为 set 的第一参数和 if 的参数都是不加 $ 的，所以要设置 ${x} 就变成了 set(x …)。而设置 $ENV{x} 自然就是 set(ENV{x} …) 咯。</p><p>同理还可以用 if (DEFINED CACHE{x}) 判断是否存在这个缓存变量，但是 set(CACHE{x} …) 就不行。</p><h2 id="其他建议"><a href="#其他建议" class="headerlink" title="其他建议"></a>其他建议</h2><h3 id="CCache：编译加速缓存"><a href="#CCache：编译加速缓存" class="headerlink" title="CCache：编译加速缓存"></a>CCache：编译加速缓存</h3><p>用法：把 gcc -c main.cpp -o main 换成 ccache gcc -c main.cpp -o main 即可</p><p>在 CMake 中可以这样来启用 ccache（就是给每个编译和链接命令前面加上 ccache）：</p><pre><code>cmake_minimum_required(VERSION 3.15)project(hellocmake)find_program(CCACHE_PROGRAM ccache)if (CCACHE_PROGRAM)    message(STATUS &quot;Found CCache: $&#123;CCACHE_PROGRAM&#125;&quot;)    set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE $&#123;CCACHE_PROGRAM&#125;)    set_property(GLOBAL PROPERTY RULE_LAUNCH_LINK $&#123;CCACHE_PROGRAM&#125;)endif()add_executable(main main.cpp)</code></pre><h3 id="快速启动主程序"><a href="#快速启动主程序" class="headerlink" title="快速启动主程序"></a>快速启动主程序</h3><p>创建一个 run 伪目标，其执行 main 的可执行文件。</p><p>这里用了生成器表达式 $&lt;TARGET_FILE:main&gt;，会自动让 run 依赖于 main。如果不放心有没有自动依赖上，手动加一个 add_dependencies(run main) 也是可以的。</p><p>这样就可以在命令行运行 cmake –build build –target run 来启动 main.exe 运行了。而不必根据不同的平台，手动写出 build&#x2F;main 或是 build\main.exe。</p><pre><code class="cmake">add_executable(main main.cpp)add_custom_target(run COMMAND $&lt;TARGET_FILE:main&gt;)#命令行输入下列命令启动cmake --build build --target run</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/01/21/hello-world/"/>
      <url>/2023/01/21/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
